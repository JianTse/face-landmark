I0822 15:54:09.288583 13823 caffe.cpp:204] Using GPUs 0
I0822 15:54:10.385442 13823 caffe.cpp:209] GPU 0: GeForce RTX 2070
I0822 15:54:12.419948 13823 solver.cpp:45] Initializing solver from parameters: 
test_iter: 1300
test_interval: 20000
base_lr: 0.001
display: 100
max_iter: 2000000
lr_policy: "multistep"
gamma: 0.1
momentum: 0.9
weight_decay: 0.0004
snapshot: 20000
snapshot_prefix: "./model_112/cascade_mobilenet_112"
solver_mode: GPU
device_id: 0
net: "./cascade_mobilenet_112.prototxt"
train_state {
  level: 0
  stage: ""
}
stepvalue: 20000
stepvalue: 80000
stepvalue: 160000
momentum2: 0.999
type: "Adam"
I0822 15:54:12.420186 13823 solver.cpp:102] Creating training net from net file: ./cascade_mobilenet_112.prototxt
I0822 15:54:12.421263 13823 upgrade_proto.cpp:79] Attempting to upgrade batch norm layers using deprecated params: ./cascade_mobilenet_112.prototxt
I0822 15:54:12.421286 13823 upgrade_proto.cpp:82] Successfully upgraded batch norm layers using deprecated params.
I0822 15:54:12.421883 13823 net.cpp:294] The NetState phase (0) differed from the phase (1) specified by a rule in layer data
I0822 15:54:12.422950 13823 net.cpp:51] Initializing net from parameters: 
name: "subMobileNet"
state {
  phase: TRAIN
  level: 0
  stage: ""
}
layer {
  name: "data"
  type: "HDF5Data"
  top: "data"
  top: "label"
  include {
    phase: TRAIN
  }
  hdf5_data_param {
    source: "/home/sxdz/data/landmark/beadwallet/samples/trainHDF5/112/hdf5-norm.txt"
    batch_size: 64
    shuffle: true
  }
}
layer {
  name: "conv1_new"
  type: "Convolution"
  bottom: "data"
  top: "conv1_new"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  convolution_param {
    num_output: 16
    bias_term: false
    pad: 1
    kernel_size: 3
    stride: 2
    weight_filler {
      type: "msra"
    }
  }
}
layer {
  name: "conv1/bn_new"
  type: "BatchNorm"
  bottom: "conv1_new"
  top: "conv1_new"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "conv1/scale_new"
  type: "Scale"
  bottom: "conv1_new"
  top: "conv1_new"
  scale_param {
    filler {
      value: 1
    }
    bias_term: true
    bias_filler {
      value: 0
    }
  }
}
layer {
  name: "relu1_new"
  type: "ReLU"
  bottom: "conv1_new"
  top: "conv1_new"
}
layer {
  name: "conv1_1/in/pw_new"
  type: "Convolution"
  bottom: "conv1_new"
  top: "conv1_1/in/pw_new"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  convolution_param {
    num_output: 64
    bias_term: false
    pad: 0
    kernel_size: 1
    stride: 1
    weight_filler {
      type: "msra"
    }
    engine: CAFFE
  }
}
layer {
  name: "conv1_1/in/pw/bn_new"
  type: "BatchNorm"
  bottom: "conv1_1/in/pw_new"
  top: "conv1_1/in/pw_new"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "conv1_1/in/pw/scale_new"
  type: "Scale"
  bottom: "conv1_1/in/pw_new"
  top: "conv1_1/in/pw_new"
  scale_param {
    filler {
      value: 1
    }
    bias_term: true
    bias_filler {
      value: 0
    }
  }
}
layer {
  name: "relu1_1/in/pw_new"
  type: "ReLU"
  bottom: "conv1_1/in/pw_new"
  top: "conv1_1/in/pw_new"
}
layer {
  name: "conv1_1/dw_new"
  type: "ConvolutionDepthwise"
  bottom: "conv1_1/in/pw_new"
  top: "conv1_1/dw_new"
  param {
    lr_mult: 1
    decay_mult: 0
  }
  convolution_param {
    num_output: 64
    bias_term: false
    pad: 1
    kernel_size: 3
    stride: 2
    weight_filler {
      type: "msra"
    }
    engine: CAFFE
  }
}
layer {
  name: "conv1_1/dw/bn_new"
  type: "BatchNorm"
  bottom: "conv1_1/dw_new"
  top: "conv1_1/dw_new"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "conv1_1/dw/scale_new"
  type: "Scale"
  bottom: "conv1_1/dw_new"
  top: "conv1_1/dw_new"
  scale_param {
    filler {
      value: 1
    }
    bias_term: true
    bias_filler {
      value: 0
    }
  }
}
layer {
  name: "relu1_1/dw_new"
  type: "ReLU"
  bottom: "conv1_1/dw_new"
  top: "conv1_1/dw_new"
}
layer {
  name: "conv1_1/out/pw_new"
  type: "Convolution"
  bottom: "conv1_1/dw_new"
  top: "conv1_1/out/pw_new"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  convolution_param {
    num_output: 24
    bias_term: false
    pad: 0
    kernel_size: 1
    stride: 1
    weight_filler {
      type: "msra"
    }
    engine: CAFFE
  }
}
layer {
  name: "conv1_1/out/pw/bn_new"
  type: "BatchNorm"
  bottom: "conv1_1/out/pw_new"
  top: "conv1_1/out/pw_new"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "conv1_1/out/pw/scale_new"
  type: "Scale"
  bottom: "conv1_1/out/pw_new"
  top: "conv1_1/out/pw_new"
  scale_param {
    filler {
      value: 1
    }
    bias_term: true
    bias_filler {
      value: 0
    }
  }
}
layer {
  name: "conv1_2/in/pw_new"
  type: "Convolution"
  bottom: "conv1_1/out/pw_new"
  top: "conv1_2/in/pw_new"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  convolution_param {
    num_output: 144
    bias_term: false
    pad: 0
    kernel_size: 1
    stride: 1
    weight_filler {
      type: "msra"
    }
    engine: CAFFE
  }
}
layer {
  name: "conv1_2/in/pw/bn_new"
  type: "BatchNorm"
  bottom: "conv1_2/in/pw_new"
  top: "conv1_2/in/pw_new"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "conv1_2/in/pw/scale_new"
  type: "Scale"
  bottom: "conv1_2/in/pw_new"
  top: "conv1_2/in/pw_new"
  scale_param {
    filler {
      value: 1
    }
    bias_term: true
    bias_filler {
      value: 0
    }
  }
}
layer {
  name: "relu1_2/in/pw_new"
  type: "ReLU"
  bottom: "conv1_2/in/pw_new"
  top: "conv1_2/in/pw_new"
}
layer {
  name: "conv1_2/dw_new"
  type: "ConvolutionDepthwise"
  bottom: "conv1_2/in/pw_new"
  top: "conv1_2/dw_new"
  param {
    lr_mult: 1
    decay_mult: 0
  }
  convolution_param {
    num_output: 144
    bias_term: false
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    engine: CAFFE
  }
}
layer {
  name: "conv1_2/dw/bn_new"
  type: "BatchNorm"
  bottom: "conv1_2/dw_new"
  top: "conv1_2/dw_new"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "conv1_2/dw/scale_new"
  type: "Scale"
  bottom: "conv1_2/dw_new"
  top: "conv1_2/dw_new"
  scale_param {
    filler {
      value: 1
    }
    bias_term: true
    bias_filler {
      value: 0
    }
  }
}
layer {
  name: "relu1_2/dw_new"
  type: "ReLU"
  bottom: "conv1_2/dw_new"
  top: "conv1_2/dw_new"
}
layer {
  name: "conv1_2/out/pw_new"
  type: "Convolution"
  bottom: "conv1_2/dw_new"
  top: "conv1_2/out/pw_new"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  convolution_param {
    num_output: 24
    bias_term: false
    pad: 0
    kernel_size: 1
    stride: 1
    weight_filler {
      type: "msra"
    }
    engine: CAFFE
  }
}
layer {
  name: "conv1_2/out/pw/bn_new"
  type: "BatchNorm"
  bottom: "conv1_2/out/pw_new"
  top: "conv1_2/out/pw_new"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "conv1_2/out/pw/scale_new"
  type: "Scale"
  bottom: "conv1_2/out/pw_new"
  top: "conv1_2/out/pw_new"
  scale_param {
    filler {
      value: 1
    }
    bias_term: true
    bias_filler {
      value: 0
    }
  }
}
layer {
  name: "fuse_conv1_2"
  type: "Eltwise"
  bottom: "conv1_1/out/pw_new"
  bottom: "conv1_2/out/pw_new"
  top: "fuse_conv1_2"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "conv2_1/in/pw_new"
  type: "Convolution"
  bottom: "fuse_conv1_2"
  top: "conv2_1/in/pw_new"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  convolution_param {
    num_output: 144
    bias_term: false
    pad: 0
    kernel_size: 1
    stride: 1
    weight_filler {
      type: "msra"
    }
    engine: CAFFE
  }
}
layer {
  name: "conv2_1/in/pw/bn_new"
  type: "BatchNorm"
  bottom: "conv2_1/in/pw_new"
  top: "conv2_1/in/pw_new"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "conv2_1/in/pw/scale_new"
  type: "Scale"
  bottom: "conv2_1/in/pw_new"
  top: "conv2_1/in/pw_new"
  scale_param {
    filler {
      value: 1
    }
    bias_term: true
    bias_filler {
      value: 0
    }
  }
}
layer {
  name: "relu2_1/in/pw_new"
  type: "ReLU"
  bottom: "conv2_1/in/pw_new"
  top: "conv2_1/in/pw_new"
}
layer {
  name: "conv2_1/dw_new"
  type: "ConvolutionDepthwise"
  bottom: "conv2_1/in/pw_new"
  top: "conv2_1/dw_new"
  param {
    lr_mult: 1
    decay_mult: 0
  }
  convolution_param {
    num_output: 144
    bias_term: false
    pad: 1
    kernel_size: 3
    stride: 2
    weight_filler {
      type: "msra"
    }
    engine: CAFFE
  }
}
layer {
  name: "conv2_1/dw/bn_new"
  type: "BatchNorm"
  bottom: "conv2_1/dw_new"
  top: "conv2_1/dw_new"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "conv2_1/dw/scale_new"
  type: "Scale"
  bottom: "conv2_1/dw_new"
  top: "conv2_1/dw_new"
  scale_param {
    filler {
      value: 1
    }
    bias_term: true
    bias_filler {
      value: 0
    }
  }
}
layer {
  name: "relu2_1/dw_new"
  type: "ReLU"
  bottom: "conv2_1/dw_new"
  top: "conv2_1/dw_new"
}
layer {
  name: "conv2_1/out/pw_new"
  type: "Convolution"
  bottom: "conv2_1/dw_new"
  top: "conv2_1/out/pw_new"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  convolution_param {
    num_output: 32
    bias_term: false
    pad: 0
    kernel_size: 1
    stride: 1
    weight_filler {
      type: "msra"
    }
    engine: CAFFE
  }
}
layer {
  name: "conv2_1/out/pw/bn_new"
  type: "BatchNorm"
  bottom: "conv2_1/out/pw_new"
  top: "conv2_1/out/pw_new"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "conv2_1/out/pw/scale_new"
  type: "Scale"
  bottom: "conv2_1/out/pw_new"
  top: "conv2_1/out/pw_new"
  scale_param {
    filler {
      value: 1
    }
    bias_term: true
    bias_filler {
      value: 0
    }
  }
}
layer {
  name: "conv2_2/in/pw_new"
  type: "Convolution"
  bottom: "conv2_1/out/pw_new"
  top: "conv2_2/in/pw_new"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  convolution_param {
    num_output: 192
    bias_term: false
    pad: 0
    kernel_size: 1
    stride: 1
    weight_filler {
      type: "msra"
    }
    engine: CAFFE
  }
}
layer {
  name: "conv2_2/in/pw/bn_new"
  type: "BatchNorm"
  bottom: "conv2_2/in/pw_new"
  top: "conv2_2/in/pw_new"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "conv2_2/in/pw/scale_new"
  type: "Scale"
  bottom: "conv2_2/in/pw_new"
  top: "conv2_2/in/pw_new"
  scale_param {
    filler {
      value: 1
    }
    bias_term: true
    bias_filler {
      value: 0
    }
  }
}
layer {
  name: "relu2_2/in/pw_new"
  type: "ReLU"
  bottom: "conv2_2/in/pw_new"
  top: "conv2_2/in/pw_new"
}
layer {
  name: "conv2_2/dw_new"
  type: "ConvolutionDepthwise"
  bottom: "conv2_2/in/pw_new"
  top: "conv2_2/dw_new"
  param {
    lr_mult: 1
    decay_mult: 0
  }
  convolution_param {
    num_output: 192
    bias_term: false
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    engine: CAFFE
  }
}
layer {
  name: "conv2_2/dw/bn_new"
  type: "BatchNorm"
  bottom: "conv2_2/dw_new"
  top: "conv2_2/dw_new"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "conv2_2/dw/scale_new"
  type: "Scale"
  bottom: "conv2_2/dw_new"
  top: "conv2_2/dw_new"
  scale_param {
    filler {
      value: 1
    }
    bias_term: true
    bias_filler {
      value: 0
    }
  }
}
layer {
  name: "relu2_2/dw_new"
  type: "ReLU"
  bottom: "conv2_2/dw_new"
  top: "conv2_2/dw_new"
}
layer {
  name: "conv2_2/out/pw_new"
  type: "Convolution"
  bottom: "conv2_2/dw_new"
  top: "conv2_2/out/pw_new"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  convolution_param {
    num_output: 32
    bias_term: false
    pad: 0
    kernel_size: 1
    stride: 1
    weight_filler {
      type: "msra"
    }
    engine: CAFFE
  }
}
layer {
  name: "conv2_2/out/pw/bn_new"
  type: "BatchNorm"
  bottom: "conv2_2/out/pw_new"
  top: "conv2_2/out/pw_new"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "conv2_2/out/pw/scale_new"
  type: "Scale"
  bottom: "conv2_2/out/pw_new"
  top: "conv2_2/out/pw_new"
  scale_param {
    filler {
      value: 1
    }
    bias_term: true
    bias_filler {
      value: 0
    }
  }
}
layer {
  name: "fuse_conv2_2"
  type: "Eltwise"
  bottom: "conv2_1/out/pw_new"
  bottom: "conv2_2/out/pw_new"
  top: "fuse_conv2_2"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "conv3_1/in/pw_new"
  type: "Convolution"
  bottom: "fuse_conv2_2"
  top: "conv3_1/in/pw_new"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  convolution_param {
    num_output: 192
    bias_term: false
    pad: 0
    kernel_size: 1
    stride: 1
    weight_filler {
      type: "msra"
    }
    engine: CAFFE
  }
}
layer {
  name: "conv3_1/in/pw/bn_new"
  type: "BatchNorm"
  bottom: "conv3_1/in/pw_new"
  top: "conv3_1/in/pw_new"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "conv3_1/in/pw/scale_new"
  type: "Scale"
  bottom: "conv3_1/in/pw_new"
  top: "conv3_1/in/pw_new"
  scale_param {
    filler {
      value: 1
    }
    bias_term: true
    bias_filler {
      value: 0
    }
  }
}
layer {
  name: "relu3_1/in/pw_new"
  type: "ReLU"
  bottom: "conv3_1/in/pw_new"
  top: "conv3_1/in/pw_new"
}
layer {
  name: "conv3_1/dw_new"
  type: "ConvolutionDepthwise"
  bottom: "conv3_1/in/pw_new"
  top: "conv3_1/dw_new"
  param {
    lr_mult: 1
    decay_mult: 0
  }
  convolution_param {
    num_output: 192
    bias_term: false
    pad: 1
    kernel_size: 3
    stride: 2
    weight_filler {
      type: "msra"
    }
    engine: CAFFE
  }
}
layer {
  name: "conv3_1/dw/bn_new"
  type: "BatchNorm"
  bottom: "conv3_1/dw_new"
  top: "conv3_1/dw_new"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "conv3_1/dw/scale_new"
  type: "Scale"
  bottom: "conv3_1/dw_new"
  top: "conv3_1/dw_new"
  scale_param {
    filler {
      value: 1
    }
    bias_term: true
    bias_filler {
      value: 0
    }
  }
}
layer {
  name: "relu3_1/dw_new"
  type: "ReLU"
  bottom: "conv3_1/dw_new"
  top: "conv3_1/dw_new"
}
layer {
  name: "conv3_1/out/pw_new"
  type: "Convolution"
  bottom: "conv3_1/dw_new"
  top: "conv3_1/out/pw_new"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  convolution_param {
    num_output: 64
    bias_term: false
    pad: 0
    kernel_size: 1
    stride: 1
    weight_filler {
      type: "msra"
    }
    engine: CAFFE
  }
}
layer {
  name: "conv3_1/out/pw/bn_new"
  type: "BatchNorm"
  bottom: "conv3_1/out/pw_new"
  top: "conv3_1/out/pw_new"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "conv3_1/out/pw/scale_new"
  type: "Scale"
  bottom: "conv3_1/out/pw_new"
  top: "conv3_1/out/pw_new"
  scale_param {
    filler {
      value: 1
    }
    bias_term: true
    bias_filler {
      value: 0
    }
  }
}
layer {
  name: "conv3_2/in/pw_new"
  type: "Convolution"
  bottom: "conv3_1/out/pw_new"
  top: "conv3_2/in/pw_new"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  convolution_param {
    num_output: 192
    bias_term: false
    pad: 0
    kernel_size: 1
    stride: 1
    weight_filler {
      type: "msra"
    }
    engine: CAFFE
  }
}
layer {
  name: "conv3_2/in/pw/bn_new"
  type: "BatchNorm"
  bottom: "conv3_2/in/pw_new"
  top: "conv3_2/in/pw_new"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "conv3_2/in/pw/scale_new"
  type: "Scale"
  bottom: "conv3_2/in/pw_new"
  top: "conv3_2/in/pw_new"
  scale_param {
    filler {
      value: 1
    }
    bias_term: true
    bias_filler {
      value: 0
    }
  }
}
layer {
  name: "relu3_2/in/pw_new"
  type: "ReLU"
  bottom: "conv3_2/in/pw_new"
  top: "conv3_2/in/pw_new"
}
layer {
  name: "conv3_2/dw_new"
  type: "ConvolutionDepthwise"
  bottom: "conv3_2/in/pw_new"
  top: "conv3_2/dw_new"
  param {
    lr_mult: 1
    decay_mult: 0
  }
  convolution_param {
    num_output: 192
    bias_term: false
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    engine: CAFFE
  }
}
layer {
  name: "conv3_2/dw/bn_new"
  type: "BatchNorm"
  bottom: "conv3_2/dw_new"
  top: "conv3_2/dw_new"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "conv3_2/dw/scale_new"
  type: "Scale"
  bottom: "conv3_2/dw_new"
  top: "conv3_2/dw_new"
  scale_param {
    filler {
      value: 1
    }
    bias_term: true
    bias_filler {
      value: 0
    }
  }
}
layer {
  name: "relu3_2/dw_new"
  type: "ReLU"
  bottom: "conv3_2/dw_new"
  top: "conv3_2/dw_new"
}
layer {
  name: "conv3_2/out/pw_new"
  type: "Convolution"
  bottom: "conv3_2/dw_new"
  top: "conv3_2/out/pw_new"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  convolution_param {
    num_output: 64
    bias_term: false
    pad: 0
    kernel_size: 1
    stride: 1
    weight_filler {
      type: "msra"
    }
    engine: CAFFE
  }
}
layer {
  name: "conv3_2/out/pw/bn_new"
  type: "BatchNorm"
  bottom: "conv3_2/out/pw_new"
  top: "conv3_2/out/pw_new"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "conv3_2/out/pw/scale_new"
  type: "Scale"
  bottom: "conv3_2/out/pw_new"
  top: "conv3_2/out/pw_new"
  scale_param {
    filler {
      value: 1
    }
    bias_term: true
    bias_filler {
      value: 0
    }
  }
}
layer {
  name: "fuse_conv3_2"
  type: "Eltwise"
  bottom: "conv3_1/out/pw_new"
  bottom: "conv3_2/out/pw_new"
  top: "fuse_conv3_2"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "fc1"
  type: "InnerProduct"
  bottom: "fuse_conv3_2"
  top: "fc1"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 1
  }
  inner_product_param {
    num_output: 512
    weight_filler {
      type: "gaussian"
      std: 0.01
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "relu_fc1"
  type: "ReLU"
  bottom: "fc1"
  top: "fc1"
}
layer {
  name: "drop_fc1"
  type: "Dropout"
  bottom: "fc1"
  top: "fc1"
  dropout_param {
    dropout_ratio: 0.3
  }
}
layer {
  name: "landmark_pred"
  type: "InnerProduct"
  bottom: "fc1"
  top: "landmark_pred"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 1
  }
  inner_product_param {
    num_output: 254
    weight_filler {
      type: "gaussian"
      std: 0.01
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "landmark_loss"
  type: "EuclideanLoss"
  bottom: "landmark_pred"
  bottom: "label"
  top: "landmark_loss"
  loss_weight: 1
}
I0822 15:54:12.423470 13823 layer_factory.hpp:77] Creating layer data
I0822 15:54:12.423502 13823 net.cpp:84] Creating Layer data
I0822 15:54:12.423518 13823 net.cpp:380] data -> data
I0822 15:54:12.423552 13823 net.cpp:380] data -> label
I0822 15:54:12.423570 13823 hdf5_data_layer.cpp:80] Loading list of HDF5 filenames from: /home/sxdz/data/landmark/beadwallet/samples/trainHDF5/112/hdf5-norm.txt
I0822 15:54:12.441712 13823 hdf5_data_layer.cpp:94] Number of HDF5 files: 18260
I0822 15:54:12.501541 13823 hdf5.cpp:32] Datatype class: H5T_FLOAT
I0822 15:54:12.512702 13823 net.cpp:122] Setting up data
I0822 15:54:12.512742 13823 net.cpp:129] Top shape: 64 3 112 112 (2408448)
I0822 15:54:12.512753 13823 net.cpp:129] Top shape: 64 254 (16256)
I0822 15:54:12.512759 13823 net.cpp:137] Memory required for data: 9698816
I0822 15:54:12.512773 13823 layer_factory.hpp:77] Creating layer conv1_new
I0822 15:54:12.512809 13823 net.cpp:84] Creating Layer conv1_new
I0822 15:54:12.512823 13823 net.cpp:406] conv1_new <- data
I0822 15:54:12.512846 13823 net.cpp:380] conv1_new -> conv1_new
I0822 15:54:12.513897 13823 net.cpp:122] Setting up conv1_new
I0822 15:54:12.513921 13823 net.cpp:129] Top shape: 64 16 56 56 (3211264)
I0822 15:54:12.513927 13823 net.cpp:137] Memory required for data: 22543872
I0822 15:54:12.513952 13823 layer_factory.hpp:77] Creating layer conv1/bn_new
I0822 15:54:12.513972 13823 net.cpp:84] Creating Layer conv1/bn_new
I0822 15:54:12.513983 13823 net.cpp:406] conv1/bn_new <- conv1_new
I0822 15:54:12.513994 13823 net.cpp:367] conv1/bn_new -> conv1_new (in-place)
I0822 15:54:12.514343 13823 net.cpp:122] Setting up conv1/bn_new
I0822 15:54:12.514359 13823 net.cpp:129] Top shape: 64 16 56 56 (3211264)
I0822 15:54:12.514365 13823 net.cpp:137] Memory required for data: 35388928
I0822 15:54:12.514387 13823 layer_factory.hpp:77] Creating layer conv1/scale_new
I0822 15:54:12.514402 13823 net.cpp:84] Creating Layer conv1/scale_new
I0822 15:54:12.514408 13823 net.cpp:406] conv1/scale_new <- conv1_new
I0822 15:54:12.514418 13823 net.cpp:367] conv1/scale_new -> conv1_new (in-place)
I0822 15:54:12.514492 13823 layer_factory.hpp:77] Creating layer conv1/scale_new
I0822 15:54:12.514714 13823 net.cpp:122] Setting up conv1/scale_new
I0822 15:54:12.514730 13823 net.cpp:129] Top shape: 64 16 56 56 (3211264)
I0822 15:54:12.514736 13823 net.cpp:137] Memory required for data: 48233984
I0822 15:54:12.514752 13823 layer_factory.hpp:77] Creating layer relu1_new
I0822 15:54:12.514767 13823 net.cpp:84] Creating Layer relu1_new
I0822 15:54:12.514773 13823 net.cpp:406] relu1_new <- conv1_new
I0822 15:54:12.514783 13823 net.cpp:367] relu1_new -> conv1_new (in-place)
I0822 15:54:12.514794 13823 net.cpp:122] Setting up relu1_new
I0822 15:54:12.514803 13823 net.cpp:129] Top shape: 64 16 56 56 (3211264)
I0822 15:54:12.514809 13823 net.cpp:137] Memory required for data: 61079040
I0822 15:54:12.514816 13823 layer_factory.hpp:77] Creating layer conv1_1/in/pw_new
I0822 15:54:12.514830 13823 net.cpp:84] Creating Layer conv1_1/in/pw_new
I0822 15:54:12.514842 13823 net.cpp:406] conv1_1/in/pw_new <- conv1_new
I0822 15:54:12.514853 13823 net.cpp:380] conv1_1/in/pw_new -> conv1_1/in/pw_new
I0822 15:54:12.515197 13823 net.cpp:122] Setting up conv1_1/in/pw_new
I0822 15:54:12.515213 13823 net.cpp:129] Top shape: 64 64 56 56 (12845056)
I0822 15:54:12.515220 13823 net.cpp:137] Memory required for data: 112459264
I0822 15:54:12.515229 13823 layer_factory.hpp:77] Creating layer conv1_1/in/pw/bn_new
I0822 15:54:12.515242 13823 net.cpp:84] Creating Layer conv1_1/in/pw/bn_new
I0822 15:54:12.515249 13823 net.cpp:406] conv1_1/in/pw/bn_new <- conv1_1/in/pw_new
I0822 15:54:12.515259 13823 net.cpp:367] conv1_1/in/pw/bn_new -> conv1_1/in/pw_new (in-place)
I0822 15:54:12.515604 13823 net.cpp:122] Setting up conv1_1/in/pw/bn_new
I0822 15:54:12.515617 13823 net.cpp:129] Top shape: 64 64 56 56 (12845056)
I0822 15:54:12.515625 13823 net.cpp:137] Memory required for data: 163839488
I0822 15:54:12.515643 13823 layer_factory.hpp:77] Creating layer conv1_1/in/pw/scale_new
I0822 15:54:12.515656 13823 net.cpp:84] Creating Layer conv1_1/in/pw/scale_new
I0822 15:54:12.515663 13823 net.cpp:406] conv1_1/in/pw/scale_new <- conv1_1/in/pw_new
I0822 15:54:12.515673 13823 net.cpp:367] conv1_1/in/pw/scale_new -> conv1_1/in/pw_new (in-place)
I0822 15:54:12.515738 13823 layer_factory.hpp:77] Creating layer conv1_1/in/pw/scale_new
I0822 15:54:12.515954 13823 net.cpp:122] Setting up conv1_1/in/pw/scale_new
I0822 15:54:12.515969 13823 net.cpp:129] Top shape: 64 64 56 56 (12845056)
I0822 15:54:12.515975 13823 net.cpp:137] Memory required for data: 215219712
I0822 15:54:12.515987 13823 layer_factory.hpp:77] Creating layer relu1_1/in/pw_new
I0822 15:54:12.516000 13823 net.cpp:84] Creating Layer relu1_1/in/pw_new
I0822 15:54:12.516007 13823 net.cpp:406] relu1_1/in/pw_new <- conv1_1/in/pw_new
I0822 15:54:12.516016 13823 net.cpp:367] relu1_1/in/pw_new -> conv1_1/in/pw_new (in-place)
I0822 15:54:12.516027 13823 net.cpp:122] Setting up relu1_1/in/pw_new
I0822 15:54:12.516036 13823 net.cpp:129] Top shape: 64 64 56 56 (12845056)
I0822 15:54:12.516042 13823 net.cpp:137] Memory required for data: 266599936
I0822 15:54:12.516048 13823 layer_factory.hpp:77] Creating layer conv1_1/dw_new
I0822 15:54:12.516062 13823 net.cpp:84] Creating Layer conv1_1/dw_new
I0822 15:54:12.516072 13823 net.cpp:406] conv1_1/dw_new <- conv1_1/in/pw_new
I0822 15:54:12.516083 13823 net.cpp:380] conv1_1/dw_new -> conv1_1/dw_new
I0822 15:54:12.516374 13823 net.cpp:122] Setting up conv1_1/dw_new
I0822 15:54:12.516399 13823 net.cpp:129] Top shape: 64 64 28 28 (3211264)
I0822 15:54:12.516407 13823 net.cpp:137] Memory required for data: 279444992
I0822 15:54:12.516417 13823 layer_factory.hpp:77] Creating layer conv1_1/dw/bn_new
I0822 15:54:12.516430 13823 net.cpp:84] Creating Layer conv1_1/dw/bn_new
I0822 15:54:12.516438 13823 net.cpp:406] conv1_1/dw/bn_new <- conv1_1/dw_new
I0822 15:54:12.516448 13823 net.cpp:367] conv1_1/dw/bn_new -> conv1_1/dw_new (in-place)
I0822 15:54:12.516795 13823 net.cpp:122] Setting up conv1_1/dw/bn_new
I0822 15:54:12.516809 13823 net.cpp:129] Top shape: 64 64 28 28 (3211264)
I0822 15:54:12.516815 13823 net.cpp:137] Memory required for data: 292290048
I0822 15:54:12.516829 13823 layer_factory.hpp:77] Creating layer conv1_1/dw/scale_new
I0822 15:54:12.516839 13823 net.cpp:84] Creating Layer conv1_1/dw/scale_new
I0822 15:54:12.516846 13823 net.cpp:406] conv1_1/dw/scale_new <- conv1_1/dw_new
I0822 15:54:12.516855 13823 net.cpp:367] conv1_1/dw/scale_new -> conv1_1/dw_new (in-place)
I0822 15:54:12.516916 13823 layer_factory.hpp:77] Creating layer conv1_1/dw/scale_new
I0822 15:54:12.517096 13823 net.cpp:122] Setting up conv1_1/dw/scale_new
I0822 15:54:12.517110 13823 net.cpp:129] Top shape: 64 64 28 28 (3211264)
I0822 15:54:12.517117 13823 net.cpp:137] Memory required for data: 305135104
I0822 15:54:12.517134 13823 layer_factory.hpp:77] Creating layer relu1_1/dw_new
I0822 15:54:12.517146 13823 net.cpp:84] Creating Layer relu1_1/dw_new
I0822 15:54:12.517153 13823 net.cpp:406] relu1_1/dw_new <- conv1_1/dw_new
I0822 15:54:12.517161 13823 net.cpp:367] relu1_1/dw_new -> conv1_1/dw_new (in-place)
I0822 15:54:12.517170 13823 net.cpp:122] Setting up relu1_1/dw_new
I0822 15:54:12.517179 13823 net.cpp:129] Top shape: 64 64 28 28 (3211264)
I0822 15:54:12.517184 13823 net.cpp:137] Memory required for data: 317980160
I0822 15:54:12.517190 13823 layer_factory.hpp:77] Creating layer conv1_1/out/pw_new
I0822 15:54:12.517205 13823 net.cpp:84] Creating Layer conv1_1/out/pw_new
I0822 15:54:12.517213 13823 net.cpp:406] conv1_1/out/pw_new <- conv1_1/dw_new
I0822 15:54:12.517223 13823 net.cpp:380] conv1_1/out/pw_new -> conv1_1/out/pw_new
I0822 15:54:12.517565 13823 net.cpp:122] Setting up conv1_1/out/pw_new
I0822 15:54:12.517583 13823 net.cpp:129] Top shape: 64 24 28 28 (1204224)
I0822 15:54:12.517590 13823 net.cpp:137] Memory required for data: 322797056
I0822 15:54:12.517597 13823 layer_factory.hpp:77] Creating layer conv1_1/out/pw/bn_new
I0822 15:54:12.517609 13823 net.cpp:84] Creating Layer conv1_1/out/pw/bn_new
I0822 15:54:12.517616 13823 net.cpp:406] conv1_1/out/pw/bn_new <- conv1_1/out/pw_new
I0822 15:54:12.517626 13823 net.cpp:367] conv1_1/out/pw/bn_new -> conv1_1/out/pw_new (in-place)
I0822 15:54:12.517944 13823 net.cpp:122] Setting up conv1_1/out/pw/bn_new
I0822 15:54:12.517957 13823 net.cpp:129] Top shape: 64 24 28 28 (1204224)
I0822 15:54:12.517963 13823 net.cpp:137] Memory required for data: 327613952
I0822 15:54:12.517976 13823 layer_factory.hpp:77] Creating layer conv1_1/out/pw/scale_new
I0822 15:54:12.517987 13823 net.cpp:84] Creating Layer conv1_1/out/pw/scale_new
I0822 15:54:12.517993 13823 net.cpp:406] conv1_1/out/pw/scale_new <- conv1_1/out/pw_new
I0822 15:54:12.518002 13823 net.cpp:367] conv1_1/out/pw/scale_new -> conv1_1/out/pw_new (in-place)
I0822 15:54:12.518060 13823 layer_factory.hpp:77] Creating layer conv1_1/out/pw/scale_new
I0822 15:54:12.518245 13823 net.cpp:122] Setting up conv1_1/out/pw/scale_new
I0822 15:54:12.518261 13823 net.cpp:129] Top shape: 64 24 28 28 (1204224)
I0822 15:54:12.518266 13823 net.cpp:137] Memory required for data: 332430848
I0822 15:54:12.518278 13823 layer_factory.hpp:77] Creating layer conv1_1/out/pw_new_conv1_1/out/pw/scale_new_0_split
I0822 15:54:12.518296 13823 net.cpp:84] Creating Layer conv1_1/out/pw_new_conv1_1/out/pw/scale_new_0_split
I0822 15:54:12.518304 13823 net.cpp:406] conv1_1/out/pw_new_conv1_1/out/pw/scale_new_0_split <- conv1_1/out/pw_new
I0822 15:54:12.518316 13823 net.cpp:380] conv1_1/out/pw_new_conv1_1/out/pw/scale_new_0_split -> conv1_1/out/pw_new_conv1_1/out/pw/scale_new_0_split_0
I0822 15:54:12.518328 13823 net.cpp:380] conv1_1/out/pw_new_conv1_1/out/pw/scale_new_0_split -> conv1_1/out/pw_new_conv1_1/out/pw/scale_new_0_split_1
I0822 15:54:12.518385 13823 net.cpp:122] Setting up conv1_1/out/pw_new_conv1_1/out/pw/scale_new_0_split
I0822 15:54:12.518401 13823 net.cpp:129] Top shape: 64 24 28 28 (1204224)
I0822 15:54:12.518410 13823 net.cpp:129] Top shape: 64 24 28 28 (1204224)
I0822 15:54:12.518415 13823 net.cpp:137] Memory required for data: 342064640
I0822 15:54:12.518421 13823 layer_factory.hpp:77] Creating layer conv1_2/in/pw_new
I0822 15:54:12.518435 13823 net.cpp:84] Creating Layer conv1_2/in/pw_new
I0822 15:54:12.518445 13823 net.cpp:406] conv1_2/in/pw_new <- conv1_1/out/pw_new_conv1_1/out/pw/scale_new_0_split_0
I0822 15:54:12.518455 13823 net.cpp:380] conv1_2/in/pw_new -> conv1_2/in/pw_new
I0822 15:54:12.518832 13823 net.cpp:122] Setting up conv1_2/in/pw_new
I0822 15:54:12.518848 13823 net.cpp:129] Top shape: 64 144 28 28 (7225344)
I0822 15:54:12.518854 13823 net.cpp:137] Memory required for data: 370966016
I0822 15:54:12.518863 13823 layer_factory.hpp:77] Creating layer conv1_2/in/pw/bn_new
I0822 15:54:12.518874 13823 net.cpp:84] Creating Layer conv1_2/in/pw/bn_new
I0822 15:54:12.518882 13823 net.cpp:406] conv1_2/in/pw/bn_new <- conv1_2/in/pw_new
I0822 15:54:12.518891 13823 net.cpp:367] conv1_2/in/pw/bn_new -> conv1_2/in/pw_new (in-place)
I0822 15:54:12.519210 13823 net.cpp:122] Setting up conv1_2/in/pw/bn_new
I0822 15:54:12.519224 13823 net.cpp:129] Top shape: 64 144 28 28 (7225344)
I0822 15:54:12.519230 13823 net.cpp:137] Memory required for data: 399867392
I0822 15:54:12.519243 13823 layer_factory.hpp:77] Creating layer conv1_2/in/pw/scale_new
I0822 15:54:12.519254 13823 net.cpp:84] Creating Layer conv1_2/in/pw/scale_new
I0822 15:54:12.519261 13823 net.cpp:406] conv1_2/in/pw/scale_new <- conv1_2/in/pw_new
I0822 15:54:12.519270 13823 net.cpp:367] conv1_2/in/pw/scale_new -> conv1_2/in/pw_new (in-place)
I0822 15:54:12.519333 13823 layer_factory.hpp:77] Creating layer conv1_2/in/pw/scale_new
I0822 15:54:12.519522 13823 net.cpp:122] Setting up conv1_2/in/pw/scale_new
I0822 15:54:12.519536 13823 net.cpp:129] Top shape: 64 144 28 28 (7225344)
I0822 15:54:12.519542 13823 net.cpp:137] Memory required for data: 428768768
I0822 15:54:12.519554 13823 layer_factory.hpp:77] Creating layer relu1_2/in/pw_new
I0822 15:54:12.519563 13823 net.cpp:84] Creating Layer relu1_2/in/pw_new
I0822 15:54:12.519569 13823 net.cpp:406] relu1_2/in/pw_new <- conv1_2/in/pw_new
I0822 15:54:12.519578 13823 net.cpp:367] relu1_2/in/pw_new -> conv1_2/in/pw_new (in-place)
I0822 15:54:12.519588 13823 net.cpp:122] Setting up relu1_2/in/pw_new
I0822 15:54:12.519596 13823 net.cpp:129] Top shape: 64 144 28 28 (7225344)
I0822 15:54:12.519603 13823 net.cpp:137] Memory required for data: 457670144
I0822 15:54:12.519608 13823 layer_factory.hpp:77] Creating layer conv1_2/dw_new
I0822 15:54:12.519619 13823 net.cpp:84] Creating Layer conv1_2/dw_new
I0822 15:54:12.519625 13823 net.cpp:406] conv1_2/dw_new <- conv1_2/in/pw_new
I0822 15:54:12.519634 13823 net.cpp:380] conv1_2/dw_new -> conv1_2/dw_new
I0822 15:54:12.519851 13823 net.cpp:122] Setting up conv1_2/dw_new
I0822 15:54:12.519870 13823 net.cpp:129] Top shape: 64 144 28 28 (7225344)
I0822 15:54:12.519876 13823 net.cpp:137] Memory required for data: 486571520
I0822 15:54:12.519886 13823 layer_factory.hpp:77] Creating layer conv1_2/dw/bn_new
I0822 15:54:12.519897 13823 net.cpp:84] Creating Layer conv1_2/dw/bn_new
I0822 15:54:12.519904 13823 net.cpp:406] conv1_2/dw/bn_new <- conv1_2/dw_new
I0822 15:54:12.519914 13823 net.cpp:367] conv1_2/dw/bn_new -> conv1_2/dw_new (in-place)
I0822 15:54:12.520251 13823 net.cpp:122] Setting up conv1_2/dw/bn_new
I0822 15:54:12.520267 13823 net.cpp:129] Top shape: 64 144 28 28 (7225344)
I0822 15:54:12.520272 13823 net.cpp:137] Memory required for data: 515472896
I0822 15:54:12.520293 13823 layer_factory.hpp:77] Creating layer conv1_2/dw/scale_new
I0822 15:54:12.520308 13823 net.cpp:84] Creating Layer conv1_2/dw/scale_new
I0822 15:54:12.520315 13823 net.cpp:406] conv1_2/dw/scale_new <- conv1_2/dw_new
I0822 15:54:12.520324 13823 net.cpp:367] conv1_2/dw/scale_new -> conv1_2/dw_new (in-place)
I0822 15:54:12.520390 13823 layer_factory.hpp:77] Creating layer conv1_2/dw/scale_new
I0822 15:54:12.520581 13823 net.cpp:122] Setting up conv1_2/dw/scale_new
I0822 15:54:12.520596 13823 net.cpp:129] Top shape: 64 144 28 28 (7225344)
I0822 15:54:12.520601 13823 net.cpp:137] Memory required for data: 544374272
I0822 15:54:12.520613 13823 layer_factory.hpp:77] Creating layer relu1_2/dw_new
I0822 15:54:12.520624 13823 net.cpp:84] Creating Layer relu1_2/dw_new
I0822 15:54:12.520630 13823 net.cpp:406] relu1_2/dw_new <- conv1_2/dw_new
I0822 15:54:12.520639 13823 net.cpp:367] relu1_2/dw_new -> conv1_2/dw_new (in-place)
I0822 15:54:12.520649 13823 net.cpp:122] Setting up relu1_2/dw_new
I0822 15:54:12.520658 13823 net.cpp:129] Top shape: 64 144 28 28 (7225344)
I0822 15:54:12.520663 13823 net.cpp:137] Memory required for data: 573275648
I0822 15:54:12.520668 13823 layer_factory.hpp:77] Creating layer conv1_2/out/pw_new
I0822 15:54:12.520682 13823 net.cpp:84] Creating Layer conv1_2/out/pw_new
I0822 15:54:12.520692 13823 net.cpp:406] conv1_2/out/pw_new <- conv1_2/dw_new
I0822 15:54:12.520702 13823 net.cpp:380] conv1_2/out/pw_new -> conv1_2/out/pw_new
I0822 15:54:12.521088 13823 net.cpp:122] Setting up conv1_2/out/pw_new
I0822 15:54:12.521104 13823 net.cpp:129] Top shape: 64 24 28 28 (1204224)
I0822 15:54:12.521111 13823 net.cpp:137] Memory required for data: 578092544
I0822 15:54:12.521118 13823 layer_factory.hpp:77] Creating layer conv1_2/out/pw/bn_new
I0822 15:54:12.521129 13823 net.cpp:84] Creating Layer conv1_2/out/pw/bn_new
I0822 15:54:12.521136 13823 net.cpp:406] conv1_2/out/pw/bn_new <- conv1_2/out/pw_new
I0822 15:54:12.521145 13823 net.cpp:367] conv1_2/out/pw/bn_new -> conv1_2/out/pw_new (in-place)
I0822 15:54:12.521459 13823 net.cpp:122] Setting up conv1_2/out/pw/bn_new
I0822 15:54:12.521472 13823 net.cpp:129] Top shape: 64 24 28 28 (1204224)
I0822 15:54:12.521478 13823 net.cpp:137] Memory required for data: 582909440
I0822 15:54:12.521492 13823 layer_factory.hpp:77] Creating layer conv1_2/out/pw/scale_new
I0822 15:54:12.521502 13823 net.cpp:84] Creating Layer conv1_2/out/pw/scale_new
I0822 15:54:12.521508 13823 net.cpp:406] conv1_2/out/pw/scale_new <- conv1_2/out/pw_new
I0822 15:54:12.521517 13823 net.cpp:367] conv1_2/out/pw/scale_new -> conv1_2/out/pw_new (in-place)
I0822 15:54:12.521577 13823 layer_factory.hpp:77] Creating layer conv1_2/out/pw/scale_new
I0822 15:54:12.521761 13823 net.cpp:122] Setting up conv1_2/out/pw/scale_new
I0822 15:54:12.521775 13823 net.cpp:129] Top shape: 64 24 28 28 (1204224)
I0822 15:54:12.521781 13823 net.cpp:137] Memory required for data: 587726336
I0822 15:54:12.521792 13823 layer_factory.hpp:77] Creating layer fuse_conv1_2
I0822 15:54:12.521807 13823 net.cpp:84] Creating Layer fuse_conv1_2
I0822 15:54:12.521816 13823 net.cpp:406] fuse_conv1_2 <- conv1_1/out/pw_new_conv1_1/out/pw/scale_new_0_split_1
I0822 15:54:12.521824 13823 net.cpp:406] fuse_conv1_2 <- conv1_2/out/pw_new
I0822 15:54:12.521833 13823 net.cpp:380] fuse_conv1_2 -> fuse_conv1_2
I0822 15:54:12.521878 13823 net.cpp:122] Setting up fuse_conv1_2
I0822 15:54:12.521891 13823 net.cpp:129] Top shape: 64 24 28 28 (1204224)
I0822 15:54:12.521898 13823 net.cpp:137] Memory required for data: 592543232
I0822 15:54:12.521903 13823 layer_factory.hpp:77] Creating layer conv2_1/in/pw_new
I0822 15:54:12.521916 13823 net.cpp:84] Creating Layer conv2_1/in/pw_new
I0822 15:54:12.521925 13823 net.cpp:406] conv2_1/in/pw_new <- fuse_conv1_2
I0822 15:54:12.521936 13823 net.cpp:380] conv2_1/in/pw_new -> conv2_1/in/pw_new
I0822 15:54:12.522316 13823 net.cpp:122] Setting up conv2_1/in/pw_new
I0822 15:54:12.522332 13823 net.cpp:129] Top shape: 64 144 28 28 (7225344)
I0822 15:54:12.522338 13823 net.cpp:137] Memory required for data: 621444608
I0822 15:54:12.522347 13823 layer_factory.hpp:77] Creating layer conv2_1/in/pw/bn_new
I0822 15:54:12.522358 13823 net.cpp:84] Creating Layer conv2_1/in/pw/bn_new
I0822 15:54:12.522366 13823 net.cpp:406] conv2_1/in/pw/bn_new <- conv2_1/in/pw_new
I0822 15:54:12.522374 13823 net.cpp:367] conv2_1/in/pw/bn_new -> conv2_1/in/pw_new (in-place)
I0822 15:54:12.522691 13823 net.cpp:122] Setting up conv2_1/in/pw/bn_new
I0822 15:54:12.522703 13823 net.cpp:129] Top shape: 64 144 28 28 (7225344)
I0822 15:54:12.522709 13823 net.cpp:137] Memory required for data: 650345984
I0822 15:54:12.522722 13823 layer_factory.hpp:77] Creating layer conv2_1/in/pw/scale_new
I0822 15:54:12.522733 13823 net.cpp:84] Creating Layer conv2_1/in/pw/scale_new
I0822 15:54:12.522739 13823 net.cpp:406] conv2_1/in/pw/scale_new <- conv2_1/in/pw_new
I0822 15:54:12.522748 13823 net.cpp:367] conv2_1/in/pw/scale_new -> conv2_1/in/pw_new (in-place)
I0822 15:54:12.522811 13823 layer_factory.hpp:77] Creating layer conv2_1/in/pw/scale_new
I0822 15:54:12.523005 13823 net.cpp:122] Setting up conv2_1/in/pw/scale_new
I0822 15:54:12.523018 13823 net.cpp:129] Top shape: 64 144 28 28 (7225344)
I0822 15:54:12.523025 13823 net.cpp:137] Memory required for data: 679247360
I0822 15:54:12.523034 13823 layer_factory.hpp:77] Creating layer relu2_1/in/pw_new
I0822 15:54:12.523053 13823 net.cpp:84] Creating Layer relu2_1/in/pw_new
I0822 15:54:12.523062 13823 net.cpp:406] relu2_1/in/pw_new <- conv2_1/in/pw_new
I0822 15:54:12.523070 13823 net.cpp:367] relu2_1/in/pw_new -> conv2_1/in/pw_new (in-place)
I0822 15:54:12.523080 13823 net.cpp:122] Setting up relu2_1/in/pw_new
I0822 15:54:12.523089 13823 net.cpp:129] Top shape: 64 144 28 28 (7225344)
I0822 15:54:12.523094 13823 net.cpp:137] Memory required for data: 708148736
I0822 15:54:12.523100 13823 layer_factory.hpp:77] Creating layer conv2_1/dw_new
I0822 15:54:12.523111 13823 net.cpp:84] Creating Layer conv2_1/dw_new
I0822 15:54:12.523118 13823 net.cpp:406] conv2_1/dw_new <- conv2_1/in/pw_new
I0822 15:54:12.523128 13823 net.cpp:380] conv2_1/dw_new -> conv2_1/dw_new
I0822 15:54:12.523339 13823 net.cpp:122] Setting up conv2_1/dw_new
I0822 15:54:12.523357 13823 net.cpp:129] Top shape: 64 144 14 14 (1806336)
I0822 15:54:12.523363 13823 net.cpp:137] Memory required for data: 715374080
I0822 15:54:12.523372 13823 layer_factory.hpp:77] Creating layer conv2_1/dw/bn_new
I0822 15:54:12.523385 13823 net.cpp:84] Creating Layer conv2_1/dw/bn_new
I0822 15:54:12.523391 13823 net.cpp:406] conv2_1/dw/bn_new <- conv2_1/dw_new
I0822 15:54:12.523401 13823 net.cpp:367] conv2_1/dw/bn_new -> conv2_1/dw_new (in-place)
I0822 15:54:12.523735 13823 net.cpp:122] Setting up conv2_1/dw/bn_new
I0822 15:54:12.523748 13823 net.cpp:129] Top shape: 64 144 14 14 (1806336)
I0822 15:54:12.523753 13823 net.cpp:137] Memory required for data: 722599424
I0822 15:54:12.523766 13823 layer_factory.hpp:77] Creating layer conv2_1/dw/scale_new
I0822 15:54:12.523777 13823 net.cpp:84] Creating Layer conv2_1/dw/scale_new
I0822 15:54:12.523784 13823 net.cpp:406] conv2_1/dw/scale_new <- conv2_1/dw_new
I0822 15:54:12.523793 13823 net.cpp:367] conv2_1/dw/scale_new -> conv2_1/dw_new (in-place)
I0822 15:54:12.523854 13823 layer_factory.hpp:77] Creating layer conv2_1/dw/scale_new
I0822 15:54:12.524044 13823 net.cpp:122] Setting up conv2_1/dw/scale_new
I0822 15:54:12.524057 13823 net.cpp:129] Top shape: 64 144 14 14 (1806336)
I0822 15:54:12.524063 13823 net.cpp:137] Memory required for data: 729824768
I0822 15:54:12.524073 13823 layer_factory.hpp:77] Creating layer relu2_1/dw_new
I0822 15:54:12.524083 13823 net.cpp:84] Creating Layer relu2_1/dw_new
I0822 15:54:12.524089 13823 net.cpp:406] relu2_1/dw_new <- conv2_1/dw_new
I0822 15:54:12.524098 13823 net.cpp:367] relu2_1/dw_new -> conv2_1/dw_new (in-place)
I0822 15:54:12.524107 13823 net.cpp:122] Setting up relu2_1/dw_new
I0822 15:54:12.524118 13823 net.cpp:129] Top shape: 64 144 14 14 (1806336)
I0822 15:54:12.524123 13823 net.cpp:137] Memory required for data: 737050112
I0822 15:54:12.524129 13823 layer_factory.hpp:77] Creating layer conv2_1/out/pw_new
I0822 15:54:12.524157 13823 net.cpp:84] Creating Layer conv2_1/out/pw_new
I0822 15:54:12.524165 13823 net.cpp:406] conv2_1/out/pw_new <- conv2_1/dw_new
I0822 15:54:12.524176 13823 net.cpp:380] conv2_1/out/pw_new -> conv2_1/out/pw_new
I0822 15:54:12.524585 13823 net.cpp:122] Setting up conv2_1/out/pw_new
I0822 15:54:12.524601 13823 net.cpp:129] Top shape: 64 32 14 14 (401408)
I0822 15:54:12.524607 13823 net.cpp:137] Memory required for data: 738655744
I0822 15:54:12.524616 13823 layer_factory.hpp:77] Creating layer conv2_1/out/pw/bn_new
I0822 15:54:12.524627 13823 net.cpp:84] Creating Layer conv2_1/out/pw/bn_new
I0822 15:54:12.524634 13823 net.cpp:406] conv2_1/out/pw/bn_new <- conv2_1/out/pw_new
I0822 15:54:12.524644 13823 net.cpp:367] conv2_1/out/pw/bn_new -> conv2_1/out/pw_new (in-place)
I0822 15:54:12.524971 13823 net.cpp:122] Setting up conv2_1/out/pw/bn_new
I0822 15:54:12.524983 13823 net.cpp:129] Top shape: 64 32 14 14 (401408)
I0822 15:54:12.524989 13823 net.cpp:137] Memory required for data: 740261376
I0822 15:54:12.525002 13823 layer_factory.hpp:77] Creating layer conv2_1/out/pw/scale_new
I0822 15:54:12.525013 13823 net.cpp:84] Creating Layer conv2_1/out/pw/scale_new
I0822 15:54:12.525019 13823 net.cpp:406] conv2_1/out/pw/scale_new <- conv2_1/out/pw_new
I0822 15:54:12.525028 13823 net.cpp:367] conv2_1/out/pw/scale_new -> conv2_1/out/pw_new (in-place)
I0822 15:54:12.525089 13823 layer_factory.hpp:77] Creating layer conv2_1/out/pw/scale_new
I0822 15:54:12.525277 13823 net.cpp:122] Setting up conv2_1/out/pw/scale_new
I0822 15:54:12.525291 13823 net.cpp:129] Top shape: 64 32 14 14 (401408)
I0822 15:54:12.525298 13823 net.cpp:137] Memory required for data: 741867008
I0822 15:54:12.525308 13823 layer_factory.hpp:77] Creating layer conv2_1/out/pw_new_conv2_1/out/pw/scale_new_0_split
I0822 15:54:12.525319 13823 net.cpp:84] Creating Layer conv2_1/out/pw_new_conv2_1/out/pw/scale_new_0_split
I0822 15:54:12.525328 13823 net.cpp:406] conv2_1/out/pw_new_conv2_1/out/pw/scale_new_0_split <- conv2_1/out/pw_new
I0822 15:54:12.525338 13823 net.cpp:380] conv2_1/out/pw_new_conv2_1/out/pw/scale_new_0_split -> conv2_1/out/pw_new_conv2_1/out/pw/scale_new_0_split_0
I0822 15:54:12.525352 13823 net.cpp:380] conv2_1/out/pw_new_conv2_1/out/pw/scale_new_0_split -> conv2_1/out/pw_new_conv2_1/out/pw/scale_new_0_split_1
I0822 15:54:12.525422 13823 net.cpp:122] Setting up conv2_1/out/pw_new_conv2_1/out/pw/scale_new_0_split
I0822 15:54:12.525437 13823 net.cpp:129] Top shape: 64 32 14 14 (401408)
I0822 15:54:12.525446 13823 net.cpp:129] Top shape: 64 32 14 14 (401408)
I0822 15:54:12.525451 13823 net.cpp:137] Memory required for data: 745078272
I0822 15:54:12.525457 13823 layer_factory.hpp:77] Creating layer conv2_2/in/pw_new
I0822 15:54:12.525471 13823 net.cpp:84] Creating Layer conv2_2/in/pw_new
I0822 15:54:12.525481 13823 net.cpp:406] conv2_2/in/pw_new <- conv2_1/out/pw_new_conv2_1/out/pw/scale_new_0_split_0
I0822 15:54:12.525492 13823 net.cpp:380] conv2_2/in/pw_new -> conv2_2/in/pw_new
I0822 15:54:12.525924 13823 net.cpp:122] Setting up conv2_2/in/pw_new
I0822 15:54:12.525940 13823 net.cpp:129] Top shape: 64 192 14 14 (2408448)
I0822 15:54:12.525946 13823 net.cpp:137] Memory required for data: 754712064
I0822 15:54:12.525955 13823 layer_factory.hpp:77] Creating layer conv2_2/in/pw/bn_new
I0822 15:54:12.525966 13823 net.cpp:84] Creating Layer conv2_2/in/pw/bn_new
I0822 15:54:12.525974 13823 net.cpp:406] conv2_2/in/pw/bn_new <- conv2_2/in/pw_new
I0822 15:54:12.525982 13823 net.cpp:367] conv2_2/in/pw/bn_new -> conv2_2/in/pw_new (in-place)
I0822 15:54:12.526309 13823 net.cpp:122] Setting up conv2_2/in/pw/bn_new
I0822 15:54:12.526322 13823 net.cpp:129] Top shape: 64 192 14 14 (2408448)
I0822 15:54:12.526329 13823 net.cpp:137] Memory required for data: 764345856
I0822 15:54:12.526341 13823 layer_factory.hpp:77] Creating layer conv2_2/in/pw/scale_new
I0822 15:54:12.526351 13823 net.cpp:84] Creating Layer conv2_2/in/pw/scale_new
I0822 15:54:12.526358 13823 net.cpp:406] conv2_2/in/pw/scale_new <- conv2_2/in/pw_new
I0822 15:54:12.526367 13823 net.cpp:367] conv2_2/in/pw/scale_new -> conv2_2/in/pw_new (in-place)
I0822 15:54:12.526428 13823 layer_factory.hpp:77] Creating layer conv2_2/in/pw/scale_new
I0822 15:54:12.526621 13823 net.cpp:122] Setting up conv2_2/in/pw/scale_new
I0822 15:54:12.526636 13823 net.cpp:129] Top shape: 64 192 14 14 (2408448)
I0822 15:54:12.526643 13823 net.cpp:137] Memory required for data: 773979648
I0822 15:54:12.526664 13823 layer_factory.hpp:77] Creating layer relu2_2/in/pw_new
I0822 15:54:12.526676 13823 net.cpp:84] Creating Layer relu2_2/in/pw_new
I0822 15:54:12.526684 13823 net.cpp:406] relu2_2/in/pw_new <- conv2_2/in/pw_new
I0822 15:54:12.526692 13823 net.cpp:367] relu2_2/in/pw_new -> conv2_2/in/pw_new (in-place)
I0822 15:54:12.526702 13823 net.cpp:122] Setting up relu2_2/in/pw_new
I0822 15:54:12.526710 13823 net.cpp:129] Top shape: 64 192 14 14 (2408448)
I0822 15:54:12.526716 13823 net.cpp:137] Memory required for data: 783613440
I0822 15:54:12.526721 13823 layer_factory.hpp:77] Creating layer conv2_2/dw_new
I0822 15:54:12.526733 13823 net.cpp:84] Creating Layer conv2_2/dw_new
I0822 15:54:12.526739 13823 net.cpp:406] conv2_2/dw_new <- conv2_2/in/pw_new
I0822 15:54:12.526749 13823 net.cpp:380] conv2_2/dw_new -> conv2_2/dw_new
I0822 15:54:12.526971 13823 net.cpp:122] Setting up conv2_2/dw_new
I0822 15:54:12.526991 13823 net.cpp:129] Top shape: 64 192 14 14 (2408448)
I0822 15:54:12.527004 13823 net.cpp:137] Memory required for data: 793247232
I0822 15:54:12.527014 13823 layer_factory.hpp:77] Creating layer conv2_2/dw/bn_new
I0822 15:54:12.527026 13823 net.cpp:84] Creating Layer conv2_2/dw/bn_new
I0822 15:54:12.527034 13823 net.cpp:406] conv2_2/dw/bn_new <- conv2_2/dw_new
I0822 15:54:12.527042 13823 net.cpp:367] conv2_2/dw/bn_new -> conv2_2/dw_new (in-place)
I0822 15:54:12.527384 13823 net.cpp:122] Setting up conv2_2/dw/bn_new
I0822 15:54:12.527398 13823 net.cpp:129] Top shape: 64 192 14 14 (2408448)
I0822 15:54:12.527405 13823 net.cpp:137] Memory required for data: 802881024
I0822 15:54:12.527417 13823 layer_factory.hpp:77] Creating layer conv2_2/dw/scale_new
I0822 15:54:12.527428 13823 net.cpp:84] Creating Layer conv2_2/dw/scale_new
I0822 15:54:12.527436 13823 net.cpp:406] conv2_2/dw/scale_new <- conv2_2/dw_new
I0822 15:54:12.527443 13823 net.cpp:367] conv2_2/dw/scale_new -> conv2_2/dw_new (in-place)
I0822 15:54:12.527509 13823 layer_factory.hpp:77] Creating layer conv2_2/dw/scale_new
I0822 15:54:12.527695 13823 net.cpp:122] Setting up conv2_2/dw/scale_new
I0822 15:54:12.527710 13823 net.cpp:129] Top shape: 64 192 14 14 (2408448)
I0822 15:54:12.527716 13823 net.cpp:137] Memory required for data: 812514816
I0822 15:54:12.527726 13823 layer_factory.hpp:77] Creating layer relu2_2/dw_new
I0822 15:54:12.527736 13823 net.cpp:84] Creating Layer relu2_2/dw_new
I0822 15:54:12.527742 13823 net.cpp:406] relu2_2/dw_new <- conv2_2/dw_new
I0822 15:54:12.527750 13823 net.cpp:367] relu2_2/dw_new -> conv2_2/dw_new (in-place)
I0822 15:54:12.527760 13823 net.cpp:122] Setting up relu2_2/dw_new
I0822 15:54:12.527768 13823 net.cpp:129] Top shape: 64 192 14 14 (2408448)
I0822 15:54:12.527774 13823 net.cpp:137] Memory required for data: 822148608
I0822 15:54:12.527779 13823 layer_factory.hpp:77] Creating layer conv2_2/out/pw_new
I0822 15:54:12.527793 13823 net.cpp:84] Creating Layer conv2_2/out/pw_new
I0822 15:54:12.527799 13823 net.cpp:406] conv2_2/out/pw_new <- conv2_2/dw_new
I0822 15:54:12.527809 13823 net.cpp:380] conv2_2/out/pw_new -> conv2_2/out/pw_new
I0822 15:54:12.528266 13823 net.cpp:122] Setting up conv2_2/out/pw_new
I0822 15:54:12.528285 13823 net.cpp:129] Top shape: 64 32 14 14 (401408)
I0822 15:54:12.528290 13823 net.cpp:137] Memory required for data: 823754240
I0822 15:54:12.528298 13823 layer_factory.hpp:77] Creating layer conv2_2/out/pw/bn_new
I0822 15:54:12.528311 13823 net.cpp:84] Creating Layer conv2_2/out/pw/bn_new
I0822 15:54:12.528317 13823 net.cpp:406] conv2_2/out/pw/bn_new <- conv2_2/out/pw_new
I0822 15:54:12.528327 13823 net.cpp:367] conv2_2/out/pw/bn_new -> conv2_2/out/pw_new (in-place)
I0822 15:54:12.528659 13823 net.cpp:122] Setting up conv2_2/out/pw/bn_new
I0822 15:54:12.528672 13823 net.cpp:129] Top shape: 64 32 14 14 (401408)
I0822 15:54:12.528677 13823 net.cpp:137] Memory required for data: 825359872
I0822 15:54:12.528689 13823 layer_factory.hpp:77] Creating layer conv2_2/out/pw/scale_new
I0822 15:54:12.528700 13823 net.cpp:84] Creating Layer conv2_2/out/pw/scale_new
I0822 15:54:12.528707 13823 net.cpp:406] conv2_2/out/pw/scale_new <- conv2_2/out/pw_new
I0822 15:54:12.528714 13823 net.cpp:367] conv2_2/out/pw/scale_new -> conv2_2/out/pw_new (in-place)
I0822 15:54:12.528770 13823 layer_factory.hpp:77] Creating layer conv2_2/out/pw/scale_new
I0822 15:54:12.528957 13823 net.cpp:122] Setting up conv2_2/out/pw/scale_new
I0822 15:54:12.528972 13823 net.cpp:129] Top shape: 64 32 14 14 (401408)
I0822 15:54:12.528977 13823 net.cpp:137] Memory required for data: 826965504
I0822 15:54:12.528988 13823 layer_factory.hpp:77] Creating layer fuse_conv2_2
I0822 15:54:12.528998 13823 net.cpp:84] Creating Layer fuse_conv2_2
I0822 15:54:12.529004 13823 net.cpp:406] fuse_conv2_2 <- conv2_1/out/pw_new_conv2_1/out/pw/scale_new_0_split_1
I0822 15:54:12.529012 13823 net.cpp:406] fuse_conv2_2 <- conv2_2/out/pw_new
I0822 15:54:12.529021 13823 net.cpp:380] fuse_conv2_2 -> fuse_conv2_2
I0822 15:54:12.529058 13823 net.cpp:122] Setting up fuse_conv2_2
I0822 15:54:12.529073 13823 net.cpp:129] Top shape: 64 32 14 14 (401408)
I0822 15:54:12.529080 13823 net.cpp:137] Memory required for data: 828571136
I0822 15:54:12.529086 13823 layer_factory.hpp:77] Creating layer conv3_1/in/pw_new
I0822 15:54:12.529098 13823 net.cpp:84] Creating Layer conv3_1/in/pw_new
I0822 15:54:12.529108 13823 net.cpp:406] conv3_1/in/pw_new <- fuse_conv2_2
I0822 15:54:12.529116 13823 net.cpp:380] conv3_1/in/pw_new -> conv3_1/in/pw_new
I0822 15:54:12.529522 13823 net.cpp:122] Setting up conv3_1/in/pw_new
I0822 15:54:12.529536 13823 net.cpp:129] Top shape: 64 192 14 14 (2408448)
I0822 15:54:12.529542 13823 net.cpp:137] Memory required for data: 838204928
I0822 15:54:12.529551 13823 layer_factory.hpp:77] Creating layer conv3_1/in/pw/bn_new
I0822 15:54:12.529561 13823 net.cpp:84] Creating Layer conv3_1/in/pw/bn_new
I0822 15:54:12.529567 13823 net.cpp:406] conv3_1/in/pw/bn_new <- conv3_1/in/pw_new
I0822 15:54:12.529575 13823 net.cpp:367] conv3_1/in/pw/bn_new -> conv3_1/in/pw_new (in-place)
I0822 15:54:12.529877 13823 net.cpp:122] Setting up conv3_1/in/pw/bn_new
I0822 15:54:12.529889 13823 net.cpp:129] Top shape: 64 192 14 14 (2408448)
I0822 15:54:12.529896 13823 net.cpp:137] Memory required for data: 847838720
I0822 15:54:12.529907 13823 layer_factory.hpp:77] Creating layer conv3_1/in/pw/scale_new
I0822 15:54:12.529917 13823 net.cpp:84] Creating Layer conv3_1/in/pw/scale_new
I0822 15:54:12.529923 13823 net.cpp:406] conv3_1/in/pw/scale_new <- conv3_1/in/pw_new
I0822 15:54:12.529932 13823 net.cpp:367] conv3_1/in/pw/scale_new -> conv3_1/in/pw_new (in-place)
I0822 15:54:12.529991 13823 layer_factory.hpp:77] Creating layer conv3_1/in/pw/scale_new
I0822 15:54:12.530171 13823 net.cpp:122] Setting up conv3_1/in/pw/scale_new
I0822 15:54:12.530184 13823 net.cpp:129] Top shape: 64 192 14 14 (2408448)
I0822 15:54:12.530190 13823 net.cpp:137] Memory required for data: 857472512
I0822 15:54:12.530200 13823 layer_factory.hpp:77] Creating layer relu3_1/in/pw_new
I0822 15:54:12.530212 13823 net.cpp:84] Creating Layer relu3_1/in/pw_new
I0822 15:54:12.530218 13823 net.cpp:406] relu3_1/in/pw_new <- conv3_1/in/pw_new
I0822 15:54:12.530226 13823 net.cpp:367] relu3_1/in/pw_new -> conv3_1/in/pw_new (in-place)
I0822 15:54:12.530236 13823 net.cpp:122] Setting up relu3_1/in/pw_new
I0822 15:54:12.530243 13823 net.cpp:129] Top shape: 64 192 14 14 (2408448)
I0822 15:54:12.530248 13823 net.cpp:137] Memory required for data: 867106304
I0822 15:54:12.530253 13823 layer_factory.hpp:77] Creating layer conv3_1/dw_new
I0822 15:54:12.530264 13823 net.cpp:84] Creating Layer conv3_1/dw_new
I0822 15:54:12.530269 13823 net.cpp:406] conv3_1/dw_new <- conv3_1/in/pw_new
I0822 15:54:12.530278 13823 net.cpp:380] conv3_1/dw_new -> conv3_1/dw_new
I0822 15:54:12.530486 13823 net.cpp:122] Setting up conv3_1/dw_new
I0822 15:54:12.530505 13823 net.cpp:129] Top shape: 64 192 7 7 (602112)
I0822 15:54:12.530511 13823 net.cpp:137] Memory required for data: 869514752
I0822 15:54:12.530520 13823 layer_factory.hpp:77] Creating layer conv3_1/dw/bn_new
I0822 15:54:12.530531 13823 net.cpp:84] Creating Layer conv3_1/dw/bn_new
I0822 15:54:12.530537 13823 net.cpp:406] conv3_1/dw/bn_new <- conv3_1/dw_new
I0822 15:54:12.530547 13823 net.cpp:367] conv3_1/dw/bn_new -> conv3_1/dw_new (in-place)
I0822 15:54:12.530863 13823 net.cpp:122] Setting up conv3_1/dw/bn_new
I0822 15:54:12.530875 13823 net.cpp:129] Top shape: 64 192 7 7 (602112)
I0822 15:54:12.530881 13823 net.cpp:137] Memory required for data: 871923200
I0822 15:54:12.530894 13823 layer_factory.hpp:77] Creating layer conv3_1/dw/scale_new
I0822 15:54:12.530903 13823 net.cpp:84] Creating Layer conv3_1/dw/scale_new
I0822 15:54:12.530910 13823 net.cpp:406] conv3_1/dw/scale_new <- conv3_1/dw_new
I0822 15:54:12.530917 13823 net.cpp:367] conv3_1/dw/scale_new -> conv3_1/dw_new (in-place)
I0822 15:54:12.530975 13823 layer_factory.hpp:77] Creating layer conv3_1/dw/scale_new
I0822 15:54:12.531152 13823 net.cpp:122] Setting up conv3_1/dw/scale_new
I0822 15:54:12.531165 13823 net.cpp:129] Top shape: 64 192 7 7 (602112)
I0822 15:54:12.531170 13823 net.cpp:137] Memory required for data: 874331648
I0822 15:54:12.531181 13823 layer_factory.hpp:77] Creating layer relu3_1/dw_new
I0822 15:54:12.531189 13823 net.cpp:84] Creating Layer relu3_1/dw_new
I0822 15:54:12.531195 13823 net.cpp:406] relu3_1/dw_new <- conv3_1/dw_new
I0822 15:54:12.531203 13823 net.cpp:367] relu3_1/dw_new -> conv3_1/dw_new (in-place)
I0822 15:54:12.531213 13823 net.cpp:122] Setting up relu3_1/dw_new
I0822 15:54:12.531219 13823 net.cpp:129] Top shape: 64 192 7 7 (602112)
I0822 15:54:12.531225 13823 net.cpp:137] Memory required for data: 876740096
I0822 15:54:12.531230 13823 layer_factory.hpp:77] Creating layer conv3_1/out/pw_new
I0822 15:54:12.531242 13823 net.cpp:84] Creating Layer conv3_1/out/pw_new
I0822 15:54:12.531249 13823 net.cpp:406] conv3_1/out/pw_new <- conv3_1/dw_new
I0822 15:54:12.531257 13823 net.cpp:380] conv3_1/out/pw_new -> conv3_1/out/pw_new
I0822 15:54:12.531792 13823 net.cpp:122] Setting up conv3_1/out/pw_new
I0822 15:54:12.531808 13823 net.cpp:129] Top shape: 64 64 7 7 (200704)
I0822 15:54:12.531813 13823 net.cpp:137] Memory required for data: 877542912
I0822 15:54:12.531821 13823 layer_factory.hpp:77] Creating layer conv3_1/out/pw/bn_new
I0822 15:54:12.531832 13823 net.cpp:84] Creating Layer conv3_1/out/pw/bn_new
I0822 15:54:12.531838 13823 net.cpp:406] conv3_1/out/pw/bn_new <- conv3_1/out/pw_new
I0822 15:54:12.531847 13823 net.cpp:367] conv3_1/out/pw/bn_new -> conv3_1/out/pw_new (in-place)
I0822 15:54:12.532168 13823 net.cpp:122] Setting up conv3_1/out/pw/bn_new
I0822 15:54:12.532183 13823 net.cpp:129] Top shape: 64 64 7 7 (200704)
I0822 15:54:12.532188 13823 net.cpp:137] Memory required for data: 878345728
I0822 15:54:12.532202 13823 layer_factory.hpp:77] Creating layer conv3_1/out/pw/scale_new
I0822 15:54:12.532212 13823 net.cpp:84] Creating Layer conv3_1/out/pw/scale_new
I0822 15:54:12.532217 13823 net.cpp:406] conv3_1/out/pw/scale_new <- conv3_1/out/pw_new
I0822 15:54:12.532227 13823 net.cpp:367] conv3_1/out/pw/scale_new -> conv3_1/out/pw_new (in-place)
I0822 15:54:12.532284 13823 layer_factory.hpp:77] Creating layer conv3_1/out/pw/scale_new
I0822 15:54:12.532464 13823 net.cpp:122] Setting up conv3_1/out/pw/scale_new
I0822 15:54:12.532479 13823 net.cpp:129] Top shape: 64 64 7 7 (200704)
I0822 15:54:12.532483 13823 net.cpp:137] Memory required for data: 879148544
I0822 15:54:12.532495 13823 layer_factory.hpp:77] Creating layer conv3_1/out/pw_new_conv3_1/out/pw/scale_new_0_split
I0822 15:54:12.532521 13823 net.cpp:84] Creating Layer conv3_1/out/pw_new_conv3_1/out/pw/scale_new_0_split
I0822 15:54:12.532531 13823 net.cpp:406] conv3_1/out/pw_new_conv3_1/out/pw/scale_new_0_split <- conv3_1/out/pw_new
I0822 15:54:12.532539 13823 net.cpp:380] conv3_1/out/pw_new_conv3_1/out/pw/scale_new_0_split -> conv3_1/out/pw_new_conv3_1/out/pw/scale_new_0_split_0
I0822 15:54:12.532552 13823 net.cpp:380] conv3_1/out/pw_new_conv3_1/out/pw/scale_new_0_split -> conv3_1/out/pw_new_conv3_1/out/pw/scale_new_0_split_1
I0822 15:54:12.532613 13823 net.cpp:122] Setting up conv3_1/out/pw_new_conv3_1/out/pw/scale_new_0_split
I0822 15:54:12.532625 13823 net.cpp:129] Top shape: 64 64 7 7 (200704)
I0822 15:54:12.532634 13823 net.cpp:129] Top shape: 64 64 7 7 (200704)
I0822 15:54:12.532639 13823 net.cpp:137] Memory required for data: 880754176
I0822 15:54:12.532644 13823 layer_factory.hpp:77] Creating layer conv3_2/in/pw_new
I0822 15:54:12.532658 13823 net.cpp:84] Creating Layer conv3_2/in/pw_new
I0822 15:54:12.532665 13823 net.cpp:406] conv3_2/in/pw_new <- conv3_1/out/pw_new_conv3_1/out/pw/scale_new_0_split_0
I0822 15:54:12.532675 13823 net.cpp:380] conv3_2/in/pw_new -> conv3_2/in/pw_new
I0822 15:54:12.533210 13823 net.cpp:122] Setting up conv3_2/in/pw_new
I0822 15:54:12.533224 13823 net.cpp:129] Top shape: 64 192 7 7 (602112)
I0822 15:54:12.533231 13823 net.cpp:137] Memory required for data: 883162624
I0822 15:54:12.533238 13823 layer_factory.hpp:77] Creating layer conv3_2/in/pw/bn_new
I0822 15:54:12.533248 13823 net.cpp:84] Creating Layer conv3_2/in/pw/bn_new
I0822 15:54:12.533255 13823 net.cpp:406] conv3_2/in/pw/bn_new <- conv3_2/in/pw_new
I0822 15:54:12.533264 13823 net.cpp:367] conv3_2/in/pw/bn_new -> conv3_2/in/pw_new (in-place)
I0822 15:54:12.533567 13823 net.cpp:122] Setting up conv3_2/in/pw/bn_new
I0822 15:54:12.533581 13823 net.cpp:129] Top shape: 64 192 7 7 (602112)
I0822 15:54:12.533586 13823 net.cpp:137] Memory required for data: 885571072
I0822 15:54:12.533598 13823 layer_factory.hpp:77] Creating layer conv3_2/in/pw/scale_new
I0822 15:54:12.533608 13823 net.cpp:84] Creating Layer conv3_2/in/pw/scale_new
I0822 15:54:12.533615 13823 net.cpp:406] conv3_2/in/pw/scale_new <- conv3_2/in/pw_new
I0822 15:54:12.533623 13823 net.cpp:367] conv3_2/in/pw/scale_new -> conv3_2/in/pw_new (in-place)
I0822 15:54:12.533685 13823 layer_factory.hpp:77] Creating layer conv3_2/in/pw/scale_new
I0822 15:54:12.533866 13823 net.cpp:122] Setting up conv3_2/in/pw/scale_new
I0822 15:54:12.533880 13823 net.cpp:129] Top shape: 64 192 7 7 (602112)
I0822 15:54:12.533885 13823 net.cpp:137] Memory required for data: 887979520
I0822 15:54:12.533895 13823 layer_factory.hpp:77] Creating layer relu3_2/in/pw_new
I0822 15:54:12.533905 13823 net.cpp:84] Creating Layer relu3_2/in/pw_new
I0822 15:54:12.533910 13823 net.cpp:406] relu3_2/in/pw_new <- conv3_2/in/pw_new
I0822 15:54:12.533918 13823 net.cpp:367] relu3_2/in/pw_new -> conv3_2/in/pw_new (in-place)
I0822 15:54:12.533928 13823 net.cpp:122] Setting up relu3_2/in/pw_new
I0822 15:54:12.533936 13823 net.cpp:129] Top shape: 64 192 7 7 (602112)
I0822 15:54:12.533941 13823 net.cpp:137] Memory required for data: 890387968
I0822 15:54:12.533946 13823 layer_factory.hpp:77] Creating layer conv3_2/dw_new
I0822 15:54:12.533957 13823 net.cpp:84] Creating Layer conv3_2/dw_new
I0822 15:54:12.533963 13823 net.cpp:406] conv3_2/dw_new <- conv3_2/in/pw_new
I0822 15:54:12.533972 13823 net.cpp:380] conv3_2/dw_new -> conv3_2/dw_new
I0822 15:54:12.534191 13823 net.cpp:122] Setting up conv3_2/dw_new
I0822 15:54:12.534211 13823 net.cpp:129] Top shape: 64 192 7 7 (602112)
I0822 15:54:12.534217 13823 net.cpp:137] Memory required for data: 892796416
I0822 15:54:12.534226 13823 layer_factory.hpp:77] Creating layer conv3_2/dw/bn_new
I0822 15:54:12.534236 13823 net.cpp:84] Creating Layer conv3_2/dw/bn_new
I0822 15:54:12.534243 13823 net.cpp:406] conv3_2/dw/bn_new <- conv3_2/dw_new
I0822 15:54:12.534252 13823 net.cpp:367] conv3_2/dw/bn_new -> conv3_2/dw_new (in-place)
I0822 15:54:12.534574 13823 net.cpp:122] Setting up conv3_2/dw/bn_new
I0822 15:54:12.534586 13823 net.cpp:129] Top shape: 64 192 7 7 (602112)
I0822 15:54:12.534592 13823 net.cpp:137] Memory required for data: 895204864
I0822 15:54:12.534605 13823 layer_factory.hpp:77] Creating layer conv3_2/dw/scale_new
I0822 15:54:12.534615 13823 net.cpp:84] Creating Layer conv3_2/dw/scale_new
I0822 15:54:12.534621 13823 net.cpp:406] conv3_2/dw/scale_new <- conv3_2/dw_new
I0822 15:54:12.534629 13823 net.cpp:367] conv3_2/dw/scale_new -> conv3_2/dw_new (in-place)
I0822 15:54:12.534685 13823 layer_factory.hpp:77] Creating layer conv3_2/dw/scale_new
I0822 15:54:12.534869 13823 net.cpp:122] Setting up conv3_2/dw/scale_new
I0822 15:54:12.534883 13823 net.cpp:129] Top shape: 64 192 7 7 (602112)
I0822 15:54:12.534889 13823 net.cpp:137] Memory required for data: 897613312
I0822 15:54:12.534899 13823 layer_factory.hpp:77] Creating layer relu3_2/dw_new
I0822 15:54:12.534910 13823 net.cpp:84] Creating Layer relu3_2/dw_new
I0822 15:54:12.534916 13823 net.cpp:406] relu3_2/dw_new <- conv3_2/dw_new
I0822 15:54:12.534924 13823 net.cpp:367] relu3_2/dw_new -> conv3_2/dw_new (in-place)
I0822 15:54:12.534934 13823 net.cpp:122] Setting up relu3_2/dw_new
I0822 15:54:12.534941 13823 net.cpp:129] Top shape: 64 192 7 7 (602112)
I0822 15:54:12.534946 13823 net.cpp:137] Memory required for data: 900021760
I0822 15:54:12.534951 13823 layer_factory.hpp:77] Creating layer conv3_2/out/pw_new
I0822 15:54:12.534965 13823 net.cpp:84] Creating Layer conv3_2/out/pw_new
I0822 15:54:12.534970 13823 net.cpp:406] conv3_2/out/pw_new <- conv3_2/dw_new
I0822 15:54:12.534979 13823 net.cpp:380] conv3_2/out/pw_new -> conv3_2/out/pw_new
I0822 15:54:12.535521 13823 net.cpp:122] Setting up conv3_2/out/pw_new
I0822 15:54:12.535535 13823 net.cpp:129] Top shape: 64 64 7 7 (200704)
I0822 15:54:12.535542 13823 net.cpp:137] Memory required for data: 900824576
I0822 15:54:12.535549 13823 layer_factory.hpp:77] Creating layer conv3_2/out/pw/bn_new
I0822 15:54:12.535559 13823 net.cpp:84] Creating Layer conv3_2/out/pw/bn_new
I0822 15:54:12.535565 13823 net.cpp:406] conv3_2/out/pw/bn_new <- conv3_2/out/pw_new
I0822 15:54:12.535575 13823 net.cpp:367] conv3_2/out/pw/bn_new -> conv3_2/out/pw_new (in-place)
I0822 15:54:12.535892 13823 net.cpp:122] Setting up conv3_2/out/pw/bn_new
I0822 15:54:12.535903 13823 net.cpp:129] Top shape: 64 64 7 7 (200704)
I0822 15:54:12.535909 13823 net.cpp:137] Memory required for data: 901627392
I0822 15:54:12.535921 13823 layer_factory.hpp:77] Creating layer conv3_2/out/pw/scale_new
I0822 15:54:12.535931 13823 net.cpp:84] Creating Layer conv3_2/out/pw/scale_new
I0822 15:54:12.535938 13823 net.cpp:406] conv3_2/out/pw/scale_new <- conv3_2/out/pw_new
I0822 15:54:12.535948 13823 net.cpp:367] conv3_2/out/pw/scale_new -> conv3_2/out/pw_new (in-place)
I0822 15:54:12.536006 13823 layer_factory.hpp:77] Creating layer conv3_2/out/pw/scale_new
I0822 15:54:12.536203 13823 net.cpp:122] Setting up conv3_2/out/pw/scale_new
I0822 15:54:12.536219 13823 net.cpp:129] Top shape: 64 64 7 7 (200704)
I0822 15:54:12.536226 13823 net.cpp:137] Memory required for data: 902430208
I0822 15:54:12.536236 13823 layer_factory.hpp:77] Creating layer fuse_conv3_2
I0822 15:54:12.536247 13823 net.cpp:84] Creating Layer fuse_conv3_2
I0822 15:54:12.536252 13823 net.cpp:406] fuse_conv3_2 <- conv3_1/out/pw_new_conv3_1/out/pw/scale_new_0_split_1
I0822 15:54:12.536260 13823 net.cpp:406] fuse_conv3_2 <- conv3_2/out/pw_new
I0822 15:54:12.536270 13823 net.cpp:380] fuse_conv3_2 -> fuse_conv3_2
I0822 15:54:12.536307 13823 net.cpp:122] Setting up fuse_conv3_2
I0822 15:54:12.536320 13823 net.cpp:129] Top shape: 64 64 7 7 (200704)
I0822 15:54:12.536325 13823 net.cpp:137] Memory required for data: 903233024
I0822 15:54:12.536331 13823 layer_factory.hpp:77] Creating layer fc1
I0822 15:54:12.536343 13823 net.cpp:84] Creating Layer fc1
I0822 15:54:12.536350 13823 net.cpp:406] fc1 <- fuse_conv3_2
I0822 15:54:12.536358 13823 net.cpp:380] fc1 -> fc1
I0822 15:54:12.568445 13823 net.cpp:122] Setting up fc1
I0822 15:54:12.568478 13823 net.cpp:129] Top shape: 64 512 (32768)
I0822 15:54:12.568483 13823 net.cpp:137] Memory required for data: 903364096
I0822 15:54:12.568497 13823 layer_factory.hpp:77] Creating layer relu_fc1
I0822 15:54:12.568511 13823 net.cpp:84] Creating Layer relu_fc1
I0822 15:54:12.568517 13823 net.cpp:406] relu_fc1 <- fc1
I0822 15:54:12.568526 13823 net.cpp:367] relu_fc1 -> fc1 (in-place)
I0822 15:54:12.568539 13823 net.cpp:122] Setting up relu_fc1
I0822 15:54:12.568548 13823 net.cpp:129] Top shape: 64 512 (32768)
I0822 15:54:12.568552 13823 net.cpp:137] Memory required for data: 903495168
I0822 15:54:12.568557 13823 layer_factory.hpp:77] Creating layer drop_fc1
I0822 15:54:12.568567 13823 net.cpp:84] Creating Layer drop_fc1
I0822 15:54:12.568570 13823 net.cpp:406] drop_fc1 <- fc1
I0822 15:54:12.568578 13823 net.cpp:367] drop_fc1 -> fc1 (in-place)
I0822 15:54:12.568615 13823 net.cpp:122] Setting up drop_fc1
I0822 15:54:12.568625 13823 net.cpp:129] Top shape: 64 512 (32768)
I0822 15:54:12.568632 13823 net.cpp:137] Memory required for data: 903626240
I0822 15:54:12.568637 13823 layer_factory.hpp:77] Creating layer landmark_pred
I0822 15:54:12.568650 13823 net.cpp:84] Creating Layer landmark_pred
I0822 15:54:12.568656 13823 net.cpp:406] landmark_pred <- fc1
I0822 15:54:12.568663 13823 net.cpp:380] landmark_pred -> landmark_pred
I0822 15:54:12.570950 13823 net.cpp:122] Setting up landmark_pred
I0822 15:54:12.570964 13823 net.cpp:129] Top shape: 64 254 (16256)
I0822 15:54:12.570969 13823 net.cpp:137] Memory required for data: 903691264
I0822 15:54:12.570977 13823 layer_factory.hpp:77] Creating layer landmark_loss
I0822 15:54:12.570986 13823 net.cpp:84] Creating Layer landmark_loss
I0822 15:54:12.570991 13823 net.cpp:406] landmark_loss <- landmark_pred
I0822 15:54:12.570998 13823 net.cpp:406] landmark_loss <- label
I0822 15:54:12.571007 13823 net.cpp:380] landmark_loss -> landmark_loss
I0822 15:54:12.571070 13823 net.cpp:122] Setting up landmark_loss
I0822 15:54:12.571082 13823 net.cpp:129] Top shape: (1)
I0822 15:54:12.571086 13823 net.cpp:132]     with loss weight 1
I0822 15:54:12.571113 13823 net.cpp:137] Memory required for data: 903691268
I0822 15:54:12.571120 13823 net.cpp:198] landmark_loss needs backward computation.
I0822 15:54:12.571128 13823 net.cpp:198] landmark_pred needs backward computation.
I0822 15:54:12.571135 13823 net.cpp:198] drop_fc1 needs backward computation.
I0822 15:54:12.571139 13823 net.cpp:198] relu_fc1 needs backward computation.
I0822 15:54:12.571143 13823 net.cpp:198] fc1 needs backward computation.
I0822 15:54:12.571149 13823 net.cpp:198] fuse_conv3_2 needs backward computation.
I0822 15:54:12.571156 13823 net.cpp:198] conv3_2/out/pw/scale_new needs backward computation.
I0822 15:54:12.571161 13823 net.cpp:198] conv3_2/out/pw/bn_new needs backward computation.
I0822 15:54:12.571164 13823 net.cpp:198] conv3_2/out/pw_new needs backward computation.
I0822 15:54:12.571169 13823 net.cpp:198] relu3_2/dw_new needs backward computation.
I0822 15:54:12.571174 13823 net.cpp:198] conv3_2/dw/scale_new needs backward computation.
I0822 15:54:12.571179 13823 net.cpp:198] conv3_2/dw/bn_new needs backward computation.
I0822 15:54:12.571183 13823 net.cpp:198] conv3_2/dw_new needs backward computation.
I0822 15:54:12.571189 13823 net.cpp:198] relu3_2/in/pw_new needs backward computation.
I0822 15:54:12.571194 13823 net.cpp:198] conv3_2/in/pw/scale_new needs backward computation.
I0822 15:54:12.571198 13823 net.cpp:198] conv3_2/in/pw/bn_new needs backward computation.
I0822 15:54:12.571203 13823 net.cpp:198] conv3_2/in/pw_new needs backward computation.
I0822 15:54:12.571209 13823 net.cpp:198] conv3_1/out/pw_new_conv3_1/out/pw/scale_new_0_split needs backward computation.
I0822 15:54:12.571214 13823 net.cpp:198] conv3_1/out/pw/scale_new needs backward computation.
I0822 15:54:12.571218 13823 net.cpp:198] conv3_1/out/pw/bn_new needs backward computation.
I0822 15:54:12.571223 13823 net.cpp:198] conv3_1/out/pw_new needs backward computation.
I0822 15:54:12.571228 13823 net.cpp:198] relu3_1/dw_new needs backward computation.
I0822 15:54:12.571233 13823 net.cpp:198] conv3_1/dw/scale_new needs backward computation.
I0822 15:54:12.571238 13823 net.cpp:198] conv3_1/dw/bn_new needs backward computation.
I0822 15:54:12.571244 13823 net.cpp:198] conv3_1/dw_new needs backward computation.
I0822 15:54:12.571249 13823 net.cpp:198] relu3_1/in/pw_new needs backward computation.
I0822 15:54:12.571254 13823 net.cpp:198] conv3_1/in/pw/scale_new needs backward computation.
I0822 15:54:12.571259 13823 net.cpp:198] conv3_1/in/pw/bn_new needs backward computation.
I0822 15:54:12.571264 13823 net.cpp:198] conv3_1/in/pw_new needs backward computation.
I0822 15:54:12.571269 13823 net.cpp:198] fuse_conv2_2 needs backward computation.
I0822 15:54:12.571274 13823 net.cpp:198] conv2_2/out/pw/scale_new needs backward computation.
I0822 15:54:12.571280 13823 net.cpp:198] conv2_2/out/pw/bn_new needs backward computation.
I0822 15:54:12.571285 13823 net.cpp:198] conv2_2/out/pw_new needs backward computation.
I0822 15:54:12.571290 13823 net.cpp:198] relu2_2/dw_new needs backward computation.
I0822 15:54:12.571295 13823 net.cpp:198] conv2_2/dw/scale_new needs backward computation.
I0822 15:54:12.571300 13823 net.cpp:198] conv2_2/dw/bn_new needs backward computation.
I0822 15:54:12.571305 13823 net.cpp:198] conv2_2/dw_new needs backward computation.
I0822 15:54:12.571310 13823 net.cpp:198] relu2_2/in/pw_new needs backward computation.
I0822 15:54:12.571314 13823 net.cpp:198] conv2_2/in/pw/scale_new needs backward computation.
I0822 15:54:12.571319 13823 net.cpp:198] conv2_2/in/pw/bn_new needs backward computation.
I0822 15:54:12.571323 13823 net.cpp:198] conv2_2/in/pw_new needs backward computation.
I0822 15:54:12.571328 13823 net.cpp:198] conv2_1/out/pw_new_conv2_1/out/pw/scale_new_0_split needs backward computation.
I0822 15:54:12.571334 13823 net.cpp:198] conv2_1/out/pw/scale_new needs backward computation.
I0822 15:54:12.571339 13823 net.cpp:198] conv2_1/out/pw/bn_new needs backward computation.
I0822 15:54:12.571343 13823 net.cpp:198] conv2_1/out/pw_new needs backward computation.
I0822 15:54:12.571348 13823 net.cpp:198] relu2_1/dw_new needs backward computation.
I0822 15:54:12.571353 13823 net.cpp:198] conv2_1/dw/scale_new needs backward computation.
I0822 15:54:12.571358 13823 net.cpp:198] conv2_1/dw/bn_new needs backward computation.
I0822 15:54:12.571363 13823 net.cpp:198] conv2_1/dw_new needs backward computation.
I0822 15:54:12.571368 13823 net.cpp:198] relu2_1/in/pw_new needs backward computation.
I0822 15:54:12.571373 13823 net.cpp:198] conv2_1/in/pw/scale_new needs backward computation.
I0822 15:54:12.571377 13823 net.cpp:198] conv2_1/in/pw/bn_new needs backward computation.
I0822 15:54:12.571382 13823 net.cpp:198] conv2_1/in/pw_new needs backward computation.
I0822 15:54:12.571388 13823 net.cpp:198] fuse_conv1_2 needs backward computation.
I0822 15:54:12.571394 13823 net.cpp:198] conv1_2/out/pw/scale_new needs backward computation.
I0822 15:54:12.571398 13823 net.cpp:198] conv1_2/out/pw/bn_new needs backward computation.
I0822 15:54:12.571403 13823 net.cpp:198] conv1_2/out/pw_new needs backward computation.
I0822 15:54:12.571409 13823 net.cpp:198] relu1_2/dw_new needs backward computation.
I0822 15:54:12.571414 13823 net.cpp:198] conv1_2/dw/scale_new needs backward computation.
I0822 15:54:12.571419 13823 net.cpp:198] conv1_2/dw/bn_new needs backward computation.
I0822 15:54:12.571424 13823 net.cpp:198] conv1_2/dw_new needs backward computation.
I0822 15:54:12.571429 13823 net.cpp:198] relu1_2/in/pw_new needs backward computation.
I0822 15:54:12.571434 13823 net.cpp:198] conv1_2/in/pw/scale_new needs backward computation.
I0822 15:54:12.571439 13823 net.cpp:198] conv1_2/in/pw/bn_new needs backward computation.
I0822 15:54:12.571442 13823 net.cpp:198] conv1_2/in/pw_new needs backward computation.
I0822 15:54:12.571447 13823 net.cpp:198] conv1_1/out/pw_new_conv1_1/out/pw/scale_new_0_split needs backward computation.
I0822 15:54:12.571458 13823 net.cpp:198] conv1_1/out/pw/scale_new needs backward computation.
I0822 15:54:12.571462 13823 net.cpp:198] conv1_1/out/pw/bn_new needs backward computation.
I0822 15:54:12.571467 13823 net.cpp:198] conv1_1/out/pw_new needs backward computation.
I0822 15:54:12.571472 13823 net.cpp:198] relu1_1/dw_new needs backward computation.
I0822 15:54:12.571477 13823 net.cpp:198] conv1_1/dw/scale_new needs backward computation.
I0822 15:54:12.571481 13823 net.cpp:198] conv1_1/dw/bn_new needs backward computation.
I0822 15:54:12.571486 13823 net.cpp:198] conv1_1/dw_new needs backward computation.
I0822 15:54:12.571491 13823 net.cpp:198] relu1_1/in/pw_new needs backward computation.
I0822 15:54:12.571496 13823 net.cpp:198] conv1_1/in/pw/scale_new needs backward computation.
I0822 15:54:12.571501 13823 net.cpp:198] conv1_1/in/pw/bn_new needs backward computation.
I0822 15:54:12.571506 13823 net.cpp:198] conv1_1/in/pw_new needs backward computation.
I0822 15:54:12.571511 13823 net.cpp:198] relu1_new needs backward computation.
I0822 15:54:12.571516 13823 net.cpp:198] conv1/scale_new needs backward computation.
I0822 15:54:12.571519 13823 net.cpp:198] conv1/bn_new needs backward computation.
I0822 15:54:12.571524 13823 net.cpp:198] conv1_new needs backward computation.
I0822 15:54:12.571530 13823 net.cpp:200] data does not need backward computation.
I0822 15:54:12.571534 13823 net.cpp:242] This network produces output landmark_loss
I0822 15:54:12.571606 13823 net.cpp:255] Network initialization done.
I0822 15:54:12.572769 13823 upgrade_proto.cpp:79] Attempting to upgrade batch norm layers using deprecated params: ./cascade_mobilenet_112.prototxt
I0822 15:54:12.572788 13823 upgrade_proto.cpp:82] Successfully upgraded batch norm layers using deprecated params.
I0822 15:54:12.572796 13823 solver.cpp:190] Creating test net (#0) specified by net file: ./cascade_mobilenet_112.prototxt
I0822 15:54:12.572909 13823 net.cpp:294] The NetState phase (1) differed from the phase (0) specified by a rule in layer data
I0822 15:54:12.573729 13823 net.cpp:51] Initializing net from parameters: 
name: "subMobileNet"
state {
  phase: TEST
}
layer {
  name: "data"
  type: "HDF5Data"
  top: "data"
  top: "label"
  include {
    phase: TEST
  }
  hdf5_data_param {
    source: "/home/sxdz/data/landmark/beadwallet/samples/valHDF5/112/hdf5-norm.txt"
    batch_size: 64
    shuffle: true
  }
}
layer {
  name: "conv1_new"
  type: "Convolution"
  bottom: "data"
  top: "conv1_new"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  convolution_param {
    num_output: 16
    bias_term: false
    pad: 1
    kernel_size: 3
    stride: 2
    weight_filler {
      type: "msra"
    }
  }
}
layer {
  name: "conv1/bn_new"
  type: "BatchNorm"
  bottom: "conv1_new"
  top: "conv1_new"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "conv1/scale_new"
  type: "Scale"
  bottom: "conv1_new"
  top: "conv1_new"
  scale_param {
    filler {
      value: 1
    }
    bias_term: true
    bias_filler {
      value: 0
    }
  }
}
layer {
  name: "relu1_new"
  type: "ReLU"
  bottom: "conv1_new"
  top: "conv1_new"
}
layer {
  name: "conv1_1/in/pw_new"
  type: "Convolution"
  bottom: "conv1_new"
  top: "conv1_1/in/pw_new"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  convolution_param {
    num_output: 64
    bias_term: false
    pad: 0
    kernel_size: 1
    stride: 1
    weight_filler {
      type: "msra"
    }
    engine: CAFFE
  }
}
layer {
  name: "conv1_1/in/pw/bn_new"
  type: "BatchNorm"
  bottom: "conv1_1/in/pw_new"
  top: "conv1_1/in/pw_new"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "conv1_1/in/pw/scale_new"
  type: "Scale"
  bottom: "conv1_1/in/pw_new"
  top: "conv1_1/in/pw_new"
  scale_param {
    filler {
      value: 1
    }
    bias_term: true
    bias_filler {
      value: 0
    }
  }
}
layer {
  name: "relu1_1/in/pw_new"
  type: "ReLU"
  bottom: "conv1_1/in/pw_new"
  top: "conv1_1/in/pw_new"
}
layer {
  name: "conv1_1/dw_new"
  type: "ConvolutionDepthwise"
  bottom: "conv1_1/in/pw_new"
  top: "conv1_1/dw_new"
  param {
    lr_mult: 1
    decay_mult: 0
  }
  convolution_param {
    num_output: 64
    bias_term: false
    pad: 1
    kernel_size: 3
    stride: 2
    weight_filler {
      type: "msra"
    }
    engine: CAFFE
  }
}
layer {
  name: "conv1_1/dw/bn_new"
  type: "BatchNorm"
  bottom: "conv1_1/dw_new"
  top: "conv1_1/dw_new"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "conv1_1/dw/scale_new"
  type: "Scale"
  bottom: "conv1_1/dw_new"
  top: "conv1_1/dw_new"
  scale_param {
    filler {
      value: 1
    }
    bias_term: true
    bias_filler {
      value: 0
    }
  }
}
layer {
  name: "relu1_1/dw_new"
  type: "ReLU"
  bottom: "conv1_1/dw_new"
  top: "conv1_1/dw_new"
}
layer {
  name: "conv1_1/out/pw_new"
  type: "Convolution"
  bottom: "conv1_1/dw_new"
  top: "conv1_1/out/pw_new"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  convolution_param {
    num_output: 24
    bias_term: false
    pad: 0
    kernel_size: 1
    stride: 1
    weight_filler {
      type: "msra"
    }
    engine: CAFFE
  }
}
layer {
  name: "conv1_1/out/pw/bn_new"
  type: "BatchNorm"
  bottom: "conv1_1/out/pw_new"
  top: "conv1_1/out/pw_new"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "conv1_1/out/pw/scale_new"
  type: "Scale"
  bottom: "conv1_1/out/pw_new"
  top: "conv1_1/out/pw_new"
  scale_param {
    filler {
      value: 1
    }
    bias_term: true
    bias_filler {
      value: 0
    }
  }
}
layer {
  name: "conv1_2/in/pw_new"
  type: "Convolution"
  bottom: "conv1_1/out/pw_new"
  top: "conv1_2/in/pw_new"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  convolution_param {
    num_output: 144
    bias_term: false
    pad: 0
    kernel_size: 1
    stride: 1
    weight_filler {
      type: "msra"
    }
    engine: CAFFE
  }
}
layer {
  name: "conv1_2/in/pw/bn_new"
  type: "BatchNorm"
  bottom: "conv1_2/in/pw_new"
  top: "conv1_2/in/pw_new"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "conv1_2/in/pw/scale_new"
  type: "Scale"
  bottom: "conv1_2/in/pw_new"
  top: "conv1_2/in/pw_new"
  scale_param {
    filler {
      value: 1
    }
    bias_term: true
    bias_filler {
      value: 0
    }
  }
}
layer {
  name: "relu1_2/in/pw_new"
  type: "ReLU"
  bottom: "conv1_2/in/pw_new"
  top: "conv1_2/in/pw_new"
}
layer {
  name: "conv1_2/dw_new"
  type: "ConvolutionDepthwise"
  bottom: "conv1_2/in/pw_new"
  top: "conv1_2/dw_new"
  param {
    lr_mult: 1
    decay_mult: 0
  }
  convolution_param {
    num_output: 144
    bias_term: false
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    engine: CAFFE
  }
}
layer {
  name: "conv1_2/dw/bn_new"
  type: "BatchNorm"
  bottom: "conv1_2/dw_new"
  top: "conv1_2/dw_new"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "conv1_2/dw/scale_new"
  type: "Scale"
  bottom: "conv1_2/dw_new"
  top: "conv1_2/dw_new"
  scale_param {
    filler {
      value: 1
    }
    bias_term: true
    bias_filler {
      value: 0
    }
  }
}
layer {
  name: "relu1_2/dw_new"
  type: "ReLU"
  bottom: "conv1_2/dw_new"
  top: "conv1_2/dw_new"
}
layer {
  name: "conv1_2/out/pw_new"
  type: "Convolution"
  bottom: "conv1_2/dw_new"
  top: "conv1_2/out/pw_new"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  convolution_param {
    num_output: 24
    bias_term: false
    pad: 0
    kernel_size: 1
    stride: 1
    weight_filler {
      type: "msra"
    }
    engine: CAFFE
  }
}
layer {
  name: "conv1_2/out/pw/bn_new"
  type: "BatchNorm"
  bottom: "conv1_2/out/pw_new"
  top: "conv1_2/out/pw_new"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "conv1_2/out/pw/scale_new"
  type: "Scale"
  bottom: "conv1_2/out/pw_new"
  top: "conv1_2/out/pw_new"
  scale_param {
    filler {
      value: 1
    }
    bias_term: true
    bias_filler {
      value: 0
    }
  }
}
layer {
  name: "fuse_conv1_2"
  type: "Eltwise"
  bottom: "conv1_1/out/pw_new"
  bottom: "conv1_2/out/pw_new"
  top: "fuse_conv1_2"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "conv2_1/in/pw_new"
  type: "Convolution"
  bottom: "fuse_conv1_2"
  top: "conv2_1/in/pw_new"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  convolution_param {
    num_output: 144
    bias_term: false
    pad: 0
    kernel_size: 1
    stride: 1
    weight_filler {
      type: "msra"
    }
    engine: CAFFE
  }
}
layer {
  name: "conv2_1/in/pw/bn_new"
  type: "BatchNorm"
  bottom: "conv2_1/in/pw_new"
  top: "conv2_1/in/pw_new"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "conv2_1/in/pw/scale_new"
  type: "Scale"
  bottom: "conv2_1/in/pw_new"
  top: "conv2_1/in/pw_new"
  scale_param {
    filler {
      value: 1
    }
    bias_term: true
    bias_filler {
      value: 0
    }
  }
}
layer {
  name: "relu2_1/in/pw_new"
  type: "ReLU"
  bottom: "conv2_1/in/pw_new"
  top: "conv2_1/in/pw_new"
}
layer {
  name: "conv2_1/dw_new"
  type: "ConvolutionDepthwise"
  bottom: "conv2_1/in/pw_new"
  top: "conv2_1/dw_new"
  param {
    lr_mult: 1
    decay_mult: 0
  }
  convolution_param {
    num_output: 144
    bias_term: false
    pad: 1
    kernel_size: 3
    stride: 2
    weight_filler {
      type: "msra"
    }
    engine: CAFFE
  }
}
layer {
  name: "conv2_1/dw/bn_new"
  type: "BatchNorm"
  bottom: "conv2_1/dw_new"
  top: "conv2_1/dw_new"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "conv2_1/dw/scale_new"
  type: "Scale"
  bottom: "conv2_1/dw_new"
  top: "conv2_1/dw_new"
  scale_param {
    filler {
      value: 1
    }
    bias_term: true
    bias_filler {
      value: 0
    }
  }
}
layer {
  name: "relu2_1/dw_new"
  type: "ReLU"
  bottom: "conv2_1/dw_new"
  top: "conv2_1/dw_new"
}
layer {
  name: "conv2_1/out/pw_new"
  type: "Convolution"
  bottom: "conv2_1/dw_new"
  top: "conv2_1/out/pw_new"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  convolution_param {
    num_output: 32
    bias_term: false
    pad: 0
    kernel_size: 1
    stride: 1
    weight_filler {
      type: "msra"
    }
    engine: CAFFE
  }
}
layer {
  name: "conv2_1/out/pw/bn_new"
  type: "BatchNorm"
  bottom: "conv2_1/out/pw_new"
  top: "conv2_1/out/pw_new"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "conv2_1/out/pw/scale_new"
  type: "Scale"
  bottom: "conv2_1/out/pw_new"
  top: "conv2_1/out/pw_new"
  scale_param {
    filler {
      value: 1
    }
    bias_term: true
    bias_filler {
      value: 0
    }
  }
}
layer {
  name: "conv2_2/in/pw_new"
  type: "Convolution"
  bottom: "conv2_1/out/pw_new"
  top: "conv2_2/in/pw_new"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  convolution_param {
    num_output: 192
    bias_term: false
    pad: 0
    kernel_size: 1
    stride: 1
    weight_filler {
      type: "msra"
    }
    engine: CAFFE
  }
}
layer {
  name: "conv2_2/in/pw/bn_new"
  type: "BatchNorm"
  bottom: "conv2_2/in/pw_new"
  top: "conv2_2/in/pw_new"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "conv2_2/in/pw/scale_new"
  type: "Scale"
  bottom: "conv2_2/in/pw_new"
  top: "conv2_2/in/pw_new"
  scale_param {
    filler {
      value: 1
    }
    bias_term: true
    bias_filler {
      value: 0
    }
  }
}
layer {
  name: "relu2_2/in/pw_new"
  type: "ReLU"
  bottom: "conv2_2/in/pw_new"
  top: "conv2_2/in/pw_new"
}
layer {
  name: "conv2_2/dw_new"
  type: "ConvolutionDepthwise"
  bottom: "conv2_2/in/pw_new"
  top: "conv2_2/dw_new"
  param {
    lr_mult: 1
    decay_mult: 0
  }
  convolution_param {
    num_output: 192
    bias_term: false
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    engine: CAFFE
  }
}
layer {
  name: "conv2_2/dw/bn_new"
  type: "BatchNorm"
  bottom: "conv2_2/dw_new"
  top: "conv2_2/dw_new"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "conv2_2/dw/scale_new"
  type: "Scale"
  bottom: "conv2_2/dw_new"
  top: "conv2_2/dw_new"
  scale_param {
    filler {
      value: 1
    }
    bias_term: true
    bias_filler {
      value: 0
    }
  }
}
layer {
  name: "relu2_2/dw_new"
  type: "ReLU"
  bottom: "conv2_2/dw_new"
  top: "conv2_2/dw_new"
}
layer {
  name: "conv2_2/out/pw_new"
  type: "Convolution"
  bottom: "conv2_2/dw_new"
  top: "conv2_2/out/pw_new"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  convolution_param {
    num_output: 32
    bias_term: false
    pad: 0
    kernel_size: 1
    stride: 1
    weight_filler {
      type: "msra"
    }
    engine: CAFFE
  }
}
layer {
  name: "conv2_2/out/pw/bn_new"
  type: "BatchNorm"
  bottom: "conv2_2/out/pw_new"
  top: "conv2_2/out/pw_new"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "conv2_2/out/pw/scale_new"
  type: "Scale"
  bottom: "conv2_2/out/pw_new"
  top: "conv2_2/out/pw_new"
  scale_param {
    filler {
      value: 1
    }
    bias_term: true
    bias_filler {
      value: 0
    }
  }
}
layer {
  name: "fuse_conv2_2"
  type: "Eltwise"
  bottom: "conv2_1/out/pw_new"
  bottom: "conv2_2/out/pw_new"
  top: "fuse_conv2_2"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "conv3_1/in/pw_new"
  type: "Convolution"
  bottom: "fuse_conv2_2"
  top: "conv3_1/in/pw_new"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  convolution_param {
    num_output: 192
    bias_term: false
    pad: 0
    kernel_size: 1
    stride: 1
    weight_filler {
      type: "msra"
    }
    engine: CAFFE
  }
}
layer {
  name: "conv3_1/in/pw/bn_new"
  type: "BatchNorm"
  bottom: "conv3_1/in/pw_new"
  top: "conv3_1/in/pw_new"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "conv3_1/in/pw/scale_new"
  type: "Scale"
  bottom: "conv3_1/in/pw_new"
  top: "conv3_1/in/pw_new"
  scale_param {
    filler {
      value: 1
    }
    bias_term: true
    bias_filler {
      value: 0
    }
  }
}
layer {
  name: "relu3_1/in/pw_new"
  type: "ReLU"
  bottom: "conv3_1/in/pw_new"
  top: "conv3_1/in/pw_new"
}
layer {
  name: "conv3_1/dw_new"
  type: "ConvolutionDepthwise"
  bottom: "conv3_1/in/pw_new"
  top: "conv3_1/dw_new"
  param {
    lr_mult: 1
    decay_mult: 0
  }
  convolution_param {
    num_output: 192
    bias_term: false
    pad: 1
    kernel_size: 3
    stride: 2
    weight_filler {
      type: "msra"
    }
    engine: CAFFE
  }
}
layer {
  name: "conv3_1/dw/bn_new"
  type: "BatchNorm"
  bottom: "conv3_1/dw_new"
  top: "conv3_1/dw_new"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "conv3_1/dw/scale_new"
  type: "Scale"
  bottom: "conv3_1/dw_new"
  top: "conv3_1/dw_new"
  scale_param {
    filler {
      value: 1
    }
    bias_term: true
    bias_filler {
      value: 0
    }
  }
}
layer {
  name: "relu3_1/dw_new"
  type: "ReLU"
  bottom: "conv3_1/dw_new"
  top: "conv3_1/dw_new"
}
layer {
  name: "conv3_1/out/pw_new"
  type: "Convolution"
  bottom: "conv3_1/dw_new"
  top: "conv3_1/out/pw_new"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  convolution_param {
    num_output: 64
    bias_term: false
    pad: 0
    kernel_size: 1
    stride: 1
    weight_filler {
      type: "msra"
    }
    engine: CAFFE
  }
}
layer {
  name: "conv3_1/out/pw/bn_new"
  type: "BatchNorm"
  bottom: "conv3_1/out/pw_new"
  top: "conv3_1/out/pw_new"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "conv3_1/out/pw/scale_new"
  type: "Scale"
  bottom: "conv3_1/out/pw_new"
  top: "conv3_1/out/pw_new"
  scale_param {
    filler {
      value: 1
    }
    bias_term: true
    bias_filler {
      value: 0
    }
  }
}
layer {
  name: "conv3_2/in/pw_new"
  type: "Convolution"
  bottom: "conv3_1/out/pw_new"
  top: "conv3_2/in/pw_new"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  convolution_param {
    num_output: 192
    bias_term: false
    pad: 0
    kernel_size: 1
    stride: 1
    weight_filler {
      type: "msra"
    }
    engine: CAFFE
  }
}
layer {
  name: "conv3_2/in/pw/bn_new"
  type: "BatchNorm"
  bottom: "conv3_2/in/pw_new"
  top: "conv3_2/in/pw_new"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "conv3_2/in/pw/scale_new"
  type: "Scale"
  bottom: "conv3_2/in/pw_new"
  top: "conv3_2/in/pw_new"
  scale_param {
    filler {
      value: 1
    }
    bias_term: true
    bias_filler {
      value: 0
    }
  }
}
layer {
  name: "relu3_2/in/pw_new"
  type: "ReLU"
  bottom: "conv3_2/in/pw_new"
  top: "conv3_2/in/pw_new"
}
layer {
  name: "conv3_2/dw_new"
  type: "ConvolutionDepthwise"
  bottom: "conv3_2/in/pw_new"
  top: "conv3_2/dw_new"
  param {
    lr_mult: 1
    decay_mult: 0
  }
  convolution_param {
    num_output: 192
    bias_term: false
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    engine: CAFFE
  }
}
layer {
  name: "conv3_2/dw/bn_new"
  type: "BatchNorm"
  bottom: "conv3_2/dw_new"
  top: "conv3_2/dw_new"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "conv3_2/dw/scale_new"
  type: "Scale"
  bottom: "conv3_2/dw_new"
  top: "conv3_2/dw_new"
  scale_param {
    filler {
      value: 1
    }
    bias_term: true
    bias_filler {
      value: 0
    }
  }
}
layer {
  name: "relu3_2/dw_new"
  type: "ReLU"
  bottom: "conv3_2/dw_new"
  top: "conv3_2/dw_new"
}
layer {
  name: "conv3_2/out/pw_new"
  type: "Convolution"
  bottom: "conv3_2/dw_new"
  top: "conv3_2/out/pw_new"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  convolution_param {
    num_output: 64
    bias_term: false
    pad: 0
    kernel_size: 1
    stride: 1
    weight_filler {
      type: "msra"
    }
    engine: CAFFE
  }
}
layer {
  name: "conv3_2/out/pw/bn_new"
  type: "BatchNorm"
  bottom: "conv3_2/out/pw_new"
  top: "conv3_2/out/pw_new"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "conv3_2/out/pw/scale_new"
  type: "Scale"
  bottom: "conv3_2/out/pw_new"
  top: "conv3_2/out/pw_new"
  scale_param {
    filler {
      value: 1
    }
    bias_term: true
    bias_filler {
      value: 0
    }
  }
}
layer {
  name: "fuse_conv3_2"
  type: "Eltwise"
  bottom: "conv3_1/out/pw_new"
  bottom: "conv3_2/out/pw_new"
  top: "fuse_conv3_2"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "fc1"
  type: "InnerProduct"
  bottom: "fuse_conv3_2"
  top: "fc1"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 1
  }
  inner_product_param {
    num_output: 512
    weight_filler {
      type: "gaussian"
      std: 0.01
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "relu_fc1"
  type: "ReLU"
  bottom: "fc1"
  top: "fc1"
}
layer {
  name: "drop_fc1"
  type: "Dropout"
  bottom: "fc1"
  top: "fc1"
  dropout_param {
    dropout_ratio: 0.3
  }
}
layer {
  name: "landmark_pred"
  type: "InnerProduct"
  bottom: "fc1"
  top: "landmark_pred"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 1
  }
  inner_product_param {
    num_output: 254
    weight_filler {
      type: "gaussian"
      std: 0.01
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "landmark_loss"
  type: "EuclideanLoss"
  bottom: "landmark_pred"
  bottom: "label"
  top: "landmark_loss"
  loss_weight: 1
}
I0822 15:54:12.574075 13823 layer_factory.hpp:77] Creating layer data
I0822 15:54:12.574090 13823 net.cpp:84] Creating Layer data
I0822 15:54:12.574096 13823 net.cpp:380] data -> data
I0822 15:54:12.574107 13823 net.cpp:380] data -> label
I0822 15:54:12.574117 13823 hdf5_data_layer.cpp:80] Loading list of HDF5 filenames from: /home/sxdz/data/landmark/beadwallet/samples/valHDF5/112/hdf5-norm.txt
I0822 15:54:12.575668 13823 hdf5_data_layer.cpp:94] Number of HDF5 files: 1218
I0822 15:54:12.610431 13823 net.cpp:122] Setting up data
I0822 15:54:12.610468 13823 net.cpp:129] Top shape: 64 3 112 112 (2408448)
I0822 15:54:12.610477 13823 net.cpp:129] Top shape: 64 254 (16256)
I0822 15:54:12.610481 13823 net.cpp:137] Memory required for data: 9698816
I0822 15:54:12.610489 13823 layer_factory.hpp:77] Creating layer conv1_new
I0822 15:54:12.610512 13823 net.cpp:84] Creating Layer conv1_new
I0822 15:54:12.610517 13823 net.cpp:406] conv1_new <- data
I0822 15:54:12.610528 13823 net.cpp:380] conv1_new -> conv1_new
I0822 15:54:12.610793 13823 net.cpp:122] Setting up conv1_new
I0822 15:54:12.610808 13823 net.cpp:129] Top shape: 64 16 56 56 (3211264)
I0822 15:54:12.610812 13823 net.cpp:137] Memory required for data: 22543872
I0822 15:54:12.610823 13823 layer_factory.hpp:77] Creating layer conv1/bn_new
I0822 15:54:12.610834 13823 net.cpp:84] Creating Layer conv1/bn_new
I0822 15:54:12.610841 13823 net.cpp:406] conv1/bn_new <- conv1_new
I0822 15:54:12.610848 13823 net.cpp:367] conv1/bn_new -> conv1_new (in-place)
I0822 15:54:12.611093 13823 net.cpp:122] Setting up conv1/bn_new
I0822 15:54:12.611106 13823 net.cpp:129] Top shape: 64 16 56 56 (3211264)
I0822 15:54:12.611110 13823 net.cpp:137] Memory required for data: 35388928
I0822 15:54:12.611124 13823 layer_factory.hpp:77] Creating layer conv1/scale_new
I0822 15:54:12.611135 13823 net.cpp:84] Creating Layer conv1/scale_new
I0822 15:54:12.611140 13823 net.cpp:406] conv1/scale_new <- conv1_new
I0822 15:54:12.611146 13823 net.cpp:367] conv1/scale_new -> conv1_new (in-place)
I0822 15:54:12.611196 13823 layer_factory.hpp:77] Creating layer conv1/scale_new
I0822 15:54:12.611344 13823 net.cpp:122] Setting up conv1/scale_new
I0822 15:54:12.611356 13823 net.cpp:129] Top shape: 64 16 56 56 (3211264)
I0822 15:54:12.611361 13823 net.cpp:137] Memory required for data: 48233984
I0822 15:54:12.611371 13823 layer_factory.hpp:77] Creating layer relu1_new
I0822 15:54:12.611379 13823 net.cpp:84] Creating Layer relu1_new
I0822 15:54:12.611384 13823 net.cpp:406] relu1_new <- conv1_new
I0822 15:54:12.611392 13823 net.cpp:367] relu1_new -> conv1_new (in-place)
I0822 15:54:12.611399 13823 net.cpp:122] Setting up relu1_new
I0822 15:54:12.611405 13823 net.cpp:129] Top shape: 64 16 56 56 (3211264)
I0822 15:54:12.611409 13823 net.cpp:137] Memory required for data: 61079040
I0822 15:54:12.611413 13823 layer_factory.hpp:77] Creating layer conv1_1/in/pw_new
I0822 15:54:12.611423 13823 net.cpp:84] Creating Layer conv1_1/in/pw_new
I0822 15:54:12.611428 13823 net.cpp:406] conv1_1/in/pw_new <- conv1_new
I0822 15:54:12.611434 13823 net.cpp:380] conv1_1/in/pw_new -> conv1_1/in/pw_new
I0822 15:54:12.611670 13823 net.cpp:122] Setting up conv1_1/in/pw_new
I0822 15:54:12.611682 13823 net.cpp:129] Top shape: 64 64 56 56 (12845056)
I0822 15:54:12.611686 13823 net.cpp:137] Memory required for data: 112459264
I0822 15:54:12.611693 13823 layer_factory.hpp:77] Creating layer conv1_1/in/pw/bn_new
I0822 15:54:12.611702 13823 net.cpp:84] Creating Layer conv1_1/in/pw/bn_new
I0822 15:54:12.611707 13823 net.cpp:406] conv1_1/in/pw/bn_new <- conv1_1/in/pw_new
I0822 15:54:12.611714 13823 net.cpp:367] conv1_1/in/pw/bn_new -> conv1_1/in/pw_new (in-place)
I0822 15:54:12.611948 13823 net.cpp:122] Setting up conv1_1/in/pw/bn_new
I0822 15:54:12.611959 13823 net.cpp:129] Top shape: 64 64 56 56 (12845056)
I0822 15:54:12.611964 13823 net.cpp:137] Memory required for data: 163839488
I0822 15:54:12.611976 13823 layer_factory.hpp:77] Creating layer conv1_1/in/pw/scale_new
I0822 15:54:12.611984 13823 net.cpp:84] Creating Layer conv1_1/in/pw/scale_new
I0822 15:54:12.611989 13823 net.cpp:406] conv1_1/in/pw/scale_new <- conv1_1/in/pw_new
I0822 15:54:12.611996 13823 net.cpp:367] conv1_1/in/pw/scale_new -> conv1_1/in/pw_new (in-place)
I0822 15:54:12.612042 13823 layer_factory.hpp:77] Creating layer conv1_1/in/pw/scale_new
I0822 15:54:12.612200 13823 net.cpp:122] Setting up conv1_1/in/pw/scale_new
I0822 15:54:12.612212 13823 net.cpp:129] Top shape: 64 64 56 56 (12845056)
I0822 15:54:12.612217 13823 net.cpp:137] Memory required for data: 215219712
I0822 15:54:12.612226 13823 layer_factory.hpp:77] Creating layer relu1_1/in/pw_new
I0822 15:54:12.612236 13823 net.cpp:84] Creating Layer relu1_1/in/pw_new
I0822 15:54:12.612241 13823 net.cpp:406] relu1_1/in/pw_new <- conv1_1/in/pw_new
I0822 15:54:12.612247 13823 net.cpp:367] relu1_1/in/pw_new -> conv1_1/in/pw_new (in-place)
I0822 15:54:12.612268 13823 net.cpp:122] Setting up relu1_1/in/pw_new
I0822 15:54:12.612275 13823 net.cpp:129] Top shape: 64 64 56 56 (12845056)
I0822 15:54:12.612280 13823 net.cpp:137] Memory required for data: 266599936
I0822 15:54:12.612284 13823 layer_factory.hpp:77] Creating layer conv1_1/dw_new
I0822 15:54:12.612295 13823 net.cpp:84] Creating Layer conv1_1/dw_new
I0822 15:54:12.612299 13823 net.cpp:406] conv1_1/dw_new <- conv1_1/in/pw_new
I0822 15:54:12.612308 13823 net.cpp:380] conv1_1/dw_new -> conv1_1/dw_new
I0822 15:54:12.612514 13823 net.cpp:122] Setting up conv1_1/dw_new
I0822 15:54:12.612532 13823 net.cpp:129] Top shape: 64 64 28 28 (3211264)
I0822 15:54:12.612537 13823 net.cpp:137] Memory required for data: 279444992
I0822 15:54:12.612545 13823 layer_factory.hpp:77] Creating layer conv1_1/dw/bn_new
I0822 15:54:12.612553 13823 net.cpp:84] Creating Layer conv1_1/dw/bn_new
I0822 15:54:12.612558 13823 net.cpp:406] conv1_1/dw/bn_new <- conv1_1/dw_new
I0822 15:54:12.612566 13823 net.cpp:367] conv1_1/dw/bn_new -> conv1_1/dw_new (in-place)
I0822 15:54:12.612821 13823 net.cpp:122] Setting up conv1_1/dw/bn_new
I0822 15:54:12.612833 13823 net.cpp:129] Top shape: 64 64 28 28 (3211264)
I0822 15:54:12.612838 13823 net.cpp:137] Memory required for data: 292290048
I0822 15:54:12.612848 13823 layer_factory.hpp:77] Creating layer conv1_1/dw/scale_new
I0822 15:54:12.612855 13823 net.cpp:84] Creating Layer conv1_1/dw/scale_new
I0822 15:54:12.612860 13823 net.cpp:406] conv1_1/dw/scale_new <- conv1_1/dw_new
I0822 15:54:12.612869 13823 net.cpp:367] conv1_1/dw/scale_new -> conv1_1/dw_new (in-place)
I0822 15:54:12.612916 13823 layer_factory.hpp:77] Creating layer conv1_1/dw/scale_new
I0822 15:54:12.613067 13823 net.cpp:122] Setting up conv1_1/dw/scale_new
I0822 15:54:12.613080 13823 net.cpp:129] Top shape: 64 64 28 28 (3211264)
I0822 15:54:12.613083 13823 net.cpp:137] Memory required for data: 305135104
I0822 15:54:12.613096 13823 layer_factory.hpp:77] Creating layer relu1_1/dw_new
I0822 15:54:12.613106 13823 net.cpp:84] Creating Layer relu1_1/dw_new
I0822 15:54:12.613111 13823 net.cpp:406] relu1_1/dw_new <- conv1_1/dw_new
I0822 15:54:12.613117 13823 net.cpp:367] relu1_1/dw_new -> conv1_1/dw_new (in-place)
I0822 15:54:12.613126 13823 net.cpp:122] Setting up relu1_1/dw_new
I0822 15:54:12.613132 13823 net.cpp:129] Top shape: 64 64 28 28 (3211264)
I0822 15:54:12.613137 13823 net.cpp:137] Memory required for data: 317980160
I0822 15:54:12.613140 13823 layer_factory.hpp:77] Creating layer conv1_1/out/pw_new
I0822 15:54:12.613152 13823 net.cpp:84] Creating Layer conv1_1/out/pw_new
I0822 15:54:12.613155 13823 net.cpp:406] conv1_1/out/pw_new <- conv1_1/dw_new
I0822 15:54:12.613163 13823 net.cpp:380] conv1_1/out/pw_new -> conv1_1/out/pw_new
I0822 15:54:12.613420 13823 net.cpp:122] Setting up conv1_1/out/pw_new
I0822 15:54:12.613432 13823 net.cpp:129] Top shape: 64 24 28 28 (1204224)
I0822 15:54:12.613437 13823 net.cpp:137] Memory required for data: 322797056
I0822 15:54:12.613443 13823 layer_factory.hpp:77] Creating layer conv1_1/out/pw/bn_new
I0822 15:54:12.613451 13823 net.cpp:84] Creating Layer conv1_1/out/pw/bn_new
I0822 15:54:12.613456 13823 net.cpp:406] conv1_1/out/pw/bn_new <- conv1_1/out/pw_new
I0822 15:54:12.613464 13823 net.cpp:367] conv1_1/out/pw/bn_new -> conv1_1/out/pw_new (in-place)
I0822 15:54:12.613713 13823 net.cpp:122] Setting up conv1_1/out/pw/bn_new
I0822 15:54:12.613725 13823 net.cpp:129] Top shape: 64 24 28 28 (1204224)
I0822 15:54:12.613730 13823 net.cpp:137] Memory required for data: 327613952
I0822 15:54:12.613740 13823 layer_factory.hpp:77] Creating layer conv1_1/out/pw/scale_new
I0822 15:54:12.613749 13823 net.cpp:84] Creating Layer conv1_1/out/pw/scale_new
I0822 15:54:12.613754 13823 net.cpp:406] conv1_1/out/pw/scale_new <- conv1_1/out/pw_new
I0822 15:54:12.613760 13823 net.cpp:367] conv1_1/out/pw/scale_new -> conv1_1/out/pw_new (in-place)
I0822 15:54:12.613806 13823 layer_factory.hpp:77] Creating layer conv1_1/out/pw/scale_new
I0822 15:54:12.613953 13823 net.cpp:122] Setting up conv1_1/out/pw/scale_new
I0822 15:54:12.613965 13823 net.cpp:129] Top shape: 64 24 28 28 (1204224)
I0822 15:54:12.613970 13823 net.cpp:137] Memory required for data: 332430848
I0822 15:54:12.613977 13823 layer_factory.hpp:77] Creating layer conv1_1/out/pw_new_conv1_1/out/pw/scale_new_0_split
I0822 15:54:12.613991 13823 net.cpp:84] Creating Layer conv1_1/out/pw_new_conv1_1/out/pw/scale_new_0_split
I0822 15:54:12.613996 13823 net.cpp:406] conv1_1/out/pw_new_conv1_1/out/pw/scale_new_0_split <- conv1_1/out/pw_new
I0822 15:54:12.614002 13823 net.cpp:380] conv1_1/out/pw_new_conv1_1/out/pw/scale_new_0_split -> conv1_1/out/pw_new_conv1_1/out/pw/scale_new_0_split_0
I0822 15:54:12.614013 13823 net.cpp:380] conv1_1/out/pw_new_conv1_1/out/pw/scale_new_0_split -> conv1_1/out/pw_new_conv1_1/out/pw/scale_new_0_split_1
I0822 15:54:12.614058 13823 net.cpp:122] Setting up conv1_1/out/pw_new_conv1_1/out/pw/scale_new_0_split
I0822 15:54:12.614068 13823 net.cpp:129] Top shape: 64 24 28 28 (1204224)
I0822 15:54:12.614075 13823 net.cpp:129] Top shape: 64 24 28 28 (1204224)
I0822 15:54:12.614079 13823 net.cpp:137] Memory required for data: 342064640
I0822 15:54:12.614084 13823 layer_factory.hpp:77] Creating layer conv1_2/in/pw_new
I0822 15:54:12.614094 13823 net.cpp:84] Creating Layer conv1_2/in/pw_new
I0822 15:54:12.614099 13823 net.cpp:406] conv1_2/in/pw_new <- conv1_1/out/pw_new_conv1_1/out/pw/scale_new_0_split_0
I0822 15:54:12.614107 13823 net.cpp:380] conv1_2/in/pw_new -> conv1_2/in/pw_new
I0822 15:54:12.614398 13823 net.cpp:122] Setting up conv1_2/in/pw_new
I0822 15:54:12.614410 13823 net.cpp:129] Top shape: 64 144 28 28 (7225344)
I0822 15:54:12.614414 13823 net.cpp:137] Memory required for data: 370966016
I0822 15:54:12.614421 13823 layer_factory.hpp:77] Creating layer conv1_2/in/pw/bn_new
I0822 15:54:12.614429 13823 net.cpp:84] Creating Layer conv1_2/in/pw/bn_new
I0822 15:54:12.614434 13823 net.cpp:406] conv1_2/in/pw/bn_new <- conv1_2/in/pw_new
I0822 15:54:12.614441 13823 net.cpp:367] conv1_2/in/pw/bn_new -> conv1_2/in/pw_new (in-place)
I0822 15:54:12.614689 13823 net.cpp:122] Setting up conv1_2/in/pw/bn_new
I0822 15:54:12.614701 13823 net.cpp:129] Top shape: 64 144 28 28 (7225344)
I0822 15:54:12.614706 13823 net.cpp:137] Memory required for data: 399867392
I0822 15:54:12.614714 13823 layer_factory.hpp:77] Creating layer conv1_2/in/pw/scale_new
I0822 15:54:12.614723 13823 net.cpp:84] Creating Layer conv1_2/in/pw/scale_new
I0822 15:54:12.614732 13823 net.cpp:406] conv1_2/in/pw/scale_new <- conv1_2/in/pw_new
I0822 15:54:12.614738 13823 net.cpp:367] conv1_2/in/pw/scale_new -> conv1_2/in/pw_new (in-place)
I0822 15:54:12.614786 13823 layer_factory.hpp:77] Creating layer conv1_2/in/pw/scale_new
I0822 15:54:12.614931 13823 net.cpp:122] Setting up conv1_2/in/pw/scale_new
I0822 15:54:12.614943 13823 net.cpp:129] Top shape: 64 144 28 28 (7225344)
I0822 15:54:12.614948 13823 net.cpp:137] Memory required for data: 428768768
I0822 15:54:12.614956 13823 layer_factory.hpp:77] Creating layer relu1_2/in/pw_new
I0822 15:54:12.614964 13823 net.cpp:84] Creating Layer relu1_2/in/pw_new
I0822 15:54:12.614969 13823 net.cpp:406] relu1_2/in/pw_new <- conv1_2/in/pw_new
I0822 15:54:12.614975 13823 net.cpp:367] relu1_2/in/pw_new -> conv1_2/in/pw_new (in-place)
I0822 15:54:12.614984 13823 net.cpp:122] Setting up relu1_2/in/pw_new
I0822 15:54:12.614990 13823 net.cpp:129] Top shape: 64 144 28 28 (7225344)
I0822 15:54:12.614995 13823 net.cpp:137] Memory required for data: 457670144
I0822 15:54:12.614998 13823 layer_factory.hpp:77] Creating layer conv1_2/dw_new
I0822 15:54:12.615007 13823 net.cpp:84] Creating Layer conv1_2/dw_new
I0822 15:54:12.615012 13823 net.cpp:406] conv1_2/dw_new <- conv1_2/in/pw_new
I0822 15:54:12.615020 13823 net.cpp:380] conv1_2/dw_new -> conv1_2/dw_new
I0822 15:54:12.615185 13823 net.cpp:122] Setting up conv1_2/dw_new
I0822 15:54:12.615200 13823 net.cpp:129] Top shape: 64 144 28 28 (7225344)
I0822 15:54:12.615206 13823 net.cpp:137] Memory required for data: 486571520
I0822 15:54:12.615212 13823 layer_factory.hpp:77] Creating layer conv1_2/dw/bn_new
I0822 15:54:12.615221 13823 net.cpp:84] Creating Layer conv1_2/dw/bn_new
I0822 15:54:12.615226 13823 net.cpp:406] conv1_2/dw/bn_new <- conv1_2/dw_new
I0822 15:54:12.615234 13823 net.cpp:367] conv1_2/dw/bn_new -> conv1_2/dw_new (in-place)
I0822 15:54:12.615485 13823 net.cpp:122] Setting up conv1_2/dw/bn_new
I0822 15:54:12.615496 13823 net.cpp:129] Top shape: 64 144 28 28 (7225344)
I0822 15:54:12.615500 13823 net.cpp:137] Memory required for data: 515472896
I0822 15:54:12.615515 13823 layer_factory.hpp:77] Creating layer conv1_2/dw/scale_new
I0822 15:54:12.615525 13823 net.cpp:84] Creating Layer conv1_2/dw/scale_new
I0822 15:54:12.615530 13823 net.cpp:406] conv1_2/dw/scale_new <- conv1_2/dw_new
I0822 15:54:12.615537 13823 net.cpp:367] conv1_2/dw/scale_new -> conv1_2/dw_new (in-place)
I0822 15:54:12.615586 13823 layer_factory.hpp:77] Creating layer conv1_2/dw/scale_new
I0822 15:54:12.615734 13823 net.cpp:122] Setting up conv1_2/dw/scale_new
I0822 15:54:12.615746 13823 net.cpp:129] Top shape: 64 144 28 28 (7225344)
I0822 15:54:12.615751 13823 net.cpp:137] Memory required for data: 544374272
I0822 15:54:12.615759 13823 layer_factory.hpp:77] Creating layer relu1_2/dw_new
I0822 15:54:12.615767 13823 net.cpp:84] Creating Layer relu1_2/dw_new
I0822 15:54:12.615772 13823 net.cpp:406] relu1_2/dw_new <- conv1_2/dw_new
I0822 15:54:12.615778 13823 net.cpp:367] relu1_2/dw_new -> conv1_2/dw_new (in-place)
I0822 15:54:12.615785 13823 net.cpp:122] Setting up relu1_2/dw_new
I0822 15:54:12.615792 13823 net.cpp:129] Top shape: 64 144 28 28 (7225344)
I0822 15:54:12.615797 13823 net.cpp:137] Memory required for data: 573275648
I0822 15:54:12.615800 13823 layer_factory.hpp:77] Creating layer conv1_2/out/pw_new
I0822 15:54:12.615811 13823 net.cpp:84] Creating Layer conv1_2/out/pw_new
I0822 15:54:12.615815 13823 net.cpp:406] conv1_2/out/pw_new <- conv1_2/dw_new
I0822 15:54:12.615823 13823 net.cpp:380] conv1_2/out/pw_new -> conv1_2/out/pw_new
I0822 15:54:12.616114 13823 net.cpp:122] Setting up conv1_2/out/pw_new
I0822 15:54:12.616127 13823 net.cpp:129] Top shape: 64 24 28 28 (1204224)
I0822 15:54:12.616139 13823 net.cpp:137] Memory required for data: 578092544
I0822 15:54:12.616147 13823 layer_factory.hpp:77] Creating layer conv1_2/out/pw/bn_new
I0822 15:54:12.616155 13823 net.cpp:84] Creating Layer conv1_2/out/pw/bn_new
I0822 15:54:12.616160 13823 net.cpp:406] conv1_2/out/pw/bn_new <- conv1_2/out/pw_new
I0822 15:54:12.616168 13823 net.cpp:367] conv1_2/out/pw/bn_new -> conv1_2/out/pw_new (in-place)
I0822 15:54:12.616418 13823 net.cpp:122] Setting up conv1_2/out/pw/bn_new
I0822 15:54:12.616430 13823 net.cpp:129] Top shape: 64 24 28 28 (1204224)
I0822 15:54:12.616433 13823 net.cpp:137] Memory required for data: 582909440
I0822 15:54:12.616443 13823 layer_factory.hpp:77] Creating layer conv1_2/out/pw/scale_new
I0822 15:54:12.616452 13823 net.cpp:84] Creating Layer conv1_2/out/pw/scale_new
I0822 15:54:12.616457 13823 net.cpp:406] conv1_2/out/pw/scale_new <- conv1_2/out/pw_new
I0822 15:54:12.616464 13823 net.cpp:367] conv1_2/out/pw/scale_new -> conv1_2/out/pw_new (in-place)
I0822 15:54:12.616513 13823 layer_factory.hpp:77] Creating layer conv1_2/out/pw/scale_new
I0822 15:54:12.616657 13823 net.cpp:122] Setting up conv1_2/out/pw/scale_new
I0822 15:54:12.616668 13823 net.cpp:129] Top shape: 64 24 28 28 (1204224)
I0822 15:54:12.616672 13823 net.cpp:137] Memory required for data: 587726336
I0822 15:54:12.616680 13823 layer_factory.hpp:77] Creating layer fuse_conv1_2
I0822 15:54:12.616690 13823 net.cpp:84] Creating Layer fuse_conv1_2
I0822 15:54:12.616695 13823 net.cpp:406] fuse_conv1_2 <- conv1_1/out/pw_new_conv1_1/out/pw/scale_new_0_split_1
I0822 15:54:12.616703 13823 net.cpp:406] fuse_conv1_2 <- conv1_2/out/pw_new
I0822 15:54:12.616710 13823 net.cpp:380] fuse_conv1_2 -> fuse_conv1_2
I0822 15:54:12.616740 13823 net.cpp:122] Setting up fuse_conv1_2
I0822 15:54:12.616751 13823 net.cpp:129] Top shape: 64 24 28 28 (1204224)
I0822 15:54:12.616755 13823 net.cpp:137] Memory required for data: 592543232
I0822 15:54:12.616760 13823 layer_factory.hpp:77] Creating layer conv2_1/in/pw_new
I0822 15:54:12.616770 13823 net.cpp:84] Creating Layer conv2_1/in/pw_new
I0822 15:54:12.616775 13823 net.cpp:406] conv2_1/in/pw_new <- fuse_conv1_2
I0822 15:54:12.616783 13823 net.cpp:380] conv2_1/in/pw_new -> conv2_1/in/pw_new
I0822 15:54:12.617076 13823 net.cpp:122] Setting up conv2_1/in/pw_new
I0822 15:54:12.617089 13823 net.cpp:129] Top shape: 64 144 28 28 (7225344)
I0822 15:54:12.617094 13823 net.cpp:137] Memory required for data: 621444608
I0822 15:54:12.617100 13823 layer_factory.hpp:77] Creating layer conv2_1/in/pw/bn_new
I0822 15:54:12.617108 13823 net.cpp:84] Creating Layer conv2_1/in/pw/bn_new
I0822 15:54:12.617113 13823 net.cpp:406] conv2_1/in/pw/bn_new <- conv2_1/in/pw_new
I0822 15:54:12.617120 13823 net.cpp:367] conv2_1/in/pw/bn_new -> conv2_1/in/pw_new (in-place)
I0822 15:54:12.617367 13823 net.cpp:122] Setting up conv2_1/in/pw/bn_new
I0822 15:54:12.617377 13823 net.cpp:129] Top shape: 64 144 28 28 (7225344)
I0822 15:54:12.617381 13823 net.cpp:137] Memory required for data: 650345984
I0822 15:54:12.617391 13823 layer_factory.hpp:77] Creating layer conv2_1/in/pw/scale_new
I0822 15:54:12.617399 13823 net.cpp:84] Creating Layer conv2_1/in/pw/scale_new
I0822 15:54:12.617404 13823 net.cpp:406] conv2_1/in/pw/scale_new <- conv2_1/in/pw_new
I0822 15:54:12.617411 13823 net.cpp:367] conv2_1/in/pw/scale_new -> conv2_1/in/pw_new (in-place)
I0822 15:54:12.617458 13823 layer_factory.hpp:77] Creating layer conv2_1/in/pw/scale_new
I0822 15:54:12.617601 13823 net.cpp:122] Setting up conv2_1/in/pw/scale_new
I0822 15:54:12.617615 13823 net.cpp:129] Top shape: 64 144 28 28 (7225344)
I0822 15:54:12.617619 13823 net.cpp:137] Memory required for data: 679247360
I0822 15:54:12.617627 13823 layer_factory.hpp:77] Creating layer relu2_1/in/pw_new
I0822 15:54:12.617641 13823 net.cpp:84] Creating Layer relu2_1/in/pw_new
I0822 15:54:12.617648 13823 net.cpp:406] relu2_1/in/pw_new <- conv2_1/in/pw_new
I0822 15:54:12.617655 13823 net.cpp:367] relu2_1/in/pw_new -> conv2_1/in/pw_new (in-place)
I0822 15:54:12.617664 13823 net.cpp:122] Setting up relu2_1/in/pw_new
I0822 15:54:12.617671 13823 net.cpp:129] Top shape: 64 144 28 28 (7225344)
I0822 15:54:12.617676 13823 net.cpp:137] Memory required for data: 708148736
I0822 15:54:12.617681 13823 layer_factory.hpp:77] Creating layer conv2_1/dw_new
I0822 15:54:12.617688 13823 net.cpp:84] Creating Layer conv2_1/dw_new
I0822 15:54:12.617693 13823 net.cpp:406] conv2_1/dw_new <- conv2_1/in/pw_new
I0822 15:54:12.617702 13823 net.cpp:380] conv2_1/dw_new -> conv2_1/dw_new
I0822 15:54:12.617871 13823 net.cpp:122] Setting up conv2_1/dw_new
I0822 15:54:12.617887 13823 net.cpp:129] Top shape: 64 144 14 14 (1806336)
I0822 15:54:12.617890 13823 net.cpp:137] Memory required for data: 715374080
I0822 15:54:12.617897 13823 layer_factory.hpp:77] Creating layer conv2_1/dw/bn_new
I0822 15:54:12.617916 13823 net.cpp:84] Creating Layer conv2_1/dw/bn_new
I0822 15:54:12.617923 13823 net.cpp:406] conv2_1/dw/bn_new <- conv2_1/dw_new
I0822 15:54:12.617930 13823 net.cpp:367] conv2_1/dw/bn_new -> conv2_1/dw_new (in-place)
I0822 15:54:12.618191 13823 net.cpp:122] Setting up conv2_1/dw/bn_new
I0822 15:54:12.618204 13823 net.cpp:129] Top shape: 64 144 14 14 (1806336)
I0822 15:54:12.618209 13823 net.cpp:137] Memory required for data: 722599424
I0822 15:54:12.618219 13823 layer_factory.hpp:77] Creating layer conv2_1/dw/scale_new
I0822 15:54:12.618228 13823 net.cpp:84] Creating Layer conv2_1/dw/scale_new
I0822 15:54:12.618233 13823 net.cpp:406] conv2_1/dw/scale_new <- conv2_1/dw_new
I0822 15:54:12.618242 13823 net.cpp:367] conv2_1/dw/scale_new -> conv2_1/dw_new (in-place)
I0822 15:54:12.618291 13823 layer_factory.hpp:77] Creating layer conv2_1/dw/scale_new
I0822 15:54:12.618459 13823 net.cpp:122] Setting up conv2_1/dw/scale_new
I0822 15:54:12.618471 13823 net.cpp:129] Top shape: 64 144 14 14 (1806336)
I0822 15:54:12.618476 13823 net.cpp:137] Memory required for data: 729824768
I0822 15:54:12.618484 13823 layer_factory.hpp:77] Creating layer relu2_1/dw_new
I0822 15:54:12.618491 13823 net.cpp:84] Creating Layer relu2_1/dw_new
I0822 15:54:12.618496 13823 net.cpp:406] relu2_1/dw_new <- conv2_1/dw_new
I0822 15:54:12.618502 13823 net.cpp:367] relu2_1/dw_new -> conv2_1/dw_new (in-place)
I0822 15:54:12.618510 13823 net.cpp:122] Setting up relu2_1/dw_new
I0822 15:54:12.618516 13823 net.cpp:129] Top shape: 64 144 14 14 (1806336)
I0822 15:54:12.618521 13823 net.cpp:137] Memory required for data: 737050112
I0822 15:54:12.618525 13823 layer_factory.hpp:77] Creating layer conv2_1/out/pw_new
I0822 15:54:12.618538 13823 net.cpp:84] Creating Layer conv2_1/out/pw_new
I0822 15:54:12.618543 13823 net.cpp:406] conv2_1/out/pw_new <- conv2_1/dw_new
I0822 15:54:12.618553 13823 net.cpp:380] conv2_1/out/pw_new -> conv2_1/out/pw_new
I0822 15:54:12.618877 13823 net.cpp:122] Setting up conv2_1/out/pw_new
I0822 15:54:12.618891 13823 net.cpp:129] Top shape: 64 32 14 14 (401408)
I0822 15:54:12.618896 13823 net.cpp:137] Memory required for data: 738655744
I0822 15:54:12.618901 13823 layer_factory.hpp:77] Creating layer conv2_1/out/pw/bn_new
I0822 15:54:12.618912 13823 net.cpp:84] Creating Layer conv2_1/out/pw/bn_new
I0822 15:54:12.618917 13823 net.cpp:406] conv2_1/out/pw/bn_new <- conv2_1/out/pw_new
I0822 15:54:12.618926 13823 net.cpp:367] conv2_1/out/pw/bn_new -> conv2_1/out/pw_new (in-place)
I0822 15:54:12.619187 13823 net.cpp:122] Setting up conv2_1/out/pw/bn_new
I0822 15:54:12.619199 13823 net.cpp:129] Top shape: 64 32 14 14 (401408)
I0822 15:54:12.619204 13823 net.cpp:137] Memory required for data: 740261376
I0822 15:54:12.619212 13823 layer_factory.hpp:77] Creating layer conv2_1/out/pw/scale_new
I0822 15:54:12.619225 13823 net.cpp:84] Creating Layer conv2_1/out/pw/scale_new
I0822 15:54:12.619230 13823 net.cpp:406] conv2_1/out/pw/scale_new <- conv2_1/out/pw_new
I0822 15:54:12.619236 13823 net.cpp:367] conv2_1/out/pw/scale_new -> conv2_1/out/pw_new (in-place)
I0822 15:54:12.619287 13823 layer_factory.hpp:77] Creating layer conv2_1/out/pw/scale_new
I0822 15:54:12.619444 13823 net.cpp:122] Setting up conv2_1/out/pw/scale_new
I0822 15:54:12.619457 13823 net.cpp:129] Top shape: 64 32 14 14 (401408)
I0822 15:54:12.619462 13823 net.cpp:137] Memory required for data: 741867008
I0822 15:54:12.619468 13823 layer_factory.hpp:77] Creating layer conv2_1/out/pw_new_conv2_1/out/pw/scale_new_0_split
I0822 15:54:12.619482 13823 net.cpp:84] Creating Layer conv2_1/out/pw_new_conv2_1/out/pw/scale_new_0_split
I0822 15:54:12.619487 13823 net.cpp:406] conv2_1/out/pw_new_conv2_1/out/pw/scale_new_0_split <- conv2_1/out/pw_new
I0822 15:54:12.619494 13823 net.cpp:380] conv2_1/out/pw_new_conv2_1/out/pw/scale_new_0_split -> conv2_1/out/pw_new_conv2_1/out/pw/scale_new_0_split_0
I0822 15:54:12.619506 13823 net.cpp:380] conv2_1/out/pw_new_conv2_1/out/pw/scale_new_0_split -> conv2_1/out/pw_new_conv2_1/out/pw/scale_new_0_split_1
I0822 15:54:12.619558 13823 net.cpp:122] Setting up conv2_1/out/pw_new_conv2_1/out/pw/scale_new_0_split
I0822 15:54:12.619575 13823 net.cpp:129] Top shape: 64 32 14 14 (401408)
I0822 15:54:12.619582 13823 net.cpp:129] Top shape: 64 32 14 14 (401408)
I0822 15:54:12.619586 13823 net.cpp:137] Memory required for data: 745078272
I0822 15:54:12.619590 13823 layer_factory.hpp:77] Creating layer conv2_2/in/pw_new
I0822 15:54:12.619612 13823 net.cpp:84] Creating Layer conv2_2/in/pw_new
I0822 15:54:12.619621 13823 net.cpp:406] conv2_2/in/pw_new <- conv2_1/out/pw_new_conv2_1/out/pw/scale_new_0_split_0
I0822 15:54:12.619629 13823 net.cpp:380] conv2_2/in/pw_new -> conv2_2/in/pw_new
I0822 15:54:12.619971 13823 net.cpp:122] Setting up conv2_2/in/pw_new
I0822 15:54:12.619983 13823 net.cpp:129] Top shape: 64 192 14 14 (2408448)
I0822 15:54:12.619987 13823 net.cpp:137] Memory required for data: 754712064
I0822 15:54:12.619994 13823 layer_factory.hpp:77] Creating layer conv2_2/in/pw/bn_new
I0822 15:54:12.620005 13823 net.cpp:84] Creating Layer conv2_2/in/pw/bn_new
I0822 15:54:12.620010 13823 net.cpp:406] conv2_2/in/pw/bn_new <- conv2_2/in/pw_new
I0822 15:54:12.620018 13823 net.cpp:367] conv2_2/in/pw/bn_new -> conv2_2/in/pw_new (in-place)
I0822 15:54:12.620283 13823 net.cpp:122] Setting up conv2_2/in/pw/bn_new
I0822 15:54:12.620296 13823 net.cpp:129] Top shape: 64 192 14 14 (2408448)
I0822 15:54:12.620301 13823 net.cpp:137] Memory required for data: 764345856
I0822 15:54:12.620311 13823 layer_factory.hpp:77] Creating layer conv2_2/in/pw/scale_new
I0822 15:54:12.620321 13823 net.cpp:84] Creating Layer conv2_2/in/pw/scale_new
I0822 15:54:12.620326 13823 net.cpp:406] conv2_2/in/pw/scale_new <- conv2_2/in/pw_new
I0822 15:54:12.620335 13823 net.cpp:367] conv2_2/in/pw/scale_new -> conv2_2/in/pw_new (in-place)
I0822 15:54:12.620386 13823 layer_factory.hpp:77] Creating layer conv2_2/in/pw/scale_new
I0822 15:54:12.620548 13823 net.cpp:122] Setting up conv2_2/in/pw/scale_new
I0822 15:54:12.620561 13823 net.cpp:129] Top shape: 64 192 14 14 (2408448)
I0822 15:54:12.620566 13823 net.cpp:137] Memory required for data: 773979648
I0822 15:54:12.620591 13823 layer_factory.hpp:77] Creating layer relu2_2/in/pw_new
I0822 15:54:12.620601 13823 net.cpp:84] Creating Layer relu2_2/in/pw_new
I0822 15:54:12.620606 13823 net.cpp:406] relu2_2/in/pw_new <- conv2_2/in/pw_new
I0822 15:54:12.620615 13823 net.cpp:367] relu2_2/in/pw_new -> conv2_2/in/pw_new (in-place)
I0822 15:54:12.620622 13823 net.cpp:122] Setting up relu2_2/in/pw_new
I0822 15:54:12.620630 13823 net.cpp:129] Top shape: 64 192 14 14 (2408448)
I0822 15:54:12.620633 13823 net.cpp:137] Memory required for data: 783613440
I0822 15:54:12.620638 13823 layer_factory.hpp:77] Creating layer conv2_2/dw_new
I0822 15:54:12.620647 13823 net.cpp:84] Creating Layer conv2_2/dw_new
I0822 15:54:12.620651 13823 net.cpp:406] conv2_2/dw_new <- conv2_2/in/pw_new
I0822 15:54:12.620659 13823 net.cpp:380] conv2_2/dw_new -> conv2_2/dw_new
I0822 15:54:12.620846 13823 net.cpp:122] Setting up conv2_2/dw_new
I0822 15:54:12.620862 13823 net.cpp:129] Top shape: 64 192 14 14 (2408448)
I0822 15:54:12.620865 13823 net.cpp:137] Memory required for data: 793247232
I0822 15:54:12.620873 13823 layer_factory.hpp:77] Creating layer conv2_2/dw/bn_new
I0822 15:54:12.620882 13823 net.cpp:84] Creating Layer conv2_2/dw/bn_new
I0822 15:54:12.620887 13823 net.cpp:406] conv2_2/dw/bn_new <- conv2_2/dw_new
I0822 15:54:12.620898 13823 net.cpp:367] conv2_2/dw/bn_new -> conv2_2/dw_new (in-place)
I0822 15:54:12.621160 13823 net.cpp:122] Setting up conv2_2/dw/bn_new
I0822 15:54:12.621170 13823 net.cpp:129] Top shape: 64 192 14 14 (2408448)
I0822 15:54:12.621176 13823 net.cpp:137] Memory required for data: 802881024
I0822 15:54:12.621186 13823 layer_factory.hpp:77] Creating layer conv2_2/dw/scale_new
I0822 15:54:12.621196 13823 net.cpp:84] Creating Layer conv2_2/dw/scale_new
I0822 15:54:12.621201 13823 net.cpp:406] conv2_2/dw/scale_new <- conv2_2/dw_new
I0822 15:54:12.621208 13823 net.cpp:367] conv2_2/dw/scale_new -> conv2_2/dw_new (in-place)
I0822 15:54:12.621261 13823 layer_factory.hpp:77] Creating layer conv2_2/dw/scale_new
I0822 15:54:12.621426 13823 net.cpp:122] Setting up conv2_2/dw/scale_new
I0822 15:54:12.621439 13823 net.cpp:129] Top shape: 64 192 14 14 (2408448)
I0822 15:54:12.621443 13823 net.cpp:137] Memory required for data: 812514816
I0822 15:54:12.621453 13823 layer_factory.hpp:77] Creating layer relu2_2/dw_new
I0822 15:54:12.621460 13823 net.cpp:84] Creating Layer relu2_2/dw_new
I0822 15:54:12.621465 13823 net.cpp:406] relu2_2/dw_new <- conv2_2/dw_new
I0822 15:54:12.621474 13823 net.cpp:367] relu2_2/dw_new -> conv2_2/dw_new (in-place)
I0822 15:54:12.621484 13823 net.cpp:122] Setting up relu2_2/dw_new
I0822 15:54:12.621491 13823 net.cpp:129] Top shape: 64 192 14 14 (2408448)
I0822 15:54:12.621495 13823 net.cpp:137] Memory required for data: 822148608
I0822 15:54:12.621500 13823 layer_factory.hpp:77] Creating layer conv2_2/out/pw_new
I0822 15:54:12.621513 13823 net.cpp:84] Creating Layer conv2_2/out/pw_new
I0822 15:54:12.621520 13823 net.cpp:406] conv2_2/out/pw_new <- conv2_2/dw_new
I0822 15:54:12.621528 13823 net.cpp:380] conv2_2/out/pw_new -> conv2_2/out/pw_new
I0822 15:54:12.621871 13823 net.cpp:122] Setting up conv2_2/out/pw_new
I0822 15:54:12.621884 13823 net.cpp:129] Top shape: 64 32 14 14 (401408)
I0822 15:54:12.621889 13823 net.cpp:137] Memory required for data: 823754240
I0822 15:54:12.621896 13823 layer_factory.hpp:77] Creating layer conv2_2/out/pw/bn_new
I0822 15:54:12.621904 13823 net.cpp:84] Creating Layer conv2_2/out/pw/bn_new
I0822 15:54:12.621909 13823 net.cpp:406] conv2_2/out/pw/bn_new <- conv2_2/out/pw_new
I0822 15:54:12.621919 13823 net.cpp:367] conv2_2/out/pw/bn_new -> conv2_2/out/pw_new (in-place)
I0822 15:54:12.622186 13823 net.cpp:122] Setting up conv2_2/out/pw/bn_new
I0822 15:54:12.622198 13823 net.cpp:129] Top shape: 64 32 14 14 (401408)
I0822 15:54:12.622203 13823 net.cpp:137] Memory required for data: 825359872
I0822 15:54:12.622213 13823 layer_factory.hpp:77] Creating layer conv2_2/out/pw/scale_new
I0822 15:54:12.622221 13823 net.cpp:84] Creating Layer conv2_2/out/pw/scale_new
I0822 15:54:12.622226 13823 net.cpp:406] conv2_2/out/pw/scale_new <- conv2_2/out/pw_new
I0822 15:54:12.622233 13823 net.cpp:367] conv2_2/out/pw/scale_new -> conv2_2/out/pw_new (in-place)
I0822 15:54:12.622285 13823 layer_factory.hpp:77] Creating layer conv2_2/out/pw/scale_new
I0822 15:54:12.622442 13823 net.cpp:122] Setting up conv2_2/out/pw/scale_new
I0822 15:54:12.622454 13823 net.cpp:129] Top shape: 64 32 14 14 (401408)
I0822 15:54:12.622459 13823 net.cpp:137] Memory required for data: 826965504
I0822 15:54:12.622467 13823 layer_factory.hpp:77] Creating layer fuse_conv2_2
I0822 15:54:12.622476 13823 net.cpp:84] Creating Layer fuse_conv2_2
I0822 15:54:12.622481 13823 net.cpp:406] fuse_conv2_2 <- conv2_1/out/pw_new_conv2_1/out/pw/scale_new_0_split_1
I0822 15:54:12.622488 13823 net.cpp:406] fuse_conv2_2 <- conv2_2/out/pw_new
I0822 15:54:12.622498 13823 net.cpp:380] fuse_conv2_2 -> fuse_conv2_2
I0822 15:54:12.622529 13823 net.cpp:122] Setting up fuse_conv2_2
I0822 15:54:12.622541 13823 net.cpp:129] Top shape: 64 32 14 14 (401408)
I0822 15:54:12.622545 13823 net.cpp:137] Memory required for data: 828571136
I0822 15:54:12.622550 13823 layer_factory.hpp:77] Creating layer conv3_1/in/pw_new
I0822 15:54:12.622563 13823 net.cpp:84] Creating Layer conv3_1/in/pw_new
I0822 15:54:12.622570 13823 net.cpp:406] conv3_1/in/pw_new <- fuse_conv2_2
I0822 15:54:12.622577 13823 net.cpp:380] conv3_1/in/pw_new -> conv3_1/in/pw_new
I0822 15:54:12.622926 13823 net.cpp:122] Setting up conv3_1/in/pw_new
I0822 15:54:12.622939 13823 net.cpp:129] Top shape: 64 192 14 14 (2408448)
I0822 15:54:12.622943 13823 net.cpp:137] Memory required for data: 838204928
I0822 15:54:12.622951 13823 layer_factory.hpp:77] Creating layer conv3_1/in/pw/bn_new
I0822 15:54:12.622958 13823 net.cpp:84] Creating Layer conv3_1/in/pw/bn_new
I0822 15:54:12.622963 13823 net.cpp:406] conv3_1/in/pw/bn_new <- conv3_1/in/pw_new
I0822 15:54:12.622972 13823 net.cpp:367] conv3_1/in/pw/bn_new -> conv3_1/in/pw_new (in-place)
I0822 15:54:12.623234 13823 net.cpp:122] Setting up conv3_1/in/pw/bn_new
I0822 15:54:12.623245 13823 net.cpp:129] Top shape: 64 192 14 14 (2408448)
I0822 15:54:12.623248 13823 net.cpp:137] Memory required for data: 847838720
I0822 15:54:12.623258 13823 layer_factory.hpp:77] Creating layer conv3_1/in/pw/scale_new
I0822 15:54:12.623272 13823 net.cpp:84] Creating Layer conv3_1/in/pw/scale_new
I0822 15:54:12.623278 13823 net.cpp:406] conv3_1/in/pw/scale_new <- conv3_1/in/pw_new
I0822 15:54:12.623286 13823 net.cpp:367] conv3_1/in/pw/scale_new -> conv3_1/in/pw_new (in-place)
I0822 15:54:12.623337 13823 layer_factory.hpp:77] Creating layer conv3_1/in/pw/scale_new
I0822 15:54:12.623500 13823 net.cpp:122] Setting up conv3_1/in/pw/scale_new
I0822 15:54:12.623513 13823 net.cpp:129] Top shape: 64 192 14 14 (2408448)
I0822 15:54:12.623518 13823 net.cpp:137] Memory required for data: 857472512
I0822 15:54:12.623526 13823 layer_factory.hpp:77] Creating layer relu3_1/in/pw_new
I0822 15:54:12.623533 13823 net.cpp:84] Creating Layer relu3_1/in/pw_new
I0822 15:54:12.623538 13823 net.cpp:406] relu3_1/in/pw_new <- conv3_1/in/pw_new
I0822 15:54:12.623548 13823 net.cpp:367] relu3_1/in/pw_new -> conv3_1/in/pw_new (in-place)
I0822 15:54:12.623556 13823 net.cpp:122] Setting up relu3_1/in/pw_new
I0822 15:54:12.623562 13823 net.cpp:129] Top shape: 64 192 14 14 (2408448)
I0822 15:54:12.623567 13823 net.cpp:137] Memory required for data: 867106304
I0822 15:54:12.623571 13823 layer_factory.hpp:77] Creating layer conv3_1/dw_new
I0822 15:54:12.623580 13823 net.cpp:84] Creating Layer conv3_1/dw_new
I0822 15:54:12.623585 13823 net.cpp:406] conv3_1/dw_new <- conv3_1/in/pw_new
I0822 15:54:12.623594 13823 net.cpp:380] conv3_1/dw_new -> conv3_1/dw_new
I0822 15:54:12.623773 13823 net.cpp:122] Setting up conv3_1/dw_new
I0822 15:54:12.623790 13823 net.cpp:129] Top shape: 64 192 7 7 (602112)
I0822 15:54:12.623795 13823 net.cpp:137] Memory required for data: 869514752
I0822 15:54:12.623801 13823 layer_factory.hpp:77] Creating layer conv3_1/dw/bn_new
I0822 15:54:12.623811 13823 net.cpp:84] Creating Layer conv3_1/dw/bn_new
I0822 15:54:12.623816 13823 net.cpp:406] conv3_1/dw/bn_new <- conv3_1/dw_new
I0822 15:54:12.623823 13823 net.cpp:367] conv3_1/dw/bn_new -> conv3_1/dw_new (in-place)
I0822 15:54:12.624094 13823 net.cpp:122] Setting up conv3_1/dw/bn_new
I0822 15:54:12.624105 13823 net.cpp:129] Top shape: 64 192 7 7 (602112)
I0822 15:54:12.624110 13823 net.cpp:137] Memory required for data: 871923200
I0822 15:54:12.624119 13823 layer_factory.hpp:77] Creating layer conv3_1/dw/scale_new
I0822 15:54:12.624143 13823 net.cpp:84] Creating Layer conv3_1/dw/scale_new
I0822 15:54:12.624150 13823 net.cpp:406] conv3_1/dw/scale_new <- conv3_1/dw_new
I0822 15:54:12.624157 13823 net.cpp:367] conv3_1/dw/scale_new -> conv3_1/dw_new (in-place)
I0822 15:54:12.624212 13823 layer_factory.hpp:77] Creating layer conv3_1/dw/scale_new
I0822 15:54:12.625546 13823 net.cpp:122] Setting up conv3_1/dw/scale_new
I0822 15:54:12.625569 13823 net.cpp:129] Top shape: 64 192 7 7 (602112)
I0822 15:54:12.625574 13823 net.cpp:137] Memory required for data: 874331648
I0822 15:54:12.625584 13823 layer_factory.hpp:77] Creating layer relu3_1/dw_new
I0822 15:54:12.625593 13823 net.cpp:84] Creating Layer relu3_1/dw_new
I0822 15:54:12.625598 13823 net.cpp:406] relu3_1/dw_new <- conv3_1/dw_new
I0822 15:54:12.625605 13823 net.cpp:367] relu3_1/dw_new -> conv3_1/dw_new (in-place)
I0822 15:54:12.625614 13823 net.cpp:122] Setting up relu3_1/dw_new
I0822 15:54:12.625622 13823 net.cpp:129] Top shape: 64 192 7 7 (602112)
I0822 15:54:12.625625 13823 net.cpp:137] Memory required for data: 876740096
I0822 15:54:12.625629 13823 layer_factory.hpp:77] Creating layer conv3_1/out/pw_new
I0822 15:54:12.625643 13823 net.cpp:84] Creating Layer conv3_1/out/pw_new
I0822 15:54:12.625651 13823 net.cpp:406] conv3_1/out/pw_new <- conv3_1/dw_new
I0822 15:54:12.625659 13823 net.cpp:380] conv3_1/out/pw_new -> conv3_1/out/pw_new
I0822 15:54:12.626092 13823 net.cpp:122] Setting up conv3_1/out/pw_new
I0822 15:54:12.626106 13823 net.cpp:129] Top shape: 64 64 7 7 (200704)
I0822 15:54:12.626111 13823 net.cpp:137] Memory required for data: 877542912
I0822 15:54:12.626117 13823 layer_factory.hpp:77] Creating layer conv3_1/out/pw/bn_new
I0822 15:54:12.626127 13823 net.cpp:84] Creating Layer conv3_1/out/pw/bn_new
I0822 15:54:12.626132 13823 net.cpp:406] conv3_1/out/pw/bn_new <- conv3_1/out/pw_new
I0822 15:54:12.626142 13823 net.cpp:367] conv3_1/out/pw/bn_new -> conv3_1/out/pw_new (in-place)
I0822 15:54:12.626390 13823 net.cpp:122] Setting up conv3_1/out/pw/bn_new
I0822 15:54:12.626404 13823 net.cpp:129] Top shape: 64 64 7 7 (200704)
I0822 15:54:12.626407 13823 net.cpp:137] Memory required for data: 878345728
I0822 15:54:12.626417 13823 layer_factory.hpp:77] Creating layer conv3_1/out/pw/scale_new
I0822 15:54:12.626428 13823 net.cpp:84] Creating Layer conv3_1/out/pw/scale_new
I0822 15:54:12.626433 13823 net.cpp:406] conv3_1/out/pw/scale_new <- conv3_1/out/pw_new
I0822 15:54:12.626441 13823 net.cpp:367] conv3_1/out/pw/scale_new -> conv3_1/out/pw_new (in-place)
I0822 15:54:12.626489 13823 layer_factory.hpp:77] Creating layer conv3_1/out/pw/scale_new
I0822 15:54:12.626639 13823 net.cpp:122] Setting up conv3_1/out/pw/scale_new
I0822 15:54:12.626652 13823 net.cpp:129] Top shape: 64 64 7 7 (200704)
I0822 15:54:12.626655 13823 net.cpp:137] Memory required for data: 879148544
I0822 15:54:12.626663 13823 layer_factory.hpp:77] Creating layer conv3_1/out/pw_new_conv3_1/out/pw/scale_new_0_split
I0822 15:54:12.626688 13823 net.cpp:84] Creating Layer conv3_1/out/pw_new_conv3_1/out/pw/scale_new_0_split
I0822 15:54:12.626694 13823 net.cpp:406] conv3_1/out/pw_new_conv3_1/out/pw/scale_new_0_split <- conv3_1/out/pw_new
I0822 15:54:12.626703 13823 net.cpp:380] conv3_1/out/pw_new_conv3_1/out/pw/scale_new_0_split -> conv3_1/out/pw_new_conv3_1/out/pw/scale_new_0_split_0
I0822 15:54:12.626713 13823 net.cpp:380] conv3_1/out/pw_new_conv3_1/out/pw/scale_new_0_split -> conv3_1/out/pw_new_conv3_1/out/pw/scale_new_0_split_1
I0822 15:54:12.626760 13823 net.cpp:122] Setting up conv3_1/out/pw_new_conv3_1/out/pw/scale_new_0_split
I0822 15:54:12.626770 13823 net.cpp:129] Top shape: 64 64 7 7 (200704)
I0822 15:54:12.626780 13823 net.cpp:129] Top shape: 64 64 7 7 (200704)
I0822 15:54:12.626785 13823 net.cpp:137] Memory required for data: 880754176
I0822 15:54:12.626790 13823 layer_factory.hpp:77] Creating layer conv3_2/in/pw_new
I0822 15:54:12.626801 13823 net.cpp:84] Creating Layer conv3_2/in/pw_new
I0822 15:54:12.626806 13823 net.cpp:406] conv3_2/in/pw_new <- conv3_1/out/pw_new_conv3_1/out/pw/scale_new_0_split_0
I0822 15:54:12.626813 13823 net.cpp:380] conv3_2/in/pw_new -> conv3_2/in/pw_new
I0822 15:54:12.627240 13823 net.cpp:122] Setting up conv3_2/in/pw_new
I0822 15:54:12.627254 13823 net.cpp:129] Top shape: 64 192 7 7 (602112)
I0822 15:54:12.627257 13823 net.cpp:137] Memory required for data: 883162624
I0822 15:54:12.627264 13823 layer_factory.hpp:77] Creating layer conv3_2/in/pw/bn_new
I0822 15:54:12.627274 13823 net.cpp:84] Creating Layer conv3_2/in/pw/bn_new
I0822 15:54:12.627277 13823 net.cpp:406] conv3_2/in/pw/bn_new <- conv3_2/in/pw_new
I0822 15:54:12.627285 13823 net.cpp:367] conv3_2/in/pw/bn_new -> conv3_2/in/pw_new (in-place)
I0822 15:54:12.627529 13823 net.cpp:122] Setting up conv3_2/in/pw/bn_new
I0822 15:54:12.627540 13823 net.cpp:129] Top shape: 64 192 7 7 (602112)
I0822 15:54:12.627544 13823 net.cpp:137] Memory required for data: 885571072
I0822 15:54:12.627554 13823 layer_factory.hpp:77] Creating layer conv3_2/in/pw/scale_new
I0822 15:54:12.627566 13823 net.cpp:84] Creating Layer conv3_2/in/pw/scale_new
I0822 15:54:12.627571 13823 net.cpp:406] conv3_2/in/pw/scale_new <- conv3_2/in/pw_new
I0822 15:54:12.627578 13823 net.cpp:367] conv3_2/in/pw/scale_new -> conv3_2/in/pw_new (in-place)
I0822 15:54:12.627627 13823 layer_factory.hpp:77] Creating layer conv3_2/in/pw/scale_new
I0822 15:54:12.627784 13823 net.cpp:122] Setting up conv3_2/in/pw/scale_new
I0822 15:54:12.627795 13823 net.cpp:129] Top shape: 64 192 7 7 (602112)
I0822 15:54:12.627799 13823 net.cpp:137] Memory required for data: 887979520
I0822 15:54:12.627807 13823 layer_factory.hpp:77] Creating layer relu3_2/in/pw_new
I0822 15:54:12.627815 13823 net.cpp:84] Creating Layer relu3_2/in/pw_new
I0822 15:54:12.627820 13823 net.cpp:406] relu3_2/in/pw_new <- conv3_2/in/pw_new
I0822 15:54:12.627828 13823 net.cpp:367] relu3_2/in/pw_new -> conv3_2/in/pw_new (in-place)
I0822 15:54:12.627836 13823 net.cpp:122] Setting up relu3_2/in/pw_new
I0822 15:54:12.627842 13823 net.cpp:129] Top shape: 64 192 7 7 (602112)
I0822 15:54:12.627846 13823 net.cpp:137] Memory required for data: 890387968
I0822 15:54:12.627851 13823 layer_factory.hpp:77] Creating layer conv3_2/dw_new
I0822 15:54:12.627858 13823 net.cpp:84] Creating Layer conv3_2/dw_new
I0822 15:54:12.627863 13823 net.cpp:406] conv3_2/dw_new <- conv3_2/in/pw_new
I0822 15:54:12.627876 13823 net.cpp:380] conv3_2/dw_new -> conv3_2/dw_new
I0822 15:54:12.628051 13823 net.cpp:122] Setting up conv3_2/dw_new
I0822 15:54:12.628068 13823 net.cpp:129] Top shape: 64 192 7 7 (602112)
I0822 15:54:12.628072 13823 net.cpp:137] Memory required for data: 892796416
I0822 15:54:12.628079 13823 layer_factory.hpp:77] Creating layer conv3_2/dw/bn_new
I0822 15:54:12.628087 13823 net.cpp:84] Creating Layer conv3_2/dw/bn_new
I0822 15:54:12.628093 13823 net.cpp:406] conv3_2/dw/bn_new <- conv3_2/dw_new
I0822 15:54:12.628103 13823 net.cpp:367] conv3_2/dw/bn_new -> conv3_2/dw_new (in-place)
I0822 15:54:12.628373 13823 net.cpp:122] Setting up conv3_2/dw/bn_new
I0822 15:54:12.628386 13823 net.cpp:129] Top shape: 64 192 7 7 (602112)
I0822 15:54:12.628391 13823 net.cpp:137] Memory required for data: 895204864
I0822 15:54:12.628401 13823 layer_factory.hpp:77] Creating layer conv3_2/dw/scale_new
I0822 15:54:12.628409 13823 net.cpp:84] Creating Layer conv3_2/dw/scale_new
I0822 15:54:12.628414 13823 net.cpp:406] conv3_2/dw/scale_new <- conv3_2/dw_new
I0822 15:54:12.628422 13823 net.cpp:367] conv3_2/dw/scale_new -> conv3_2/dw_new (in-place)
I0822 15:54:12.628473 13823 layer_factory.hpp:77] Creating layer conv3_2/dw/scale_new
I0822 15:54:12.628629 13823 net.cpp:122] Setting up conv3_2/dw/scale_new
I0822 15:54:12.628643 13823 net.cpp:129] Top shape: 64 192 7 7 (602112)
I0822 15:54:12.628646 13823 net.cpp:137] Memory required for data: 897613312
I0822 15:54:12.628654 13823 layer_factory.hpp:77] Creating layer relu3_2/dw_new
I0822 15:54:12.628661 13823 net.cpp:84] Creating Layer relu3_2/dw_new
I0822 15:54:12.628665 13823 net.cpp:406] relu3_2/dw_new <- conv3_2/dw_new
I0822 15:54:12.628674 13823 net.cpp:367] relu3_2/dw_new -> conv3_2/dw_new (in-place)
I0822 15:54:12.628682 13823 net.cpp:122] Setting up relu3_2/dw_new
I0822 15:54:12.628688 13823 net.cpp:129] Top shape: 64 192 7 7 (602112)
I0822 15:54:12.628692 13823 net.cpp:137] Memory required for data: 900021760
I0822 15:54:12.628696 13823 layer_factory.hpp:77] Creating layer conv3_2/out/pw_new
I0822 15:54:12.628706 13823 net.cpp:84] Creating Layer conv3_2/out/pw_new
I0822 15:54:12.628711 13823 net.cpp:406] conv3_2/out/pw_new <- conv3_2/dw_new
I0822 15:54:12.628720 13823 net.cpp:380] conv3_2/out/pw_new -> conv3_2/out/pw_new
I0822 15:54:12.629150 13823 net.cpp:122] Setting up conv3_2/out/pw_new
I0822 15:54:12.629163 13823 net.cpp:129] Top shape: 64 64 7 7 (200704)
I0822 15:54:12.629168 13823 net.cpp:137] Memory required for data: 900824576
I0822 15:54:12.629173 13823 layer_factory.hpp:77] Creating layer conv3_2/out/pw/bn_new
I0822 15:54:12.629185 13823 net.cpp:84] Creating Layer conv3_2/out/pw/bn_new
I0822 15:54:12.629191 13823 net.cpp:406] conv3_2/out/pw/bn_new <- conv3_2/out/pw_new
I0822 15:54:12.629199 13823 net.cpp:367] conv3_2/out/pw/bn_new -> conv3_2/out/pw_new (in-place)
I0822 15:54:12.629443 13823 net.cpp:122] Setting up conv3_2/out/pw/bn_new
I0822 15:54:12.629454 13823 net.cpp:129] Top shape: 64 64 7 7 (200704)
I0822 15:54:12.629458 13823 net.cpp:137] Memory required for data: 901627392
I0822 15:54:12.629467 13823 layer_factory.hpp:77] Creating layer conv3_2/out/pw/scale_new
I0822 15:54:12.629477 13823 net.cpp:84] Creating Layer conv3_2/out/pw/scale_new
I0822 15:54:12.629480 13823 net.cpp:406] conv3_2/out/pw/scale_new <- conv3_2/out/pw_new
I0822 15:54:12.629489 13823 net.cpp:367] conv3_2/out/pw/scale_new -> conv3_2/out/pw_new (in-place)
I0822 15:54:12.629535 13823 layer_factory.hpp:77] Creating layer conv3_2/out/pw/scale_new
I0822 15:54:12.629683 13823 net.cpp:122] Setting up conv3_2/out/pw/scale_new
I0822 15:54:12.629694 13823 net.cpp:129] Top shape: 64 64 7 7 (200704)
I0822 15:54:12.629698 13823 net.cpp:137] Memory required for data: 902430208
I0822 15:54:12.629706 13823 layer_factory.hpp:77] Creating layer fuse_conv3_2
I0822 15:54:12.629714 13823 net.cpp:84] Creating Layer fuse_conv3_2
I0822 15:54:12.629719 13823 net.cpp:406] fuse_conv3_2 <- conv3_1/out/pw_new_conv3_1/out/pw/scale_new_0_split_1
I0822 15:54:12.629725 13823 net.cpp:406] fuse_conv3_2 <- conv3_2/out/pw_new
I0822 15:54:12.629737 13823 net.cpp:380] fuse_conv3_2 -> fuse_conv3_2
I0822 15:54:12.629766 13823 net.cpp:122] Setting up fuse_conv3_2
I0822 15:54:12.629781 13823 net.cpp:129] Top shape: 64 64 7 7 (200704)
I0822 15:54:12.629784 13823 net.cpp:137] Memory required for data: 903233024
I0822 15:54:12.629788 13823 layer_factory.hpp:77] Creating layer fc1
I0822 15:54:12.629798 13823 net.cpp:84] Creating Layer fc1
I0822 15:54:12.629803 13823 net.cpp:406] fc1 <- fuse_conv3_2
I0822 15:54:12.629810 13823 net.cpp:380] fc1 -> fc1
I0822 15:54:12.656018 13823 net.cpp:122] Setting up fc1
I0822 15:54:12.656038 13823 net.cpp:129] Top shape: 64 512 (32768)
I0822 15:54:12.656042 13823 net.cpp:137] Memory required for data: 903364096
I0822 15:54:12.656051 13823 layer_factory.hpp:77] Creating layer relu_fc1
I0822 15:54:12.656062 13823 net.cpp:84] Creating Layer relu_fc1
I0822 15:54:12.656067 13823 net.cpp:406] relu_fc1 <- fc1
I0822 15:54:12.656075 13823 net.cpp:367] relu_fc1 -> fc1 (in-place)
I0822 15:54:12.656082 13823 net.cpp:122] Setting up relu_fc1
I0822 15:54:12.656087 13823 net.cpp:129] Top shape: 64 512 (32768)
I0822 15:54:12.656090 13823 net.cpp:137] Memory required for data: 903495168
I0822 15:54:12.656095 13823 layer_factory.hpp:77] Creating layer drop_fc1
I0822 15:54:12.656103 13823 net.cpp:84] Creating Layer drop_fc1
I0822 15:54:12.656107 13823 net.cpp:406] drop_fc1 <- fc1
I0822 15:54:12.656112 13823 net.cpp:367] drop_fc1 -> fc1 (in-place)
I0822 15:54:12.656150 13823 net.cpp:122] Setting up drop_fc1
I0822 15:54:12.656160 13823 net.cpp:129] Top shape: 64 512 (32768)
I0822 15:54:12.656164 13823 net.cpp:137] Memory required for data: 903626240
I0822 15:54:12.656168 13823 layer_factory.hpp:77] Creating layer landmark_pred
I0822 15:54:12.656175 13823 net.cpp:84] Creating Layer landmark_pred
I0822 15:54:12.656179 13823 net.cpp:406] landmark_pred <- fc1
I0822 15:54:12.656188 13823 net.cpp:380] landmark_pred -> landmark_pred
I0822 15:54:12.658118 13823 net.cpp:122] Setting up landmark_pred
I0822 15:54:12.658133 13823 net.cpp:129] Top shape: 64 254 (16256)
I0822 15:54:12.658138 13823 net.cpp:137] Memory required for data: 903691264
I0822 15:54:12.658144 13823 layer_factory.hpp:77] Creating layer landmark_loss
I0822 15:54:12.658151 13823 net.cpp:84] Creating Layer landmark_loss
I0822 15:54:12.658156 13823 net.cpp:406] landmark_loss <- landmark_pred
I0822 15:54:12.658161 13823 net.cpp:406] landmark_loss <- label
I0822 15:54:12.658174 13823 net.cpp:380] landmark_loss -> landmark_loss
I0822 15:54:12.658234 13823 net.cpp:122] Setting up landmark_loss
I0822 15:54:12.658247 13823 net.cpp:129] Top shape: (1)
I0822 15:54:12.658252 13823 net.cpp:132]     with loss weight 1
I0822 15:54:12.658264 13823 net.cpp:137] Memory required for data: 903691268
I0822 15:54:12.658269 13823 net.cpp:198] landmark_loss needs backward computation.
I0822 15:54:12.658274 13823 net.cpp:198] landmark_pred needs backward computation.
I0822 15:54:12.658279 13823 net.cpp:198] drop_fc1 needs backward computation.
I0822 15:54:12.658282 13823 net.cpp:198] relu_fc1 needs backward computation.
I0822 15:54:12.658286 13823 net.cpp:198] fc1 needs backward computation.
I0822 15:54:12.658291 13823 net.cpp:198] fuse_conv3_2 needs backward computation.
I0822 15:54:12.658295 13823 net.cpp:198] conv3_2/out/pw/scale_new needs backward computation.
I0822 15:54:12.658299 13823 net.cpp:198] conv3_2/out/pw/bn_new needs backward computation.
I0822 15:54:12.658303 13823 net.cpp:198] conv3_2/out/pw_new needs backward computation.
I0822 15:54:12.658308 13823 net.cpp:198] relu3_2/dw_new needs backward computation.
I0822 15:54:12.658311 13823 net.cpp:198] conv3_2/dw/scale_new needs backward computation.
I0822 15:54:12.658314 13823 net.cpp:198] conv3_2/dw/bn_new needs backward computation.
I0822 15:54:12.658318 13823 net.cpp:198] conv3_2/dw_new needs backward computation.
I0822 15:54:12.658322 13823 net.cpp:198] relu3_2/in/pw_new needs backward computation.
I0822 15:54:12.658326 13823 net.cpp:198] conv3_2/in/pw/scale_new needs backward computation.
I0822 15:54:12.658329 13823 net.cpp:198] conv3_2/in/pw/bn_new needs backward computation.
I0822 15:54:12.658334 13823 net.cpp:198] conv3_2/in/pw_new needs backward computation.
I0822 15:54:12.658337 13823 net.cpp:198] conv3_1/out/pw_new_conv3_1/out/pw/scale_new_0_split needs backward computation.
I0822 15:54:12.658342 13823 net.cpp:198] conv3_1/out/pw/scale_new needs backward computation.
I0822 15:54:12.658345 13823 net.cpp:198] conv3_1/out/pw/bn_new needs backward computation.
I0822 15:54:12.658349 13823 net.cpp:198] conv3_1/out/pw_new needs backward computation.
I0822 15:54:12.658354 13823 net.cpp:198] relu3_1/dw_new needs backward computation.
I0822 15:54:12.658357 13823 net.cpp:198] conv3_1/dw/scale_new needs backward computation.
I0822 15:54:12.658361 13823 net.cpp:198] conv3_1/dw/bn_new needs backward computation.
I0822 15:54:12.658365 13823 net.cpp:198] conv3_1/dw_new needs backward computation.
I0822 15:54:12.658370 13823 net.cpp:198] relu3_1/in/pw_new needs backward computation.
I0822 15:54:12.658373 13823 net.cpp:198] conv3_1/in/pw/scale_new needs backward computation.
I0822 15:54:12.658376 13823 net.cpp:198] conv3_1/in/pw/bn_new needs backward computation.
I0822 15:54:12.658380 13823 net.cpp:198] conv3_1/in/pw_new needs backward computation.
I0822 15:54:12.658385 13823 net.cpp:198] fuse_conv2_2 needs backward computation.
I0822 15:54:12.658390 13823 net.cpp:198] conv2_2/out/pw/scale_new needs backward computation.
I0822 15:54:12.658394 13823 net.cpp:198] conv2_2/out/pw/bn_new needs backward computation.
I0822 15:54:12.658397 13823 net.cpp:198] conv2_2/out/pw_new needs backward computation.
I0822 15:54:12.658402 13823 net.cpp:198] relu2_2/dw_new needs backward computation.
I0822 15:54:12.658406 13823 net.cpp:198] conv2_2/dw/scale_new needs backward computation.
I0822 15:54:12.658409 13823 net.cpp:198] conv2_2/dw/bn_new needs backward computation.
I0822 15:54:12.658413 13823 net.cpp:198] conv2_2/dw_new needs backward computation.
I0822 15:54:12.658418 13823 net.cpp:198] relu2_2/in/pw_new needs backward computation.
I0822 15:54:12.658422 13823 net.cpp:198] conv2_2/in/pw/scale_new needs backward computation.
I0822 15:54:12.658426 13823 net.cpp:198] conv2_2/in/pw/bn_new needs backward computation.
I0822 15:54:12.658429 13823 net.cpp:198] conv2_2/in/pw_new needs backward computation.
I0822 15:54:12.658434 13823 net.cpp:198] conv2_1/out/pw_new_conv2_1/out/pw/scale_new_0_split needs backward computation.
I0822 15:54:12.658438 13823 net.cpp:198] conv2_1/out/pw/scale_new needs backward computation.
I0822 15:54:12.658442 13823 net.cpp:198] conv2_1/out/pw/bn_new needs backward computation.
I0822 15:54:12.658447 13823 net.cpp:198] conv2_1/out/pw_new needs backward computation.
I0822 15:54:12.658450 13823 net.cpp:198] relu2_1/dw_new needs backward computation.
I0822 15:54:12.658454 13823 net.cpp:198] conv2_1/dw/scale_new needs backward computation.
I0822 15:54:12.658458 13823 net.cpp:198] conv2_1/dw/bn_new needs backward computation.
I0822 15:54:12.658463 13823 net.cpp:198] conv2_1/dw_new needs backward computation.
I0822 15:54:12.658468 13823 net.cpp:198] relu2_1/in/pw_new needs backward computation.
I0822 15:54:12.658471 13823 net.cpp:198] conv2_1/in/pw/scale_new needs backward computation.
I0822 15:54:12.658475 13823 net.cpp:198] conv2_1/in/pw/bn_new needs backward computation.
I0822 15:54:12.658479 13823 net.cpp:198] conv2_1/in/pw_new needs backward computation.
I0822 15:54:12.658483 13823 net.cpp:198] fuse_conv1_2 needs backward computation.
I0822 15:54:12.658488 13823 net.cpp:198] conv1_2/out/pw/scale_new needs backward computation.
I0822 15:54:12.658493 13823 net.cpp:198] conv1_2/out/pw/bn_new needs backward computation.
I0822 15:54:12.658495 13823 net.cpp:198] conv1_2/out/pw_new needs backward computation.
I0822 15:54:12.658500 13823 net.cpp:198] relu1_2/dw_new needs backward computation.
I0822 15:54:12.658504 13823 net.cpp:198] conv1_2/dw/scale_new needs backward computation.
I0822 15:54:12.658507 13823 net.cpp:198] conv1_2/dw/bn_new needs backward computation.
I0822 15:54:12.658511 13823 net.cpp:198] conv1_2/dw_new needs backward computation.
I0822 15:54:12.658516 13823 net.cpp:198] relu1_2/in/pw_new needs backward computation.
I0822 15:54:12.658519 13823 net.cpp:198] conv1_2/in/pw/scale_new needs backward computation.
I0822 15:54:12.658524 13823 net.cpp:198] conv1_2/in/pw/bn_new needs backward computation.
I0822 15:54:12.658527 13823 net.cpp:198] conv1_2/in/pw_new needs backward computation.
I0822 15:54:12.658531 13823 net.cpp:198] conv1_1/out/pw_new_conv1_1/out/pw/scale_new_0_split needs backward computation.
I0822 15:54:12.658536 13823 net.cpp:198] conv1_1/out/pw/scale_new needs backward computation.
I0822 15:54:12.658540 13823 net.cpp:198] conv1_1/out/pw/bn_new needs backward computation.
I0822 15:54:12.658543 13823 net.cpp:198] conv1_1/out/pw_new needs backward computation.
I0822 15:54:12.658547 13823 net.cpp:198] relu1_1/dw_new needs backward computation.
I0822 15:54:12.658552 13823 net.cpp:198] conv1_1/dw/scale_new needs backward computation.
I0822 15:54:12.658556 13823 net.cpp:198] conv1_1/dw/bn_new needs backward computation.
I0822 15:54:12.658560 13823 net.cpp:198] conv1_1/dw_new needs backward computation.
I0822 15:54:12.658563 13823 net.cpp:198] relu1_1/in/pw_new needs backward computation.
I0822 15:54:12.658568 13823 net.cpp:198] conv1_1/in/pw/scale_new needs backward computation.
I0822 15:54:12.658571 13823 net.cpp:198] conv1_1/in/pw/bn_new needs backward computation.
I0822 15:54:12.658576 13823 net.cpp:198] conv1_1/in/pw_new needs backward computation.
I0822 15:54:12.658579 13823 net.cpp:198] relu1_new needs backward computation.
I0822 15:54:12.658583 13823 net.cpp:198] conv1/scale_new needs backward computation.
I0822 15:54:12.658587 13823 net.cpp:198] conv1/bn_new needs backward computation.
I0822 15:54:12.658591 13823 net.cpp:198] conv1_new needs backward computation.
I0822 15:54:12.658596 13823 net.cpp:200] data does not need backward computation.
I0822 15:54:12.658601 13823 net.cpp:242] This network produces output landmark_loss
I0822 15:54:12.658664 13823 net.cpp:255] Network initialization done.
I0822 15:54:12.658974 13823 solver.cpp:57] Solver scaffolding done.
I0822 15:54:12.665345 13823 caffe.cpp:239] Starting Optimization
I0822 15:54:12.665359 13823 solver.cpp:289] Solving subMobileNet
I0822 15:54:12.665362 13823 solver.cpp:290] Learning Rate Policy: multistep
I0822 15:54:12.667737 13823 solver.cpp:347] Iteration 0, Testing net (#0)
I0822 15:55:30.178411 13823 solver.cpp:414]     Test net output #0: landmark_loss = nan (* 1 = nan loss)
I0822 15:55:30.372753 13823 solver.cpp:239] Iteration 0 (0 iter/s, 77.7078s/100 iters), loss = 37.9821
I0822 15:55:30.372812 13823 solver.cpp:258]     Train net output #0: landmark_loss = 37.9821 (* 1 = 37.9821 loss)
I0822 15:55:30.372831 13823 sgd_solver.cpp:112] Iteration 0, lr = 0.001
I0822 15:55:42.028445 13823 solver.cpp:239] Iteration 100 (8.5795 iter/s, 11.6557s/100 iters), loss = 1.18929
I0822 15:55:42.028497 13823 solver.cpp:258]     Train net output #0: landmark_loss = 1.18929 (* 1 = 1.18929 loss)
I0822 15:55:42.028506 13823 sgd_solver.cpp:112] Iteration 100, lr = 0.001
I0822 15:55:53.088160 13823 solver.cpp:239] Iteration 200 (9.04182 iter/s, 11.0597s/100 iters), loss = 0.579799
I0822 15:55:53.088214 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.579799 (* 1 = 0.579799 loss)
I0822 15:55:53.088223 13823 sgd_solver.cpp:112] Iteration 200, lr = 0.001
I0822 15:56:04.632143 13823 solver.cpp:239] Iteration 300 (8.66252 iter/s, 11.544s/100 iters), loss = 0.642049
I0822 15:56:04.632198 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.642049 (* 1 = 0.642049 loss)
I0822 15:56:04.632208 13823 sgd_solver.cpp:112] Iteration 300, lr = 0.001
I0822 15:56:15.602214 13823 solver.cpp:239] Iteration 400 (9.11572 iter/s, 10.9701s/100 iters), loss = 0.576075
I0822 15:56:15.602272 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.576075 (* 1 = 0.576075 loss)
I0822 15:56:15.602282 13823 sgd_solver.cpp:112] Iteration 400, lr = 0.001
I0822 15:56:26.521682 13823 solver.cpp:239] Iteration 500 (9.15797 iter/s, 10.9195s/100 iters), loss = 0.525339
I0822 15:56:26.521736 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.525339 (* 1 = 0.525339 loss)
I0822 15:56:26.521745 13823 sgd_solver.cpp:112] Iteration 500, lr = 0.001
I0822 15:56:37.634059 13823 solver.cpp:239] Iteration 600 (8.99898 iter/s, 11.1124s/100 iters), loss = 0.385772
I0822 15:56:37.634115 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.385772 (* 1 = 0.385772 loss)
I0822 15:56:37.634125 13823 sgd_solver.cpp:112] Iteration 600, lr = 0.001
I0822 15:56:48.591178 13823 solver.cpp:239] Iteration 700 (9.1265 iter/s, 10.9571s/100 iters), loss = 0.281543
I0822 15:56:48.591238 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.281543 (* 1 = 0.281543 loss)
I0822 15:56:48.591248 13823 sgd_solver.cpp:112] Iteration 700, lr = 0.001
I0822 15:56:59.643368 13823 solver.cpp:239] Iteration 800 (9.048 iter/s, 11.0522s/100 iters), loss = 0.346871
I0822 15:56:59.643442 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.346871 (* 1 = 0.346871 loss)
I0822 15:56:59.643455 13823 sgd_solver.cpp:112] Iteration 800, lr = 0.001
I0822 15:57:10.752632 13823 solver.cpp:239] Iteration 900 (9.00152 iter/s, 11.1092s/100 iters), loss = 0.372765
I0822 15:57:10.752688 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.372765 (* 1 = 0.372765 loss)
I0822 15:57:10.752697 13823 sgd_solver.cpp:112] Iteration 900, lr = 0.001
I0822 15:57:21.799216 13823 solver.cpp:239] Iteration 1000 (9.05259 iter/s, 11.0466s/100 iters), loss = 0.345466
I0822 15:57:21.799269 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.345466 (* 1 = 0.345466 loss)
I0822 15:57:21.799279 13823 sgd_solver.cpp:112] Iteration 1000, lr = 0.001
I0822 15:57:33.037087 13823 solver.cpp:239] Iteration 1100 (8.89849 iter/s, 11.2379s/100 iters), loss = 0.325015
I0822 15:57:33.037142 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.325015 (* 1 = 0.325015 loss)
I0822 15:57:33.037150 13823 sgd_solver.cpp:112] Iteration 1100, lr = 0.001
I0822 15:57:44.227469 13823 solver.cpp:239] Iteration 1200 (8.93626 iter/s, 11.1904s/100 iters), loss = 0.233647
I0822 15:57:44.227532 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.233647 (* 1 = 0.233647 loss)
I0822 15:57:44.227543 13823 sgd_solver.cpp:112] Iteration 1200, lr = 0.001
I0822 15:57:55.022665 13823 solver.cpp:239] Iteration 1300 (9.26341 iter/s, 10.7952s/100 iters), loss = 0.199457
I0822 15:57:55.022738 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.199456 (* 1 = 0.199456 loss)
I0822 15:57:55.022749 13823 sgd_solver.cpp:112] Iteration 1300, lr = 0.001
I0822 15:58:06.069866 13823 solver.cpp:239] Iteration 1400 (9.0521 iter/s, 11.0472s/100 iters), loss = 0.259618
I0822 15:58:06.069922 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.259618 (* 1 = 0.259618 loss)
I0822 15:58:06.069932 13823 sgd_solver.cpp:112] Iteration 1400, lr = 0.001
I0822 15:58:17.058328 13823 solver.cpp:239] Iteration 1500 (9.10047 iter/s, 10.9884s/100 iters), loss = 0.202521
I0822 15:58:17.058382 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.202521 (* 1 = 0.202521 loss)
I0822 15:58:17.058393 13823 sgd_solver.cpp:112] Iteration 1500, lr = 0.001
I0822 15:58:28.267588 13823 solver.cpp:239] Iteration 1600 (8.92121 iter/s, 11.2092s/100 iters), loss = 0.17488
I0822 15:58:28.267644 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.17488 (* 1 = 0.17488 loss)
I0822 15:58:28.267654 13823 sgd_solver.cpp:112] Iteration 1600, lr = 0.001
I0822 15:58:39.635499 13823 solver.cpp:239] Iteration 1700 (8.79671 iter/s, 11.3679s/100 iters), loss = 0.211753
I0822 15:58:39.635574 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.211753 (* 1 = 0.211753 loss)
I0822 15:58:39.635587 13823 sgd_solver.cpp:112] Iteration 1700, lr = 0.001
I0822 15:58:51.138340 13823 solver.cpp:239] Iteration 1800 (8.69353 iter/s, 11.5028s/100 iters), loss = 0.127447
I0822 15:58:51.138399 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.127447 (* 1 = 0.127447 loss)
I0822 15:58:51.138411 13823 sgd_solver.cpp:112] Iteration 1800, lr = 0.001
I0822 15:59:02.467188 13823 solver.cpp:239] Iteration 1900 (8.82704 iter/s, 11.3288s/100 iters), loss = 0.125815
I0822 15:59:02.467249 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.125815 (* 1 = 0.125815 loss)
I0822 15:59:02.467260 13823 sgd_solver.cpp:112] Iteration 1900, lr = 0.001
I0822 15:59:13.921913 13823 solver.cpp:239] Iteration 2000 (8.73004 iter/s, 11.4547s/100 iters), loss = 0.131943
I0822 15:59:13.921969 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.131943 (* 1 = 0.131943 loss)
I0822 15:59:13.921979 13823 sgd_solver.cpp:112] Iteration 2000, lr = 0.001
I0822 15:59:25.993113 13823 solver.cpp:239] Iteration 2100 (8.2842 iter/s, 12.0712s/100 iters), loss = 0.0960314
I0822 15:59:25.993173 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0960314 (* 1 = 0.0960314 loss)
I0822 15:59:25.993183 13823 sgd_solver.cpp:112] Iteration 2100, lr = 0.001
I0822 15:59:38.136076 13823 solver.cpp:239] Iteration 2200 (8.23524 iter/s, 12.1429s/100 iters), loss = 0.0805408
I0822 15:59:38.136152 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0805407 (* 1 = 0.0805407 loss)
I0822 15:59:38.136162 13823 sgd_solver.cpp:112] Iteration 2200, lr = 0.001
I0822 15:59:50.078310 13823 solver.cpp:239] Iteration 2300 (8.37366 iter/s, 11.9422s/100 iters), loss = 0.0941877
I0822 15:59:50.078367 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0941877 (* 1 = 0.0941877 loss)
I0822 15:59:50.078377 13823 sgd_solver.cpp:112] Iteration 2300, lr = 0.001
I0822 16:00:02.024161 13823 solver.cpp:239] Iteration 2400 (8.37113 iter/s, 11.9458s/100 iters), loss = 0.0814848
I0822 16:00:02.024211 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0814847 (* 1 = 0.0814847 loss)
I0822 16:00:02.024221 13823 sgd_solver.cpp:112] Iteration 2400, lr = 0.001
I0822 16:00:13.977097 13823 solver.cpp:239] Iteration 2500 (8.36616 iter/s, 11.9529s/100 iters), loss = 0.12865
I0822 16:00:13.977154 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.12865 (* 1 = 0.12865 loss)
I0822 16:00:13.977164 13823 sgd_solver.cpp:112] Iteration 2500, lr = 0.001
I0822 16:00:25.966128 13823 solver.cpp:239] Iteration 2600 (8.34097 iter/s, 11.989s/100 iters), loss = 0.115175
I0822 16:00:25.966189 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.115174 (* 1 = 0.115174 loss)
I0822 16:00:25.966200 13823 sgd_solver.cpp:112] Iteration 2600, lr = 0.001
I0822 16:00:37.945379 13823 solver.cpp:239] Iteration 2700 (8.34779 iter/s, 11.9792s/100 iters), loss = 0.0766233
I0822 16:00:37.945446 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0766232 (* 1 = 0.0766232 loss)
I0822 16:00:37.945458 13823 sgd_solver.cpp:112] Iteration 2700, lr = 0.001
I0822 16:00:50.305538 13823 solver.cpp:239] Iteration 2800 (8.09053 iter/s, 12.3601s/100 iters), loss = 0.0938535
I0822 16:00:50.305591 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0938534 (* 1 = 0.0938534 loss)
I0822 16:00:50.305601 13823 sgd_solver.cpp:112] Iteration 2800, lr = 0.001
I0822 16:01:02.478878 13823 solver.cpp:239] Iteration 2900 (8.21469 iter/s, 12.1733s/100 iters), loss = 0.0926032
I0822 16:01:02.478940 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0926031 (* 1 = 0.0926031 loss)
I0822 16:01:02.478952 13823 sgd_solver.cpp:112] Iteration 2900, lr = 0.001
I0822 16:01:14.523511 13823 solver.cpp:239] Iteration 3000 (8.30247 iter/s, 12.0446s/100 iters), loss = 0.0863694
I0822 16:01:14.523568 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0863693 (* 1 = 0.0863693 loss)
I0822 16:01:14.523577 13823 sgd_solver.cpp:112] Iteration 3000, lr = 0.001
I0822 16:01:26.531358 13823 solver.cpp:239] Iteration 3100 (8.32791 iter/s, 12.0078s/100 iters), loss = 0.0979915
I0822 16:01:26.531417 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0979915 (* 1 = 0.0979915 loss)
I0822 16:01:26.531427 13823 sgd_solver.cpp:112] Iteration 3100, lr = 0.001
I0822 16:01:38.458518 13823 solver.cpp:239] Iteration 3200 (8.38424 iter/s, 11.9271s/100 iters), loss = 0.0834752
I0822 16:01:38.458573 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0834752 (* 1 = 0.0834752 loss)
I0822 16:01:38.458582 13823 sgd_solver.cpp:112] Iteration 3200, lr = 0.001
I0822 16:01:50.729781 13823 solver.cpp:239] Iteration 3300 (8.14914 iter/s, 12.2712s/100 iters), loss = 0.0648921
I0822 16:01:50.729848 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.064892 (* 1 = 0.064892 loss)
I0822 16:01:50.729857 13823 sgd_solver.cpp:112] Iteration 3300, lr = 0.001
I0822 16:02:02.691129 13823 solver.cpp:239] Iteration 3400 (8.36029 iter/s, 11.9613s/100 iters), loss = 0.0782005
I0822 16:02:02.691198 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0782004 (* 1 = 0.0782004 loss)
I0822 16:02:02.691210 13823 sgd_solver.cpp:112] Iteration 3400, lr = 0.001
I0822 16:02:14.690135 13823 solver.cpp:239] Iteration 3500 (8.33405 iter/s, 11.999s/100 iters), loss = 0.0867431
I0822 16:02:14.690191 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.086743 (* 1 = 0.086743 loss)
I0822 16:02:14.690199 13823 sgd_solver.cpp:112] Iteration 3500, lr = 0.001
I0822 16:02:26.623526 13823 solver.cpp:239] Iteration 3600 (8.37987 iter/s, 11.9334s/100 iters), loss = 0.0936563
I0822 16:02:26.623589 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0936562 (* 1 = 0.0936562 loss)
I0822 16:02:26.623600 13823 sgd_solver.cpp:112] Iteration 3600, lr = 0.001
I0822 16:02:38.664939 13823 solver.cpp:239] Iteration 3700 (8.30469 iter/s, 12.0414s/100 iters), loss = 0.0758277
I0822 16:02:38.664999 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0758276 (* 1 = 0.0758276 loss)
I0822 16:02:38.665009 13823 sgd_solver.cpp:112] Iteration 3700, lr = 0.001
I0822 16:02:50.806069 13823 solver.cpp:239] Iteration 3800 (8.23648 iter/s, 12.1411s/100 iters), loss = 0.0849978
I0822 16:02:50.806128 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0849977 (* 1 = 0.0849977 loss)
I0822 16:02:50.806139 13823 sgd_solver.cpp:112] Iteration 3800, lr = 0.001
I0822 16:03:02.834483 13823 solver.cpp:239] Iteration 3900 (8.31377 iter/s, 12.0282s/100 iters), loss = 0.0758738
I0822 16:03:02.834542 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0758737 (* 1 = 0.0758737 loss)
I0822 16:03:02.834553 13823 sgd_solver.cpp:112] Iteration 3900, lr = 0.001
I0822 16:03:14.955389 13823 solver.cpp:239] Iteration 4000 (8.25034 iter/s, 12.1207s/100 iters), loss = 0.0961567
I0822 16:03:14.955451 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0961566 (* 1 = 0.0961566 loss)
I0822 16:03:14.955461 13823 sgd_solver.cpp:112] Iteration 4000, lr = 0.001
I0822 16:03:27.055030 13823 solver.cpp:239] Iteration 4100 (8.26484 iter/s, 12.0994s/100 iters), loss = 0.0810981
I0822 16:03:27.055094 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.081098 (* 1 = 0.081098 loss)
I0822 16:03:27.055105 13823 sgd_solver.cpp:112] Iteration 4100, lr = 0.001
I0822 16:03:39.174525 13823 solver.cpp:239] Iteration 4200 (8.2513 iter/s, 12.1193s/100 iters), loss = 0.0639724
I0822 16:03:39.174579 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0639724 (* 1 = 0.0639724 loss)
I0822 16:03:39.174588 13823 sgd_solver.cpp:112] Iteration 4200, lr = 0.001
I0822 16:03:51.379451 13823 solver.cpp:239] Iteration 4300 (8.19353 iter/s, 12.2048s/100 iters), loss = 0.106037
I0822 16:03:51.379503 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.106037 (* 1 = 0.106037 loss)
I0822 16:03:51.379514 13823 sgd_solver.cpp:112] Iteration 4300, lr = 0.001
I0822 16:04:03.411339 13823 solver.cpp:239] Iteration 4400 (8.31137 iter/s, 12.0317s/100 iters), loss = 0.0819
I0822 16:04:03.411401 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0818999 (* 1 = 0.0818999 loss)
I0822 16:04:03.411411 13823 sgd_solver.cpp:112] Iteration 4400, lr = 0.001
I0822 16:04:15.533247 13823 solver.cpp:239] Iteration 4500 (8.24965 iter/s, 12.1217s/100 iters), loss = 0.0816346
I0822 16:04:15.533313 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0816345 (* 1 = 0.0816345 loss)
I0822 16:04:15.533326 13823 sgd_solver.cpp:112] Iteration 4500, lr = 0.001
I0822 16:04:27.300050 13823 solver.cpp:239] Iteration 4600 (8.49861 iter/s, 11.7666s/100 iters), loss = 0.0828082
I0822 16:04:27.300108 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0828081 (* 1 = 0.0828081 loss)
I0822 16:04:27.300117 13823 sgd_solver.cpp:112] Iteration 4600, lr = 0.001
I0822 16:04:39.574172 13823 solver.cpp:239] Iteration 4700 (8.14733 iter/s, 12.274s/100 iters), loss = 0.0893755
I0822 16:04:39.574226 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0893754 (* 1 = 0.0893754 loss)
I0822 16:04:39.574235 13823 sgd_solver.cpp:112] Iteration 4700, lr = 0.001
I0822 16:04:51.616392 13823 solver.cpp:239] Iteration 4800 (8.30423 iter/s, 12.0421s/100 iters), loss = 0.121018
I0822 16:04:51.616456 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.121018 (* 1 = 0.121018 loss)
I0822 16:04:51.616468 13823 sgd_solver.cpp:112] Iteration 4800, lr = 0.001
I0822 16:05:03.529666 13823 solver.cpp:239] Iteration 4900 (8.39411 iter/s, 11.9131s/100 iters), loss = 0.0738722
I0822 16:05:03.529721 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0738721 (* 1 = 0.0738721 loss)
I0822 16:05:03.529731 13823 sgd_solver.cpp:112] Iteration 4900, lr = 0.001
I0822 16:05:15.401545 13823 solver.cpp:239] Iteration 5000 (8.42338 iter/s, 11.8717s/100 iters), loss = 0.0698846
I0822 16:05:15.401600 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0698845 (* 1 = 0.0698845 loss)
I0822 16:05:15.401610 13823 sgd_solver.cpp:112] Iteration 5000, lr = 0.001
I0822 16:05:27.665187 13823 solver.cpp:239] Iteration 5100 (8.15429 iter/s, 12.2635s/100 iters), loss = 0.0697435
I0822 16:05:27.665246 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0697433 (* 1 = 0.0697433 loss)
I0822 16:05:27.665259 13823 sgd_solver.cpp:112] Iteration 5100, lr = 0.001
I0822 16:05:39.760746 13823 solver.cpp:239] Iteration 5200 (8.26761 iter/s, 12.0954s/100 iters), loss = 0.061199
I0822 16:05:39.760809 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0611989 (* 1 = 0.0611989 loss)
I0822 16:05:39.760823 13823 sgd_solver.cpp:112] Iteration 5200, lr = 0.001
I0822 16:05:51.790189 13823 solver.cpp:239] Iteration 5300 (8.31305 iter/s, 12.0293s/100 iters), loss = 0.0558021
I0822 16:05:51.790261 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.055802 (* 1 = 0.055802 loss)
I0822 16:05:51.790272 13823 sgd_solver.cpp:112] Iteration 5300, lr = 0.001
I0822 16:06:03.585093 13823 solver.cpp:239] Iteration 5400 (8.47835 iter/s, 11.7947s/100 iters), loss = 0.0800947
I0822 16:06:03.585153 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0800945 (* 1 = 0.0800945 loss)
I0822 16:06:03.585165 13823 sgd_solver.cpp:112] Iteration 5400, lr = 0.001
I0822 16:06:15.555397 13823 solver.cpp:239] Iteration 5500 (8.35411 iter/s, 11.9702s/100 iters), loss = 0.0571571
I0822 16:06:15.555460 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.057157 (* 1 = 0.057157 loss)
I0822 16:06:15.555469 13823 sgd_solver.cpp:112] Iteration 5500, lr = 0.001
I0822 16:06:27.346451 13823 solver.cpp:239] Iteration 5600 (8.48111 iter/s, 11.7909s/100 iters), loss = 0.0667057
I0822 16:06:27.346506 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0667056 (* 1 = 0.0667056 loss)
I0822 16:06:27.346515 13823 sgd_solver.cpp:112] Iteration 5600, lr = 0.001
I0822 16:06:39.440567 13823 solver.cpp:239] Iteration 5700 (8.26858 iter/s, 12.094s/100 iters), loss = 0.0524825
I0822 16:06:39.440631 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0524824 (* 1 = 0.0524824 loss)
I0822 16:06:39.440644 13823 sgd_solver.cpp:112] Iteration 5700, lr = 0.001
I0822 16:06:51.538332 13823 solver.cpp:239] Iteration 5800 (8.26609 iter/s, 12.0976s/100 iters), loss = 0.0789866
I0822 16:06:51.538393 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0789865 (* 1 = 0.0789865 loss)
I0822 16:06:51.538403 13823 sgd_solver.cpp:112] Iteration 5800, lr = 0.001
I0822 16:07:03.670351 13823 solver.cpp:239] Iteration 5900 (8.24275 iter/s, 12.1319s/100 iters), loss = 0.0657745
I0822 16:07:03.670415 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0657744 (* 1 = 0.0657744 loss)
I0822 16:07:03.670428 13823 sgd_solver.cpp:112] Iteration 5900, lr = 0.001
I0822 16:07:15.660497 13823 solver.cpp:239] Iteration 6000 (8.34028 iter/s, 11.99s/100 iters), loss = 0.0909553
I0822 16:07:15.660565 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0909552 (* 1 = 0.0909552 loss)
I0822 16:07:15.660578 13823 sgd_solver.cpp:112] Iteration 6000, lr = 0.001
I0822 16:07:27.679307 13823 solver.cpp:239] Iteration 6100 (8.32039 iter/s, 12.0187s/100 iters), loss = 0.0647661
I0822 16:07:27.679358 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.064766 (* 1 = 0.064766 loss)
I0822 16:07:27.679374 13823 sgd_solver.cpp:112] Iteration 6100, lr = 0.001
I0822 16:07:39.852560 13823 solver.cpp:239] Iteration 6200 (8.21482 iter/s, 12.1731s/100 iters), loss = 0.0690419
I0822 16:07:39.852618 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0690417 (* 1 = 0.0690417 loss)
I0822 16:07:39.852630 13823 sgd_solver.cpp:112] Iteration 6200, lr = 0.001
I0822 16:07:51.911304 13823 solver.cpp:239] Iteration 6300 (8.29283 iter/s, 12.0586s/100 iters), loss = 0.0509732
I0822 16:07:51.911368 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.050973 (* 1 = 0.050973 loss)
I0822 16:07:51.911384 13823 sgd_solver.cpp:112] Iteration 6300, lr = 0.001
I0822 16:08:03.835726 13823 solver.cpp:239] Iteration 6400 (8.38624 iter/s, 11.9243s/100 iters), loss = 0.0784055
I0822 16:08:03.835786 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0784054 (* 1 = 0.0784054 loss)
I0822 16:08:03.835796 13823 sgd_solver.cpp:112] Iteration 6400, lr = 0.001
I0822 16:08:15.570485 13823 solver.cpp:239] Iteration 6500 (8.52179 iter/s, 11.7346s/100 iters), loss = 0.11792
I0822 16:08:15.570536 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.11792 (* 1 = 0.11792 loss)
I0822 16:08:15.570546 13823 sgd_solver.cpp:112] Iteration 6500, lr = 0.001
I0822 16:08:27.313949 13823 solver.cpp:239] Iteration 6600 (8.51546 iter/s, 11.7433s/100 iters), loss = 0.0518499
I0822 16:08:27.314010 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0518498 (* 1 = 0.0518498 loss)
I0822 16:08:27.314018 13823 sgd_solver.cpp:112] Iteration 6600, lr = 0.001
I0822 16:08:39.029117 13823 solver.cpp:239] Iteration 6700 (8.53603 iter/s, 11.715s/100 iters), loss = 0.102076
I0822 16:08:39.029181 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.102076 (* 1 = 0.102076 loss)
I0822 16:08:39.029196 13823 sgd_solver.cpp:112] Iteration 6700, lr = 0.001
I0822 16:08:50.915434 13823 solver.cpp:239] Iteration 6800 (8.41312 iter/s, 11.8862s/100 iters), loss = 0.0562568
I0822 16:08:50.915491 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0562566 (* 1 = 0.0562566 loss)
I0822 16:08:50.915499 13823 sgd_solver.cpp:112] Iteration 6800, lr = 0.001
I0822 16:09:02.842944 13823 solver.cpp:239] Iteration 6900 (8.38406 iter/s, 11.9274s/100 iters), loss = 0.0544222
I0822 16:09:02.842994 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0544221 (* 1 = 0.0544221 loss)
I0822 16:09:02.843004 13823 sgd_solver.cpp:112] Iteration 6900, lr = 0.001
I0822 16:09:14.493947 13823 solver.cpp:239] Iteration 7000 (8.58303 iter/s, 11.6509s/100 iters), loss = 0.0595305
I0822 16:09:14.494012 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0595303 (* 1 = 0.0595303 loss)
I0822 16:09:14.494021 13823 sgd_solver.cpp:112] Iteration 7000, lr = 0.001
I0822 16:09:26.341948 13823 solver.cpp:239] Iteration 7100 (8.44033 iter/s, 11.8479s/100 iters), loss = 0.15395
I0822 16:09:26.342012 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.15395 (* 1 = 0.15395 loss)
I0822 16:09:26.342021 13823 sgd_solver.cpp:112] Iteration 7100, lr = 0.001
I0822 16:09:37.919939 13823 solver.cpp:239] Iteration 7200 (8.63717 iter/s, 11.5779s/100 iters), loss = 0.0562278
I0822 16:09:37.920001 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0562276 (* 1 = 0.0562276 loss)
I0822 16:09:37.920011 13823 sgd_solver.cpp:112] Iteration 7200, lr = 0.001
I0822 16:09:49.472163 13823 solver.cpp:239] Iteration 7300 (8.65644 iter/s, 11.5521s/100 iters), loss = 0.0378047
I0822 16:09:49.472213 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0378046 (* 1 = 0.0378046 loss)
I0822 16:09:49.472220 13823 sgd_solver.cpp:112] Iteration 7300, lr = 0.001
I0822 16:10:01.051721 13823 solver.cpp:239] Iteration 7400 (8.63599 iter/s, 11.5795s/100 iters), loss = 0.0395672
I0822 16:10:01.051787 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.039567 (* 1 = 0.039567 loss)
I0822 16:10:01.051797 13823 sgd_solver.cpp:112] Iteration 7400, lr = 0.001
I0822 16:10:13.029767 13823 solver.cpp:239] Iteration 7500 (8.3487 iter/s, 11.9779s/100 iters), loss = 0.0601119
I0822 16:10:13.029831 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0601118 (* 1 = 0.0601118 loss)
I0822 16:10:13.029844 13823 sgd_solver.cpp:112] Iteration 7500, lr = 0.001
I0822 16:10:25.071498 13823 solver.cpp:239] Iteration 7600 (8.30453 iter/s, 12.0416s/100 iters), loss = 0.0412693
I0822 16:10:25.071554 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0412691 (* 1 = 0.0412691 loss)
I0822 16:10:25.071564 13823 sgd_solver.cpp:112] Iteration 7600, lr = 0.001
I0822 16:10:37.088963 13823 solver.cpp:239] Iteration 7700 (8.3213 iter/s, 12.0174s/100 iters), loss = 0.0483912
I0822 16:10:37.089021 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.048391 (* 1 = 0.048391 loss)
I0822 16:10:37.089032 13823 sgd_solver.cpp:112] Iteration 7700, lr = 0.001
I0822 16:10:49.108551 13823 solver.cpp:239] Iteration 7800 (8.31983 iter/s, 12.0195s/100 iters), loss = 0.0850435
I0822 16:10:49.108620 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0850434 (* 1 = 0.0850434 loss)
I0822 16:10:49.108633 13823 sgd_solver.cpp:112] Iteration 7800, lr = 0.001
I0822 16:11:01.367621 13823 solver.cpp:239] Iteration 7900 (8.15731 iter/s, 12.2589s/100 iters), loss = 0.0787395
I0822 16:11:01.367681 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0787393 (* 1 = 0.0787393 loss)
I0822 16:11:01.367691 13823 sgd_solver.cpp:112] Iteration 7900, lr = 0.001
I0822 16:11:13.169740 13823 solver.cpp:239] Iteration 8000 (8.47313 iter/s, 11.802s/100 iters), loss = 0.0452553
I0822 16:11:13.169798 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0452551 (* 1 = 0.0452551 loss)
I0822 16:11:13.169808 13823 sgd_solver.cpp:112] Iteration 8000, lr = 0.001
I0822 16:11:24.979229 13823 solver.cpp:239] Iteration 8100 (8.46784 iter/s, 11.8094s/100 iters), loss = 0.0548038
I0822 16:11:24.979290 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0548036 (* 1 = 0.0548036 loss)
I0822 16:11:24.979300 13823 sgd_solver.cpp:112] Iteration 8100, lr = 0.001
I0822 16:11:36.708873 13823 solver.cpp:239] Iteration 8200 (8.52548 iter/s, 11.7295s/100 iters), loss = 0.048143
I0822 16:11:36.708932 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0481428 (* 1 = 0.0481428 loss)
I0822 16:11:36.708941 13823 sgd_solver.cpp:112] Iteration 8200, lr = 0.001
I0822 16:11:48.648793 13823 solver.cpp:239] Iteration 8300 (8.37534 iter/s, 11.9398s/100 iters), loss = 0.0500773
I0822 16:11:48.648847 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0500772 (* 1 = 0.0500772 loss)
I0822 16:11:48.648857 13823 sgd_solver.cpp:112] Iteration 8300, lr = 0.001
I0822 16:12:00.678442 13823 solver.cpp:239] Iteration 8400 (8.31286 iter/s, 12.0295s/100 iters), loss = 0.0428025
I0822 16:12:00.678498 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0428023 (* 1 = 0.0428023 loss)
I0822 16:12:00.678508 13823 sgd_solver.cpp:112] Iteration 8400, lr = 0.001
I0822 16:12:12.652562 13823 solver.cpp:239] Iteration 8500 (8.35141 iter/s, 11.974s/100 iters), loss = 0.0440599
I0822 16:12:12.652624 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0440597 (* 1 = 0.0440597 loss)
I0822 16:12:12.652637 13823 sgd_solver.cpp:112] Iteration 8500, lr = 0.001
I0822 16:12:24.743963 13823 solver.cpp:239] Iteration 8600 (8.2704 iter/s, 12.0913s/100 iters), loss = 0.0556459
I0822 16:12:24.744019 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0556457 (* 1 = 0.0556457 loss)
I0822 16:12:24.744029 13823 sgd_solver.cpp:112] Iteration 8600, lr = 0.001
I0822 16:12:36.452008 13823 solver.cpp:239] Iteration 8700 (8.54121 iter/s, 11.7079s/100 iters), loss = 0.0756534
I0822 16:12:36.452064 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0756532 (* 1 = 0.0756532 loss)
I0822 16:12:36.452088 13823 sgd_solver.cpp:112] Iteration 8700, lr = 0.001
I0822 16:12:48.276715 13823 solver.cpp:239] Iteration 8800 (8.45693 iter/s, 11.8246s/100 iters), loss = 0.101058
I0822 16:12:48.276777 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.101058 (* 1 = 0.101058 loss)
I0822 16:12:48.276791 13823 sgd_solver.cpp:112] Iteration 8800, lr = 0.001
I0822 16:13:00.273536 13823 solver.cpp:239] Iteration 8900 (8.33561 iter/s, 11.9967s/100 iters), loss = 0.0526969
I0822 16:13:00.273600 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0526967 (* 1 = 0.0526967 loss)
I0822 16:13:00.273613 13823 sgd_solver.cpp:112] Iteration 8900, lr = 0.001
I0822 16:13:12.407764 13823 solver.cpp:239] Iteration 9000 (8.24122 iter/s, 12.1341s/100 iters), loss = 0.0629476
I0822 16:13:12.407832 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0629474 (* 1 = 0.0629474 loss)
I0822 16:13:12.407843 13823 sgd_solver.cpp:112] Iteration 9000, lr = 0.001
I0822 16:13:24.461853 13823 solver.cpp:239] Iteration 9100 (8.29601 iter/s, 12.054s/100 iters), loss = 0.0460682
I0822 16:13:24.461906 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.046068 (* 1 = 0.046068 loss)
I0822 16:13:24.461916 13823 sgd_solver.cpp:112] Iteration 9100, lr = 0.001
I0822 16:13:36.496732 13823 solver.cpp:239] Iteration 9200 (8.30925 iter/s, 12.0348s/100 iters), loss = 0.0449973
I0822 16:13:36.496791 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0449971 (* 1 = 0.0449971 loss)
I0822 16:13:36.496809 13823 sgd_solver.cpp:112] Iteration 9200, lr = 0.001
I0822 16:13:48.704563 13823 solver.cpp:239] Iteration 9300 (8.19153 iter/s, 12.2077s/100 iters), loss = 0.0639692
I0822 16:13:48.704617 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.063969 (* 1 = 0.063969 loss)
I0822 16:13:48.704627 13823 sgd_solver.cpp:112] Iteration 9300, lr = 0.001
I0822 16:14:00.499050 13823 solver.cpp:239] Iteration 9400 (8.4786 iter/s, 11.7944s/100 iters), loss = 0.038679
I0822 16:14:00.499095 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0386789 (* 1 = 0.0386789 loss)
I0822 16:14:00.499104 13823 sgd_solver.cpp:112] Iteration 9400, lr = 0.001
I0822 16:14:12.272619 13823 solver.cpp:239] Iteration 9500 (8.49366 iter/s, 11.7735s/100 iters), loss = 0.0490663
I0822 16:14:12.272686 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0490661 (* 1 = 0.0490661 loss)
I0822 16:14:12.272701 13823 sgd_solver.cpp:112] Iteration 9500, lr = 0.001
I0822 16:14:24.189363 13823 solver.cpp:239] Iteration 9600 (8.39162 iter/s, 11.9167s/100 iters), loss = 0.0458743
I0822 16:14:24.189416 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0458741 (* 1 = 0.0458741 loss)
I0822 16:14:24.189429 13823 sgd_solver.cpp:112] Iteration 9600, lr = 0.001
I0822 16:14:35.995893 13823 solver.cpp:239] Iteration 9700 (8.46995 iter/s, 11.8064s/100 iters), loss = 0.0444702
I0822 16:14:35.995945 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.04447 (* 1 = 0.04447 loss)
I0822 16:14:35.995966 13823 sgd_solver.cpp:112] Iteration 9700, lr = 0.001
I0822 16:14:47.913107 13823 solver.cpp:239] Iteration 9800 (8.39128 iter/s, 11.9171s/100 iters), loss = 0.0394781
I0822 16:14:47.913170 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0394779 (* 1 = 0.0394779 loss)
I0822 16:14:47.913182 13823 sgd_solver.cpp:112] Iteration 9800, lr = 0.001
I0822 16:14:59.713230 13823 solver.cpp:239] Iteration 9900 (8.47455 iter/s, 11.8s/100 iters), loss = 0.0404569
I0822 16:14:59.713287 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0404567 (* 1 = 0.0404567 loss)
I0822 16:14:59.713299 13823 sgd_solver.cpp:112] Iteration 9900, lr = 0.001
I0822 16:15:11.928669 13823 solver.cpp:239] Iteration 10000 (8.18642 iter/s, 12.2154s/100 iters), loss = 0.0482638
I0822 16:15:11.928728 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0482636 (* 1 = 0.0482636 loss)
I0822 16:15:11.928738 13823 sgd_solver.cpp:112] Iteration 10000, lr = 0.001
I0822 16:15:23.922405 13823 solver.cpp:239] Iteration 10100 (8.33774 iter/s, 11.9937s/100 iters), loss = 0.0509899
I0822 16:15:23.922461 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0509897 (* 1 = 0.0509897 loss)
I0822 16:15:23.922472 13823 sgd_solver.cpp:112] Iteration 10100, lr = 0.001
I0822 16:15:35.845762 13823 solver.cpp:239] Iteration 10200 (8.38696 iter/s, 11.9233s/100 iters), loss = 0.0491443
I0822 16:15:35.845824 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0491442 (* 1 = 0.0491442 loss)
I0822 16:15:35.845834 13823 sgd_solver.cpp:112] Iteration 10200, lr = 0.001
I0822 16:15:47.612527 13823 solver.cpp:239] Iteration 10300 (8.49858 iter/s, 11.7667s/100 iters), loss = 0.0411987
I0822 16:15:47.612576 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0411985 (* 1 = 0.0411985 loss)
I0822 16:15:47.612583 13823 sgd_solver.cpp:112] Iteration 10300, lr = 0.001
I0822 16:15:59.232846 13823 solver.cpp:239] Iteration 10400 (8.60567 iter/s, 11.6202s/100 iters), loss = 0.0501412
I0822 16:15:59.232899 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0501411 (* 1 = 0.0501411 loss)
I0822 16:15:59.232918 13823 sgd_solver.cpp:112] Iteration 10400, lr = 0.001
I0822 16:16:11.314877 13823 solver.cpp:239] Iteration 10500 (8.27681 iter/s, 12.0819s/100 iters), loss = 0.0416983
I0822 16:16:11.314939 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0416982 (* 1 = 0.0416982 loss)
I0822 16:16:11.314949 13823 sgd_solver.cpp:112] Iteration 10500, lr = 0.001
I0822 16:16:23.395866 13823 solver.cpp:239] Iteration 10600 (8.27753 iter/s, 12.0809s/100 iters), loss = 0.0524129
I0822 16:16:23.395928 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0524127 (* 1 = 0.0524127 loss)
I0822 16:16:23.395938 13823 sgd_solver.cpp:112] Iteration 10600, lr = 0.001
I0822 16:16:35.155460 13823 solver.cpp:239] Iteration 10700 (8.50376 iter/s, 11.7595s/100 iters), loss = 0.0362278
I0822 16:16:35.155516 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0362277 (* 1 = 0.0362277 loss)
I0822 16:16:35.155525 13823 sgd_solver.cpp:112] Iteration 10700, lr = 0.001
I0822 16:16:46.923898 13823 solver.cpp:239] Iteration 10800 (8.49736 iter/s, 11.7684s/100 iters), loss = 0.0604369
I0822 16:16:46.923951 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0604368 (* 1 = 0.0604368 loss)
I0822 16:16:46.923972 13823 sgd_solver.cpp:112] Iteration 10800, lr = 0.001
I0822 16:16:58.680838 13823 solver.cpp:239] Iteration 10900 (8.50567 iter/s, 11.7569s/100 iters), loss = 0.043082
I0822 16:16:58.680896 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0430819 (* 1 = 0.0430819 loss)
I0822 16:16:58.680907 13823 sgd_solver.cpp:112] Iteration 10900, lr = 0.001
I0822 16:17:10.742540 13823 solver.cpp:239] Iteration 11000 (8.29076 iter/s, 12.0616s/100 iters), loss = 0.0344094
I0822 16:17:10.742604 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0344092 (* 1 = 0.0344092 loss)
I0822 16:17:10.742620 13823 sgd_solver.cpp:112] Iteration 11000, lr = 0.001
I0822 16:17:22.743985 13823 solver.cpp:239] Iteration 11100 (8.33239 iter/s, 12.0014s/100 iters), loss = 0.035386
I0822 16:17:22.744045 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0353858 (* 1 = 0.0353858 loss)
I0822 16:17:22.744056 13823 sgd_solver.cpp:112] Iteration 11100, lr = 0.001
I0822 16:17:34.642086 13823 solver.cpp:239] Iteration 11200 (8.40476 iter/s, 11.898s/100 iters), loss = 0.0778479
I0822 16:17:34.642158 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0778478 (* 1 = 0.0778478 loss)
I0822 16:17:34.642170 13823 sgd_solver.cpp:112] Iteration 11200, lr = 0.001
I0822 16:17:46.754654 13823 solver.cpp:239] Iteration 11300 (8.25595 iter/s, 12.1125s/100 iters), loss = 0.0454111
I0822 16:17:46.754715 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.045411 (* 1 = 0.045411 loss)
I0822 16:17:46.754726 13823 sgd_solver.cpp:112] Iteration 11300, lr = 0.001
I0822 16:17:58.849289 13823 solver.cpp:239] Iteration 11400 (8.26819 iter/s, 12.0946s/100 iters), loss = 0.0739056
I0822 16:17:58.849352 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0739055 (* 1 = 0.0739055 loss)
I0822 16:17:58.849362 13823 sgd_solver.cpp:112] Iteration 11400, lr = 0.001
I0822 16:18:10.666123 13823 solver.cpp:239] Iteration 11500 (8.46257 iter/s, 11.8167s/100 iters), loss = 0.0436774
I0822 16:18:10.666184 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0436772 (* 1 = 0.0436772 loss)
I0822 16:18:10.666199 13823 sgd_solver.cpp:112] Iteration 11500, lr = 0.001
I0822 16:18:22.695925 13823 solver.cpp:239] Iteration 11600 (8.31275 iter/s, 12.0297s/100 iters), loss = 0.0537115
I0822 16:18:22.695987 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0537115 (* 1 = 0.0537115 loss)
I0822 16:18:22.695998 13823 sgd_solver.cpp:112] Iteration 11600, lr = 0.001
I0822 16:18:34.786415 13823 solver.cpp:239] Iteration 11700 (8.27102 iter/s, 12.0904s/100 iters), loss = 0.0439474
I0822 16:18:34.786468 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0439473 (* 1 = 0.0439473 loss)
I0822 16:18:34.786478 13823 sgd_solver.cpp:112] Iteration 11700, lr = 0.001
I0822 16:18:46.863574 13823 solver.cpp:239] Iteration 11800 (8.28014 iter/s, 12.0771s/100 iters), loss = 0.0429752
I0822 16:18:46.863631 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0429751 (* 1 = 0.0429751 loss)
I0822 16:18:46.863643 13823 sgd_solver.cpp:112] Iteration 11800, lr = 0.001
I0822 16:18:58.879824 13823 solver.cpp:239] Iteration 11900 (8.32212 iter/s, 12.0162s/100 iters), loss = 0.0460348
I0822 16:18:58.879886 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0460346 (* 1 = 0.0460346 loss)
I0822 16:18:58.879904 13823 sgd_solver.cpp:112] Iteration 11900, lr = 0.001
I0822 16:19:10.809586 13823 solver.cpp:239] Iteration 12000 (8.38245 iter/s, 11.9297s/100 iters), loss = 0.0384544
I0822 16:19:10.809648 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0384543 (* 1 = 0.0384543 loss)
I0822 16:19:10.809670 13823 sgd_solver.cpp:112] Iteration 12000, lr = 0.001
I0822 16:19:22.532585 13823 solver.cpp:239] Iteration 12100 (8.5303 iter/s, 11.7229s/100 iters), loss = 0.0810853
I0822 16:19:22.532646 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0810852 (* 1 = 0.0810852 loss)
I0822 16:19:22.532655 13823 sgd_solver.cpp:112] Iteration 12100, lr = 0.001
I0822 16:19:34.396551 13823 solver.cpp:239] Iteration 12200 (8.42894 iter/s, 11.8639s/100 iters), loss = 0.0421005
I0822 16:19:34.396610 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0421004 (* 1 = 0.0421004 loss)
I0822 16:19:34.396620 13823 sgd_solver.cpp:112] Iteration 12200, lr = 0.001
I0822 16:19:45.989465 13823 solver.cpp:239] Iteration 12300 (8.62602 iter/s, 11.5928s/100 iters), loss = 0.0423723
I0822 16:19:45.989529 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0423722 (* 1 = 0.0423722 loss)
I0822 16:19:45.989539 13823 sgd_solver.cpp:112] Iteration 12300, lr = 0.001
I0822 16:19:57.645795 13823 solver.cpp:239] Iteration 12400 (8.57909 iter/s, 11.6562s/100 iters), loss = 0.0533541
I0822 16:19:57.645848 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.053354 (* 1 = 0.053354 loss)
I0822 16:19:57.645859 13823 sgd_solver.cpp:112] Iteration 12400, lr = 0.001
I0822 16:20:09.793731 13823 solver.cpp:239] Iteration 12500 (8.2319 iter/s, 12.1479s/100 iters), loss = 0.0470822
I0822 16:20:09.793787 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0470821 (* 1 = 0.0470821 loss)
I0822 16:20:09.793797 13823 sgd_solver.cpp:112] Iteration 12500, lr = 0.001
I0822 16:20:21.586393 13823 solver.cpp:239] Iteration 12600 (8.4799 iter/s, 11.7926s/100 iters), loss = 0.0435278
I0822 16:20:21.586455 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0435277 (* 1 = 0.0435277 loss)
I0822 16:20:21.586475 13823 sgd_solver.cpp:112] Iteration 12600, lr = 0.001
I0822 16:20:33.517012 13823 solver.cpp:239] Iteration 12700 (8.38185 iter/s, 11.9305s/100 iters), loss = 0.0450609
I0822 16:20:33.517069 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0450608 (* 1 = 0.0450608 loss)
I0822 16:20:33.517081 13823 sgd_solver.cpp:112] Iteration 12700, lr = 0.001
I0822 16:20:45.580425 13823 solver.cpp:239] Iteration 12800 (8.28958 iter/s, 12.0633s/100 iters), loss = 0.0402345
I0822 16:20:45.580483 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0402344 (* 1 = 0.0402344 loss)
I0822 16:20:45.580494 13823 sgd_solver.cpp:112] Iteration 12800, lr = 0.001
I0822 16:20:57.469379 13823 solver.cpp:239] Iteration 12900 (8.41122 iter/s, 11.8889s/100 iters), loss = 0.0371258
I0822 16:20:57.469441 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0371257 (* 1 = 0.0371257 loss)
I0822 16:20:57.469450 13823 sgd_solver.cpp:112] Iteration 12900, lr = 0.001
I0822 16:21:09.381168 13823 solver.cpp:239] Iteration 13000 (8.3951 iter/s, 11.9117s/100 iters), loss = 0.0338433
I0822 16:21:09.381219 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0338432 (* 1 = 0.0338432 loss)
I0822 16:21:09.381237 13823 sgd_solver.cpp:112] Iteration 13000, lr = 0.001
I0822 16:21:21.250520 13823 solver.cpp:239] Iteration 13100 (8.42511 iter/s, 11.8693s/100 iters), loss = 0.0441077
I0822 16:21:21.250577 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0441076 (* 1 = 0.0441076 loss)
I0822 16:21:21.250588 13823 sgd_solver.cpp:112] Iteration 13100, lr = 0.001
I0822 16:21:33.119462 13823 solver.cpp:239] Iteration 13200 (8.4254 iter/s, 11.8689s/100 iters), loss = 0.0511844
I0822 16:21:33.119520 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0511842 (* 1 = 0.0511842 loss)
I0822 16:21:33.119535 13823 sgd_solver.cpp:112] Iteration 13200, lr = 0.001
I0822 16:21:44.949261 13823 solver.cpp:239] Iteration 13300 (8.45328 iter/s, 11.8297s/100 iters), loss = 0.0362099
I0822 16:21:44.949312 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0362098 (* 1 = 0.0362098 loss)
I0822 16:21:44.949323 13823 sgd_solver.cpp:112] Iteration 13300, lr = 0.001
I0822 16:21:56.486393 13823 solver.cpp:239] Iteration 13400 (8.66772 iter/s, 11.5371s/100 iters), loss = 0.0353676
I0822 16:21:56.486456 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0353674 (* 1 = 0.0353674 loss)
I0822 16:21:56.486469 13823 sgd_solver.cpp:112] Iteration 13400, lr = 0.001
I0822 16:22:08.548681 13823 solver.cpp:239] Iteration 13500 (8.29035 iter/s, 12.0622s/100 iters), loss = 0.036648
I0822 16:22:08.548725 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0366479 (* 1 = 0.0366479 loss)
I0822 16:22:08.548733 13823 sgd_solver.cpp:112] Iteration 13500, lr = 0.001
I0822 16:22:20.299517 13823 solver.cpp:239] Iteration 13600 (8.51007 iter/s, 11.7508s/100 iters), loss = 0.03972
I0822 16:22:20.299564 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0397198 (* 1 = 0.0397198 loss)
I0822 16:22:20.299584 13823 sgd_solver.cpp:112] Iteration 13600, lr = 0.001
I0822 16:22:32.379863 13823 solver.cpp:239] Iteration 13700 (8.27795 iter/s, 12.0803s/100 iters), loss = 0.0448304
I0822 16:22:32.379920 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0448303 (* 1 = 0.0448303 loss)
I0822 16:22:32.379935 13823 sgd_solver.cpp:112] Iteration 13700, lr = 0.001
I0822 16:22:44.773566 13823 solver.cpp:239] Iteration 13800 (8.06866 iter/s, 12.3936s/100 iters), loss = 0.0353362
I0822 16:22:44.773634 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.035336 (* 1 = 0.035336 loss)
I0822 16:22:44.773648 13823 sgd_solver.cpp:112] Iteration 13800, lr = 0.001
I0822 16:22:57.055889 13823 solver.cpp:239] Iteration 13900 (8.14183 iter/s, 12.2822s/100 iters), loss = 0.0399587
I0822 16:22:57.055945 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0399585 (* 1 = 0.0399585 loss)
I0822 16:22:57.055956 13823 sgd_solver.cpp:112] Iteration 13900, lr = 0.001
I0822 16:23:09.265188 13823 solver.cpp:239] Iteration 14000 (8.19052 iter/s, 12.2092s/100 iters), loss = 0.0584106
I0822 16:23:09.265244 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0584104 (* 1 = 0.0584104 loss)
I0822 16:23:09.265256 13823 sgd_solver.cpp:112] Iteration 14000, lr = 0.001
I0822 16:23:21.470996 13823 solver.cpp:239] Iteration 14100 (8.19287 iter/s, 12.2057s/100 iters), loss = 0.0478888
I0822 16:23:21.471060 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0478886 (* 1 = 0.0478886 loss)
I0822 16:23:21.471072 13823 sgd_solver.cpp:112] Iteration 14100, lr = 0.001
I0822 16:23:33.940974 13823 solver.cpp:239] Iteration 14200 (8.01931 iter/s, 12.4699s/100 iters), loss = 0.0632591
I0822 16:23:33.941043 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0632589 (* 1 = 0.0632589 loss)
I0822 16:23:33.941057 13823 sgd_solver.cpp:112] Iteration 14200, lr = 0.001
I0822 16:23:46.137665 13823 solver.cpp:239] Iteration 14300 (8.199 iter/s, 12.1966s/100 iters), loss = 0.0394855
I0822 16:23:46.137715 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0394853 (* 1 = 0.0394853 loss)
I0822 16:23:46.137725 13823 sgd_solver.cpp:112] Iteration 14300, lr = 0.001
I0822 16:23:58.435698 13823 solver.cpp:239] Iteration 14400 (8.13142 iter/s, 12.298s/100 iters), loss = 0.0439774
I0822 16:23:58.435752 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0439773 (* 1 = 0.0439773 loss)
I0822 16:23:58.435763 13823 sgd_solver.cpp:112] Iteration 14400, lr = 0.001
I0822 16:24:10.653861 13823 solver.cpp:239] Iteration 14500 (8.18458 iter/s, 12.2181s/100 iters), loss = 0.0388646
I0822 16:24:10.653921 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0388645 (* 1 = 0.0388645 loss)
I0822 16:24:10.653934 13823 sgd_solver.cpp:112] Iteration 14500, lr = 0.001
I0822 16:24:22.824221 13823 solver.cpp:239] Iteration 14600 (8.21673 iter/s, 12.1703s/100 iters), loss = 0.0351174
I0822 16:24:22.824278 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0351172 (* 1 = 0.0351172 loss)
I0822 16:24:22.824288 13823 sgd_solver.cpp:112] Iteration 14600, lr = 0.001
I0822 16:24:34.931993 13823 solver.cpp:239] Iteration 14700 (8.2592 iter/s, 12.1077s/100 iters), loss = 0.0523806
I0822 16:24:34.932054 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0523805 (* 1 = 0.0523805 loss)
I0822 16:24:34.932067 13823 sgd_solver.cpp:112] Iteration 14700, lr = 0.001
I0822 16:24:46.700709 13823 solver.cpp:239] Iteration 14800 (8.49715 iter/s, 11.7686s/100 iters), loss = 0.039559
I0822 16:24:46.700762 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0395589 (* 1 = 0.0395589 loss)
I0822 16:24:46.700772 13823 sgd_solver.cpp:112] Iteration 14800, lr = 0.001
I0822 16:24:58.553699 13823 solver.cpp:239] Iteration 14900 (8.43673 iter/s, 11.8529s/100 iters), loss = 0.037078
I0822 16:24:58.553757 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0370778 (* 1 = 0.0370778 loss)
I0822 16:24:58.553766 13823 sgd_solver.cpp:112] Iteration 14900, lr = 0.001
I0822 16:25:10.117595 13823 solver.cpp:239] Iteration 15000 (8.64765 iter/s, 11.5638s/100 iters), loss = 0.0373348
I0822 16:25:10.117650 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0373346 (* 1 = 0.0373346 loss)
I0822 16:25:10.117671 13823 sgd_solver.cpp:112] Iteration 15000, lr = 0.001
I0822 16:25:22.143800 13823 solver.cpp:239] Iteration 15100 (8.31522 iter/s, 12.0261s/100 iters), loss = 0.0343741
I0822 16:25:22.143854 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0343739 (* 1 = 0.0343739 loss)
I0822 16:25:22.143863 13823 sgd_solver.cpp:112] Iteration 15100, lr = 0.001
I0822 16:25:34.593008 13823 solver.cpp:239] Iteration 15200 (8.03269 iter/s, 12.4491s/100 iters), loss = 0.0391327
I0822 16:25:34.593065 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0391325 (* 1 = 0.0391325 loss)
I0822 16:25:34.593086 13823 sgd_solver.cpp:112] Iteration 15200, lr = 0.001
I0822 16:25:46.090699 13823 solver.cpp:239] Iteration 15300 (8.69745 iter/s, 11.4976s/100 iters), loss = 0.108066
I0822 16:25:46.090744 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.108066 (* 1 = 0.108066 loss)
I0822 16:25:46.090752 13823 sgd_solver.cpp:112] Iteration 15300, lr = 0.001
I0822 16:25:57.587458 13823 solver.cpp:239] Iteration 15400 (8.69814 iter/s, 11.4967s/100 iters), loss = 0.0345175
I0822 16:25:57.587507 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0345174 (* 1 = 0.0345174 loss)
I0822 16:25:57.587517 13823 sgd_solver.cpp:112] Iteration 15400, lr = 0.001
I0822 16:26:09.294946 13823 solver.cpp:239] Iteration 15500 (8.54158 iter/s, 11.7074s/100 iters), loss = 0.0505296
I0822 16:26:09.294996 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0505294 (* 1 = 0.0505294 loss)
I0822 16:26:09.295006 13823 sgd_solver.cpp:112] Iteration 15500, lr = 0.001
I0822 16:26:20.868307 13823 solver.cpp:239] Iteration 15600 (8.64058 iter/s, 11.5733s/100 iters), loss = 0.03596
I0822 16:26:20.868362 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0359598 (* 1 = 0.0359598 loss)
I0822 16:26:20.868381 13823 sgd_solver.cpp:112] Iteration 15600, lr = 0.001
I0822 16:26:32.493144 13823 solver.cpp:239] Iteration 15700 (8.60232 iter/s, 11.6248s/100 iters), loss = 0.0378529
I0822 16:26:32.493193 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0378527 (* 1 = 0.0378527 loss)
I0822 16:26:32.493203 13823 sgd_solver.cpp:112] Iteration 15700, lr = 0.001
I0822 16:26:44.253415 13823 solver.cpp:239] Iteration 15800 (8.50325 iter/s, 11.7602s/100 iters), loss = 0.0414465
I0822 16:26:44.253473 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0414463 (* 1 = 0.0414463 loss)
I0822 16:26:44.253485 13823 sgd_solver.cpp:112] Iteration 15800, lr = 0.001
I0822 16:26:55.964480 13823 solver.cpp:239] Iteration 15900 (8.53898 iter/s, 11.711s/100 iters), loss = 0.0380203
I0822 16:26:55.964536 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0380202 (* 1 = 0.0380202 loss)
I0822 16:26:55.964555 13823 sgd_solver.cpp:112] Iteration 15900, lr = 0.001
I0822 16:27:07.750365 13823 solver.cpp:239] Iteration 16000 (8.48477 iter/s, 11.7858s/100 iters), loss = 0.0420161
I0822 16:27:07.750423 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0420159 (* 1 = 0.0420159 loss)
I0822 16:27:07.750442 13823 sgd_solver.cpp:112] Iteration 16000, lr = 0.001
I0822 16:27:19.517633 13823 solver.cpp:239] Iteration 16100 (8.49819 iter/s, 11.7672s/100 iters), loss = 0.041273
I0822 16:27:19.517683 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0412728 (* 1 = 0.0412728 loss)
I0822 16:27:19.517700 13823 sgd_solver.cpp:112] Iteration 16100, lr = 0.001
I0822 16:27:31.245788 13823 solver.cpp:239] Iteration 16200 (8.52653 iter/s, 11.7281s/100 iters), loss = 0.0358573
I0822 16:27:31.245837 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0358571 (* 1 = 0.0358571 loss)
I0822 16:27:31.245847 13823 sgd_solver.cpp:112] Iteration 16200, lr = 0.001
I0822 16:27:42.637886 13823 solver.cpp:239] Iteration 16300 (8.77806 iter/s, 11.392s/100 iters), loss = 0.0389086
I0822 16:27:42.637928 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0389085 (* 1 = 0.0389085 loss)
I0822 16:27:42.637936 13823 sgd_solver.cpp:112] Iteration 16300, lr = 0.001
I0822 16:27:53.919116 13823 solver.cpp:239] Iteration 16400 (8.86432 iter/s, 11.2812s/100 iters), loss = 0.0679953
I0822 16:27:53.919158 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0679952 (* 1 = 0.0679952 loss)
I0822 16:27:53.919167 13823 sgd_solver.cpp:112] Iteration 16400, lr = 0.001
I0822 16:28:05.497923 13823 solver.cpp:239] Iteration 16500 (8.63651 iter/s, 11.5788s/100 iters), loss = 0.0451508
I0822 16:28:05.497987 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0451507 (* 1 = 0.0451507 loss)
I0822 16:28:05.498005 13823 sgd_solver.cpp:112] Iteration 16500, lr = 0.001
I0822 16:28:17.358994 13823 solver.cpp:239] Iteration 16600 (8.43099 iter/s, 11.861s/100 iters), loss = 0.0911689
I0822 16:28:17.359043 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0911688 (* 1 = 0.0911688 loss)
I0822 16:28:17.359052 13823 sgd_solver.cpp:112] Iteration 16600, lr = 0.001
I0822 16:28:29.083978 13823 solver.cpp:239] Iteration 16700 (8.52884 iter/s, 11.7249s/100 iters), loss = 0.0315483
I0822 16:28:29.084025 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0315482 (* 1 = 0.0315482 loss)
I0822 16:28:29.084034 13823 sgd_solver.cpp:112] Iteration 16700, lr = 0.001
I0822 16:28:41.034704 13823 solver.cpp:239] Iteration 16800 (8.36773 iter/s, 11.9507s/100 iters), loss = 0.0485082
I0822 16:28:41.034763 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0485081 (* 1 = 0.0485081 loss)
I0822 16:28:41.034775 13823 sgd_solver.cpp:112] Iteration 16800, lr = 0.001
I0822 16:28:52.863509 13823 solver.cpp:239] Iteration 16900 (8.45399 iter/s, 11.8287s/100 iters), loss = 0.0447417
I0822 16:28:52.863561 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0447415 (* 1 = 0.0447415 loss)
I0822 16:28:52.863571 13823 sgd_solver.cpp:112] Iteration 16900, lr = 0.001
I0822 16:29:04.587958 13823 solver.cpp:239] Iteration 17000 (8.52923 iter/s, 11.7244s/100 iters), loss = 0.0355014
I0822 16:29:04.588024 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0355012 (* 1 = 0.0355012 loss)
I0822 16:29:04.588042 13823 sgd_solver.cpp:112] Iteration 17000, lr = 0.001
I0822 16:29:16.300803 13823 solver.cpp:239] Iteration 17100 (8.53768 iter/s, 11.7128s/100 iters), loss = 0.0405045
I0822 16:29:16.300864 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0405044 (* 1 = 0.0405044 loss)
I0822 16:29:16.300873 13823 sgd_solver.cpp:112] Iteration 17100, lr = 0.001
I0822 16:29:28.021035 13823 solver.cpp:239] Iteration 17200 (8.5323 iter/s, 11.7202s/100 iters), loss = 0.0359183
I0822 16:29:28.021090 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0359182 (* 1 = 0.0359182 loss)
I0822 16:29:28.021100 13823 sgd_solver.cpp:112] Iteration 17200, lr = 0.001
I0822 16:29:39.654809 13823 solver.cpp:239] Iteration 17300 (8.59571 iter/s, 11.6337s/100 iters), loss = 0.032711
I0822 16:29:39.654866 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0327109 (* 1 = 0.0327109 loss)
I0822 16:29:39.654875 13823 sgd_solver.cpp:112] Iteration 17300, lr = 0.001
I0822 16:29:51.654492 13823 solver.cpp:239] Iteration 17400 (8.3336 iter/s, 11.9996s/100 iters), loss = 0.0421994
I0822 16:29:51.654551 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0421993 (* 1 = 0.0421993 loss)
I0822 16:29:51.654565 13823 sgd_solver.cpp:112] Iteration 17400, lr = 0.001
I0822 16:30:03.900398 13823 solver.cpp:239] Iteration 17500 (8.16604 iter/s, 12.2458s/100 iters), loss = 0.0471987
I0822 16:30:03.900462 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0471985 (* 1 = 0.0471985 loss)
I0822 16:30:03.900475 13823 sgd_solver.cpp:112] Iteration 17500, lr = 0.001
I0822 16:30:15.983718 13823 solver.cpp:239] Iteration 17600 (8.27592 iter/s, 12.0833s/100 iters), loss = 0.0390886
I0822 16:30:15.983779 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0390885 (* 1 = 0.0390885 loss)
I0822 16:30:15.983790 13823 sgd_solver.cpp:112] Iteration 17600, lr = 0.001
I0822 16:30:27.823678 13823 solver.cpp:239] Iteration 17700 (8.44602 iter/s, 11.8399s/100 iters), loss = 0.0606954
I0822 16:30:27.823729 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0606953 (* 1 = 0.0606953 loss)
I0822 16:30:27.823740 13823 sgd_solver.cpp:112] Iteration 17700, lr = 0.001
I0822 16:30:39.771364 13823 solver.cpp:239] Iteration 17800 (8.36986 iter/s, 11.9476s/100 iters), loss = 0.0431402
I0822 16:30:39.771416 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.04314 (* 1 = 0.04314 loss)
I0822 16:30:39.771426 13823 sgd_solver.cpp:112] Iteration 17800, lr = 0.001
I0822 16:30:51.835373 13823 solver.cpp:239] Iteration 17900 (8.28916 iter/s, 12.064s/100 iters), loss = 0.0356321
I0822 16:30:51.835431 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.035632 (* 1 = 0.035632 loss)
I0822 16:30:51.835441 13823 sgd_solver.cpp:112] Iteration 17900, lr = 0.001
I0822 16:31:03.736240 13823 solver.cpp:239] Iteration 18000 (8.40279 iter/s, 11.9008s/100 iters), loss = 0.0424181
I0822 16:31:03.736286 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0424179 (* 1 = 0.0424179 loss)
I0822 16:31:03.736295 13823 sgd_solver.cpp:112] Iteration 18000, lr = 0.001
I0822 16:31:15.784098 13823 solver.cpp:239] Iteration 18100 (8.30027 iter/s, 12.0478s/100 iters), loss = 0.0345795
I0822 16:31:15.784162 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0345794 (* 1 = 0.0345794 loss)
I0822 16:31:15.784175 13823 sgd_solver.cpp:112] Iteration 18100, lr = 0.001
I0822 16:31:27.725121 13823 solver.cpp:239] Iteration 18200 (8.37454 iter/s, 11.941s/100 iters), loss = 0.0396055
I0822 16:31:27.725172 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0396054 (* 1 = 0.0396054 loss)
I0822 16:31:27.725183 13823 sgd_solver.cpp:112] Iteration 18200, lr = 0.001
I0822 16:31:39.152266 13823 solver.cpp:239] Iteration 18300 (8.75113 iter/s, 11.4271s/100 iters), loss = 0.0516516
I0822 16:31:39.152323 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0516515 (* 1 = 0.0516515 loss)
I0822 16:31:39.152335 13823 sgd_solver.cpp:112] Iteration 18300, lr = 0.001
I0822 16:31:49.912613 13823 solver.cpp:239] Iteration 18400 (9.29343 iter/s, 10.7603s/100 iters), loss = 0.0359564
I0822 16:31:49.912673 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0359563 (* 1 = 0.0359563 loss)
I0822 16:31:49.912683 13823 sgd_solver.cpp:112] Iteration 18400, lr = 0.001
I0822 16:32:01.041923 13823 solver.cpp:239] Iteration 18500 (8.98533 iter/s, 11.1292s/100 iters), loss = 0.0317084
I0822 16:32:01.041980 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0317083 (* 1 = 0.0317083 loss)
I0822 16:32:01.041988 13823 sgd_solver.cpp:112] Iteration 18500, lr = 0.001
I0822 16:32:11.893319 13823 solver.cpp:239] Iteration 18600 (9.21546 iter/s, 10.8513s/100 iters), loss = 0.0564431
I0822 16:32:11.893384 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.056443 (* 1 = 0.056443 loss)
I0822 16:32:11.893396 13823 sgd_solver.cpp:112] Iteration 18600, lr = 0.001
I0822 16:32:23.118007 13823 solver.cpp:239] Iteration 18700 (8.90899 iter/s, 11.2246s/100 iters), loss = 0.038533
I0822 16:32:23.118070 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0385329 (* 1 = 0.0385329 loss)
I0822 16:32:23.118086 13823 sgd_solver.cpp:112] Iteration 18700, lr = 0.001
I0822 16:32:34.285876 13823 solver.cpp:239] Iteration 18800 (8.95431 iter/s, 11.1678s/100 iters), loss = 0.0363846
I0822 16:32:34.285933 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0363845 (* 1 = 0.0363845 loss)
I0822 16:32:34.285943 13823 sgd_solver.cpp:112] Iteration 18800, lr = 0.001
I0822 16:32:45.477598 13823 solver.cpp:239] Iteration 18900 (8.93522 iter/s, 11.1917s/100 iters), loss = 0.0529669
I0822 16:32:45.477655 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0529668 (* 1 = 0.0529668 loss)
I0822 16:32:45.477665 13823 sgd_solver.cpp:112] Iteration 18900, lr = 0.001
I0822 16:32:56.433769 13823 solver.cpp:239] Iteration 19000 (9.12733 iter/s, 10.9561s/100 iters), loss = 0.0395915
I0822 16:32:56.433822 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0395914 (* 1 = 0.0395914 loss)
I0822 16:32:56.433840 13823 sgd_solver.cpp:112] Iteration 19000, lr = 0.001
I0822 16:33:07.584466 13823 solver.cpp:239] Iteration 19100 (8.96809 iter/s, 11.1506s/100 iters), loss = 0.0318969
I0822 16:33:07.584520 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0318968 (* 1 = 0.0318968 loss)
I0822 16:33:07.584532 13823 sgd_solver.cpp:112] Iteration 19100, lr = 0.001
I0822 16:33:18.593004 13823 solver.cpp:239] Iteration 19200 (9.08391 iter/s, 11.0085s/100 iters), loss = 0.0519843
I0822 16:33:18.593063 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0519842 (* 1 = 0.0519842 loss)
I0822 16:33:18.593072 13823 sgd_solver.cpp:112] Iteration 19200, lr = 0.001
I0822 16:33:29.516263 13823 solver.cpp:239] Iteration 19300 (9.15483 iter/s, 10.9232s/100 iters), loss = 0.0571378
I0822 16:33:29.516309 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0571376 (* 1 = 0.0571376 loss)
I0822 16:33:29.516317 13823 sgd_solver.cpp:112] Iteration 19300, lr = 0.001
I0822 16:33:40.309070 13823 solver.cpp:239] Iteration 19400 (9.26547 iter/s, 10.7928s/100 iters), loss = 0.0423171
I0822 16:33:40.309129 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.042317 (* 1 = 0.042317 loss)
I0822 16:33:40.309139 13823 sgd_solver.cpp:112] Iteration 19400, lr = 0.001
I0822 16:33:51.470573 13823 solver.cpp:239] Iteration 19500 (8.95942 iter/s, 11.1614s/100 iters), loss = 0.0415414
I0822 16:33:51.470628 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0415413 (* 1 = 0.0415413 loss)
I0822 16:33:51.470636 13823 sgd_solver.cpp:112] Iteration 19500, lr = 0.001
I0822 16:34:02.315528 13823 solver.cpp:239] Iteration 19600 (9.22092 iter/s, 10.8449s/100 iters), loss = 0.0448769
I0822 16:34:02.315582 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0448767 (* 1 = 0.0448767 loss)
I0822 16:34:02.315593 13823 sgd_solver.cpp:112] Iteration 19600, lr = 0.001
I0822 16:34:13.110007 13823 solver.cpp:239] Iteration 19700 (9.26405 iter/s, 10.7944s/100 iters), loss = 0.040643
I0822 16:34:13.110064 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0406429 (* 1 = 0.0406429 loss)
I0822 16:34:13.110072 13823 sgd_solver.cpp:112] Iteration 19700, lr = 0.001
I0822 16:34:24.029160 13823 solver.cpp:239] Iteration 19800 (9.15827 iter/s, 10.9191s/100 iters), loss = 0.0435261
I0822 16:34:24.029208 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.043526 (* 1 = 0.043526 loss)
I0822 16:34:24.029228 13823 sgd_solver.cpp:112] Iteration 19800, lr = 0.001
I0822 16:34:34.580900 13823 solver.cpp:239] Iteration 19900 (9.47716 iter/s, 10.5517s/100 iters), loss = 0.037269
I0822 16:34:34.580958 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0372689 (* 1 = 0.0372689 loss)
I0822 16:34:34.580966 13823 sgd_solver.cpp:112] Iteration 19900, lr = 0.001
I0822 16:34:45.344611 13823 solver.cpp:464] Snapshotting to binary proto file ./model_112/cascade_mobilenet_112_iter_20000.caffemodel
I0822 16:34:45.398191 13823 sgd_solver.cpp:284] Snapshotting solver state to binary proto file ./model_112/cascade_mobilenet_112_iter_20000.solverstate
I0822 16:34:45.428822 13823 solver.cpp:347] Iteration 20000, Testing net (#0)
I0822 16:35:58.772109 13823 solver.cpp:414]     Test net output #0: landmark_loss = 0.0458874 (* 1 = 0.0458874 loss)
I0822 16:35:58.890076 13823 solver.cpp:239] Iteration 20000 (1.18611 iter/s, 84.3092s/100 iters), loss = 0.0496478
I0822 16:35:58.890141 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0496477 (* 1 = 0.0496477 loss)
I0822 16:35:58.890152 13823 sgd_solver.cpp:50] MultiStep Status: Iteration 20000, step = 1
I0822 16:35:58.890158 13823 sgd_solver.cpp:112] Iteration 20000, lr = 0.0001
I0822 16:36:10.359158 13823 solver.cpp:239] Iteration 20100 (8.71914 iter/s, 11.469s/100 iters), loss = 0.0494953
I0822 16:36:10.359215 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0494951 (* 1 = 0.0494951 loss)
I0822 16:36:10.359225 13823 sgd_solver.cpp:112] Iteration 20100, lr = 0.0001
I0822 16:36:21.411547 13823 solver.cpp:239] Iteration 20200 (9.04786 iter/s, 11.0523s/100 iters), loss = 0.0555279
I0822 16:36:21.411603 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0555278 (* 1 = 0.0555278 loss)
I0822 16:36:21.411617 13823 sgd_solver.cpp:112] Iteration 20200, lr = 0.0001
I0822 16:36:32.514477 13823 solver.cpp:239] Iteration 20300 (9.00667 iter/s, 11.1029s/100 iters), loss = 0.0324726
I0822 16:36:32.514528 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0324724 (* 1 = 0.0324724 loss)
I0822 16:36:32.514539 13823 sgd_solver.cpp:112] Iteration 20300, lr = 0.0001
I0822 16:36:43.685920 13823 solver.cpp:239] Iteration 20400 (8.95143 iter/s, 11.1714s/100 iters), loss = 0.0363887
I0822 16:36:43.685976 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0363885 (* 1 = 0.0363885 loss)
I0822 16:36:43.685986 13823 sgd_solver.cpp:112] Iteration 20400, lr = 0.0001
I0822 16:36:55.228160 13823 solver.cpp:239] Iteration 20500 (8.66387 iter/s, 11.5422s/100 iters), loss = 0.0310537
I0822 16:36:55.228217 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0310535 (* 1 = 0.0310535 loss)
I0822 16:36:55.228227 13823 sgd_solver.cpp:112] Iteration 20500, lr = 0.0001
I0822 16:37:06.572300 13823 solver.cpp:239] Iteration 20600 (8.8152 iter/s, 11.344s/100 iters), loss = 0.0436082
I0822 16:37:06.572357 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.043608 (* 1 = 0.043608 loss)
I0822 16:37:06.572368 13823 sgd_solver.cpp:112] Iteration 20600, lr = 0.0001
I0822 16:37:18.131052 13823 solver.cpp:239] Iteration 20700 (8.65155 iter/s, 11.5586s/100 iters), loss = 0.0347715
I0822 16:37:18.131103 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0347713 (* 1 = 0.0347713 loss)
I0822 16:37:18.131119 13823 sgd_solver.cpp:112] Iteration 20700, lr = 0.0001
I0822 16:37:29.679814 13823 solver.cpp:239] Iteration 20800 (8.65903 iter/s, 11.5486s/100 iters), loss = 0.040265
I0822 16:37:29.679869 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0402648 (* 1 = 0.0402648 loss)
I0822 16:37:29.679886 13823 sgd_solver.cpp:112] Iteration 20800, lr = 0.0001
I0822 16:37:40.816956 13823 solver.cpp:239] Iteration 20900 (8.97906 iter/s, 11.137s/100 iters), loss = 0.124929
I0822 16:37:40.817001 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.124928 (* 1 = 0.124928 loss)
I0822 16:37:40.817021 13823 sgd_solver.cpp:112] Iteration 20900, lr = 0.0001
I0822 16:37:51.862206 13823 solver.cpp:239] Iteration 21000 (9.05376 iter/s, 11.0451s/100 iters), loss = 0.0500515
I0822 16:37:51.862251 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0500514 (* 1 = 0.0500514 loss)
I0822 16:37:51.862259 13823 sgd_solver.cpp:112] Iteration 21000, lr = 0.0001
I0822 16:38:03.178936 13823 solver.cpp:239] Iteration 21100 (8.83657 iter/s, 11.3166s/100 iters), loss = 0.032935
I0822 16:38:03.178997 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0329348 (* 1 = 0.0329348 loss)
I0822 16:38:03.179008 13823 sgd_solver.cpp:112] Iteration 21100, lr = 0.0001
I0822 16:38:14.333801 13823 solver.cpp:239] Iteration 21200 (8.9648 iter/s, 11.1547s/100 iters), loss = 0.0315492
I0822 16:38:14.333859 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.031549 (* 1 = 0.031549 loss)
I0822 16:38:14.333868 13823 sgd_solver.cpp:112] Iteration 21200, lr = 0.0001
I0822 16:38:25.378989 13823 solver.cpp:239] Iteration 21300 (9.05382 iter/s, 11.0451s/100 iters), loss = 0.038742
I0822 16:38:25.379046 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0387419 (* 1 = 0.0387419 loss)
I0822 16:38:25.379055 13823 sgd_solver.cpp:112] Iteration 21300, lr = 0.0001
I0822 16:38:36.240039 13823 solver.cpp:239] Iteration 21400 (9.20731 iter/s, 10.8609s/100 iters), loss = 0.03143
I0822 16:38:36.240094 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0314298 (* 1 = 0.0314298 loss)
I0822 16:38:36.240103 13823 sgd_solver.cpp:112] Iteration 21400, lr = 0.0001
I0822 16:38:47.125355 13823 solver.cpp:239] Iteration 21500 (9.18679 iter/s, 10.8852s/100 iters), loss = 0.0340915
I0822 16:38:47.125413 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0340913 (* 1 = 0.0340913 loss)
I0822 16:38:47.125423 13823 sgd_solver.cpp:112] Iteration 21500, lr = 0.0001
I0822 16:38:58.061695 13823 solver.cpp:239] Iteration 21600 (9.14393 iter/s, 10.9362s/100 iters), loss = 0.0322714
I0822 16:38:58.061758 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0322712 (* 1 = 0.0322712 loss)
I0822 16:38:58.061770 13823 sgd_solver.cpp:112] Iteration 21600, lr = 0.0001
I0822 16:39:09.349792 13823 solver.cpp:239] Iteration 21700 (8.85899 iter/s, 11.288s/100 iters), loss = 0.0282605
I0822 16:39:09.349848 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0282604 (* 1 = 0.0282604 loss)
I0822 16:39:09.349858 13823 sgd_solver.cpp:112] Iteration 21700, lr = 0.0001
I0822 16:39:20.577540 13823 solver.cpp:239] Iteration 21800 (8.9066 iter/s, 11.2276s/100 iters), loss = 0.0321512
I0822 16:39:20.577598 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0321511 (* 1 = 0.0321511 loss)
I0822 16:39:20.577608 13823 sgd_solver.cpp:112] Iteration 21800, lr = 0.0001
I0822 16:39:31.938588 13823 solver.cpp:239] Iteration 21900 (8.8021 iter/s, 11.3609s/100 iters), loss = 0.0468117
I0822 16:39:31.938642 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0468116 (* 1 = 0.0468116 loss)
I0822 16:39:31.938652 13823 sgd_solver.cpp:112] Iteration 21900, lr = 0.0001
I0822 16:39:43.094645 13823 solver.cpp:239] Iteration 22000 (8.96383 iter/s, 11.1559s/100 iters), loss = 0.0335929
I0822 16:39:43.094707 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0335927 (* 1 = 0.0335927 loss)
I0822 16:39:43.094715 13823 sgd_solver.cpp:112] Iteration 22000, lr = 0.0001
I0822 16:39:54.893963 13823 solver.cpp:239] Iteration 22100 (8.47515 iter/s, 11.7992s/100 iters), loss = 0.0332373
I0822 16:39:54.894016 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0332371 (* 1 = 0.0332371 loss)
I0822 16:39:54.894026 13823 sgd_solver.cpp:112] Iteration 22100, lr = 0.0001
I0822 16:40:06.693773 13823 solver.cpp:239] Iteration 22200 (8.47479 iter/s, 11.7997s/100 iters), loss = 0.0332212
I0822 16:40:06.693833 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0332211 (* 1 = 0.0332211 loss)
I0822 16:40:06.693842 13823 sgd_solver.cpp:112] Iteration 22200, lr = 0.0001
I0822 16:40:18.319931 13823 solver.cpp:239] Iteration 22300 (8.60138 iter/s, 11.626s/100 iters), loss = 0.0334815
I0822 16:40:18.319993 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0334813 (* 1 = 0.0334813 loss)
I0822 16:40:18.320004 13823 sgd_solver.cpp:112] Iteration 22300, lr = 0.0001
I0822 16:40:29.940765 13823 solver.cpp:239] Iteration 22400 (8.60533 iter/s, 11.6207s/100 iters), loss = 0.032954
I0822 16:40:29.940820 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0329538 (* 1 = 0.0329538 loss)
I0822 16:40:29.940832 13823 sgd_solver.cpp:112] Iteration 22400, lr = 0.0001
I0822 16:40:41.651274 13823 solver.cpp:239] Iteration 22500 (8.53942 iter/s, 11.7104s/100 iters), loss = 0.028762
I0822 16:40:41.651337 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0287619 (* 1 = 0.0287619 loss)
I0822 16:40:41.651348 13823 sgd_solver.cpp:112] Iteration 22500, lr = 0.0001
I0822 16:40:53.208586 13823 solver.cpp:239] Iteration 22600 (8.65262 iter/s, 11.5572s/100 iters), loss = 0.038383
I0822 16:40:53.208655 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0383829 (* 1 = 0.0383829 loss)
I0822 16:40:53.208670 13823 sgd_solver.cpp:112] Iteration 22600, lr = 0.0001
I0822 16:41:04.828997 13823 solver.cpp:239] Iteration 22700 (8.60563 iter/s, 11.6203s/100 iters), loss = 0.0339345
I0822 16:41:04.829056 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0339344 (* 1 = 0.0339344 loss)
I0822 16:41:04.829064 13823 sgd_solver.cpp:112] Iteration 22700, lr = 0.0001
I0822 16:41:16.396529 13823 solver.cpp:239] Iteration 22800 (8.64497 iter/s, 11.5674s/100 iters), loss = 0.0343508
I0822 16:41:16.396585 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0343506 (* 1 = 0.0343506 loss)
I0822 16:41:16.396595 13823 sgd_solver.cpp:112] Iteration 22800, lr = 0.0001
I0822 16:41:28.230862 13823 solver.cpp:239] Iteration 22900 (8.45007 iter/s, 11.8342s/100 iters), loss = 0.0316884
I0822 16:41:28.230919 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0316883 (* 1 = 0.0316883 loss)
I0822 16:41:28.230929 13823 sgd_solver.cpp:112] Iteration 22900, lr = 0.0001
I0822 16:41:39.940137 13823 solver.cpp:239] Iteration 23000 (8.54032 iter/s, 11.7092s/100 iters), loss = 0.0311506
I0822 16:41:39.940196 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0311504 (* 1 = 0.0311504 loss)
I0822 16:41:39.940207 13823 sgd_solver.cpp:112] Iteration 23000, lr = 0.0001
I0822 16:41:51.836755 13823 solver.cpp:239] Iteration 23100 (8.40583 iter/s, 11.8965s/100 iters), loss = 0.0387264
I0822 16:41:51.836817 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0387263 (* 1 = 0.0387263 loss)
I0822 16:41:51.836828 13823 sgd_solver.cpp:112] Iteration 23100, lr = 0.0001
I0822 16:42:03.611105 13823 solver.cpp:239] Iteration 23200 (8.49312 iter/s, 11.7742s/100 iters), loss = 0.0291379
I0822 16:42:03.611163 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0291377 (* 1 = 0.0291377 loss)
I0822 16:42:03.611174 13823 sgd_solver.cpp:112] Iteration 23200, lr = 0.0001
I0822 16:42:15.358791 13823 solver.cpp:239] Iteration 23300 (8.51239 iter/s, 11.7476s/100 iters), loss = 0.031443
I0822 16:42:15.358848 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0314429 (* 1 = 0.0314429 loss)
I0822 16:42:15.358858 13823 sgd_solver.cpp:112] Iteration 23300, lr = 0.0001
I0822 16:42:27.276455 13823 solver.cpp:239] Iteration 23400 (8.39098 iter/s, 11.9176s/100 iters), loss = 0.0268259
I0822 16:42:27.276521 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0268257 (* 1 = 0.0268257 loss)
I0822 16:42:27.276535 13823 sgd_solver.cpp:112] Iteration 23400, lr = 0.0001
I0822 16:42:39.098163 13823 solver.cpp:239] Iteration 23500 (8.4591 iter/s, 11.8216s/100 iters), loss = 0.0277741
I0822 16:42:39.098234 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0277739 (* 1 = 0.0277739 loss)
I0822 16:42:39.098258 13823 sgd_solver.cpp:112] Iteration 23500, lr = 0.0001
I0822 16:42:50.774817 13823 solver.cpp:239] Iteration 23600 (8.56418 iter/s, 11.6765s/100 iters), loss = 0.0294197
I0822 16:42:50.774878 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0294196 (* 1 = 0.0294196 loss)
I0822 16:42:50.774888 13823 sgd_solver.cpp:112] Iteration 23600, lr = 0.0001
I0822 16:43:02.645653 13823 solver.cpp:239] Iteration 23700 (8.42408 iter/s, 11.8707s/100 iters), loss = 0.0307479
I0822 16:43:02.645712 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0307477 (* 1 = 0.0307477 loss)
I0822 16:43:02.645721 13823 sgd_solver.cpp:112] Iteration 23700, lr = 0.0001
I0822 16:43:14.484555 13823 solver.cpp:239] Iteration 23800 (8.44681 iter/s, 11.8388s/100 iters), loss = 0.0282416
I0822 16:43:14.484624 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0282415 (* 1 = 0.0282415 loss)
I0822 16:43:14.484637 13823 sgd_solver.cpp:112] Iteration 23800, lr = 0.0001
I0822 16:43:26.254880 13823 solver.cpp:239] Iteration 23900 (8.49602 iter/s, 11.7702s/100 iters), loss = 0.0363521
I0822 16:43:26.254945 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.036352 (* 1 = 0.036352 loss)
I0822 16:43:26.254956 13823 sgd_solver.cpp:112] Iteration 23900, lr = 0.0001
I0822 16:43:38.217633 13823 solver.cpp:239] Iteration 24000 (8.35935 iter/s, 11.9626s/100 iters), loss = 0.0302932
I0822 16:43:38.217689 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.030293 (* 1 = 0.030293 loss)
I0822 16:43:38.217697 13823 sgd_solver.cpp:112] Iteration 24000, lr = 0.0001
I0822 16:43:50.105387 13823 solver.cpp:239] Iteration 24100 (8.41209 iter/s, 11.8877s/100 iters), loss = 0.0364942
I0822 16:43:50.105445 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.036494 (* 1 = 0.036494 loss)
I0822 16:43:50.105463 13823 sgd_solver.cpp:112] Iteration 24100, lr = 0.0001
I0822 16:44:02.053162 13823 solver.cpp:239] Iteration 24200 (8.36983 iter/s, 11.9477s/100 iters), loss = 0.0310637
I0822 16:44:02.053225 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0310635 (* 1 = 0.0310635 loss)
I0822 16:44:02.053234 13823 sgd_solver.cpp:112] Iteration 24200, lr = 0.0001
I0822 16:44:13.974141 13823 solver.cpp:239] Iteration 24300 (8.38865 iter/s, 11.9209s/100 iters), loss = 0.129483
I0822 16:44:13.974196 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.129483 (* 1 = 0.129483 loss)
I0822 16:44:13.974206 13823 sgd_solver.cpp:112] Iteration 24300, lr = 0.0001
I0822 16:44:25.760602 13823 solver.cpp:239] Iteration 24400 (8.48438 iter/s, 11.7864s/100 iters), loss = 0.0282195
I0822 16:44:25.760658 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0282194 (* 1 = 0.0282194 loss)
I0822 16:44:25.760668 13823 sgd_solver.cpp:112] Iteration 24400, lr = 0.0001
I0822 16:44:37.683413 13823 solver.cpp:239] Iteration 24500 (8.38735 iter/s, 11.9227s/100 iters), loss = 0.043746
I0822 16:44:37.683478 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0437458 (* 1 = 0.0437458 loss)
I0822 16:44:37.683490 13823 sgd_solver.cpp:112] Iteration 24500, lr = 0.0001
I0822 16:44:49.619479 13823 solver.cpp:239] Iteration 24600 (8.37804 iter/s, 11.936s/100 iters), loss = 0.0334452
I0822 16:44:49.619539 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0334451 (* 1 = 0.0334451 loss)
I0822 16:44:49.619550 13823 sgd_solver.cpp:112] Iteration 24600, lr = 0.0001
I0822 16:45:01.491820 13823 solver.cpp:239] Iteration 24700 (8.42301 iter/s, 11.8722s/100 iters), loss = 0.030181
I0822 16:45:01.491874 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0301809 (* 1 = 0.0301809 loss)
I0822 16:45:01.491883 13823 sgd_solver.cpp:112] Iteration 24700, lr = 0.0001
I0822 16:45:13.367105 13823 solver.cpp:239] Iteration 24800 (8.42092 iter/s, 11.8752s/100 iters), loss = 0.0313586
I0822 16:45:13.367164 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0313584 (* 1 = 0.0313584 loss)
I0822 16:45:13.367174 13823 sgd_solver.cpp:112] Iteration 24800, lr = 0.0001
I0822 16:45:25.166734 13823 solver.cpp:239] Iteration 24900 (8.47491 iter/s, 11.7995s/100 iters), loss = 0.0281697
I0822 16:45:25.166795 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0281695 (* 1 = 0.0281695 loss)
I0822 16:45:25.166807 13823 sgd_solver.cpp:112] Iteration 24900, lr = 0.0001
I0822 16:45:37.049896 13823 solver.cpp:239] Iteration 25000 (8.41533 iter/s, 11.8831s/100 iters), loss = 0.0319306
I0822 16:45:37.049953 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0319304 (* 1 = 0.0319304 loss)
I0822 16:45:37.049963 13823 sgd_solver.cpp:112] Iteration 25000, lr = 0.0001
I0822 16:45:49.057584 13823 solver.cpp:239] Iteration 25100 (8.32806 iter/s, 12.0076s/100 iters), loss = 0.0285432
I0822 16:45:49.057646 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.028543 (* 1 = 0.028543 loss)
I0822 16:45:49.057655 13823 sgd_solver.cpp:112] Iteration 25100, lr = 0.0001
I0822 16:46:00.910313 13823 solver.cpp:239] Iteration 25200 (8.43694 iter/s, 11.8526s/100 iters), loss = 0.0449685
I0822 16:46:00.910368 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0449683 (* 1 = 0.0449683 loss)
I0822 16:46:00.910378 13823 sgd_solver.cpp:112] Iteration 25200, lr = 0.0001
I0822 16:46:12.710255 13823 solver.cpp:239] Iteration 25300 (8.47468 iter/s, 11.7999s/100 iters), loss = 0.0266679
I0822 16:46:12.710317 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0266677 (* 1 = 0.0266677 loss)
I0822 16:46:12.710327 13823 sgd_solver.cpp:112] Iteration 25300, lr = 0.0001
I0822 16:46:24.688395 13823 solver.cpp:239] Iteration 25400 (8.34861 iter/s, 11.978s/100 iters), loss = 0.0327707
I0822 16:46:24.688460 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0327705 (* 1 = 0.0327705 loss)
I0822 16:46:24.688477 13823 sgd_solver.cpp:112] Iteration 25400, lr = 0.0001
I0822 16:46:36.588959 13823 solver.cpp:239] Iteration 25500 (8.40304 iter/s, 11.9005s/100 iters), loss = 0.0299314
I0822 16:46:36.589023 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0299313 (* 1 = 0.0299313 loss)
I0822 16:46:36.589036 13823 sgd_solver.cpp:112] Iteration 25500, lr = 0.0001
I0822 16:46:48.300047 13823 solver.cpp:239] Iteration 25600 (8.53898 iter/s, 11.711s/100 iters), loss = 0.0327156
I0822 16:46:48.300104 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0327154 (* 1 = 0.0327154 loss)
I0822 16:46:48.300113 13823 sgd_solver.cpp:112] Iteration 25600, lr = 0.0001
I0822 16:46:59.814667 13823 solver.cpp:239] Iteration 25700 (8.68468 iter/s, 11.5145s/100 iters), loss = 0.0310526
I0822 16:46:59.814728 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0310524 (* 1 = 0.0310524 loss)
I0822 16:46:59.814738 13823 sgd_solver.cpp:112] Iteration 25700, lr = 0.0001
I0822 16:47:11.675796 13823 solver.cpp:239] Iteration 25800 (8.43097 iter/s, 11.861s/100 iters), loss = 0.0420955
I0822 16:47:11.675855 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0420953 (* 1 = 0.0420953 loss)
I0822 16:47:11.675868 13823 sgd_solver.cpp:112] Iteration 25800, lr = 0.0001
I0822 16:47:23.464874 13823 solver.cpp:239] Iteration 25900 (8.48249 iter/s, 11.789s/100 iters), loss = 0.0298935
I0822 16:47:23.464934 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0298933 (* 1 = 0.0298933 loss)
I0822 16:47:23.464946 13823 sgd_solver.cpp:112] Iteration 25900, lr = 0.0001
I0822 16:47:35.430424 13823 solver.cpp:239] Iteration 26000 (8.35739 iter/s, 11.9655s/100 iters), loss = 0.0318819
I0822 16:47:35.430482 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0318817 (* 1 = 0.0318817 loss)
I0822 16:47:35.430500 13823 sgd_solver.cpp:112] Iteration 26000, lr = 0.0001
I0822 16:47:47.224104 13823 solver.cpp:239] Iteration 26100 (8.47918 iter/s, 11.7936s/100 iters), loss = 0.0274001
I0822 16:47:47.224179 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0273999 (* 1 = 0.0273999 loss)
I0822 16:47:47.224200 13823 sgd_solver.cpp:112] Iteration 26100, lr = 0.0001
I0822 16:47:59.118774 13823 solver.cpp:239] Iteration 26200 (8.4072 iter/s, 11.8946s/100 iters), loss = 0.0322981
I0822 16:47:59.118826 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0322979 (* 1 = 0.0322979 loss)
I0822 16:47:59.118844 13823 sgd_solver.cpp:112] Iteration 26200, lr = 0.0001
I0822 16:48:10.899201 13823 solver.cpp:239] Iteration 26300 (8.48872 iter/s, 11.7803s/100 iters), loss = 0.0326742
I0822 16:48:10.899260 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0326741 (* 1 = 0.0326741 loss)
I0822 16:48:10.899277 13823 sgd_solver.cpp:112] Iteration 26300, lr = 0.0001
I0822 16:48:22.669313 13823 solver.cpp:239] Iteration 26400 (8.49616 iter/s, 11.77s/100 iters), loss = 0.0298968
I0822 16:48:22.669363 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0298967 (* 1 = 0.0298967 loss)
I0822 16:48:22.669384 13823 sgd_solver.cpp:112] Iteration 26400, lr = 0.0001
I0822 16:48:34.466224 13823 solver.cpp:239] Iteration 26500 (8.47685 iter/s, 11.7968s/100 iters), loss = 0.0461777
I0822 16:48:34.466285 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0461776 (* 1 = 0.0461776 loss)
I0822 16:48:34.466295 13823 sgd_solver.cpp:112] Iteration 26500, lr = 0.0001
I0822 16:48:46.369077 13823 solver.cpp:239] Iteration 26600 (8.40141 iter/s, 11.9028s/100 iters), loss = 0.0319534
I0822 16:48:46.369136 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0319533 (* 1 = 0.0319533 loss)
I0822 16:48:46.369145 13823 sgd_solver.cpp:112] Iteration 26600, lr = 0.0001
I0822 16:48:58.223487 13823 solver.cpp:239] Iteration 26700 (8.43574 iter/s, 11.8543s/100 iters), loss = 0.0262951
I0822 16:48:58.223536 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.026295 (* 1 = 0.026295 loss)
I0822 16:48:58.223546 13823 sgd_solver.cpp:112] Iteration 26700, lr = 0.0001
I0822 16:49:10.242810 13823 solver.cpp:239] Iteration 26800 (8.31999 iter/s, 12.0192s/100 iters), loss = 0.0285555
I0822 16:49:10.242866 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0285554 (* 1 = 0.0285554 loss)
I0822 16:49:10.242877 13823 sgd_solver.cpp:112] Iteration 26800, lr = 0.0001
I0822 16:49:21.729384 13823 solver.cpp:239] Iteration 26900 (8.70588 iter/s, 11.4865s/100 iters), loss = 0.0325297
I0822 16:49:21.729457 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0325296 (* 1 = 0.0325296 loss)
I0822 16:49:21.729466 13823 sgd_solver.cpp:112] Iteration 26900, lr = 0.0001
I0822 16:49:33.109741 13823 solver.cpp:239] Iteration 27000 (8.78715 iter/s, 11.3803s/100 iters), loss = 0.0277189
I0822 16:49:33.109810 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0277187 (* 1 = 0.0277187 loss)
I0822 16:49:33.109820 13823 sgd_solver.cpp:112] Iteration 27000, lr = 0.0001
I0822 16:49:44.749572 13823 solver.cpp:239] Iteration 27100 (8.59126 iter/s, 11.6397s/100 iters), loss = 0.0270299
I0822 16:49:44.749621 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0270298 (* 1 = 0.0270298 loss)
I0822 16:49:44.749631 13823 sgd_solver.cpp:112] Iteration 27100, lr = 0.0001
I0822 16:49:56.439342 13823 solver.cpp:239] Iteration 27200 (8.55454 iter/s, 11.6897s/100 iters), loss = 0.0313973
I0822 16:49:56.439393 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0313971 (* 1 = 0.0313971 loss)
I0822 16:49:56.439404 13823 sgd_solver.cpp:112] Iteration 27200, lr = 0.0001
I0822 16:50:08.412838 13823 solver.cpp:239] Iteration 27300 (8.35183 iter/s, 11.9734s/100 iters), loss = 0.0418964
I0822 16:50:08.412889 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0418963 (* 1 = 0.0418963 loss)
I0822 16:50:08.412899 13823 sgd_solver.cpp:112] Iteration 27300, lr = 0.0001
I0822 16:50:20.109570 13823 solver.cpp:239] Iteration 27400 (8.54945 iter/s, 11.6967s/100 iters), loss = 0.0285838
I0822 16:50:20.109621 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0285836 (* 1 = 0.0285836 loss)
I0822 16:50:20.109630 13823 sgd_solver.cpp:112] Iteration 27400, lr = 0.0001
I0822 16:50:31.967401 13823 solver.cpp:239] Iteration 27500 (8.4333 iter/s, 11.8578s/100 iters), loss = 0.0294444
I0822 16:50:31.967455 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0294442 (* 1 = 0.0294442 loss)
I0822 16:50:31.967465 13823 sgd_solver.cpp:112] Iteration 27500, lr = 0.0001
I0822 16:50:43.599525 13823 solver.cpp:239] Iteration 27600 (8.59694 iter/s, 11.6321s/100 iters), loss = 0.0305249
I0822 16:50:43.599568 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0305247 (* 1 = 0.0305247 loss)
I0822 16:50:43.599588 13823 sgd_solver.cpp:112] Iteration 27600, lr = 0.0001
I0822 16:50:55.221458 13823 solver.cpp:239] Iteration 27700 (8.60447 iter/s, 11.6219s/100 iters), loss = 0.027632
I0822 16:50:55.221510 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0276318 (* 1 = 0.0276318 loss)
I0822 16:50:55.221520 13823 sgd_solver.cpp:112] Iteration 27700, lr = 0.0001
I0822 16:51:07.116911 13823 solver.cpp:239] Iteration 27800 (8.40663 iter/s, 11.8954s/100 iters), loss = 0.0289693
I0822 16:51:07.116983 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0289691 (* 1 = 0.0289691 loss)
I0822 16:51:07.117002 13823 sgd_solver.cpp:112] Iteration 27800, lr = 0.0001
I0822 16:51:19.094830 13823 solver.cpp:239] Iteration 27900 (8.34876 iter/s, 11.9778s/100 iters), loss = 0.0250284
I0822 16:51:19.094890 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0250282 (* 1 = 0.0250282 loss)
I0822 16:51:19.094902 13823 sgd_solver.cpp:112] Iteration 27900, lr = 0.0001
I0822 16:51:31.111626 13823 solver.cpp:239] Iteration 28000 (8.32174 iter/s, 12.0167s/100 iters), loss = 0.0280952
I0822 16:51:31.111680 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.028095 (* 1 = 0.028095 loss)
I0822 16:51:31.111690 13823 sgd_solver.cpp:112] Iteration 28000, lr = 0.0001
I0822 16:51:43.067757 13823 solver.cpp:239] Iteration 28100 (8.36396 iter/s, 11.9561s/100 iters), loss = 0.033382
I0822 16:51:43.067811 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0333818 (* 1 = 0.0333818 loss)
I0822 16:51:43.067822 13823 sgd_solver.cpp:112] Iteration 28100, lr = 0.0001
I0822 16:51:55.095487 13823 solver.cpp:239] Iteration 28200 (8.31417 iter/s, 12.0277s/100 iters), loss = 0.0288383
I0822 16:51:55.095546 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0288381 (* 1 = 0.0288381 loss)
I0822 16:51:55.095556 13823 sgd_solver.cpp:112] Iteration 28200, lr = 0.0001
I0822 16:52:07.039856 13823 solver.cpp:239] Iteration 28300 (8.3722 iter/s, 11.9443s/100 iters), loss = 0.0360775
I0822 16:52:07.039916 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0360773 (* 1 = 0.0360773 loss)
I0822 16:52:07.039932 13823 sgd_solver.cpp:112] Iteration 28300, lr = 0.0001
I0822 16:52:19.105476 13823 solver.cpp:239] Iteration 28400 (8.28806 iter/s, 12.0655s/100 iters), loss = 0.0285542
I0822 16:52:19.105535 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0285541 (* 1 = 0.0285541 loss)
I0822 16:52:19.105546 13823 sgd_solver.cpp:112] Iteration 28400, lr = 0.0001
I0822 16:52:31.152848 13823 solver.cpp:239] Iteration 28500 (8.30062 iter/s, 12.0473s/100 iters), loss = 0.0276758
I0822 16:52:31.152907 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0276757 (* 1 = 0.0276757 loss)
I0822 16:52:31.152918 13823 sgd_solver.cpp:112] Iteration 28500, lr = 0.0001
I0822 16:52:43.382370 13823 solver.cpp:239] Iteration 28600 (8.17699 iter/s, 12.2294s/100 iters), loss = 0.0295885
I0822 16:52:43.382431 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0295883 (* 1 = 0.0295883 loss)
I0822 16:52:43.382443 13823 sgd_solver.cpp:112] Iteration 28600, lr = 0.0001
I0822 16:52:55.605899 13823 solver.cpp:239] Iteration 28700 (8.181 iter/s, 12.2234s/100 iters), loss = 0.0302367
I0822 16:52:55.605955 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0302366 (* 1 = 0.0302366 loss)
I0822 16:52:55.605967 13823 sgd_solver.cpp:112] Iteration 28700, lr = 0.0001
I0822 16:53:07.550837 13823 solver.cpp:239] Iteration 28800 (8.3718 iter/s, 11.9449s/100 iters), loss = 0.0313538
I0822 16:53:07.550894 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0313536 (* 1 = 0.0313536 loss)
I0822 16:53:07.550904 13823 sgd_solver.cpp:112] Iteration 28800, lr = 0.0001
I0822 16:53:19.542145 13823 solver.cpp:239] Iteration 28900 (8.33943 iter/s, 11.9912s/100 iters), loss = 0.0289346
I0822 16:53:19.542201 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0289345 (* 1 = 0.0289345 loss)
I0822 16:53:19.542210 13823 sgd_solver.cpp:112] Iteration 28900, lr = 0.0001
I0822 16:53:31.507747 13823 solver.cpp:239] Iteration 29000 (8.35734 iter/s, 11.9655s/100 iters), loss = 0.0292628
I0822 16:53:31.507804 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0292627 (* 1 = 0.0292627 loss)
I0822 16:53:31.507814 13823 sgd_solver.cpp:112] Iteration 29000, lr = 0.0001
I0822 16:53:43.520468 13823 solver.cpp:239] Iteration 29100 (8.32456 iter/s, 12.0126s/100 iters), loss = 0.0277006
I0822 16:53:43.520542 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0277004 (* 1 = 0.0277004 loss)
I0822 16:53:43.520553 13823 sgd_solver.cpp:112] Iteration 29100, lr = 0.0001
I0822 16:53:55.280730 13823 solver.cpp:239] Iteration 29200 (8.50328 iter/s, 11.7602s/100 iters), loss = 0.0286855
I0822 16:53:55.280786 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0286854 (* 1 = 0.0286854 loss)
I0822 16:53:55.280797 13823 sgd_solver.cpp:112] Iteration 29200, lr = 0.0001
I0822 16:54:07.040052 13823 solver.cpp:239] Iteration 29300 (8.50395 iter/s, 11.7592s/100 iters), loss = 0.0281252
I0822 16:54:07.040108 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0281251 (* 1 = 0.0281251 loss)
I0822 16:54:07.040118 13823 sgd_solver.cpp:112] Iteration 29300, lr = 0.0001
I0822 16:54:18.785457 13823 solver.cpp:239] Iteration 29400 (8.51402 iter/s, 11.7453s/100 iters), loss = 0.029474
I0822 16:54:18.785509 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0294739 (* 1 = 0.0294739 loss)
I0822 16:54:18.785518 13823 sgd_solver.cpp:112] Iteration 29400, lr = 0.0001
I0822 16:54:30.551614 13823 solver.cpp:239] Iteration 29500 (8.499 iter/s, 11.7661s/100 iters), loss = 0.0258873
I0822 16:54:30.551662 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0258871 (* 1 = 0.0258871 loss)
I0822 16:54:30.551671 13823 sgd_solver.cpp:112] Iteration 29500, lr = 0.0001
I0822 16:54:42.365365 13823 solver.cpp:239] Iteration 29600 (8.46476 iter/s, 11.8137s/100 iters), loss = 0.0321708
I0822 16:54:42.365424 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0321707 (* 1 = 0.0321707 loss)
I0822 16:54:42.365437 13823 sgd_solver.cpp:112] Iteration 29600, lr = 0.0001
I0822 16:54:54.394881 13823 solver.cpp:239] Iteration 29700 (8.31294 iter/s, 12.0294s/100 iters), loss = 0.0421829
I0822 16:54:54.394937 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0421828 (* 1 = 0.0421828 loss)
I0822 16:54:54.394948 13823 sgd_solver.cpp:112] Iteration 29700, lr = 0.0001
I0822 16:55:06.319347 13823 solver.cpp:239] Iteration 29800 (8.38617 iter/s, 11.9244s/100 iters), loss = 0.03064
I0822 16:55:06.319399 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0306398 (* 1 = 0.0306398 loss)
I0822 16:55:06.319408 13823 sgd_solver.cpp:112] Iteration 29800, lr = 0.0001
I0822 16:55:18.056414 13823 solver.cpp:239] Iteration 29900 (8.52007 iter/s, 11.737s/100 iters), loss = 0.0278619
I0822 16:55:18.056470 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0278618 (* 1 = 0.0278618 loss)
I0822 16:55:18.056480 13823 sgd_solver.cpp:112] Iteration 29900, lr = 0.0001
I0822 16:55:30.067641 13823 solver.cpp:239] Iteration 30000 (8.3256 iter/s, 12.0111s/100 iters), loss = 0.0359608
I0822 16:55:30.067699 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0359606 (* 1 = 0.0359606 loss)
I0822 16:55:30.067709 13823 sgd_solver.cpp:112] Iteration 30000, lr = 0.0001
I0822 16:55:42.065069 13823 solver.cpp:239] Iteration 30100 (8.33517 iter/s, 11.9973s/100 iters), loss = 0.0275807
I0822 16:55:42.065129 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0275805 (* 1 = 0.0275805 loss)
I0822 16:55:42.065140 13823 sgd_solver.cpp:112] Iteration 30100, lr = 0.0001
I0822 16:55:54.124217 13823 solver.cpp:239] Iteration 30200 (8.29251 iter/s, 12.0591s/100 iters), loss = 0.0277197
I0822 16:55:54.124277 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0277195 (* 1 = 0.0277195 loss)
I0822 16:55:54.124289 13823 sgd_solver.cpp:112] Iteration 30200, lr = 0.0001
I0822 16:56:06.095459 13823 solver.cpp:239] Iteration 30300 (8.35341 iter/s, 11.9712s/100 iters), loss = 0.0269168
I0822 16:56:06.095520 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0269166 (* 1 = 0.0269166 loss)
I0822 16:56:06.095530 13823 sgd_solver.cpp:112] Iteration 30300, lr = 0.0001
I0822 16:56:18.155788 13823 solver.cpp:239] Iteration 30400 (8.2917 iter/s, 12.0602s/100 iters), loss = 0.0562306
I0822 16:56:18.155850 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0562304 (* 1 = 0.0562304 loss)
I0822 16:56:18.155863 13823 sgd_solver.cpp:112] Iteration 30400, lr = 0.0001
I0822 16:56:30.185858 13823 solver.cpp:239] Iteration 30500 (8.31256 iter/s, 12.03s/100 iters), loss = 0.0293472
I0822 16:56:30.185920 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.029347 (* 1 = 0.029347 loss)
I0822 16:56:30.185930 13823 sgd_solver.cpp:112] Iteration 30500, lr = 0.0001
I0822 16:56:42.172300 13823 solver.cpp:239] Iteration 30600 (8.34282 iter/s, 11.9864s/100 iters), loss = 0.0291041
I0822 16:56:42.172359 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0291039 (* 1 = 0.0291039 loss)
I0822 16:56:42.172370 13823 sgd_solver.cpp:112] Iteration 30600, lr = 0.0001
I0822 16:56:54.174602 13823 solver.cpp:239] Iteration 30700 (8.33179 iter/s, 12.0022s/100 iters), loss = 0.0292879
I0822 16:56:54.174661 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0292877 (* 1 = 0.0292877 loss)
I0822 16:56:54.174671 13823 sgd_solver.cpp:112] Iteration 30700, lr = 0.0001
I0822 16:57:06.194808 13823 solver.cpp:239] Iteration 30800 (8.31938 iter/s, 12.0201s/100 iters), loss = 0.0266522
I0822 16:57:06.194860 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0266521 (* 1 = 0.0266521 loss)
I0822 16:57:06.194870 13823 sgd_solver.cpp:112] Iteration 30800, lr = 0.0001
I0822 16:57:18.024296 13823 solver.cpp:239] Iteration 30900 (8.4535 iter/s, 11.8294s/100 iters), loss = 0.0378428
I0822 16:57:18.024355 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0378426 (* 1 = 0.0378426 loss)
I0822 16:57:18.024366 13823 sgd_solver.cpp:112] Iteration 30900, lr = 0.0001
I0822 16:57:30.060679 13823 solver.cpp:239] Iteration 31000 (8.3082 iter/s, 12.0363s/100 iters), loss = 0.0350817
I0822 16:57:30.060732 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0350815 (* 1 = 0.0350815 loss)
I0822 16:57:30.060742 13823 sgd_solver.cpp:112] Iteration 31000, lr = 0.0001
I0822 16:57:42.099143 13823 solver.cpp:239] Iteration 31100 (8.30676 iter/s, 12.0384s/100 iters), loss = 0.0294694
I0822 16:57:42.099197 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0294692 (* 1 = 0.0294692 loss)
I0822 16:57:42.099208 13823 sgd_solver.cpp:112] Iteration 31100, lr = 0.0001
I0822 16:57:54.081604 13823 solver.cpp:239] Iteration 31200 (8.34558 iter/s, 11.9824s/100 iters), loss = 0.0301924
I0822 16:57:54.081655 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0301922 (* 1 = 0.0301922 loss)
I0822 16:57:54.081665 13823 sgd_solver.cpp:112] Iteration 31200, lr = 0.0001
I0822 16:58:05.838945 13823 solver.cpp:239] Iteration 31300 (8.50537 iter/s, 11.7573s/100 iters), loss = 0.0305232
I0822 16:58:05.839005 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.030523 (* 1 = 0.030523 loss)
I0822 16:58:05.839017 13823 sgd_solver.cpp:112] Iteration 31300, lr = 0.0001
I0822 16:58:17.584101 13823 solver.cpp:239] Iteration 31400 (8.5142 iter/s, 11.7451s/100 iters), loss = 0.0295975
I0822 16:58:17.584154 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0295973 (* 1 = 0.0295973 loss)
I0822 16:58:17.584163 13823 sgd_solver.cpp:112] Iteration 31400, lr = 0.0001
I0822 16:58:29.321907 13823 solver.cpp:239] Iteration 31500 (8.51953 iter/s, 11.7377s/100 iters), loss = 0.0300895
I0822 16:58:29.321957 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0300893 (* 1 = 0.0300893 loss)
I0822 16:58:29.321966 13823 sgd_solver.cpp:112] Iteration 31500, lr = 0.0001
I0822 16:58:41.327482 13823 solver.cpp:239] Iteration 31600 (8.32951 iter/s, 12.0055s/100 iters), loss = 0.0259117
I0822 16:58:41.327535 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0259115 (* 1 = 0.0259115 loss)
I0822 16:58:41.327544 13823 sgd_solver.cpp:112] Iteration 31600, lr = 0.0001
I0822 16:58:53.373096 13823 solver.cpp:239] Iteration 31700 (8.30183 iter/s, 12.0455s/100 iters), loss = 0.0313432
I0822 16:58:53.373154 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0313431 (* 1 = 0.0313431 loss)
I0822 16:58:53.373167 13823 sgd_solver.cpp:112] Iteration 31700, lr = 0.0001
I0822 16:59:05.414346 13823 solver.cpp:239] Iteration 31800 (8.30484 iter/s, 12.0412s/100 iters), loss = 0.0277769
I0822 16:59:05.414402 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0277767 (* 1 = 0.0277767 loss)
I0822 16:59:05.414412 13823 sgd_solver.cpp:112] Iteration 31800, lr = 0.0001
I0822 16:59:17.462750 13823 solver.cpp:239] Iteration 31900 (8.2999 iter/s, 12.0483s/100 iters), loss = 0.0410876
I0822 16:59:17.462807 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0410874 (* 1 = 0.0410874 loss)
I0822 16:59:17.462818 13823 sgd_solver.cpp:112] Iteration 31900, lr = 0.0001
I0822 16:59:29.368225 13823 solver.cpp:239] Iteration 32000 (8.39955 iter/s, 11.9054s/100 iters), loss = 0.0297726
I0822 16:59:29.368288 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0297724 (* 1 = 0.0297724 loss)
I0822 16:59:29.368299 13823 sgd_solver.cpp:112] Iteration 32000, lr = 0.0001
I0822 16:59:41.380771 13823 solver.cpp:239] Iteration 32100 (8.32468 iter/s, 12.0125s/100 iters), loss = 0.027793
I0822 16:59:41.380832 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0277928 (* 1 = 0.0277928 loss)
I0822 16:59:41.380843 13823 sgd_solver.cpp:112] Iteration 32100, lr = 0.0001
I0822 16:59:53.370795 13823 solver.cpp:239] Iteration 32200 (8.34032 iter/s, 11.9899s/100 iters), loss = 0.0344043
I0822 16:59:53.370854 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0344041 (* 1 = 0.0344041 loss)
I0822 16:59:53.370865 13823 sgd_solver.cpp:112] Iteration 32200, lr = 0.0001
I0822 17:00:05.404213 13823 solver.cpp:239] Iteration 32300 (8.31024 iter/s, 12.0333s/100 iters), loss = 0.0268339
I0822 17:00:05.404269 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0268338 (* 1 = 0.0268338 loss)
I0822 17:00:05.404280 13823 sgd_solver.cpp:112] Iteration 32300, lr = 0.0001
I0822 17:00:17.331743 13823 solver.cpp:239] Iteration 32400 (8.38402 iter/s, 11.9275s/100 iters), loss = 0.0282533
I0822 17:00:17.331797 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0282531 (* 1 = 0.0282531 loss)
I0822 17:00:17.331807 13823 sgd_solver.cpp:112] Iteration 32400, lr = 0.0001
I0822 17:00:29.370790 13823 solver.cpp:239] Iteration 32500 (8.30635 iter/s, 12.039s/100 iters), loss = 0.0304006
I0822 17:00:29.370847 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0304005 (* 1 = 0.0304005 loss)
I0822 17:00:29.370857 13823 sgd_solver.cpp:112] Iteration 32500, lr = 0.0001
I0822 17:00:41.238730 13823 solver.cpp:239] Iteration 32600 (8.42611 iter/s, 11.8679s/100 iters), loss = 0.029389
I0822 17:00:41.238780 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0293888 (* 1 = 0.0293888 loss)
I0822 17:00:41.238788 13823 sgd_solver.cpp:112] Iteration 32600, lr = 0.0001
I0822 17:00:53.260366 13823 solver.cpp:239] Iteration 32700 (8.31838 iter/s, 12.0216s/100 iters), loss = 0.0280696
I0822 17:00:53.260424 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0280694 (* 1 = 0.0280694 loss)
I0822 17:00:53.260435 13823 sgd_solver.cpp:112] Iteration 32700, lr = 0.0001
I0822 17:01:05.346278 13823 solver.cpp:239] Iteration 32800 (8.27415 iter/s, 12.0858s/100 iters), loss = 0.0287958
I0822 17:01:05.346336 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0287956 (* 1 = 0.0287956 loss)
I0822 17:01:05.346349 13823 sgd_solver.cpp:112] Iteration 32800, lr = 0.0001
I0822 17:01:17.347460 13823 solver.cpp:239] Iteration 32900 (8.33256 iter/s, 12.0011s/100 iters), loss = 0.0287143
I0822 17:01:17.347515 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0287141 (* 1 = 0.0287141 loss)
I0822 17:01:17.347524 13823 sgd_solver.cpp:112] Iteration 32900, lr = 0.0001
I0822 17:01:29.092262 13823 solver.cpp:239] Iteration 33000 (8.51445 iter/s, 11.7447s/100 iters), loss = 0.0256639
I0822 17:01:29.092314 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0256638 (* 1 = 0.0256638 loss)
I0822 17:01:29.092324 13823 sgd_solver.cpp:112] Iteration 33000, lr = 0.0001
I0822 17:01:40.821524 13823 solver.cpp:239] Iteration 33100 (8.52574 iter/s, 11.7292s/100 iters), loss = 0.0278424
I0822 17:01:40.821583 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0278422 (* 1 = 0.0278422 loss)
I0822 17:01:40.821594 13823 sgd_solver.cpp:112] Iteration 33100, lr = 0.0001
I0822 17:01:52.769852 13823 solver.cpp:239] Iteration 33200 (8.36942 iter/s, 11.9483s/100 iters), loss = 0.0265103
I0822 17:01:52.769907 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0265101 (* 1 = 0.0265101 loss)
I0822 17:01:52.769917 13823 sgd_solver.cpp:112] Iteration 33200, lr = 0.0001
I0822 17:02:04.773315 13823 solver.cpp:239] Iteration 33300 (8.33098 iter/s, 12.0034s/100 iters), loss = 0.0293284
I0822 17:02:04.773368 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0293282 (* 1 = 0.0293282 loss)
I0822 17:02:04.773378 13823 sgd_solver.cpp:112] Iteration 33300, lr = 0.0001
I0822 17:02:16.721208 13823 solver.cpp:239] Iteration 33400 (8.36972 iter/s, 11.9478s/100 iters), loss = 0.0397318
I0822 17:02:16.721259 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0397316 (* 1 = 0.0397316 loss)
I0822 17:02:16.721268 13823 sgd_solver.cpp:112] Iteration 33400, lr = 0.0001
I0822 17:02:28.510473 13823 solver.cpp:239] Iteration 33500 (8.48234 iter/s, 11.7892s/100 iters), loss = 0.0277237
I0822 17:02:28.510524 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0277235 (* 1 = 0.0277235 loss)
I0822 17:02:28.510532 13823 sgd_solver.cpp:112] Iteration 33500, lr = 0.0001
I0822 17:02:40.435089 13823 solver.cpp:239] Iteration 33600 (8.38606 iter/s, 11.9246s/100 iters), loss = 0.0318654
I0822 17:02:40.435149 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0318653 (* 1 = 0.0318653 loss)
I0822 17:02:40.435160 13823 sgd_solver.cpp:112] Iteration 33600, lr = 0.0001
I0822 17:02:52.432574 13823 solver.cpp:239] Iteration 33700 (8.33513 iter/s, 11.9974s/100 iters), loss = 0.0314352
I0822 17:02:52.432627 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.031435 (* 1 = 0.031435 loss)
I0822 17:02:52.432638 13823 sgd_solver.cpp:112] Iteration 33700, lr = 0.0001
I0822 17:03:04.393591 13823 solver.cpp:239] Iteration 33800 (8.36054 iter/s, 11.9609s/100 iters), loss = 0.0282313
I0822 17:03:04.393652 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0282311 (* 1 = 0.0282311 loss)
I0822 17:03:04.393664 13823 sgd_solver.cpp:112] Iteration 33800, lr = 0.0001
I0822 17:03:16.483937 13823 solver.cpp:239] Iteration 33900 (8.27112 iter/s, 12.0903s/100 iters), loss = 0.0273688
I0822 17:03:16.484005 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0273687 (* 1 = 0.0273687 loss)
I0822 17:03:16.484019 13823 sgd_solver.cpp:112] Iteration 33900, lr = 0.0001
I0822 17:03:28.479674 13823 solver.cpp:239] Iteration 34000 (8.33635 iter/s, 11.9957s/100 iters), loss = 0.0378253
I0822 17:03:28.479730 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0378251 (* 1 = 0.0378251 loss)
I0822 17:03:28.479743 13823 sgd_solver.cpp:112] Iteration 34000, lr = 0.0001
I0822 17:03:40.431452 13823 solver.cpp:239] Iteration 34100 (8.36701 iter/s, 11.9517s/100 iters), loss = 0.0247147
I0822 17:03:40.431514 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0247145 (* 1 = 0.0247145 loss)
I0822 17:03:40.431530 13823 sgd_solver.cpp:112] Iteration 34100, lr = 0.0001
I0822 17:03:52.404204 13823 solver.cpp:239] Iteration 34200 (8.35235 iter/s, 11.9727s/100 iters), loss = 0.0362359
I0822 17:03:52.404254 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0362358 (* 1 = 0.0362358 loss)
I0822 17:03:52.404263 13823 sgd_solver.cpp:112] Iteration 34200, lr = 0.0001
I0822 17:04:04.117295 13823 solver.cpp:239] Iteration 34300 (8.53751 iter/s, 11.713s/100 iters), loss = 0.0299068
I0822 17:04:04.117364 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0299066 (* 1 = 0.0299066 loss)
I0822 17:04:04.117381 13823 sgd_solver.cpp:112] Iteration 34300, lr = 0.0001
I0822 17:04:16.057719 13823 solver.cpp:239] Iteration 34400 (8.37497 iter/s, 11.9403s/100 iters), loss = 0.0258264
I0822 17:04:16.057776 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0258262 (* 1 = 0.0258262 loss)
I0822 17:04:16.057786 13823 sgd_solver.cpp:112] Iteration 34400, lr = 0.0001
I0822 17:04:27.586324 13823 solver.cpp:239] Iteration 34500 (8.67413 iter/s, 11.5285s/100 iters), loss = 0.0279989
I0822 17:04:27.586374 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0279988 (* 1 = 0.0279988 loss)
I0822 17:04:27.586382 13823 sgd_solver.cpp:112] Iteration 34500, lr = 0.0001
I0822 17:04:39.351866 13823 solver.cpp:239] Iteration 34600 (8.49944 iter/s, 11.7655s/100 iters), loss = 0.0247443
I0822 17:04:39.351931 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0247441 (* 1 = 0.0247441 loss)
I0822 17:04:39.351943 13823 sgd_solver.cpp:112] Iteration 34600, lr = 0.0001
I0822 17:04:51.369022 13823 solver.cpp:239] Iteration 34700 (8.32149 iter/s, 12.0171s/100 iters), loss = 0.030162
I0822 17:04:51.369071 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0301618 (* 1 = 0.0301618 loss)
I0822 17:04:51.369079 13823 sgd_solver.cpp:112] Iteration 34700, lr = 0.0001
I0822 17:05:03.049816 13823 solver.cpp:239] Iteration 34800 (8.56111 iter/s, 11.6807s/100 iters), loss = 0.030957
I0822 17:05:03.049865 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0309568 (* 1 = 0.0309568 loss)
I0822 17:05:03.049875 13823 sgd_solver.cpp:112] Iteration 34800, lr = 0.0001
I0822 17:05:14.627616 13823 solver.cpp:239] Iteration 34900 (8.63727 iter/s, 11.5777s/100 iters), loss = 0.0292303
I0822 17:05:14.627677 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0292302 (* 1 = 0.0292302 loss)
I0822 17:05:14.627689 13823 sgd_solver.cpp:112] Iteration 34900, lr = 0.0001
I0822 17:05:26.497022 13823 solver.cpp:239] Iteration 35000 (8.42507 iter/s, 11.8693s/100 iters), loss = 0.040508
I0822 17:05:26.497073 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0405078 (* 1 = 0.0405078 loss)
I0822 17:05:26.497082 13823 sgd_solver.cpp:112] Iteration 35000, lr = 0.0001
I0822 17:05:38.463549 13823 solver.cpp:239] Iteration 35100 (8.35669 iter/s, 11.9665s/100 iters), loss = 0.0251124
I0822 17:05:38.463603 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0251123 (* 1 = 0.0251123 loss)
I0822 17:05:38.463613 13823 sgd_solver.cpp:112] Iteration 35100, lr = 0.0001
I0822 17:05:50.332489 13823 solver.cpp:239] Iteration 35200 (8.4254 iter/s, 11.8689s/100 iters), loss = 0.0317678
I0822 17:05:50.332559 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0317677 (* 1 = 0.0317677 loss)
I0822 17:05:50.332576 13823 sgd_solver.cpp:112] Iteration 35200, lr = 0.0001
I0822 17:06:02.301731 13823 solver.cpp:239] Iteration 35300 (8.3548 iter/s, 11.9692s/100 iters), loss = 0.0299461
I0822 17:06:02.301784 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0299459 (* 1 = 0.0299459 loss)
I0822 17:06:02.301795 13823 sgd_solver.cpp:112] Iteration 35300, lr = 0.0001
I0822 17:06:14.342671 13823 solver.cpp:239] Iteration 35400 (8.30505 iter/s, 12.0409s/100 iters), loss = 0.0275961
I0822 17:06:14.342736 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0275959 (* 1 = 0.0275959 loss)
I0822 17:06:14.342748 13823 sgd_solver.cpp:112] Iteration 35400, lr = 0.0001
I0822 17:06:26.303723 13823 solver.cpp:239] Iteration 35500 (8.36052 iter/s, 11.961s/100 iters), loss = 0.0277727
I0822 17:06:26.303783 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0277726 (* 1 = 0.0277726 loss)
I0822 17:06:26.303795 13823 sgd_solver.cpp:112] Iteration 35500, lr = 0.0001
I0822 17:06:38.212162 13823 solver.cpp:239] Iteration 35600 (8.39746 iter/s, 11.9084s/100 iters), loss = 0.0554053
I0822 17:06:38.212213 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0554051 (* 1 = 0.0554051 loss)
I0822 17:06:38.212221 13823 sgd_solver.cpp:112] Iteration 35600, lr = 0.0001
I0822 17:06:49.986295 13823 solver.cpp:239] Iteration 35700 (8.49324 iter/s, 11.7741s/100 iters), loss = 0.0281891
I0822 17:06:49.986343 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0281889 (* 1 = 0.0281889 loss)
I0822 17:06:49.986352 13823 sgd_solver.cpp:112] Iteration 35700, lr = 0.0001
I0822 17:07:01.971231 13823 solver.cpp:239] Iteration 35800 (8.34385 iter/s, 11.9849s/100 iters), loss = 0.0275952
I0822 17:07:01.971289 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0275951 (* 1 = 0.0275951 loss)
I0822 17:07:01.971300 13823 sgd_solver.cpp:112] Iteration 35800, lr = 0.0001
I0822 17:07:14.021307 13823 solver.cpp:239] Iteration 35900 (8.29875 iter/s, 12.05s/100 iters), loss = 0.0283068
I0822 17:07:14.021378 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0283066 (* 1 = 0.0283066 loss)
I0822 17:07:14.021395 13823 sgd_solver.cpp:112] Iteration 35900, lr = 0.0001
I0822 17:07:25.985556 13823 solver.cpp:239] Iteration 36000 (8.35829 iter/s, 11.9642s/100 iters), loss = 0.0360172
I0822 17:07:25.985613 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.036017 (* 1 = 0.036017 loss)
I0822 17:07:25.985625 13823 sgd_solver.cpp:112] Iteration 36000, lr = 0.0001
I0822 17:07:37.919247 13823 solver.cpp:239] Iteration 36100 (8.37969 iter/s, 11.9336s/100 iters), loss = 0.0328035
I0822 17:07:37.919299 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0328033 (* 1 = 0.0328033 loss)
I0822 17:07:37.919308 13823 sgd_solver.cpp:112] Iteration 36100, lr = 0.0001
I0822 17:07:49.357951 13823 solver.cpp:239] Iteration 36200 (8.7423 iter/s, 11.4386s/100 iters), loss = 0.0288936
I0822 17:07:49.357996 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0288934 (* 1 = 0.0288934 loss)
I0822 17:07:49.358006 13823 sgd_solver.cpp:112] Iteration 36200, lr = 0.0001
I0822 17:08:00.992270 13823 solver.cpp:239] Iteration 36300 (8.59531 iter/s, 11.6343s/100 iters), loss = 0.0398137
I0822 17:08:00.992331 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0398135 (* 1 = 0.0398135 loss)
I0822 17:08:00.992343 13823 sgd_solver.cpp:112] Iteration 36300, lr = 0.0001
I0822 17:08:12.834748 13823 solver.cpp:239] Iteration 36400 (8.44423 iter/s, 11.8424s/100 iters), loss = 0.0272952
I0822 17:08:12.834797 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.027295 (* 1 = 0.027295 loss)
I0822 17:08:12.834805 13823 sgd_solver.cpp:112] Iteration 36400, lr = 0.0001
I0822 17:08:24.332340 13823 solver.cpp:239] Iteration 36500 (8.69752 iter/s, 11.4975s/100 iters), loss = 0.029165
I0822 17:08:24.332392 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0291648 (* 1 = 0.0291648 loss)
I0822 17:08:24.332401 13823 sgd_solver.cpp:112] Iteration 36500, lr = 0.0001
I0822 17:08:34.578333 13823 solver.cpp:239] Iteration 36600 (9.75997 iter/s, 10.2459s/100 iters), loss = 0.0334793
I0822 17:08:34.578385 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0334791 (* 1 = 0.0334791 loss)
I0822 17:08:34.578394 13823 sgd_solver.cpp:112] Iteration 36600, lr = 0.0001
I0822 17:08:44.395088 13823 solver.cpp:239] Iteration 36700 (10.1867 iter/s, 9.81669s/100 iters), loss = 0.0261776
I0822 17:08:44.395143 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0261774 (* 1 = 0.0261774 loss)
I0822 17:08:44.395153 13823 sgd_solver.cpp:112] Iteration 36700, lr = 0.0001
I0822 17:08:54.334094 13823 solver.cpp:239] Iteration 36800 (10.0614 iter/s, 9.93894s/100 iters), loss = 0.0290129
I0822 17:08:54.334133 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0290127 (* 1 = 0.0290127 loss)
I0822 17:08:54.334139 13823 sgd_solver.cpp:112] Iteration 36800, lr = 0.0001
I0822 17:09:04.421828 13823 solver.cpp:239] Iteration 36900 (9.91308 iter/s, 10.0877s/100 iters), loss = 0.0303286
I0822 17:09:04.421880 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0303284 (* 1 = 0.0303284 loss)
I0822 17:09:04.421890 13823 sgd_solver.cpp:112] Iteration 36900, lr = 0.0001
I0822 17:09:13.870262 13823 solver.cpp:239] Iteration 37000 (10.5838 iter/s, 9.44837s/100 iters), loss = 0.0286207
I0822 17:09:13.870304 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0286206 (* 1 = 0.0286206 loss)
I0822 17:09:13.870311 13823 sgd_solver.cpp:112] Iteration 37000, lr = 0.0001
I0822 17:09:23.639506 13823 solver.cpp:239] Iteration 37100 (10.2363 iter/s, 9.76919s/100 iters), loss = 0.0322488
I0822 17:09:23.639566 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0322486 (* 1 = 0.0322486 loss)
I0822 17:09:23.639578 13823 sgd_solver.cpp:112] Iteration 37100, lr = 0.0001
I0822 17:09:33.472898 13823 solver.cpp:239] Iteration 37200 (10.1695 iter/s, 9.83332s/100 iters), loss = 0.0917476
I0822 17:09:33.472949 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0917474 (* 1 = 0.0917474 loss)
I0822 17:09:33.472956 13823 sgd_solver.cpp:112] Iteration 37200, lr = 0.0001
I0822 17:09:43.311518 13823 solver.cpp:239] Iteration 37300 (10.1641 iter/s, 9.83856s/100 iters), loss = 0.0277191
I0822 17:09:43.311571 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0277189 (* 1 = 0.0277189 loss)
I0822 17:09:43.311579 13823 sgd_solver.cpp:112] Iteration 37300, lr = 0.0001
I0822 17:09:53.286087 13823 solver.cpp:239] Iteration 37400 (10.0256 iter/s, 9.9745s/100 iters), loss = 0.0411888
I0822 17:09:53.286154 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0411887 (* 1 = 0.0411887 loss)
I0822 17:09:53.286168 13823 sgd_solver.cpp:112] Iteration 37400, lr = 0.0001
I0822 17:10:03.218971 13823 solver.cpp:239] Iteration 37500 (10.0676 iter/s, 9.93281s/100 iters), loss = 0.0277658
I0822 17:10:03.219022 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0277656 (* 1 = 0.0277656 loss)
I0822 17:10:03.219031 13823 sgd_solver.cpp:112] Iteration 37500, lr = 0.0001
I0822 17:10:13.163779 13823 solver.cpp:239] Iteration 37600 (10.0556 iter/s, 9.94474s/100 iters), loss = 0.0309607
I0822 17:10:13.163831 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0309605 (* 1 = 0.0309605 loss)
I0822 17:10:13.163841 13823 sgd_solver.cpp:112] Iteration 37600, lr = 0.0001
I0822 17:10:23.279676 13823 solver.cpp:239] Iteration 37700 (9.88549 iter/s, 10.1158s/100 iters), loss = 0.0307409
I0822 17:10:23.279731 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0307408 (* 1 = 0.0307408 loss)
I0822 17:10:23.279739 13823 sgd_solver.cpp:112] Iteration 37700, lr = 0.0001
I0822 17:10:33.315798 13823 solver.cpp:239] Iteration 37800 (9.96408 iter/s, 10.0361s/100 iters), loss = 0.031816
I0822 17:10:33.315852 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0318158 (* 1 = 0.0318158 loss)
I0822 17:10:33.315865 13823 sgd_solver.cpp:112] Iteration 37800, lr = 0.0001
I0822 17:10:43.203757 13823 solver.cpp:239] Iteration 37900 (10.1134 iter/s, 9.88789s/100 iters), loss = 0.028932
I0822 17:10:43.203811 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0289318 (* 1 = 0.0289318 loss)
I0822 17:10:43.203824 13823 sgd_solver.cpp:112] Iteration 37900, lr = 0.0001
I0822 17:10:53.412127 13823 solver.cpp:239] Iteration 38000 (9.79595 iter/s, 10.2083s/100 iters), loss = 0.0316942
I0822 17:10:53.412189 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0316941 (* 1 = 0.0316941 loss)
I0822 17:10:53.412201 13823 sgd_solver.cpp:112] Iteration 38000, lr = 0.0001
I0822 17:11:03.272958 13823 solver.cpp:239] Iteration 38100 (10.1412 iter/s, 9.86076s/100 iters), loss = 0.0302773
I0822 17:11:03.273015 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0302772 (* 1 = 0.0302772 loss)
I0822 17:11:03.273026 13823 sgd_solver.cpp:112] Iteration 38100, lr = 0.0001
I0822 17:11:13.474685 13823 solver.cpp:239] Iteration 38200 (9.80228 iter/s, 10.2017s/100 iters), loss = 0.0307878
I0822 17:11:13.474735 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0307876 (* 1 = 0.0307876 loss)
I0822 17:11:13.474745 13823 sgd_solver.cpp:112] Iteration 38200, lr = 0.0001
I0822 17:11:23.884132 13823 solver.cpp:239] Iteration 38300 (9.60661 iter/s, 10.4095s/100 iters), loss = 0.0267854
I0822 17:11:23.884192 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0267852 (* 1 = 0.0267852 loss)
I0822 17:11:23.884207 13823 sgd_solver.cpp:112] Iteration 38300, lr = 0.0001
I0822 17:11:33.897364 13823 solver.cpp:239] Iteration 38400 (9.98674 iter/s, 10.0133s/100 iters), loss = 0.0417156
I0822 17:11:33.897426 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0417154 (* 1 = 0.0417154 loss)
I0822 17:11:33.897440 13823 sgd_solver.cpp:112] Iteration 38400, lr = 0.0001
I0822 17:11:43.726070 13823 solver.cpp:239] Iteration 38500 (10.1742 iter/s, 9.82874s/100 iters), loss = 0.0315025
I0822 17:11:43.726120 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0315022 (* 1 = 0.0315022 loss)
I0822 17:11:43.726131 13823 sgd_solver.cpp:112] Iteration 38500, lr = 0.0001
I0822 17:11:53.935828 13823 solver.cpp:239] Iteration 38600 (9.79451 iter/s, 10.2098s/100 iters), loss = 0.0253688
I0822 17:11:53.935885 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0253686 (* 1 = 0.0253686 loss)
I0822 17:11:53.935899 13823 sgd_solver.cpp:112] Iteration 38600, lr = 0.0001
I0822 17:12:04.401691 13823 solver.cpp:239] Iteration 38700 (9.55483 iter/s, 10.4659s/100 iters), loss = 0.0382562
I0822 17:12:04.401741 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.038256 (* 1 = 0.038256 loss)
I0822 17:12:04.401749 13823 sgd_solver.cpp:112] Iteration 38700, lr = 0.0001
I0822 17:12:14.542644 13823 solver.cpp:239] Iteration 38800 (9.86097 iter/s, 10.141s/100 iters), loss = 0.026137
I0822 17:12:14.542695 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0261368 (* 1 = 0.0261368 loss)
I0822 17:12:14.542704 13823 sgd_solver.cpp:112] Iteration 38800, lr = 0.0001
I0822 17:12:24.611025 13823 solver.cpp:239] Iteration 38900 (9.93204 iter/s, 10.0684s/100 iters), loss = 0.0334703
I0822 17:12:24.611075 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0334701 (* 1 = 0.0334701 loss)
I0822 17:12:24.611084 13823 sgd_solver.cpp:112] Iteration 38900, lr = 0.0001
I0822 17:12:34.795300 13823 solver.cpp:239] Iteration 39000 (9.81902 iter/s, 10.1843s/100 iters), loss = 0.0297816
I0822 17:12:34.795353 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0297814 (* 1 = 0.0297814 loss)
I0822 17:12:34.795363 13823 sgd_solver.cpp:112] Iteration 39000, lr = 0.0001
I0822 17:12:44.967738 13823 solver.cpp:239] Iteration 39100 (9.83045 iter/s, 10.1725s/100 iters), loss = 0.0313886
I0822 17:12:44.967795 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0313884 (* 1 = 0.0313884 loss)
I0822 17:12:44.967805 13823 sgd_solver.cpp:112] Iteration 39100, lr = 0.0001
I0822 17:12:55.132740 13823 solver.cpp:239] Iteration 39200 (9.83765 iter/s, 10.165s/100 iters), loss = 0.0256874
I0822 17:12:55.132797 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0256872 (* 1 = 0.0256872 loss)
I0822 17:12:55.132807 13823 sgd_solver.cpp:112] Iteration 39200, lr = 0.0001
I0822 17:13:05.155545 13823 solver.cpp:239] Iteration 39300 (9.97722 iter/s, 10.0228s/100 iters), loss = 0.0243797
I0822 17:13:05.155598 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0243795 (* 1 = 0.0243795 loss)
I0822 17:13:05.155608 13823 sgd_solver.cpp:112] Iteration 39300, lr = 0.0001
I0822 17:13:15.280422 13823 solver.cpp:239] Iteration 39400 (9.87663 iter/s, 10.1249s/100 iters), loss = 0.0295653
I0822 17:13:15.280470 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0295651 (* 1 = 0.0295651 loss)
I0822 17:13:15.280479 13823 sgd_solver.cpp:112] Iteration 39400, lr = 0.0001
I0822 17:13:25.501251 13823 solver.cpp:239] Iteration 39500 (9.78391 iter/s, 10.2209s/100 iters), loss = 0.0290265
I0822 17:13:25.501310 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0290263 (* 1 = 0.0290263 loss)
I0822 17:13:25.501322 13823 sgd_solver.cpp:112] Iteration 39500, lr = 0.0001
I0822 17:13:35.550613 13823 solver.cpp:239] Iteration 39600 (9.95086 iter/s, 10.0494s/100 iters), loss = 0.0280564
I0822 17:13:35.550663 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0280562 (* 1 = 0.0280562 loss)
I0822 17:13:35.550673 13823 sgd_solver.cpp:112] Iteration 39600, lr = 0.0001
I0822 17:13:45.624892 13823 solver.cpp:239] Iteration 39700 (9.92624 iter/s, 10.0743s/100 iters), loss = 0.027168
I0822 17:13:45.624941 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0271678 (* 1 = 0.0271678 loss)
I0822 17:13:45.624950 13823 sgd_solver.cpp:112] Iteration 39700, lr = 0.0001
I0822 17:13:55.576388 13823 solver.cpp:239] Iteration 39800 (10.0487 iter/s, 9.95152s/100 iters), loss = 0.0322185
I0822 17:13:55.576437 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0322183 (* 1 = 0.0322183 loss)
I0822 17:13:55.576447 13823 sgd_solver.cpp:112] Iteration 39800, lr = 0.0001
I0822 17:14:05.709800 13823 solver.cpp:239] Iteration 39900 (9.86832 iter/s, 10.1334s/100 iters), loss = 0.028838
I0822 17:14:05.709852 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0288378 (* 1 = 0.0288378 loss)
I0822 17:14:05.709861 13823 sgd_solver.cpp:112] Iteration 39900, lr = 0.0001
I0822 17:14:15.726208 13823 solver.cpp:464] Snapshotting to binary proto file ./model_112/cascade_mobilenet_112_iter_40000.caffemodel
I0822 17:14:15.777132 13823 sgd_solver.cpp:284] Snapshotting solver state to binary proto file ./model_112/cascade_mobilenet_112_iter_40000.solverstate
I0822 17:14:15.809160 13823 solver.cpp:347] Iteration 40000, Testing net (#0)
I0822 17:15:25.102999 13823 solver.cpp:414]     Test net output #0: landmark_loss = 0.025855 (* 1 = 0.025855 loss)
I0822 17:15:25.187878 13823 solver.cpp:239] Iteration 40000 (1.2582 iter/s, 79.4786s/100 iters), loss = 0.0356813
I0822 17:15:25.187907 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0356811 (* 1 = 0.0356811 loss)
I0822 17:15:25.187916 13823 sgd_solver.cpp:112] Iteration 40000, lr = 0.0001
I0822 17:15:35.375067 13823 solver.cpp:239] Iteration 40100 (9.81621 iter/s, 10.1872s/100 iters), loss = 0.0281493
I0822 17:15:35.375118 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0281491 (* 1 = 0.0281491 loss)
I0822 17:15:35.375128 13823 sgd_solver.cpp:112] Iteration 40100, lr = 0.0001
I0822 17:15:45.551163 13823 solver.cpp:239] Iteration 40200 (9.82694 iter/s, 10.1761s/100 iters), loss = 0.0557731
I0822 17:15:45.551214 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0557728 (* 1 = 0.0557728 loss)
I0822 17:15:45.551223 13823 sgd_solver.cpp:112] Iteration 40200, lr = 0.0001
I0822 17:15:55.952689 13823 solver.cpp:239] Iteration 40300 (9.61396 iter/s, 10.4015s/100 iters), loss = 0.0286597
I0822 17:15:55.952754 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0286595 (* 1 = 0.0286595 loss)
I0822 17:15:55.952765 13823 sgd_solver.cpp:112] Iteration 40300, lr = 0.0001
I0822 17:16:06.201663 13823 solver.cpp:239] Iteration 40400 (9.75707 iter/s, 10.249s/100 iters), loss = 0.0263861
I0822 17:16:06.201720 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0263859 (* 1 = 0.0263859 loss)
I0822 17:16:06.201731 13823 sgd_solver.cpp:112] Iteration 40400, lr = 0.0001
I0822 17:16:16.360224 13823 solver.cpp:239] Iteration 40500 (9.8439 iter/s, 10.1586s/100 iters), loss = 0.026973
I0822 17:16:16.360275 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0269728 (* 1 = 0.0269728 loss)
I0822 17:16:16.360285 13823 sgd_solver.cpp:112] Iteration 40500, lr = 0.0001
I0822 17:16:26.421221 13823 solver.cpp:239] Iteration 40600 (9.93936 iter/s, 10.061s/100 iters), loss = 0.0282929
I0822 17:16:26.421272 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0282927 (* 1 = 0.0282927 loss)
I0822 17:16:26.421280 13823 sgd_solver.cpp:112] Iteration 40600, lr = 0.0001
I0822 17:16:36.508817 13823 solver.cpp:239] Iteration 40700 (9.91315 iter/s, 10.0876s/100 iters), loss = 0.0250507
I0822 17:16:36.508858 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0250505 (* 1 = 0.0250505 loss)
I0822 17:16:36.508865 13823 sgd_solver.cpp:112] Iteration 40700, lr = 0.0001
I0822 17:16:46.827291 13823 solver.cpp:239] Iteration 40800 (9.69134 iter/s, 10.3185s/100 iters), loss = 0.0270395
I0822 17:16:46.827339 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0270393 (* 1 = 0.0270393 loss)
I0822 17:16:46.827348 13823 sgd_solver.cpp:112] Iteration 40800, lr = 0.0001
I0822 17:16:56.860055 13823 solver.cpp:239] Iteration 40900 (9.96733 iter/s, 10.0328s/100 iters), loss = 0.0273272
I0822 17:16:56.860106 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0273269 (* 1 = 0.0273269 loss)
I0822 17:16:56.860116 13823 sgd_solver.cpp:112] Iteration 40900, lr = 0.0001
I0822 17:17:07.035310 13823 solver.cpp:239] Iteration 41000 (9.82776 iter/s, 10.1753s/100 iters), loss = 0.0377179
I0822 17:17:07.035359 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0377176 (* 1 = 0.0377176 loss)
I0822 17:17:07.035368 13823 sgd_solver.cpp:112] Iteration 41000, lr = 0.0001
I0822 17:17:17.316332 13823 solver.cpp:239] Iteration 41100 (9.72665 iter/s, 10.281s/100 iters), loss = 0.0281231
I0822 17:17:17.316393 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0281228 (* 1 = 0.0281228 loss)
I0822 17:17:17.316406 13823 sgd_solver.cpp:112] Iteration 41100, lr = 0.0001
I0822 17:17:27.927342 13823 solver.cpp:239] Iteration 41200 (9.42418 iter/s, 10.611s/100 iters), loss = 0.035561
I0822 17:17:27.927402 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0355608 (* 1 = 0.0355608 loss)
I0822 17:17:27.927413 13823 sgd_solver.cpp:112] Iteration 41200, lr = 0.0001
I0822 17:17:38.091243 13823 solver.cpp:239] Iteration 41300 (9.83875 iter/s, 10.1639s/100 iters), loss = 0.0266525
I0822 17:17:38.091292 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0266522 (* 1 = 0.0266522 loss)
I0822 17:17:38.091301 13823 sgd_solver.cpp:112] Iteration 41300, lr = 0.0001
I0822 17:17:48.478008 13823 solver.cpp:239] Iteration 41400 (9.62763 iter/s, 10.3868s/100 iters), loss = 0.0391364
I0822 17:17:48.478060 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0391362 (* 1 = 0.0391362 loss)
I0822 17:17:48.478068 13823 sgd_solver.cpp:112] Iteration 41400, lr = 0.0001
I0822 17:17:58.565392 13823 solver.cpp:239] Iteration 41500 (9.91337 iter/s, 10.0874s/100 iters), loss = 0.0461284
I0822 17:17:58.565443 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0461282 (* 1 = 0.0461282 loss)
I0822 17:17:58.565450 13823 sgd_solver.cpp:112] Iteration 41500, lr = 0.0001
I0822 17:18:08.466586 13823 solver.cpp:239] Iteration 41600 (10.0998 iter/s, 9.90119s/100 iters), loss = 0.0274656
I0822 17:18:08.466637 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0274653 (* 1 = 0.0274653 loss)
I0822 17:18:08.466647 13823 sgd_solver.cpp:112] Iteration 41600, lr = 0.0001
I0822 17:18:18.775003 13823 solver.cpp:239] Iteration 41700 (9.70081 iter/s, 10.3084s/100 iters), loss = 0.0284692
I0822 17:18:18.775058 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.028469 (* 1 = 0.028469 loss)
I0822 17:18:18.775068 13823 sgd_solver.cpp:112] Iteration 41700, lr = 0.0001
I0822 17:18:28.967844 13823 solver.cpp:239] Iteration 41800 (9.81081 iter/s, 10.1928s/100 iters), loss = 0.0278725
I0822 17:18:28.967895 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0278723 (* 1 = 0.0278723 loss)
I0822 17:18:28.967903 13823 sgd_solver.cpp:112] Iteration 41800, lr = 0.0001
I0822 17:18:39.357177 13823 solver.cpp:239] Iteration 41900 (9.62526 iter/s, 10.3893s/100 iters), loss = 0.0286876
I0822 17:18:39.357226 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0286873 (* 1 = 0.0286873 loss)
I0822 17:18:39.357234 13823 sgd_solver.cpp:112] Iteration 41900, lr = 0.0001
I0822 17:18:49.769943 13823 solver.cpp:239] Iteration 42000 (9.6036 iter/s, 10.4128s/100 iters), loss = 0.0287365
I0822 17:18:49.769995 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0287362 (* 1 = 0.0287362 loss)
I0822 17:18:49.770004 13823 sgd_solver.cpp:112] Iteration 42000, lr = 0.0001
I0822 17:19:00.113835 13823 solver.cpp:239] Iteration 42100 (9.66755 iter/s, 10.3439s/100 iters), loss = 0.0414354
I0822 17:19:00.113884 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0414352 (* 1 = 0.0414352 loss)
I0822 17:19:00.113893 13823 sgd_solver.cpp:112] Iteration 42100, lr = 0.0001
I0822 17:19:10.386795 13823 solver.cpp:239] Iteration 42200 (9.7343 iter/s, 10.273s/100 iters), loss = 0.061544
I0822 17:19:10.386844 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0615438 (* 1 = 0.0615438 loss)
I0822 17:19:10.386853 13823 sgd_solver.cpp:112] Iteration 42200, lr = 0.0001
I0822 17:19:20.907048 13823 solver.cpp:239] Iteration 42300 (9.50548 iter/s, 10.5202s/100 iters), loss = 0.0288053
I0822 17:19:20.907106 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.028805 (* 1 = 0.028805 loss)
I0822 17:19:20.907116 13823 sgd_solver.cpp:112] Iteration 42300, lr = 0.0001
I0822 17:19:31.488993 13823 solver.cpp:239] Iteration 42400 (9.45007 iter/s, 10.5819s/100 iters), loss = 0.0301615
I0822 17:19:31.489053 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0301613 (* 1 = 0.0301613 loss)
I0822 17:19:31.489065 13823 sgd_solver.cpp:112] Iteration 42400, lr = 0.0001
I0822 17:19:42.170723 13823 solver.cpp:239] Iteration 42500 (9.36179 iter/s, 10.6817s/100 iters), loss = 0.0331842
I0822 17:19:42.170773 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0331839 (* 1 = 0.0331839 loss)
I0822 17:19:42.170781 13823 sgd_solver.cpp:112] Iteration 42500, lr = 0.0001
I0822 17:19:52.697602 13823 solver.cpp:239] Iteration 42600 (9.4995 iter/s, 10.5269s/100 iters), loss = 0.0326891
I0822 17:19:52.697657 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0326888 (* 1 = 0.0326888 loss)
I0822 17:19:52.697669 13823 sgd_solver.cpp:112] Iteration 42600, lr = 0.0001
I0822 17:20:03.488776 13823 solver.cpp:239] Iteration 42700 (9.26684 iter/s, 10.7912s/100 iters), loss = 0.0276254
I0822 17:20:03.488837 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0276251 (* 1 = 0.0276251 loss)
I0822 17:20:03.488848 13823 sgd_solver.cpp:112] Iteration 42700, lr = 0.0001
I0822 17:20:14.135349 13823 solver.cpp:239] Iteration 42800 (9.39271 iter/s, 10.6466s/100 iters), loss = 0.0289723
I0822 17:20:14.135401 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0289721 (* 1 = 0.0289721 loss)
I0822 17:20:14.135411 13823 sgd_solver.cpp:112] Iteration 42800, lr = 0.0001
I0822 17:20:24.903498 13823 solver.cpp:239] Iteration 42900 (9.28665 iter/s, 10.7681s/100 iters), loss = 0.0297764
I0822 17:20:24.903548 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0297761 (* 1 = 0.0297761 loss)
I0822 17:20:24.903558 13823 sgd_solver.cpp:112] Iteration 42900, lr = 0.0001
I0822 17:20:35.354713 13823 solver.cpp:239] Iteration 43000 (9.56828 iter/s, 10.4512s/100 iters), loss = 0.0307414
I0822 17:20:35.354763 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0307411 (* 1 = 0.0307411 loss)
I0822 17:20:35.354770 13823 sgd_solver.cpp:112] Iteration 43000, lr = 0.0001
I0822 17:20:45.793362 13823 solver.cpp:239] Iteration 43100 (9.57979 iter/s, 10.4386s/100 iters), loss = 0.0273066
I0822 17:20:45.793413 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0273063 (* 1 = 0.0273063 loss)
I0822 17:20:45.793422 13823 sgd_solver.cpp:112] Iteration 43100, lr = 0.0001
I0822 17:20:56.523849 13823 solver.cpp:239] Iteration 43200 (9.31925 iter/s, 10.7305s/100 iters), loss = 0.0276951
I0822 17:20:56.523900 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0276948 (* 1 = 0.0276948 loss)
I0822 17:20:56.523908 13823 sgd_solver.cpp:112] Iteration 43200, lr = 0.0001
I0822 17:21:07.252815 13823 solver.cpp:239] Iteration 43300 (9.32057 iter/s, 10.729s/100 iters), loss = 0.0269254
I0822 17:21:07.252871 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0269251 (* 1 = 0.0269251 loss)
I0822 17:21:07.252880 13823 sgd_solver.cpp:112] Iteration 43300, lr = 0.0001
I0822 17:21:18.173759 13823 solver.cpp:239] Iteration 43400 (9.15673 iter/s, 10.9209s/100 iters), loss = 0.0249945
I0822 17:21:18.173807 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0249942 (* 1 = 0.0249942 loss)
I0822 17:21:18.173816 13823 sgd_solver.cpp:112] Iteration 43400, lr = 0.0001
I0822 17:21:29.018517 13823 solver.cpp:239] Iteration 43500 (9.22106 iter/s, 10.8447s/100 iters), loss = 0.0341211
I0822 17:21:29.018577 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0341208 (* 1 = 0.0341208 loss)
I0822 17:21:29.018589 13823 sgd_solver.cpp:112] Iteration 43500, lr = 0.0001
I0822 17:21:39.807559 13823 solver.cpp:239] Iteration 43600 (9.26868 iter/s, 10.789s/100 iters), loss = 0.02712
I0822 17:21:39.807616 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0271197 (* 1 = 0.0271197 loss)
I0822 17:21:39.807626 13823 sgd_solver.cpp:112] Iteration 43600, lr = 0.0001
I0822 17:21:50.670576 13823 solver.cpp:239] Iteration 43700 (9.20556 iter/s, 10.863s/100 iters), loss = 0.02695
I0822 17:21:50.670626 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0269498 (* 1 = 0.0269498 loss)
I0822 17:21:50.670635 13823 sgd_solver.cpp:112] Iteration 43700, lr = 0.0001
I0822 17:22:01.585140 13823 solver.cpp:239] Iteration 43800 (9.16208 iter/s, 10.9145s/100 iters), loss = 0.0269404
I0822 17:22:01.585188 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0269401 (* 1 = 0.0269401 loss)
I0822 17:22:01.585197 13823 sgd_solver.cpp:112] Iteration 43800, lr = 0.0001
I0822 17:22:12.134209 13823 solver.cpp:239] Iteration 43900 (9.47953 iter/s, 10.549s/100 iters), loss = 0.0356621
I0822 17:22:12.134286 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0356618 (* 1 = 0.0356618 loss)
I0822 17:22:12.134299 13823 sgd_solver.cpp:112] Iteration 43900, lr = 0.0001
I0822 17:22:22.961526 13823 solver.cpp:239] Iteration 44000 (9.23593 iter/s, 10.8273s/100 iters), loss = 0.0352229
I0822 17:22:22.961586 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0352226 (* 1 = 0.0352226 loss)
I0822 17:22:22.961597 13823 sgd_solver.cpp:112] Iteration 44000, lr = 0.0001
I0822 17:22:33.742491 13823 solver.cpp:239] Iteration 44100 (9.27563 iter/s, 10.7809s/100 iters), loss = 0.0268958
I0822 17:22:33.742552 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0268955 (* 1 = 0.0268955 loss)
I0822 17:22:33.742563 13823 sgd_solver.cpp:112] Iteration 44100, lr = 0.0001
I0822 17:22:44.730504 13823 solver.cpp:239] Iteration 44200 (9.10085 iter/s, 10.988s/100 iters), loss = 0.0280293
I0822 17:22:44.730556 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.028029 (* 1 = 0.028029 loss)
I0822 17:22:44.730566 13823 sgd_solver.cpp:112] Iteration 44200, lr = 0.0001
I0822 17:22:55.292587 13823 solver.cpp:239] Iteration 44300 (9.46785 iter/s, 10.5621s/100 iters), loss = 0.0300176
I0822 17:22:55.292636 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0300174 (* 1 = 0.0300174 loss)
I0822 17:22:55.292645 13823 sgd_solver.cpp:112] Iteration 44300, lr = 0.0001
I0822 17:23:06.189062 13823 solver.cpp:239] Iteration 44400 (9.17729 iter/s, 10.8965s/100 iters), loss = 0.0285595
I0822 17:23:06.189116 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0285592 (* 1 = 0.0285592 loss)
I0822 17:23:06.189124 13823 sgd_solver.cpp:112] Iteration 44400, lr = 0.0001
I0822 17:23:16.857831 13823 solver.cpp:239] Iteration 44500 (9.37317 iter/s, 10.6687s/100 iters), loss = 0.0265305
I0822 17:23:16.857887 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0265302 (* 1 = 0.0265302 loss)
I0822 17:23:16.857898 13823 sgd_solver.cpp:112] Iteration 44500, lr = 0.0001
I0822 17:23:27.442657 13823 solver.cpp:239] Iteration 44600 (9.44751 iter/s, 10.5848s/100 iters), loss = 0.0307276
I0822 17:23:27.442718 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0307273 (* 1 = 0.0307273 loss)
I0822 17:23:27.442728 13823 sgd_solver.cpp:112] Iteration 44600, lr = 0.0001
I0822 17:23:38.486807 13823 solver.cpp:239] Iteration 44700 (9.05459 iter/s, 11.0441s/100 iters), loss = 0.0262953
I0822 17:23:38.486862 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0262951 (* 1 = 0.0262951 loss)
I0822 17:23:38.486872 13823 sgd_solver.cpp:112] Iteration 44700, lr = 0.0001
I0822 17:23:48.957607 13823 solver.cpp:239] Iteration 44800 (9.55039 iter/s, 10.4708s/100 iters), loss = 0.0273133
I0822 17:23:48.957659 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0273131 (* 1 = 0.0273131 loss)
I0822 17:23:48.957667 13823 sgd_solver.cpp:112] Iteration 44800, lr = 0.0001
I0822 17:23:59.656565 13823 solver.cpp:239] Iteration 44900 (9.34672 iter/s, 10.6989s/100 iters), loss = 0.0285499
I0822 17:23:59.656617 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0285497 (* 1 = 0.0285497 loss)
I0822 17:23:59.656626 13823 sgd_solver.cpp:112] Iteration 44900, lr = 0.0001
I0822 17:24:10.582682 13823 solver.cpp:239] Iteration 45000 (9.1524 iter/s, 10.9261s/100 iters), loss = 0.0253949
I0822 17:24:10.582741 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0253946 (* 1 = 0.0253946 loss)
I0822 17:24:10.582752 13823 sgd_solver.cpp:112] Iteration 45000, lr = 0.0001
I0822 17:24:21.667757 13823 solver.cpp:239] Iteration 45100 (9.02116 iter/s, 11.085s/100 iters), loss = 0.252242
I0822 17:24:21.667812 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.252241 (* 1 = 0.252241 loss)
I0822 17:24:21.667822 13823 sgd_solver.cpp:112] Iteration 45100, lr = 0.0001
I0822 17:24:32.732019 13823 solver.cpp:239] Iteration 45200 (9.03813 iter/s, 11.0642s/100 iters), loss = 0.0278801
I0822 17:24:32.732072 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0278798 (* 1 = 0.0278798 loss)
I0822 17:24:32.732082 13823 sgd_solver.cpp:112] Iteration 45200, lr = 0.0001
I0822 17:24:43.970480 13823 solver.cpp:239] Iteration 45300 (8.89804 iter/s, 11.2384s/100 iters), loss = 0.0295945
I0822 17:24:43.970528 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0295943 (* 1 = 0.0295943 loss)
I0822 17:24:43.970537 13823 sgd_solver.cpp:112] Iteration 45300, lr = 0.0001
I0822 17:24:55.360924 13823 solver.cpp:239] Iteration 45400 (8.7793 iter/s, 11.3904s/100 iters), loss = 0.0235406
I0822 17:24:55.360975 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0235403 (* 1 = 0.0235403 loss)
I0822 17:24:55.360983 13823 sgd_solver.cpp:112] Iteration 45400, lr = 0.0001
I0822 17:25:06.169479 13823 solver.cpp:239] Iteration 45500 (9.25195 iter/s, 10.8085s/100 iters), loss = 0.0276866
I0822 17:25:06.169539 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0276863 (* 1 = 0.0276863 loss)
I0822 17:25:06.169551 13823 sgd_solver.cpp:112] Iteration 45500, lr = 0.0001
I0822 17:25:17.372089 13823 solver.cpp:239] Iteration 45600 (8.92651 iter/s, 11.2026s/100 iters), loss = 0.0432183
I0822 17:25:17.372143 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.043218 (* 1 = 0.043218 loss)
I0822 17:25:17.372153 13823 sgd_solver.cpp:112] Iteration 45600, lr = 0.0001
I0822 17:25:28.352165 13823 solver.cpp:239] Iteration 45700 (9.10743 iter/s, 10.9801s/100 iters), loss = 0.0263344
I0822 17:25:28.352217 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0263341 (* 1 = 0.0263341 loss)
I0822 17:25:28.352226 13823 sgd_solver.cpp:112] Iteration 45700, lr = 0.0001
I0822 17:25:39.385789 13823 solver.cpp:239] Iteration 45800 (9.06323 iter/s, 11.0336s/100 iters), loss = 0.0273895
I0822 17:25:39.385838 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0273893 (* 1 = 0.0273893 loss)
I0822 17:25:39.385848 13823 sgd_solver.cpp:112] Iteration 45800, lr = 0.0001
I0822 17:25:50.488955 13823 solver.cpp:239] Iteration 45900 (9.00646 iter/s, 11.1031s/100 iters), loss = 0.0301083
I0822 17:25:50.489015 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0301081 (* 1 = 0.0301081 loss)
I0822 17:25:50.489027 13823 sgd_solver.cpp:112] Iteration 45900, lr = 0.0001
I0822 17:26:01.362462 13823 solver.cpp:239] Iteration 46000 (9.19669 iter/s, 10.8735s/100 iters), loss = 0.0284258
I0822 17:26:01.362509 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0284256 (* 1 = 0.0284256 loss)
I0822 17:26:01.362519 13823 sgd_solver.cpp:112] Iteration 46000, lr = 0.0001
I0822 17:26:12.380961 13823 solver.cpp:239] Iteration 46100 (9.07566 iter/s, 11.0185s/100 iters), loss = 0.0277316
I0822 17:26:12.381011 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0277313 (* 1 = 0.0277313 loss)
I0822 17:26:12.381021 13823 sgd_solver.cpp:112] Iteration 46100, lr = 0.0001
I0822 17:26:23.207726 13823 solver.cpp:239] Iteration 46200 (9.23639 iter/s, 10.8267s/100 iters), loss = 0.0288831
I0822 17:26:23.207775 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0288828 (* 1 = 0.0288828 loss)
I0822 17:26:23.207784 13823 sgd_solver.cpp:112] Iteration 46200, lr = 0.0001
I0822 17:26:34.326642 13823 solver.cpp:239] Iteration 46300 (8.9937 iter/s, 11.1189s/100 iters), loss = 0.0382954
I0822 17:26:34.326691 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0382951 (* 1 = 0.0382951 loss)
I0822 17:26:34.326700 13823 sgd_solver.cpp:112] Iteration 46300, lr = 0.0001
I0822 17:26:45.372823 13823 solver.cpp:239] Iteration 46400 (9.05293 iter/s, 11.0462s/100 iters), loss = 0.0295845
I0822 17:26:45.372884 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0295842 (* 1 = 0.0295842 loss)
I0822 17:26:45.372895 13823 sgd_solver.cpp:112] Iteration 46400, lr = 0.0001
I0822 17:26:56.435714 13823 solver.cpp:239] Iteration 46500 (9.03926 iter/s, 11.0629s/100 iters), loss = 0.0294141
I0822 17:26:56.435765 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0294138 (* 1 = 0.0294138 loss)
I0822 17:26:56.435773 13823 sgd_solver.cpp:112] Iteration 46500, lr = 0.0001
I0822 17:27:07.468083 13823 solver.cpp:239] Iteration 46600 (9.06426 iter/s, 11.0323s/100 iters), loss = 0.0320596
I0822 17:27:07.468138 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0320593 (* 1 = 0.0320593 loss)
I0822 17:27:07.468147 13823 sgd_solver.cpp:112] Iteration 46600, lr = 0.0001
I0822 17:27:18.726454 13823 solver.cpp:239] Iteration 46700 (8.8823 iter/s, 11.2583s/100 iters), loss = 0.0256467
I0822 17:27:18.726506 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0256465 (* 1 = 0.0256465 loss)
I0822 17:27:18.726516 13823 sgd_solver.cpp:112] Iteration 46700, lr = 0.0001
I0822 17:27:30.112015 13823 solver.cpp:239] Iteration 46800 (8.78308 iter/s, 11.3855s/100 iters), loss = 0.0314159
I0822 17:27:30.112067 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0314156 (* 1 = 0.0314156 loss)
I0822 17:27:30.112077 13823 sgd_solver.cpp:112] Iteration 46800, lr = 0.0001
I0822 17:27:41.679464 13823 solver.cpp:239] Iteration 46900 (8.64497 iter/s, 11.5674s/100 iters), loss = 0.0307088
I0822 17:27:41.679523 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0307086 (* 1 = 0.0307086 loss)
I0822 17:27:41.679534 13823 sgd_solver.cpp:112] Iteration 46900, lr = 0.0001
I0822 17:27:53.160378 13823 solver.cpp:239] Iteration 47000 (8.71013 iter/s, 11.4809s/100 iters), loss = 0.0284192
I0822 17:27:53.160429 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.028419 (* 1 = 0.028419 loss)
I0822 17:27:53.160437 13823 sgd_solver.cpp:112] Iteration 47000, lr = 0.0001
I0822 17:28:04.912390 13823 solver.cpp:239] Iteration 47100 (8.5092 iter/s, 11.752s/100 iters), loss = 0.0292374
I0822 17:28:04.912441 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0292371 (* 1 = 0.0292371 loss)
I0822 17:28:04.912451 13823 sgd_solver.cpp:112] Iteration 47100, lr = 0.0001
I0822 17:28:16.704931 13823 solver.cpp:239] Iteration 47200 (8.47996 iter/s, 11.7925s/100 iters), loss = 0.0260425
I0822 17:28:16.704994 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0260422 (* 1 = 0.0260422 loss)
I0822 17:28:16.705006 13823 sgd_solver.cpp:112] Iteration 47200, lr = 0.0001
I0822 17:28:28.553323 13823 solver.cpp:239] Iteration 47300 (8.43999 iter/s, 11.8484s/100 iters), loss = 0.0393677
I0822 17:28:28.553382 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0393674 (* 1 = 0.0393674 loss)
I0822 17:28:28.553393 13823 sgd_solver.cpp:112] Iteration 47300, lr = 0.0001
I0822 17:28:40.393976 13823 solver.cpp:239] Iteration 47400 (8.44551 iter/s, 11.8406s/100 iters), loss = 0.0408238
I0822 17:28:40.394032 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0408236 (* 1 = 0.0408236 loss)
I0822 17:28:40.394043 13823 sgd_solver.cpp:112] Iteration 47400, lr = 0.0001
I0822 17:28:51.997997 13823 solver.cpp:239] Iteration 47500 (8.61773 iter/s, 11.604s/100 iters), loss = 0.0268455
I0822 17:28:51.998044 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0268452 (* 1 = 0.0268452 loss)
I0822 17:28:51.998054 13823 sgd_solver.cpp:112] Iteration 47500, lr = 0.0001
I0822 17:29:03.871793 13823 solver.cpp:239] Iteration 47600 (8.42193 iter/s, 11.8738s/100 iters), loss = 0.0254126
I0822 17:29:03.871852 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0254123 (* 1 = 0.0254123 loss)
I0822 17:29:03.871863 13823 sgd_solver.cpp:112] Iteration 47600, lr = 0.0001
I0822 17:29:15.625336 13823 solver.cpp:239] Iteration 47700 (8.5081 iter/s, 11.7535s/100 iters), loss = 0.0282558
I0822 17:29:15.625386 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0282555 (* 1 = 0.0282555 loss)
I0822 17:29:15.625396 13823 sgd_solver.cpp:112] Iteration 47700, lr = 0.0001
I0822 17:29:27.037055 13823 solver.cpp:239] Iteration 47800 (8.76294 iter/s, 11.4117s/100 iters), loss = 0.0273635
I0822 17:29:27.037104 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0273632 (* 1 = 0.0273632 loss)
I0822 17:29:27.037113 13823 sgd_solver.cpp:112] Iteration 47800, lr = 0.0001
I0822 17:29:38.697075 13823 solver.cpp:239] Iteration 47900 (8.57634 iter/s, 11.66s/100 iters), loss = 0.0392188
I0822 17:29:38.697124 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0392185 (* 1 = 0.0392185 loss)
I0822 17:29:38.697134 13823 sgd_solver.cpp:112] Iteration 47900, lr = 0.0001
I0822 17:29:50.116946 13823 solver.cpp:239] Iteration 48000 (8.75669 iter/s, 11.4198s/100 iters), loss = 0.0285872
I0822 17:29:50.117002 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.028587 (* 1 = 0.028587 loss)
I0822 17:29:50.117013 13823 sgd_solver.cpp:112] Iteration 48000, lr = 0.0001
I0822 17:30:01.605226 13823 solver.cpp:239] Iteration 48100 (8.70455 iter/s, 11.4882s/100 iters), loss = 0.0335158
I0822 17:30:01.605276 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0335155 (* 1 = 0.0335155 loss)
I0822 17:30:01.605286 13823 sgd_solver.cpp:112] Iteration 48100, lr = 0.0001
I0822 17:30:13.192382 13823 solver.cpp:239] Iteration 48200 (8.63027 iter/s, 11.5871s/100 iters), loss = 0.0257245
I0822 17:30:13.192433 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0257242 (* 1 = 0.0257242 loss)
I0822 17:30:13.192443 13823 sgd_solver.cpp:112] Iteration 48200, lr = 0.0001
I0822 17:30:24.725910 13823 solver.cpp:239] Iteration 48300 (8.6704 iter/s, 11.5335s/100 iters), loss = 0.0283286
I0822 17:30:24.725965 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0283283 (* 1 = 0.0283283 loss)
I0822 17:30:24.725975 13823 sgd_solver.cpp:112] Iteration 48300, lr = 0.0001
I0822 17:30:36.489267 13823 solver.cpp:239] Iteration 48400 (8.501 iter/s, 11.7633s/100 iters), loss = 0.0274402
I0822 17:30:36.489321 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0274399 (* 1 = 0.0274399 loss)
I0822 17:30:36.489331 13823 sgd_solver.cpp:112] Iteration 48400, lr = 0.0001
I0822 17:30:48.218765 13823 solver.cpp:239] Iteration 48500 (8.52554 iter/s, 11.7295s/100 iters), loss = 0.0306466
I0822 17:30:48.218829 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0306463 (* 1 = 0.0306463 loss)
I0822 17:30:48.218842 13823 sgd_solver.cpp:112] Iteration 48500, lr = 0.0001
I0822 17:30:59.984694 13823 solver.cpp:239] Iteration 48600 (8.49915 iter/s, 11.7659s/100 iters), loss = 0.026785
I0822 17:30:59.984753 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0267847 (* 1 = 0.0267847 loss)
I0822 17:30:59.984764 13823 sgd_solver.cpp:112] Iteration 48600, lr = 0.0001
I0822 17:31:11.876778 13823 solver.cpp:239] Iteration 48700 (8.40898 iter/s, 11.892s/100 iters), loss = 0.0333973
I0822 17:31:11.876827 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.033397 (* 1 = 0.033397 loss)
I0822 17:31:11.876835 13823 sgd_solver.cpp:112] Iteration 48700, lr = 0.0001
I0822 17:31:23.448556 13823 solver.cpp:239] Iteration 48800 (8.64174 iter/s, 11.5717s/100 iters), loss = 0.0356707
I0822 17:31:23.448607 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0356705 (* 1 = 0.0356705 loss)
I0822 17:31:23.448616 13823 sgd_solver.cpp:112] Iteration 48800, lr = 0.0001
I0822 17:31:35.043644 13823 solver.cpp:239] Iteration 48900 (8.62437 iter/s, 11.5951s/100 iters), loss = 0.0286923
I0822 17:31:35.043694 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.028692 (* 1 = 0.028692 loss)
I0822 17:31:35.043701 13823 sgd_solver.cpp:112] Iteration 48900, lr = 0.0001
I0822 17:31:46.557118 13823 solver.cpp:239] Iteration 49000 (8.6855 iter/s, 11.5134s/100 iters), loss = 0.0256835
I0822 17:31:46.557169 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0256833 (* 1 = 0.0256833 loss)
I0822 17:31:46.557178 13823 sgd_solver.cpp:112] Iteration 49000, lr = 0.0001
I0822 17:31:58.158813 13823 solver.cpp:239] Iteration 49100 (8.61946 iter/s, 11.6017s/100 iters), loss = 0.0276692
I0822 17:31:58.158864 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0276689 (* 1 = 0.0276689 loss)
I0822 17:31:58.158872 13823 sgd_solver.cpp:112] Iteration 49100, lr = 0.0001
I0822 17:32:09.730597 13823 solver.cpp:239] Iteration 49200 (8.64174 iter/s, 11.5717s/100 iters), loss = 0.0300117
I0822 17:32:09.730648 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0300115 (* 1 = 0.0300115 loss)
I0822 17:32:09.730656 13823 sgd_solver.cpp:112] Iteration 49200, lr = 0.0001
I0822 17:32:21.202482 13823 solver.cpp:239] Iteration 49300 (8.71699 iter/s, 11.4719s/100 iters), loss = 0.0316966
I0822 17:32:21.202534 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0316964 (* 1 = 0.0316964 loss)
I0822 17:32:21.202543 13823 sgd_solver.cpp:112] Iteration 49300, lr = 0.0001
I0822 17:32:32.753798 13823 solver.cpp:239] Iteration 49400 (8.65705 iter/s, 11.5513s/100 iters), loss = 0.0263865
I0822 17:32:32.753845 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0263862 (* 1 = 0.0263862 loss)
I0822 17:32:32.753854 13823 sgd_solver.cpp:112] Iteration 49400, lr = 0.0001
I0822 17:32:44.272686 13823 solver.cpp:239] Iteration 49500 (8.68142 iter/s, 11.5189s/100 iters), loss = 0.024547
I0822 17:32:44.272739 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0245467 (* 1 = 0.0245467 loss)
I0822 17:32:44.272749 13823 sgd_solver.cpp:112] Iteration 49500, lr = 0.0001
I0822 17:32:56.069756 13823 solver.cpp:239] Iteration 49600 (8.47671 iter/s, 11.797s/100 iters), loss = 0.0318745
I0822 17:32:56.069811 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0318743 (* 1 = 0.0318743 loss)
I0822 17:32:56.069823 13823 sgd_solver.cpp:112] Iteration 49600, lr = 0.0001
I0822 17:33:07.570016 13823 solver.cpp:239] Iteration 49700 (8.69549 iter/s, 11.5002s/100 iters), loss = 0.028475
I0822 17:33:07.570070 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0284747 (* 1 = 0.0284747 loss)
I0822 17:33:07.570080 13823 sgd_solver.cpp:112] Iteration 49700, lr = 0.0001
I0822 17:33:19.164275 13823 solver.cpp:239] Iteration 49800 (8.62499 iter/s, 11.5942s/100 iters), loss = 0.0271044
I0822 17:33:19.164333 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0271041 (* 1 = 0.0271041 loss)
I0822 17:33:19.164345 13823 sgd_solver.cpp:112] Iteration 49800, lr = 0.0001
I0822 17:33:30.879559 13823 solver.cpp:239] Iteration 49900 (8.53589 iter/s, 11.7152s/100 iters), loss = 0.0258432
I0822 17:33:30.879609 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0258429 (* 1 = 0.0258429 loss)
I0822 17:33:30.879618 13823 sgd_solver.cpp:112] Iteration 49900, lr = 0.0001
I0822 17:33:42.770314 13823 solver.cpp:239] Iteration 50000 (8.40992 iter/s, 11.8907s/100 iters), loss = 0.0272576
I0822 17:33:42.770364 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0272574 (* 1 = 0.0272574 loss)
I0822 17:33:42.770373 13823 sgd_solver.cpp:112] Iteration 50000, lr = 0.0001
I0822 17:33:54.442184 13823 solver.cpp:239] Iteration 50100 (8.56763 iter/s, 11.6718s/100 iters), loss = 0.0285359
I0822 17:33:54.442232 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0285356 (* 1 = 0.0285356 loss)
I0822 17:33:54.442241 13823 sgd_solver.cpp:112] Iteration 50100, lr = 0.0001
I0822 17:34:06.016223 13823 solver.cpp:239] Iteration 50200 (8.64005 iter/s, 11.574s/100 iters), loss = 0.0300664
I0822 17:34:06.016273 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0300662 (* 1 = 0.0300662 loss)
I0822 17:34:06.016283 13823 sgd_solver.cpp:112] Iteration 50200, lr = 0.0001
I0822 17:34:17.579875 13823 solver.cpp:239] Iteration 50300 (8.64781 iter/s, 11.5636s/100 iters), loss = 0.0312021
I0822 17:34:17.579924 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0312018 (* 1 = 0.0312018 loss)
I0822 17:34:17.579933 13823 sgd_solver.cpp:112] Iteration 50300, lr = 0.0001
I0822 17:34:29.121042 13823 solver.cpp:239] Iteration 50400 (8.66466 iter/s, 11.5411s/100 iters), loss = 0.0254012
I0822 17:34:29.121100 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0254009 (* 1 = 0.0254009 loss)
I0822 17:34:29.121111 13823 sgd_solver.cpp:112] Iteration 50400, lr = 0.0001
I0822 17:34:40.682272 13823 solver.cpp:239] Iteration 50500 (8.64963 iter/s, 11.5612s/100 iters), loss = 0.0320109
I0822 17:34:40.682322 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0320106 (* 1 = 0.0320106 loss)
I0822 17:34:40.682330 13823 sgd_solver.cpp:112] Iteration 50500, lr = 0.0001
I0822 17:34:52.271374 13823 solver.cpp:239] Iteration 50600 (8.62882 iter/s, 11.5891s/100 iters), loss = 0.0265088
I0822 17:34:52.271425 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0265086 (* 1 = 0.0265086 loss)
I0822 17:34:52.271433 13823 sgd_solver.cpp:112] Iteration 50600, lr = 0.0001
I0822 17:35:04.023993 13823 solver.cpp:239] Iteration 50700 (8.50877 iter/s, 11.7526s/100 iters), loss = 0.0300567
I0822 17:35:04.024046 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0300565 (* 1 = 0.0300565 loss)
I0822 17:35:04.024057 13823 sgd_solver.cpp:112] Iteration 50700, lr = 0.0001
I0822 17:35:15.951831 13823 solver.cpp:239] Iteration 50800 (8.38378 iter/s, 11.9278s/100 iters), loss = 0.0280737
I0822 17:35:15.951885 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0280734 (* 1 = 0.0280734 loss)
I0822 17:35:15.951895 13823 sgd_solver.cpp:112] Iteration 50800, lr = 0.0001
I0822 17:35:27.914208 13823 solver.cpp:239] Iteration 50900 (8.35957 iter/s, 11.9623s/100 iters), loss = 0.0275213
I0822 17:35:27.914268 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0275211 (* 1 = 0.0275211 loss)
I0822 17:35:27.914278 13823 sgd_solver.cpp:112] Iteration 50900, lr = 0.0001
I0822 17:35:39.633714 13823 solver.cpp:239] Iteration 51000 (8.53282 iter/s, 11.7195s/100 iters), loss = 0.0293946
I0822 17:35:39.633780 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0293944 (* 1 = 0.0293944 loss)
I0822 17:35:39.633793 13823 sgd_solver.cpp:112] Iteration 51000, lr = 0.0001
I0822 17:35:51.546175 13823 solver.cpp:239] Iteration 51100 (8.39461 iter/s, 11.9124s/100 iters), loss = 0.0254361
I0822 17:35:51.546234 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0254358 (* 1 = 0.0254358 loss)
I0822 17:35:51.546245 13823 sgd_solver.cpp:112] Iteration 51100, lr = 0.0001
I0822 17:36:03.454574 13823 solver.cpp:239] Iteration 51200 (8.39746 iter/s, 11.9084s/100 iters), loss = 0.028022
I0822 17:36:03.454633 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0280217 (* 1 = 0.0280217 loss)
I0822 17:36:03.454644 13823 sgd_solver.cpp:112] Iteration 51200, lr = 0.0001
I0822 17:36:15.385288 13823 solver.cpp:239] Iteration 51300 (8.38176 iter/s, 11.9307s/100 iters), loss = 0.0291101
I0822 17:36:15.385349 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0291098 (* 1 = 0.0291098 loss)
I0822 17:36:15.385361 13823 sgd_solver.cpp:112] Iteration 51300, lr = 0.0001
I0822 17:36:27.177572 13823 solver.cpp:239] Iteration 51400 (8.48015 iter/s, 11.7922s/100 iters), loss = 0.0386675
I0822 17:36:27.177634 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0386672 (* 1 = 0.0386672 loss)
I0822 17:36:27.177644 13823 sgd_solver.cpp:112] Iteration 51400, lr = 0.0001
I0822 17:36:39.034173 13823 solver.cpp:239] Iteration 51500 (8.43415 iter/s, 11.8566s/100 iters), loss = 0.0297596
I0822 17:36:39.034229 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0297593 (* 1 = 0.0297593 loss)
I0822 17:36:39.034240 13823 sgd_solver.cpp:112] Iteration 51500, lr = 0.0001
I0822 17:36:50.937508 13823 solver.cpp:239] Iteration 51600 (8.40104 iter/s, 11.9033s/100 iters), loss = 0.028002
I0822 17:36:50.937570 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0280017 (* 1 = 0.0280017 loss)
I0822 17:36:50.937582 13823 sgd_solver.cpp:112] Iteration 51600, lr = 0.0001
I0822 17:37:02.833573 13823 solver.cpp:239] Iteration 51700 (8.40617 iter/s, 11.896s/100 iters), loss = 0.0246834
I0822 17:37:02.833642 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0246831 (* 1 = 0.0246831 loss)
I0822 17:37:02.833659 13823 sgd_solver.cpp:112] Iteration 51700, lr = 0.0001
I0822 17:37:14.671249 13823 solver.cpp:239] Iteration 51800 (8.44764 iter/s, 11.8376s/100 iters), loss = 0.0293098
I0822 17:37:14.671314 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0293095 (* 1 = 0.0293095 loss)
I0822 17:37:14.671329 13823 sgd_solver.cpp:112] Iteration 51800, lr = 0.0001
I0822 17:37:26.478989 13823 solver.cpp:239] Iteration 51900 (8.46906 iter/s, 11.8077s/100 iters), loss = 0.0274282
I0822 17:37:26.479048 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0274279 (* 1 = 0.0274279 loss)
I0822 17:37:26.479063 13823 sgd_solver.cpp:112] Iteration 51900, lr = 0.0001
I0822 17:37:38.352278 13823 solver.cpp:239] Iteration 52000 (8.4223 iter/s, 11.8732s/100 iters), loss = 0.0343995
I0822 17:37:38.352335 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0343992 (* 1 = 0.0343992 loss)
I0822 17:37:38.352346 13823 sgd_solver.cpp:112] Iteration 52000, lr = 0.0001
I0822 17:37:49.991966 13823 solver.cpp:239] Iteration 52100 (8.59133 iter/s, 11.6396s/100 iters), loss = 0.0255645
I0822 17:37:49.992019 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0255642 (* 1 = 0.0255642 loss)
I0822 17:37:49.992028 13823 sgd_solver.cpp:112] Iteration 52100, lr = 0.0001
I0822 17:38:01.634719 13823 solver.cpp:239] Iteration 52200 (8.58906 iter/s, 11.6427s/100 iters), loss = 0.0280616
I0822 17:38:01.634779 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0280613 (* 1 = 0.0280613 loss)
I0822 17:38:01.634790 13823 sgd_solver.cpp:112] Iteration 52200, lr = 0.0001
I0822 17:38:13.559082 13823 solver.cpp:239] Iteration 52300 (8.38622 iter/s, 11.9243s/100 iters), loss = 0.0263369
I0822 17:38:13.559152 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0263366 (* 1 = 0.0263366 loss)
I0822 17:38:13.559168 13823 sgd_solver.cpp:112] Iteration 52300, lr = 0.0001
I0822 17:38:25.422652 13823 solver.cpp:239] Iteration 52400 (8.4292 iter/s, 11.8635s/100 iters), loss = 0.0306905
I0822 17:38:25.422720 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0306902 (* 1 = 0.0306902 loss)
I0822 17:38:25.422736 13823 sgd_solver.cpp:112] Iteration 52400, lr = 0.0001
I0822 17:38:37.293689 13823 solver.cpp:239] Iteration 52500 (8.4239 iter/s, 11.871s/100 iters), loss = 0.0269054
I0822 17:38:37.293761 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0269052 (* 1 = 0.0269052 loss)
I0822 17:38:37.293777 13823 sgd_solver.cpp:112] Iteration 52500, lr = 0.0001
I0822 17:38:49.219584 13823 solver.cpp:239] Iteration 52600 (8.38515 iter/s, 11.9258s/100 iters), loss = 0.0303372
I0822 17:38:49.219642 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0303369 (* 1 = 0.0303369 loss)
I0822 17:38:49.219653 13823 sgd_solver.cpp:112] Iteration 52600, lr = 0.0001
I0822 17:39:01.066838 13823 solver.cpp:239] Iteration 52700 (8.44081 iter/s, 11.8472s/100 iters), loss = 0.0315435
I0822 17:39:01.066901 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0315432 (* 1 = 0.0315432 loss)
I0822 17:39:01.066913 13823 sgd_solver.cpp:112] Iteration 52700, lr = 0.0001
I0822 17:39:12.662714 13823 solver.cpp:239] Iteration 52800 (8.62379 iter/s, 11.5958s/100 iters), loss = 0.0270564
I0822 17:39:12.662765 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0270561 (* 1 = 0.0270561 loss)
I0822 17:39:12.662773 13823 sgd_solver.cpp:112] Iteration 52800, lr = 0.0001
I0822 17:39:24.221293 13823 solver.cpp:239] Iteration 52900 (8.65161 iter/s, 11.5585s/100 iters), loss = 0.0353693
I0822 17:39:24.221359 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0353691 (* 1 = 0.0353691 loss)
I0822 17:39:24.221383 13823 sgd_solver.cpp:112] Iteration 52900, lr = 0.0001
I0822 17:39:36.182971 13823 solver.cpp:239] Iteration 53000 (8.36007 iter/s, 11.9616s/100 iters), loss = 0.0304395
I0822 17:39:36.183028 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0304392 (* 1 = 0.0304392 loss)
I0822 17:39:36.183039 13823 sgd_solver.cpp:112] Iteration 53000, lr = 0.0001
I0822 17:39:48.024273 13823 solver.cpp:239] Iteration 53100 (8.44505 iter/s, 11.8413s/100 iters), loss = 0.0379044
I0822 17:39:48.024335 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0379041 (* 1 = 0.0379041 loss)
I0822 17:39:48.024346 13823 sgd_solver.cpp:112] Iteration 53100, lr = 0.0001
I0822 17:40:00.009281 13823 solver.cpp:239] Iteration 53200 (8.34379 iter/s, 11.985s/100 iters), loss = 0.0314911
I0822 17:40:00.009337 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0314909 (* 1 = 0.0314909 loss)
I0822 17:40:00.009347 13823 sgd_solver.cpp:112] Iteration 53200, lr = 0.0001
I0822 17:40:11.866163 13823 solver.cpp:239] Iteration 53300 (8.43395 iter/s, 11.8568s/100 iters), loss = 0.026075
I0822 17:40:11.866222 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0260748 (* 1 = 0.0260748 loss)
I0822 17:40:11.866236 13823 sgd_solver.cpp:112] Iteration 53300, lr = 0.0001
I0822 17:40:23.772595 13823 solver.cpp:239] Iteration 53400 (8.39885 iter/s, 11.9064s/100 iters), loss = 0.0268658
I0822 17:40:23.772655 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0268655 (* 1 = 0.0268655 loss)
I0822 17:40:23.772665 13823 sgd_solver.cpp:112] Iteration 53400, lr = 0.0001
I0822 17:40:35.673633 13823 solver.cpp:239] Iteration 53500 (8.40266 iter/s, 11.901s/100 iters), loss = 0.0309318
I0822 17:40:35.673696 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0309316 (* 1 = 0.0309316 loss)
I0822 17:40:35.673708 13823 sgd_solver.cpp:112] Iteration 53500, lr = 0.0001
I0822 17:40:47.499965 13823 solver.cpp:239] Iteration 53600 (8.45574 iter/s, 11.8263s/100 iters), loss = 0.0369805
I0822 17:40:47.500022 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0369802 (* 1 = 0.0369802 loss)
I0822 17:40:47.500032 13823 sgd_solver.cpp:112] Iteration 53600, lr = 0.0001
I0822 17:40:59.366421 13823 solver.cpp:239] Iteration 53700 (8.42715 iter/s, 11.8664s/100 iters), loss = 0.0306192
I0822 17:40:59.366488 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0306189 (* 1 = 0.0306189 loss)
I0822 17:40:59.366503 13823 sgd_solver.cpp:112] Iteration 53700, lr = 0.0001
I0822 17:41:11.285524 13823 solver.cpp:239] Iteration 53800 (8.38993 iter/s, 11.9191s/100 iters), loss = 0.0363619
I0822 17:41:11.285598 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0363616 (* 1 = 0.0363616 loss)
I0822 17:41:11.285617 13823 sgd_solver.cpp:112] Iteration 53800, lr = 0.0001
I0822 17:41:23.017153 13823 solver.cpp:239] Iteration 53900 (8.52401 iter/s, 11.7316s/100 iters), loss = 0.0276936
I0822 17:41:23.017210 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0276933 (* 1 = 0.0276933 loss)
I0822 17:41:23.017220 13823 sgd_solver.cpp:112] Iteration 53900, lr = 0.0001
I0822 17:41:34.857707 13823 solver.cpp:239] Iteration 54000 (8.44558 iter/s, 11.8405s/100 iters), loss = 0.026743
I0822 17:41:34.857765 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0267427 (* 1 = 0.0267427 loss)
I0822 17:41:34.857777 13823 sgd_solver.cpp:112] Iteration 54000, lr = 0.0001
I0822 17:41:46.726634 13823 solver.cpp:239] Iteration 54100 (8.4254 iter/s, 11.8689s/100 iters), loss = 0.0336286
I0822 17:41:46.726697 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0336283 (* 1 = 0.0336283 loss)
I0822 17:41:46.726709 13823 sgd_solver.cpp:112] Iteration 54100, lr = 0.0001
I0822 17:41:58.715647 13823 solver.cpp:239] Iteration 54200 (8.341 iter/s, 11.989s/100 iters), loss = 0.0259906
I0822 17:41:58.715704 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0259903 (* 1 = 0.0259903 loss)
I0822 17:41:58.715715 13823 sgd_solver.cpp:112] Iteration 54200, lr = 0.0001
I0822 17:42:10.618248 13823 solver.cpp:239] Iteration 54300 (8.40156 iter/s, 11.9026s/100 iters), loss = 0.0267923
I0822 17:42:10.618310 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.026792 (* 1 = 0.026792 loss)
I0822 17:42:10.618322 13823 sgd_solver.cpp:112] Iteration 54300, lr = 0.0001
I0822 17:42:22.554024 13823 solver.cpp:239] Iteration 54400 (8.37821 iter/s, 11.9357s/100 iters), loss = 0.0302475
I0822 17:42:22.554087 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0302472 (* 1 = 0.0302472 loss)
I0822 17:42:22.554100 13823 sgd_solver.cpp:112] Iteration 54400, lr = 0.0001
I0822 17:42:34.544275 13823 solver.cpp:239] Iteration 54500 (8.34014 iter/s, 11.9902s/100 iters), loss = 0.0272727
I0822 17:42:34.544332 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0272724 (* 1 = 0.0272724 loss)
I0822 17:42:34.544344 13823 sgd_solver.cpp:112] Iteration 54500, lr = 0.0001
I0822 17:42:46.504935 13823 solver.cpp:239] Iteration 54600 (8.36077 iter/s, 11.9606s/100 iters), loss = 0.0287008
I0822 17:42:46.504987 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0287005 (* 1 = 0.0287005 loss)
I0822 17:42:46.504997 13823 sgd_solver.cpp:112] Iteration 54600, lr = 0.0001
I0822 17:42:58.482842 13823 solver.cpp:239] Iteration 54700 (8.34873 iter/s, 11.9779s/100 iters), loss = 0.0311027
I0822 17:42:58.482900 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0311024 (* 1 = 0.0311024 loss)
I0822 17:42:58.482913 13823 sgd_solver.cpp:112] Iteration 54700, lr = 0.0001
I0822 17:43:10.029323 13823 solver.cpp:239] Iteration 54800 (8.66068 iter/s, 11.5464s/100 iters), loss = 0.0272955
I0822 17:43:10.029376 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0272952 (* 1 = 0.0272952 loss)
I0822 17:43:10.029386 13823 sgd_solver.cpp:112] Iteration 54800, lr = 0.0001
I0822 17:43:19.620760 13823 solver.cpp:239] Iteration 54900 (10.426 iter/s, 9.59139s/100 iters), loss = 0.0301306
I0822 17:43:19.620811 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0301303 (* 1 = 0.0301303 loss)
I0822 17:43:19.620820 13823 sgd_solver.cpp:112] Iteration 54900, lr = 0.0001
I0822 17:43:29.427997 13823 solver.cpp:239] Iteration 55000 (10.1966 iter/s, 9.8072s/100 iters), loss = 0.0249908
I0822 17:43:29.428047 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0249905 (* 1 = 0.0249905 loss)
I0822 17:43:29.428056 13823 sgd_solver.cpp:112] Iteration 55000, lr = 0.0001
I0822 17:43:39.082121 13823 solver.cpp:239] Iteration 55100 (10.3583 iter/s, 9.65408s/100 iters), loss = 0.0267294
I0822 17:43:39.082187 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0267292 (* 1 = 0.0267292 loss)
I0822 17:43:39.082199 13823 sgd_solver.cpp:112] Iteration 55100, lr = 0.0001
I0822 17:43:48.813654 13823 solver.cpp:239] Iteration 55200 (10.2759 iter/s, 9.73148s/100 iters), loss = 0.0297245
I0822 17:43:48.813714 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0297242 (* 1 = 0.0297242 loss)
I0822 17:43:48.813724 13823 sgd_solver.cpp:112] Iteration 55200, lr = 0.0001
I0822 17:43:58.422883 13823 solver.cpp:239] Iteration 55300 (10.4067 iter/s, 9.60918s/100 iters), loss = 0.0269017
I0822 17:43:58.422924 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0269014 (* 1 = 0.0269014 loss)
I0822 17:43:58.422930 13823 sgd_solver.cpp:112] Iteration 55300, lr = 0.0001
I0822 17:44:08.166064 13823 solver.cpp:239] Iteration 55400 (10.2636 iter/s, 9.74315s/100 iters), loss = 0.0275164
I0822 17:44:08.166128 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0275162 (* 1 = 0.0275162 loss)
I0822 17:44:08.166141 13823 sgd_solver.cpp:112] Iteration 55400, lr = 0.0001
I0822 17:44:18.217561 13823 solver.cpp:239] Iteration 55500 (9.94882 iter/s, 10.0514s/100 iters), loss = 0.0301544
I0822 17:44:18.217626 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0301541 (* 1 = 0.0301541 loss)
I0822 17:44:18.217638 13823 sgd_solver.cpp:112] Iteration 55500, lr = 0.0001
I0822 17:44:28.127966 13823 solver.cpp:239] Iteration 55600 (10.0905 iter/s, 9.91035s/100 iters), loss = 0.036484
I0822 17:44:28.128020 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0364838 (* 1 = 0.0364838 loss)
I0822 17:44:28.128028 13823 sgd_solver.cpp:112] Iteration 55600, lr = 0.0001
I0822 17:44:37.610751 13823 solver.cpp:239] Iteration 55700 (10.5455 iter/s, 9.48274s/100 iters), loss = 0.0270969
I0822 17:44:37.610803 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0270966 (* 1 = 0.0270966 loss)
I0822 17:44:37.610812 13823 sgd_solver.cpp:112] Iteration 55700, lr = 0.0001
I0822 17:44:47.281235 13823 solver.cpp:239] Iteration 55800 (10.3408 iter/s, 9.67045s/100 iters), loss = 0.0238401
I0822 17:44:47.281275 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0238398 (* 1 = 0.0238398 loss)
I0822 17:44:47.281282 13823 sgd_solver.cpp:112] Iteration 55800, lr = 0.0001
I0822 17:44:56.810320 13823 solver.cpp:239] Iteration 55900 (10.4942 iter/s, 9.52905s/100 iters), loss = 0.0270563
I0822 17:44:56.810372 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0270561 (* 1 = 0.0270561 loss)
I0822 17:44:56.810381 13823 sgd_solver.cpp:112] Iteration 55900, lr = 0.0001
I0822 17:45:06.791240 13823 solver.cpp:239] Iteration 56000 (10.0192 iter/s, 9.98088s/100 iters), loss = 0.0300174
I0822 17:45:06.791291 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0300172 (* 1 = 0.0300172 loss)
I0822 17:45:06.791301 13823 sgd_solver.cpp:112] Iteration 56000, lr = 0.0001
I0822 17:45:16.686224 13823 solver.cpp:239] Iteration 56100 (10.1062 iter/s, 9.89494s/100 iters), loss = 0.0321066
I0822 17:45:16.686275 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0321063 (* 1 = 0.0321063 loss)
I0822 17:45:16.686283 13823 sgd_solver.cpp:112] Iteration 56100, lr = 0.0001
I0822 17:45:26.027874 13823 solver.cpp:239] Iteration 56200 (10.7048 iter/s, 9.34163s/100 iters), loss = 0.028261
I0822 17:45:26.027923 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0282607 (* 1 = 0.0282607 loss)
I0822 17:45:26.027932 13823 sgd_solver.cpp:112] Iteration 56200, lr = 0.0001
I0822 17:45:35.849334 13823 solver.cpp:239] Iteration 56300 (10.1818 iter/s, 9.82144s/100 iters), loss = 0.0312428
I0822 17:45:35.849406 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0312425 (* 1 = 0.0312425 loss)
I0822 17:45:35.849423 13823 sgd_solver.cpp:112] Iteration 56300, lr = 0.0001
I0822 17:45:45.885138 13823 solver.cpp:239] Iteration 56400 (9.96435 iter/s, 10.0358s/100 iters), loss = 0.0256974
I0822 17:45:45.885195 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0256971 (* 1 = 0.0256971 loss)
I0822 17:45:45.885206 13823 sgd_solver.cpp:112] Iteration 56400, lr = 0.0001
I0822 17:45:55.677278 13823 solver.cpp:239] Iteration 56500 (10.2123 iter/s, 9.79212s/100 iters), loss = 0.0307152
I0822 17:45:55.677343 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0307149 (* 1 = 0.0307149 loss)
I0822 17:45:55.677359 13823 sgd_solver.cpp:112] Iteration 56500, lr = 0.0001
I0822 17:46:05.063881 13823 solver.cpp:239] Iteration 56600 (10.6535 iter/s, 9.38658s/100 iters), loss = 0.0283904
I0822 17:46:05.063925 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0283901 (* 1 = 0.0283901 loss)
I0822 17:46:05.063931 13823 sgd_solver.cpp:112] Iteration 56600, lr = 0.0001
I0822 17:46:14.546236 13823 solver.cpp:239] Iteration 56700 (10.5459 iter/s, 9.48234s/100 iters), loss = 0.0358714
I0822 17:46:14.546277 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0358711 (* 1 = 0.0358711 loss)
I0822 17:46:14.546283 13823 sgd_solver.cpp:112] Iteration 56700, lr = 0.0001
I0822 17:46:24.329162 13823 solver.cpp:239] Iteration 56800 (10.2219 iter/s, 9.78292s/100 iters), loss = 0.0307783
I0822 17:46:24.329216 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.030778 (* 1 = 0.030778 loss)
I0822 17:46:24.329227 13823 sgd_solver.cpp:112] Iteration 56800, lr = 0.0001
I0822 17:46:34.043592 13823 solver.cpp:239] Iteration 56900 (10.294 iter/s, 9.71441s/100 iters), loss = 0.0278972
I0822 17:46:34.043642 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0278969 (* 1 = 0.0278969 loss)
I0822 17:46:34.043651 13823 sgd_solver.cpp:112] Iteration 56900, lr = 0.0001
I0822 17:46:43.519979 13823 solver.cpp:239] Iteration 57000 (10.5526 iter/s, 9.47637s/100 iters), loss = 0.0259455
I0822 17:46:43.520031 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0259452 (* 1 = 0.0259452 loss)
I0822 17:46:43.520040 13823 sgd_solver.cpp:112] Iteration 57000, lr = 0.0001
I0822 17:46:53.141170 13823 solver.cpp:239] Iteration 57100 (10.3937 iter/s, 9.62117s/100 iters), loss = 0.0290183
I0822 17:46:53.141212 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0290179 (* 1 = 0.0290179 loss)
I0822 17:46:53.141219 13823 sgd_solver.cpp:112] Iteration 57100, lr = 0.0001
I0822 17:47:02.832846 13823 solver.cpp:239] Iteration 57200 (10.3181 iter/s, 9.69166s/100 iters), loss = 0.0417829
I0822 17:47:02.832897 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0417825 (* 1 = 0.0417825 loss)
I0822 17:47:02.832906 13823 sgd_solver.cpp:112] Iteration 57200, lr = 0.0001
I0822 17:47:12.582584 13823 solver.cpp:239] Iteration 57300 (10.2567 iter/s, 9.74972s/100 iters), loss = 0.0255167
I0822 17:47:12.582635 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0255163 (* 1 = 0.0255163 loss)
I0822 17:47:12.582644 13823 sgd_solver.cpp:112] Iteration 57300, lr = 0.0001
I0822 17:47:22.093044 13823 solver.cpp:239] Iteration 57400 (10.5148 iter/s, 9.51044s/100 iters), loss = 0.0277313
I0822 17:47:22.093086 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.027731 (* 1 = 0.027731 loss)
I0822 17:47:22.093092 13823 sgd_solver.cpp:112] Iteration 57400, lr = 0.0001
I0822 17:47:31.387871 13823 solver.cpp:239] Iteration 57500 (10.7587 iter/s, 9.29482s/100 iters), loss = 0.0247021
I0822 17:47:31.387924 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0247018 (* 1 = 0.0247018 loss)
I0822 17:47:31.387933 13823 sgd_solver.cpp:112] Iteration 57500, lr = 0.0001
I0822 17:47:41.002810 13823 solver.cpp:239] Iteration 57600 (10.4005 iter/s, 9.61492s/100 iters), loss = 0.0311699
I0822 17:47:41.002852 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0311696 (* 1 = 0.0311696 loss)
I0822 17:47:41.002859 13823 sgd_solver.cpp:112] Iteration 57600, lr = 0.0001
I0822 17:47:50.564009 13823 solver.cpp:239] Iteration 57700 (10.459 iter/s, 9.56119s/100 iters), loss = 0.0326003
I0822 17:47:50.564050 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0326 (* 1 = 0.0326 loss)
I0822 17:47:50.564057 13823 sgd_solver.cpp:112] Iteration 57700, lr = 0.0001
I0822 17:48:00.331429 13823 solver.cpp:239] Iteration 57800 (10.2381 iter/s, 9.76741s/100 iters), loss = 0.0295101
I0822 17:48:00.331486 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0295098 (* 1 = 0.0295098 loss)
I0822 17:48:00.331499 13823 sgd_solver.cpp:112] Iteration 57800, lr = 0.0001
I0822 17:48:10.322290 13823 solver.cpp:239] Iteration 57900 (10.0092 iter/s, 9.99083s/100 iters), loss = 0.0276163
I0822 17:48:10.322350 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.027616 (* 1 = 0.027616 loss)
I0822 17:48:10.322361 13823 sgd_solver.cpp:112] Iteration 57900, lr = 0.0001
I0822 17:48:20.085583 13823 solver.cpp:239] Iteration 58000 (10.2425 iter/s, 9.76326s/100 iters), loss = 0.0315888
I0822 17:48:20.085633 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0315885 (* 1 = 0.0315885 loss)
I0822 17:48:20.085642 13823 sgd_solver.cpp:112] Iteration 58000, lr = 0.0001
I0822 17:48:29.849709 13823 solver.cpp:239] Iteration 58100 (10.2416 iter/s, 9.7641s/100 iters), loss = 0.0678355
I0822 17:48:29.849763 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0678352 (* 1 = 0.0678352 loss)
I0822 17:48:29.849773 13823 sgd_solver.cpp:112] Iteration 58100, lr = 0.0001
I0822 17:48:39.813774 13823 solver.cpp:239] Iteration 58200 (10.0361 iter/s, 9.96404s/100 iters), loss = 0.0265228
I0822 17:48:39.813824 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0265225 (* 1 = 0.0265225 loss)
I0822 17:48:39.813833 13823 sgd_solver.cpp:112] Iteration 58200, lr = 0.0001
I0822 17:48:49.590247 13823 solver.cpp:239] Iteration 58300 (10.2287 iter/s, 9.77645s/100 iters), loss = 0.0376866
I0822 17:48:49.590296 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0376863 (* 1 = 0.0376863 loss)
I0822 17:48:49.590303 13823 sgd_solver.cpp:112] Iteration 58300, lr = 0.0001
I0822 17:48:59.268223 13823 solver.cpp:239] Iteration 58400 (10.3328 iter/s, 9.67795s/100 iters), loss = 0.0262691
I0822 17:48:59.268271 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0262688 (* 1 = 0.0262688 loss)
I0822 17:48:59.268280 13823 sgd_solver.cpp:112] Iteration 58400, lr = 0.0001
I0822 17:49:08.901111 13823 solver.cpp:239] Iteration 58500 (10.3811 iter/s, 9.63287s/100 iters), loss = 0.0382135
I0822 17:49:08.901165 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0382131 (* 1 = 0.0382131 loss)
I0822 17:49:08.901172 13823 sgd_solver.cpp:112] Iteration 58500, lr = 0.0001
I0822 17:49:18.477715 13823 solver.cpp:239] Iteration 58600 (10.4421 iter/s, 9.57657s/100 iters), loss = 0.0289065
I0822 17:49:18.477764 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0289062 (* 1 = 0.0289062 loss)
I0822 17:49:18.477773 13823 sgd_solver.cpp:112] Iteration 58600, lr = 0.0001
I0822 17:49:27.794968 13823 solver.cpp:239] Iteration 58700 (10.7328 iter/s, 9.31723s/100 iters), loss = 0.0297575
I0822 17:49:27.795017 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0297572 (* 1 = 0.0297572 loss)
I0822 17:49:27.795027 13823 sgd_solver.cpp:112] Iteration 58700, lr = 0.0001
I0822 17:49:37.719785 13823 solver.cpp:239] Iteration 58800 (10.0758 iter/s, 9.9248s/100 iters), loss = 0.0282256
I0822 17:49:37.719835 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0282253 (* 1 = 0.0282253 loss)
I0822 17:49:37.719843 13823 sgd_solver.cpp:112] Iteration 58800, lr = 0.0001
I0822 17:49:47.056726 13823 solver.cpp:239] Iteration 58900 (10.7102 iter/s, 9.33691s/100 iters), loss = 0.0311613
I0822 17:49:47.056777 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.031161 (* 1 = 0.031161 loss)
I0822 17:49:47.056787 13823 sgd_solver.cpp:112] Iteration 58900, lr = 0.0001
I0822 17:49:56.707130 13823 solver.cpp:239] Iteration 59000 (10.3623 iter/s, 9.65038s/100 iters), loss = 0.0266332
I0822 17:49:56.707171 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0266329 (* 1 = 0.0266329 loss)
I0822 17:49:56.707178 13823 sgd_solver.cpp:112] Iteration 59000, lr = 0.0001
I0822 17:50:06.215209 13823 solver.cpp:239] Iteration 59100 (10.5174 iter/s, 9.50806s/100 iters), loss = 0.0297752
I0822 17:50:06.215261 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0297749 (* 1 = 0.0297749 loss)
I0822 17:50:06.215271 13823 sgd_solver.cpp:112] Iteration 59100, lr = 0.0001
I0822 17:50:15.843353 13823 solver.cpp:239] Iteration 59200 (10.3862 iter/s, 9.62812s/100 iters), loss = 0.0297771
I0822 17:50:15.843394 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0297768 (* 1 = 0.0297768 loss)
I0822 17:50:15.843401 13823 sgd_solver.cpp:112] Iteration 59200, lr = 0.0001
I0822 17:50:25.579862 13823 solver.cpp:239] Iteration 59300 (10.2706 iter/s, 9.73649s/100 iters), loss = 0.0255506
I0822 17:50:25.579916 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0255503 (* 1 = 0.0255503 loss)
I0822 17:50:25.579922 13823 sgd_solver.cpp:112] Iteration 59300, lr = 0.0001
I0822 17:50:35.093665 13823 solver.cpp:239] Iteration 59400 (10.5111 iter/s, 9.51377s/100 iters), loss = 0.0244963
I0822 17:50:35.093715 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.024496 (* 1 = 0.024496 loss)
I0822 17:50:35.093724 13823 sgd_solver.cpp:112] Iteration 59400, lr = 0.0001
I0822 17:50:44.966395 13823 solver.cpp:239] Iteration 59500 (10.1289 iter/s, 9.8727s/100 iters), loss = 0.0256744
I0822 17:50:44.966446 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0256741 (* 1 = 0.0256741 loss)
I0822 17:50:44.966455 13823 sgd_solver.cpp:112] Iteration 59500, lr = 0.0001
I0822 17:50:54.942342 13823 solver.cpp:239] Iteration 59600 (10.0241 iter/s, 9.97592s/100 iters), loss = 0.0275984
I0822 17:50:54.942392 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0275981 (* 1 = 0.0275981 loss)
I0822 17:50:54.942401 13823 sgd_solver.cpp:112] Iteration 59600, lr = 0.0001
I0822 17:51:04.791220 13823 solver.cpp:239] Iteration 59700 (10.1535 iter/s, 9.84885s/100 iters), loss = 0.0279864
I0822 17:51:04.791277 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0279861 (* 1 = 0.0279861 loss)
I0822 17:51:04.791287 13823 sgd_solver.cpp:112] Iteration 59700, lr = 0.0001
I0822 17:51:14.761773 13823 solver.cpp:239] Iteration 59800 (10.0296 iter/s, 9.97052s/100 iters), loss = 0.027662
I0822 17:51:14.761822 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0276617 (* 1 = 0.0276617 loss)
I0822 17:51:14.761832 13823 sgd_solver.cpp:112] Iteration 59800, lr = 0.0001
I0822 17:51:24.754537 13823 solver.cpp:239] Iteration 59900 (10.0073 iter/s, 9.99273s/100 iters), loss = 0.0262189
I0822 17:51:24.754595 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0262186 (* 1 = 0.0262186 loss)
I0822 17:51:24.754604 13823 sgd_solver.cpp:112] Iteration 59900, lr = 0.0001
I0822 17:51:34.726963 13823 solver.cpp:464] Snapshotting to binary proto file ./model_112/cascade_mobilenet_112_iter_60000.caffemodel
I0822 17:51:34.818006 13823 sgd_solver.cpp:284] Snapshotting solver state to binary proto file ./model_112/cascade_mobilenet_112_iter_60000.solverstate
I0822 17:51:34.861203 13823 solver.cpp:347] Iteration 60000, Testing net (#0)
I0822 17:52:42.753041 13823 solver.cpp:414]     Test net output #0: landmark_loss = 0.0243504 (* 1 = 0.0243504 loss)
I0822 17:52:42.866961 13823 solver.cpp:239] Iteration 60000 (1.2802 iter/s, 78.1126s/100 iters), loss = 0.0265378
I0822 17:52:42.866995 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0265375 (* 1 = 0.0265375 loss)
I0822 17:52:42.867005 13823 sgd_solver.cpp:112] Iteration 60000, lr = 0.0001
I0822 17:52:53.133327 13823 solver.cpp:239] Iteration 60100 (9.74056 iter/s, 10.2664s/100 iters), loss = 0.0253617
I0822 17:52:53.133388 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0253614 (* 1 = 0.0253614 loss)
I0822 17:52:53.133400 13823 sgd_solver.cpp:112] Iteration 60100, lr = 0.0001
I0822 17:53:03.381074 13823 solver.cpp:239] Iteration 60200 (9.75828 iter/s, 10.2477s/100 iters), loss = 0.0392061
I0822 17:53:03.381125 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0392058 (* 1 = 0.0392058 loss)
I0822 17:53:03.381135 13823 sgd_solver.cpp:112] Iteration 60200, lr = 0.0001
I0822 17:53:13.664057 13823 solver.cpp:239] Iteration 60300 (9.72483 iter/s, 10.283s/100 iters), loss = 0.0261109
I0822 17:53:13.664110 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0261106 (* 1 = 0.0261106 loss)
I0822 17:53:13.664120 13823 sgd_solver.cpp:112] Iteration 60300, lr = 0.0001
I0822 17:53:23.721772 13823 solver.cpp:239] Iteration 60400 (9.94264 iter/s, 10.0577s/100 iters), loss = 0.0311674
I0822 17:53:23.721822 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0311671 (* 1 = 0.0311671 loss)
I0822 17:53:23.721830 13823 sgd_solver.cpp:112] Iteration 60400, lr = 0.0001
I0822 17:53:33.769045 13823 solver.cpp:239] Iteration 60500 (9.95298 iter/s, 10.0472s/100 iters), loss = 0.0437768
I0822 17:53:33.769099 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0437765 (* 1 = 0.0437765 loss)
I0822 17:53:33.769109 13823 sgd_solver.cpp:112] Iteration 60500, lr = 0.0001
I0822 17:53:43.804229 13823 solver.cpp:239] Iteration 60600 (9.96497 iter/s, 10.0352s/100 iters), loss = 0.0381572
I0822 17:53:43.804280 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0381569 (* 1 = 0.0381569 loss)
I0822 17:53:43.804289 13823 sgd_solver.cpp:112] Iteration 60600, lr = 0.0001
I0822 17:53:53.869828 13823 solver.cpp:239] Iteration 60700 (9.93485 iter/s, 10.0656s/100 iters), loss = 0.0280536
I0822 17:53:53.869880 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0280533 (* 1 = 0.0280533 loss)
I0822 17:53:53.869889 13823 sgd_solver.cpp:112] Iteration 60700, lr = 0.0001
I0822 17:54:03.834993 13823 solver.cpp:239] Iteration 60800 (10.035 iter/s, 9.96514s/100 iters), loss = 0.0264517
I0822 17:54:03.835043 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0264514 (* 1 = 0.0264514 loss)
I0822 17:54:03.835052 13823 sgd_solver.cpp:112] Iteration 60800, lr = 0.0001
I0822 17:54:14.340795 13823 solver.cpp:239] Iteration 60900 (9.51857 iter/s, 10.5058s/100 iters), loss = 0.0311835
I0822 17:54:14.340844 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0311832 (* 1 = 0.0311832 loss)
I0822 17:54:14.340853 13823 sgd_solver.cpp:112] Iteration 60900, lr = 0.0001
I0822 17:54:24.561530 13823 solver.cpp:239] Iteration 61000 (9.78406 iter/s, 10.2207s/100 iters), loss = 0.029903
I0822 17:54:24.561589 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0299027 (* 1 = 0.0299027 loss)
I0822 17:54:24.561600 13823 sgd_solver.cpp:112] Iteration 61000, lr = 0.0001
I0822 17:54:34.825474 13823 solver.cpp:239] Iteration 61100 (9.74288 iter/s, 10.2639s/100 iters), loss = 0.0265973
I0822 17:54:34.825526 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.026597 (* 1 = 0.026597 loss)
I0822 17:54:34.825536 13823 sgd_solver.cpp:112] Iteration 61100, lr = 0.0001
I0822 17:54:45.418134 13823 solver.cpp:239] Iteration 61200 (9.44053 iter/s, 10.5926s/100 iters), loss = 0.0308004
I0822 17:54:45.418190 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0308001 (* 1 = 0.0308001 loss)
I0822 17:54:45.418200 13823 sgd_solver.cpp:112] Iteration 61200, lr = 0.0001
I0822 17:54:55.673492 13823 solver.cpp:239] Iteration 61300 (9.75103 iter/s, 10.2553s/100 iters), loss = 0.0281257
I0822 17:54:55.673542 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0281254 (* 1 = 0.0281254 loss)
I0822 17:54:55.673552 13823 sgd_solver.cpp:112] Iteration 61300, lr = 0.0001
I0822 17:55:06.039695 13823 solver.cpp:239] Iteration 61400 (9.64676 iter/s, 10.3662s/100 iters), loss = 0.0346835
I0822 17:55:06.039746 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0346832 (* 1 = 0.0346832 loss)
I0822 17:55:06.039755 13823 sgd_solver.cpp:112] Iteration 61400, lr = 0.0001
I0822 17:55:16.367982 13823 solver.cpp:239] Iteration 61500 (9.68218 iter/s, 10.3283s/100 iters), loss = 0.0251279
I0822 17:55:16.368039 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0251276 (* 1 = 0.0251276 loss)
I0822 17:55:16.368050 13823 sgd_solver.cpp:112] Iteration 61500, lr = 0.0001
I0822 17:55:27.021337 13823 solver.cpp:239] Iteration 61600 (9.38675 iter/s, 10.6533s/100 iters), loss = 0.0332447
I0822 17:55:27.021410 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0332444 (* 1 = 0.0332444 loss)
I0822 17:55:27.021421 13823 sgd_solver.cpp:112] Iteration 61600, lr = 0.0001
I0822 17:55:37.268751 13823 solver.cpp:239] Iteration 61700 (9.75861 iter/s, 10.2474s/100 iters), loss = 0.0308063
I0822 17:55:37.268805 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.030806 (* 1 = 0.030806 loss)
I0822 17:55:37.268815 13823 sgd_solver.cpp:112] Iteration 61700, lr = 0.0001
I0822 17:55:47.744026 13823 solver.cpp:239] Iteration 61800 (9.54632 iter/s, 10.4752s/100 iters), loss = 0.0338195
I0822 17:55:47.744076 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0338192 (* 1 = 0.0338192 loss)
I0822 17:55:47.744086 13823 sgd_solver.cpp:112] Iteration 61800, lr = 0.0001
I0822 17:55:58.232934 13823 solver.cpp:239] Iteration 61900 (9.53391 iter/s, 10.4889s/100 iters), loss = 0.0280454
I0822 17:55:58.232985 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0280451 (* 1 = 0.0280451 loss)
I0822 17:55:58.232993 13823 sgd_solver.cpp:112] Iteration 61900, lr = 0.0001
I0822 17:56:08.702061 13823 solver.cpp:239] Iteration 62000 (9.55192 iter/s, 10.4691s/100 iters), loss = 0.0353482
I0822 17:56:08.702111 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0353479 (* 1 = 0.0353479 loss)
I0822 17:56:08.702121 13823 sgd_solver.cpp:112] Iteration 62000, lr = 0.0001
I0822 17:56:19.499661 13823 solver.cpp:239] Iteration 62100 (9.26134 iter/s, 10.7976s/100 iters), loss = 0.0263306
I0822 17:56:19.499712 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0263303 (* 1 = 0.0263303 loss)
I0822 17:56:19.499722 13823 sgd_solver.cpp:112] Iteration 62100, lr = 0.0001
I0822 17:56:30.005975 13823 solver.cpp:239] Iteration 62200 (9.51812 iter/s, 10.5063s/100 iters), loss = 0.0296029
I0822 17:56:30.006024 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0296026 (* 1 = 0.0296026 loss)
I0822 17:56:30.006033 13823 sgd_solver.cpp:112] Iteration 62200, lr = 0.0001
I0822 17:56:40.337327 13823 solver.cpp:239] Iteration 62300 (9.6793 iter/s, 10.3313s/100 iters), loss = 0.0289295
I0822 17:56:40.337378 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0289292 (* 1 = 0.0289292 loss)
I0822 17:56:40.337386 13823 sgd_solver.cpp:112] Iteration 62300, lr = 0.0001
I0822 17:56:50.855595 13823 solver.cpp:239] Iteration 62400 (9.5073 iter/s, 10.5182s/100 iters), loss = 0.0272848
I0822 17:56:50.855644 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0272845 (* 1 = 0.0272845 loss)
I0822 17:56:50.855654 13823 sgd_solver.cpp:112] Iteration 62400, lr = 0.0001
I0822 17:57:01.604575 13823 solver.cpp:239] Iteration 62500 (9.30324 iter/s, 10.7489s/100 iters), loss = 0.0324746
I0822 17:57:01.604626 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0324743 (* 1 = 0.0324743 loss)
I0822 17:57:01.604635 13823 sgd_solver.cpp:112] Iteration 62500, lr = 0.0001
I0822 17:57:11.870466 13823 solver.cpp:239] Iteration 62600 (9.74103 iter/s, 10.2659s/100 iters), loss = 0.024778
I0822 17:57:11.870518 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0247777 (* 1 = 0.0247777 loss)
I0822 17:57:11.870527 13823 sgd_solver.cpp:112] Iteration 62600, lr = 0.0001
I0822 17:57:22.395385 13823 solver.cpp:239] Iteration 62700 (9.50129 iter/s, 10.5249s/100 iters), loss = 0.0338105
I0822 17:57:22.395434 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0338102 (* 1 = 0.0338102 loss)
I0822 17:57:22.395443 13823 sgd_solver.cpp:112] Iteration 62700, lr = 0.0001
I0822 17:57:33.038574 13823 solver.cpp:239] Iteration 62800 (9.39571 iter/s, 10.6432s/100 iters), loss = 0.0253914
I0822 17:57:33.038624 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0253911 (* 1 = 0.0253911 loss)
I0822 17:57:33.038632 13823 sgd_solver.cpp:112] Iteration 62800, lr = 0.0001
I0822 17:57:43.766260 13823 solver.cpp:239] Iteration 62900 (9.32171 iter/s, 10.7276s/100 iters), loss = 0.032329
I0822 17:57:43.766328 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0323287 (* 1 = 0.0323287 loss)
I0822 17:57:43.766341 13823 sgd_solver.cpp:112] Iteration 62900, lr = 0.0001
I0822 17:57:54.411564 13823 solver.cpp:239] Iteration 63000 (9.39386 iter/s, 10.6453s/100 iters), loss = 0.0281566
I0822 17:57:54.411624 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0281563 (* 1 = 0.0281563 loss)
I0822 17:57:54.411636 13823 sgd_solver.cpp:112] Iteration 63000, lr = 0.0001
I0822 17:58:04.900852 13823 solver.cpp:239] Iteration 63100 (9.53357 iter/s, 10.4892s/100 iters), loss = 0.0327126
I0822 17:58:04.900904 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0327123 (* 1 = 0.0327123 loss)
I0822 17:58:04.900913 13823 sgd_solver.cpp:112] Iteration 63100, lr = 0.0001
I0822 17:58:15.211583 13823 solver.cpp:239] Iteration 63200 (9.69867 iter/s, 10.3107s/100 iters), loss = 0.028633
I0822 17:58:15.211635 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0286327 (* 1 = 0.0286327 loss)
I0822 17:58:15.211645 13823 sgd_solver.cpp:112] Iteration 63200, lr = 0.0001
I0822 17:58:25.809020 13823 solver.cpp:239] Iteration 63300 (9.43628 iter/s, 10.5974s/100 iters), loss = 0.0348695
I0822 17:58:25.809078 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0348692 (* 1 = 0.0348692 loss)
I0822 17:58:25.809089 13823 sgd_solver.cpp:112] Iteration 63300, lr = 0.0001
I0822 17:58:36.300868 13823 solver.cpp:239] Iteration 63400 (9.53125 iter/s, 10.4918s/100 iters), loss = 0.0277816
I0822 17:58:36.300928 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0277813 (* 1 = 0.0277813 loss)
I0822 17:58:36.300940 13823 sgd_solver.cpp:112] Iteration 63400, lr = 0.0001
I0822 17:58:47.400003 13823 solver.cpp:239] Iteration 63500 (9.00975 iter/s, 11.0991s/100 iters), loss = 0.0281653
I0822 17:58:47.400065 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.028165 (* 1 = 0.028165 loss)
I0822 17:58:47.400077 13823 sgd_solver.cpp:112] Iteration 63500, lr = 0.0001
I0822 17:58:58.077116 13823 solver.cpp:239] Iteration 63600 (9.36587 iter/s, 10.6771s/100 iters), loss = 0.0279014
I0822 17:58:58.077175 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0279011 (* 1 = 0.0279011 loss)
I0822 17:58:58.077188 13823 sgd_solver.cpp:112] Iteration 63600, lr = 0.0001
I0822 17:59:09.139214 13823 solver.cpp:239] Iteration 63700 (9.03991 iter/s, 11.0621s/100 iters), loss = 0.0371856
I0822 17:59:09.139266 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0371853 (* 1 = 0.0371853 loss)
I0822 17:59:09.139276 13823 sgd_solver.cpp:112] Iteration 63700, lr = 0.0001
I0822 17:59:20.153501 13823 solver.cpp:239] Iteration 63800 (9.07915 iter/s, 11.0143s/100 iters), loss = 0.0272759
I0822 17:59:20.153558 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0272755 (* 1 = 0.0272755 loss)
I0822 17:59:20.153568 13823 sgd_solver.cpp:112] Iteration 63800, lr = 0.0001
I0822 17:59:30.856690 13823 solver.cpp:239] Iteration 63900 (9.34304 iter/s, 10.7032s/100 iters), loss = 0.0249692
I0822 17:59:30.856740 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0249689 (* 1 = 0.0249689 loss)
I0822 17:59:30.856748 13823 sgd_solver.cpp:112] Iteration 63900, lr = 0.0001
I0822 17:59:41.476742 13823 solver.cpp:239] Iteration 64000 (9.41618 iter/s, 10.62s/100 iters), loss = 0.0284208
I0822 17:59:41.476800 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0284205 (* 1 = 0.0284205 loss)
I0822 17:59:41.476811 13823 sgd_solver.cpp:112] Iteration 64000, lr = 0.0001
I0822 17:59:52.442366 13823 solver.cpp:239] Iteration 64100 (9.11944 iter/s, 10.9656s/100 iters), loss = 0.0332348
I0822 17:59:52.442417 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0332344 (* 1 = 0.0332344 loss)
I0822 17:59:52.442426 13823 sgd_solver.cpp:112] Iteration 64100, lr = 0.0001
I0822 18:00:02.949383 13823 solver.cpp:239] Iteration 64200 (9.51748 iter/s, 10.507s/100 iters), loss = 0.0280458
I0822 18:00:02.949443 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0280455 (* 1 = 0.0280455 loss)
I0822 18:00:02.949455 13823 sgd_solver.cpp:112] Iteration 64200, lr = 0.0001
I0822 18:00:13.883785 13823 solver.cpp:239] Iteration 64300 (9.14548 iter/s, 10.9344s/100 iters), loss = 0.0307532
I0822 18:00:13.883839 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0307529 (* 1 = 0.0307529 loss)
I0822 18:00:13.883849 13823 sgd_solver.cpp:112] Iteration 64300, lr = 0.0001
I0822 18:00:24.835201 13823 solver.cpp:239] Iteration 64400 (9.13127 iter/s, 10.9514s/100 iters), loss = 0.0278488
I0822 18:00:24.835258 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0278485 (* 1 = 0.0278485 loss)
I0822 18:00:24.835270 13823 sgd_solver.cpp:112] Iteration 64400, lr = 0.0001
I0822 18:00:35.609714 13823 solver.cpp:239] Iteration 64500 (9.2812 iter/s, 10.7745s/100 iters), loss = 0.0331534
I0822 18:00:35.609786 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.033153 (* 1 = 0.033153 loss)
I0822 18:00:35.609802 13823 sgd_solver.cpp:112] Iteration 64500, lr = 0.0001
I0822 18:00:46.713883 13823 solver.cpp:239] Iteration 64600 (9.00567 iter/s, 11.1041s/100 iters), loss = 0.0286129
I0822 18:00:46.713948 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0286126 (* 1 = 0.0286126 loss)
I0822 18:00:46.713963 13823 sgd_solver.cpp:112] Iteration 64600, lr = 0.0001
I0822 18:00:57.578678 13823 solver.cpp:239] Iteration 64700 (9.20408 iter/s, 10.8647s/100 iters), loss = 0.0258214
I0822 18:00:57.578740 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.025821 (* 1 = 0.025821 loss)
I0822 18:00:57.578754 13823 sgd_solver.cpp:112] Iteration 64700, lr = 0.0001
I0822 18:01:08.734541 13823 solver.cpp:239] Iteration 64800 (8.96393 iter/s, 11.1558s/100 iters), loss = 0.0246944
I0822 18:01:08.734597 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0246941 (* 1 = 0.0246941 loss)
I0822 18:01:08.734611 13823 sgd_solver.cpp:112] Iteration 64800, lr = 0.0001
I0822 18:01:19.668126 13823 solver.cpp:239] Iteration 64900 (9.14616 iter/s, 10.9335s/100 iters), loss = 0.0315845
I0822 18:01:19.668202 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0315842 (* 1 = 0.0315842 loss)
I0822 18:01:19.668220 13823 sgd_solver.cpp:112] Iteration 64900, lr = 0.0001
I0822 18:01:30.426074 13823 solver.cpp:239] Iteration 65000 (9.2955 iter/s, 10.7579s/100 iters), loss = 0.0273576
I0822 18:01:30.426126 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0273572 (* 1 = 0.0273572 loss)
I0822 18:01:30.426136 13823 sgd_solver.cpp:112] Iteration 65000, lr = 0.0001
I0822 18:01:41.304432 13823 solver.cpp:239] Iteration 65100 (9.19259 iter/s, 10.8783s/100 iters), loss = 0.0255951
I0822 18:01:41.304484 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0255948 (* 1 = 0.0255948 loss)
I0822 18:01:41.304493 13823 sgd_solver.cpp:112] Iteration 65100, lr = 0.0001
I0822 18:01:51.749939 13823 solver.cpp:239] Iteration 65200 (9.57353 iter/s, 10.4455s/100 iters), loss = 0.0273867
I0822 18:01:51.749991 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0273864 (* 1 = 0.0273864 loss)
I0822 18:01:51.750000 13823 sgd_solver.cpp:112] Iteration 65200, lr = 0.0001
I0822 18:02:02.386734 13823 solver.cpp:239] Iteration 65300 (9.40136 iter/s, 10.6368s/100 iters), loss = 0.0271826
I0822 18:02:02.386793 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0271823 (* 1 = 0.0271823 loss)
I0822 18:02:02.386806 13823 sgd_solver.cpp:112] Iteration 65300, lr = 0.0001
I0822 18:02:13.359575 13823 solver.cpp:239] Iteration 65400 (9.11344 iter/s, 10.9728s/100 iters), loss = 0.0261585
I0822 18:02:13.359625 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0261582 (* 1 = 0.0261582 loss)
I0822 18:02:13.359634 13823 sgd_solver.cpp:112] Iteration 65400, lr = 0.0001
I0822 18:02:24.270117 13823 solver.cpp:239] Iteration 65500 (9.16548 iter/s, 10.9105s/100 iters), loss = 0.0323419
I0822 18:02:24.270175 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0323416 (* 1 = 0.0323416 loss)
I0822 18:02:24.270186 13823 sgd_solver.cpp:112] Iteration 65500, lr = 0.0001
I0822 18:02:34.928716 13823 solver.cpp:239] Iteration 65600 (9.38213 iter/s, 10.6586s/100 iters), loss = 0.0276034
I0822 18:02:34.928768 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0276031 (* 1 = 0.0276031 loss)
I0822 18:02:34.928777 13823 sgd_solver.cpp:112] Iteration 65600, lr = 0.0001
I0822 18:02:45.481829 13823 solver.cpp:239] Iteration 65700 (9.47591 iter/s, 10.5531s/100 iters), loss = 0.0296185
I0822 18:02:45.481884 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0296182 (* 1 = 0.0296182 loss)
I0822 18:02:45.481894 13823 sgd_solver.cpp:112] Iteration 65700, lr = 0.0001
I0822 18:02:56.390333 13823 solver.cpp:239] Iteration 65800 (9.16719 iter/s, 10.9085s/100 iters), loss = 0.0291876
I0822 18:02:56.390383 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0291874 (* 1 = 0.0291874 loss)
I0822 18:02:56.390393 13823 sgd_solver.cpp:112] Iteration 65800, lr = 0.0001
I0822 18:03:06.877377 13823 solver.cpp:239] Iteration 65900 (9.5356 iter/s, 10.487s/100 iters), loss = 0.0274212
I0822 18:03:06.877421 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0274209 (* 1 = 0.0274209 loss)
I0822 18:03:06.877429 13823 sgd_solver.cpp:112] Iteration 65900, lr = 0.0001
I0822 18:03:17.944720 13823 solver.cpp:239] Iteration 66000 (9.03562 iter/s, 11.0673s/100 iters), loss = 0.0291666
I0822 18:03:17.944777 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0291663 (* 1 = 0.0291663 loss)
I0822 18:03:17.944790 13823 sgd_solver.cpp:112] Iteration 66000, lr = 0.0001
I0822 18:03:28.864950 13823 solver.cpp:239] Iteration 66100 (9.15735 iter/s, 10.9202s/100 iters), loss = 0.0300481
I0822 18:03:28.865001 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0300478 (* 1 = 0.0300478 loss)
I0822 18:03:28.865010 13823 sgd_solver.cpp:112] Iteration 66100, lr = 0.0001
I0822 18:03:39.876165 13823 solver.cpp:239] Iteration 66200 (9.08168 iter/s, 11.0112s/100 iters), loss = 0.0320018
I0822 18:03:39.876222 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0320015 (* 1 = 0.0320015 loss)
I0822 18:03:39.876233 13823 sgd_solver.cpp:112] Iteration 66200, lr = 0.0001
I0822 18:03:51.072304 13823 solver.cpp:239] Iteration 66300 (8.93169 iter/s, 11.1961s/100 iters), loss = 0.0274039
I0822 18:03:51.072366 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0274037 (* 1 = 0.0274037 loss)
I0822 18:03:51.072378 13823 sgd_solver.cpp:112] Iteration 66300, lr = 0.0001
I0822 18:04:02.073449 13823 solver.cpp:239] Iteration 66400 (9.09 iter/s, 11.0011s/100 iters), loss = 0.0402008
I0822 18:04:02.073500 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0402005 (* 1 = 0.0402005 loss)
I0822 18:04:02.073510 13823 sgd_solver.cpp:112] Iteration 66400, lr = 0.0001
I0822 18:04:13.018106 13823 solver.cpp:239] Iteration 66500 (9.13691 iter/s, 10.9446s/100 iters), loss = 0.0301134
I0822 18:04:13.018157 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0301132 (* 1 = 0.0301132 loss)
I0822 18:04:13.018167 13823 sgd_solver.cpp:112] Iteration 66500, lr = 0.0001
I0822 18:04:23.828402 13823 solver.cpp:239] Iteration 66600 (9.25047 iter/s, 10.8103s/100 iters), loss = 0.0295422
I0822 18:04:23.828454 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.029542 (* 1 = 0.029542 loss)
I0822 18:04:23.828464 13823 sgd_solver.cpp:112] Iteration 66600, lr = 0.0001
I0822 18:04:34.877043 13823 solver.cpp:239] Iteration 66700 (9.05092 iter/s, 11.0486s/100 iters), loss = 0.0329836
I0822 18:04:34.877099 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0329834 (* 1 = 0.0329834 loss)
I0822 18:04:34.877108 13823 sgd_solver.cpp:112] Iteration 66700, lr = 0.0001
I0822 18:04:45.917888 13823 solver.cpp:239] Iteration 66800 (9.05731 iter/s, 11.0408s/100 iters), loss = 0.0243463
I0822 18:04:45.917938 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0243461 (* 1 = 0.0243461 loss)
I0822 18:04:45.917948 13823 sgd_solver.cpp:112] Iteration 66800, lr = 0.0001
I0822 18:04:57.128445 13823 solver.cpp:239] Iteration 66900 (8.92019 iter/s, 11.2105s/100 iters), loss = 0.0424866
I0822 18:04:57.128509 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0424864 (* 1 = 0.0424864 loss)
I0822 18:04:57.128518 13823 sgd_solver.cpp:112] Iteration 66900, lr = 0.0001
I0822 18:05:08.081018 13823 solver.cpp:239] Iteration 67000 (9.13032 iter/s, 10.9525s/100 iters), loss = 0.043997
I0822 18:05:08.081084 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0439967 (* 1 = 0.0439967 loss)
I0822 18:05:08.081095 13823 sgd_solver.cpp:112] Iteration 67000, lr = 0.0001
I0822 18:05:19.431339 13823 solver.cpp:239] Iteration 67100 (8.81036 iter/s, 11.3503s/100 iters), loss = 0.0301777
I0822 18:05:19.431398 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0301775 (* 1 = 0.0301775 loss)
I0822 18:05:19.431412 13823 sgd_solver.cpp:112] Iteration 67100, lr = 0.0001
I0822 18:05:30.534094 13823 solver.cpp:239] Iteration 67200 (9.00681 iter/s, 11.1027s/100 iters), loss = 0.0286985
I0822 18:05:30.534147 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0286983 (* 1 = 0.0286983 loss)
I0822 18:05:30.534155 13823 sgd_solver.cpp:112] Iteration 67200, lr = 0.0001
I0822 18:05:41.924103 13823 solver.cpp:239] Iteration 67300 (8.77965 iter/s, 11.39s/100 iters), loss = 0.0296466
I0822 18:05:41.924154 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0296464 (* 1 = 0.0296464 loss)
I0822 18:05:41.924165 13823 sgd_solver.cpp:112] Iteration 67300, lr = 0.0001
I0822 18:05:53.209066 13823 solver.cpp:239] Iteration 67400 (8.86138 iter/s, 11.2849s/100 iters), loss = 0.0346012
I0822 18:05:53.209125 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.034601 (* 1 = 0.034601 loss)
I0822 18:05:53.209136 13823 sgd_solver.cpp:112] Iteration 67400, lr = 0.0001
I0822 18:06:04.580657 13823 solver.cpp:239] Iteration 67500 (8.79388 iter/s, 11.3715s/100 iters), loss = 0.0330112
I0822 18:06:04.580719 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.033011 (* 1 = 0.033011 loss)
I0822 18:06:04.580734 13823 sgd_solver.cpp:112] Iteration 67500, lr = 0.0001
I0822 18:06:15.790513 13823 solver.cpp:239] Iteration 67600 (8.92076 iter/s, 11.2098s/100 iters), loss = 0.0308997
I0822 18:06:15.790572 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0308995 (* 1 = 0.0308995 loss)
I0822 18:06:15.790583 13823 sgd_solver.cpp:112] Iteration 67600, lr = 0.0001
I0822 18:06:26.903329 13823 solver.cpp:239] Iteration 67700 (8.99866 iter/s, 11.1128s/100 iters), loss = 0.0295289
I0822 18:06:26.903386 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0295287 (* 1 = 0.0295287 loss)
I0822 18:06:26.903396 13823 sgd_solver.cpp:112] Iteration 67700, lr = 0.0001
I0822 18:06:37.928071 13823 solver.cpp:239] Iteration 67800 (9.07054 iter/s, 11.0247s/100 iters), loss = 0.0267067
I0822 18:06:37.928122 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0267065 (* 1 = 0.0267065 loss)
I0822 18:06:37.928138 13823 sgd_solver.cpp:112] Iteration 67800, lr = 0.0001
I0822 18:06:48.500407 13823 solver.cpp:239] Iteration 67900 (9.45868 iter/s, 10.5723s/100 iters), loss = 0.0301208
I0822 18:06:48.500449 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0301206 (* 1 = 0.0301206 loss)
I0822 18:06:48.500456 13823 sgd_solver.cpp:112] Iteration 67900, lr = 0.0001
I0822 18:06:59.466327 13823 solver.cpp:239] Iteration 68000 (9.11919 iter/s, 10.9659s/100 iters), loss = 0.0279298
I0822 18:06:59.466383 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0279296 (* 1 = 0.0279296 loss)
I0822 18:06:59.466395 13823 sgd_solver.cpp:112] Iteration 68000, lr = 0.0001
I0822 18:07:10.561220 13823 solver.cpp:239] Iteration 68100 (9.01319 iter/s, 11.0949s/100 iters), loss = 0.0298294
I0822 18:07:10.561272 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0298292 (* 1 = 0.0298292 loss)
I0822 18:07:10.561281 13823 sgd_solver.cpp:112] Iteration 68100, lr = 0.0001
I0822 18:07:21.754663 13823 solver.cpp:239] Iteration 68200 (8.93383 iter/s, 11.1934s/100 iters), loss = 0.0293804
I0822 18:07:21.754716 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0293802 (* 1 = 0.0293802 loss)
I0822 18:07:21.754725 13823 sgd_solver.cpp:112] Iteration 68200, lr = 0.0001
I0822 18:07:32.798492 13823 solver.cpp:239] Iteration 68300 (9.05486 iter/s, 11.0438s/100 iters), loss = 0.0250909
I0822 18:07:32.798552 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0250907 (* 1 = 0.0250907 loss)
I0822 18:07:32.798566 13823 sgd_solver.cpp:112] Iteration 68300, lr = 0.0001
I0822 18:07:43.991875 13823 solver.cpp:239] Iteration 68400 (8.93389 iter/s, 11.1933s/100 iters), loss = 0.0261358
I0822 18:07:43.991942 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0261355 (* 1 = 0.0261355 loss)
I0822 18:07:43.991957 13823 sgd_solver.cpp:112] Iteration 68400, lr = 0.0001
I0822 18:07:55.262266 13823 solver.cpp:239] Iteration 68500 (8.87284 iter/s, 11.2703s/100 iters), loss = 0.0265001
I0822 18:07:55.262320 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0264999 (* 1 = 0.0264999 loss)
I0822 18:07:55.262329 13823 sgd_solver.cpp:112] Iteration 68500, lr = 0.0001
I0822 18:08:06.518277 13823 solver.cpp:239] Iteration 68600 (8.88417 iter/s, 11.256s/100 iters), loss = 0.03179
I0822 18:08:06.518339 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0317897 (* 1 = 0.0317897 loss)
I0822 18:08:06.518352 13823 sgd_solver.cpp:112] Iteration 68600, lr = 0.0001
I0822 18:08:17.825176 13823 solver.cpp:239] Iteration 68700 (8.84419 iter/s, 11.3069s/100 iters), loss = 0.0296439
I0822 18:08:17.825227 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0296436 (* 1 = 0.0296436 loss)
I0822 18:08:17.825237 13823 sgd_solver.cpp:112] Iteration 68700, lr = 0.0001
I0822 18:08:29.024787 13823 solver.cpp:239] Iteration 68800 (8.92891 iter/s, 11.1996s/100 iters), loss = 0.0321841
I0822 18:08:29.024849 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0321838 (* 1 = 0.0321838 loss)
I0822 18:08:29.024861 13823 sgd_solver.cpp:112] Iteration 68800, lr = 0.0001
I0822 18:08:40.362882 13823 solver.cpp:239] Iteration 68900 (8.81986 iter/s, 11.338s/100 iters), loss = 0.0308981
I0822 18:08:40.362943 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0308978 (* 1 = 0.0308978 loss)
I0822 18:08:40.362954 13823 sgd_solver.cpp:112] Iteration 68900, lr = 0.0001
I0822 18:08:51.634346 13823 solver.cpp:239] Iteration 69000 (8.872 iter/s, 11.2714s/100 iters), loss = 0.0281961
I0822 18:08:51.634419 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0281959 (* 1 = 0.0281959 loss)
I0822 18:08:51.634438 13823 sgd_solver.cpp:112] Iteration 69000, lr = 0.0001
I0822 18:09:02.840598 13823 solver.cpp:239] Iteration 69100 (8.92363 iter/s, 11.2062s/100 iters), loss = 0.0314128
I0822 18:09:02.840648 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0314126 (* 1 = 0.0314126 loss)
I0822 18:09:02.840657 13823 sgd_solver.cpp:112] Iteration 69100, lr = 0.0001
I0822 18:09:14.226145 13823 solver.cpp:239] Iteration 69200 (8.78309 iter/s, 11.3855s/100 iters), loss = 0.0286895
I0822 18:09:14.226198 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0286893 (* 1 = 0.0286893 loss)
I0822 18:09:14.226212 13823 sgd_solver.cpp:112] Iteration 69200, lr = 0.0001
I0822 18:09:25.440274 13823 solver.cpp:239] Iteration 69300 (8.91735 iter/s, 11.2141s/100 iters), loss = 0.0339433
I0822 18:09:25.440340 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.033943 (* 1 = 0.033943 loss)
I0822 18:09:25.440356 13823 sgd_solver.cpp:112] Iteration 69300, lr = 0.0001
I0822 18:09:36.687796 13823 solver.cpp:239] Iteration 69400 (8.89089 iter/s, 11.2475s/100 iters), loss = 0.0261794
I0822 18:09:36.687855 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0261792 (* 1 = 0.0261792 loss)
I0822 18:09:36.687866 13823 sgd_solver.cpp:112] Iteration 69400, lr = 0.0001
I0822 18:09:48.098160 13823 solver.cpp:239] Iteration 69500 (8.764 iter/s, 11.4103s/100 iters), loss = 0.0429936
I0822 18:09:48.098214 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0429933 (* 1 = 0.0429933 loss)
I0822 18:09:48.098227 13823 sgd_solver.cpp:112] Iteration 69500, lr = 0.0001
I0822 18:09:59.660604 13823 solver.cpp:239] Iteration 69600 (8.64872 iter/s, 11.5624s/100 iters), loss = 0.0286667
I0822 18:09:59.660673 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0286664 (* 1 = 0.0286664 loss)
I0822 18:09:59.660691 13823 sgd_solver.cpp:112] Iteration 69600, lr = 0.0001
I0822 18:10:11.056005 13823 solver.cpp:239] Iteration 69700 (8.77551 iter/s, 11.3954s/100 iters), loss = 0.0385486
I0822 18:10:11.056061 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0385484 (* 1 = 0.0385484 loss)
I0822 18:10:11.056073 13823 sgd_solver.cpp:112] Iteration 69700, lr = 0.0001
I0822 18:10:22.205448 13823 solver.cpp:239] Iteration 69800 (8.96909 iter/s, 11.1494s/100 iters), loss = 0.0232891
I0822 18:10:22.205498 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0232888 (* 1 = 0.0232888 loss)
I0822 18:10:22.205508 13823 sgd_solver.cpp:112] Iteration 69800, lr = 0.0001
I0822 18:10:33.610646 13823 solver.cpp:239] Iteration 69900 (8.76796 iter/s, 11.4052s/100 iters), loss = 0.0308514
I0822 18:10:33.610709 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0308512 (* 1 = 0.0308512 loss)
I0822 18:10:33.610721 13823 sgd_solver.cpp:112] Iteration 69900, lr = 0.0001
I0822 18:10:44.757732 13823 solver.cpp:239] Iteration 70000 (8.97099 iter/s, 11.147s/100 iters), loss = 0.0385234
I0822 18:10:44.757791 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0385232 (* 1 = 0.0385232 loss)
I0822 18:10:44.757802 13823 sgd_solver.cpp:112] Iteration 70000, lr = 0.0001
I0822 18:10:56.307899 13823 solver.cpp:239] Iteration 70100 (8.65792 iter/s, 11.5501s/100 iters), loss = 0.0314207
I0822 18:10:56.307950 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0314205 (* 1 = 0.0314205 loss)
I0822 18:10:56.307960 13823 sgd_solver.cpp:112] Iteration 70100, lr = 0.0001
I0822 18:11:07.662258 13823 solver.cpp:239] Iteration 70200 (8.80722 iter/s, 11.3543s/100 iters), loss = 0.0244909
I0822 18:11:07.662329 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0244907 (* 1 = 0.0244907 loss)
I0822 18:11:07.662346 13823 sgd_solver.cpp:112] Iteration 70200, lr = 0.0001
I0822 18:11:19.065477 13823 solver.cpp:239] Iteration 70300 (8.76949 iter/s, 11.4032s/100 iters), loss = 0.0256942
I0822 18:11:19.065527 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0256939 (* 1 = 0.0256939 loss)
I0822 18:11:19.065536 13823 sgd_solver.cpp:112] Iteration 70300, lr = 0.0001
I0822 18:11:30.580605 13823 solver.cpp:239] Iteration 70400 (8.68426 iter/s, 11.5151s/100 iters), loss = 0.0257246
I0822 18:11:30.580665 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0257244 (* 1 = 0.0257244 loss)
I0822 18:11:30.580679 13823 sgd_solver.cpp:112] Iteration 70400, lr = 0.0001
I0822 18:11:42.092195 13823 solver.cpp:239] Iteration 70500 (8.68693 iter/s, 11.5115s/100 iters), loss = 0.0331095
I0822 18:11:42.092253 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0331092 (* 1 = 0.0331092 loss)
I0822 18:11:42.092265 13823 sgd_solver.cpp:112] Iteration 70500, lr = 0.0001
I0822 18:11:53.615114 13823 solver.cpp:239] Iteration 70600 (8.67839 iter/s, 11.5229s/100 iters), loss = 0.0269933
I0822 18:11:53.615164 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.026993 (* 1 = 0.026993 loss)
I0822 18:11:53.615172 13823 sgd_solver.cpp:112] Iteration 70600, lr = 0.0001
I0822 18:12:04.467964 13823 solver.cpp:239] Iteration 70700 (9.2142 iter/s, 10.8528s/100 iters), loss = 0.0361102
I0822 18:12:04.468005 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.03611 (* 1 = 0.03611 loss)
I0822 18:12:04.468013 13823 sgd_solver.cpp:112] Iteration 70700, lr = 0.0001
I0822 18:12:16.076552 13823 solver.cpp:239] Iteration 70800 (8.61434 iter/s, 11.6086s/100 iters), loss = 0.0260098
I0822 18:12:16.076623 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0260096 (* 1 = 0.0260096 loss)
I0822 18:12:16.076640 13823 sgd_solver.cpp:112] Iteration 70800, lr = 0.0001
I0822 18:12:27.472402 13823 solver.cpp:239] Iteration 70900 (8.77516 iter/s, 11.3958s/100 iters), loss = 0.0247761
I0822 18:12:27.472463 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0247758 (* 1 = 0.0247758 loss)
I0822 18:12:27.472476 13823 sgd_solver.cpp:112] Iteration 70900, lr = 0.0001
I0822 18:12:38.711237 13823 solver.cpp:239] Iteration 71000 (8.89776 iter/s, 11.2388s/100 iters), loss = 0.0261618
I0822 18:12:38.711295 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0261615 (* 1 = 0.0261615 loss)
I0822 18:12:38.711305 13823 sgd_solver.cpp:112] Iteration 71000, lr = 0.0001
I0822 18:12:50.160156 13823 solver.cpp:239] Iteration 71100 (8.73448 iter/s, 11.4489s/100 iters), loss = 0.0285776
I0822 18:12:50.160207 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0285774 (* 1 = 0.0285774 loss)
I0822 18:12:50.160218 13823 sgd_solver.cpp:112] Iteration 71100, lr = 0.0001
I0822 18:13:01.711510 13823 solver.cpp:239] Iteration 71200 (8.65702 iter/s, 11.5513s/100 iters), loss = 0.0264859
I0822 18:13:01.711571 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0264856 (* 1 = 0.0264856 loss)
I0822 18:13:01.711583 13823 sgd_solver.cpp:112] Iteration 71200, lr = 0.0001
I0822 18:13:13.284114 13823 solver.cpp:239] Iteration 71300 (8.64113 iter/s, 11.5726s/100 iters), loss = 0.0293818
I0822 18:13:13.284178 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0293815 (* 1 = 0.0293815 loss)
I0822 18:13:13.284190 13823 sgd_solver.cpp:112] Iteration 71300, lr = 0.0001
I0822 18:13:24.652806 13823 solver.cpp:239] Iteration 71400 (8.79612 iter/s, 11.3686s/100 iters), loss = 0.0329167
I0822 18:13:24.652858 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0329165 (* 1 = 0.0329165 loss)
I0822 18:13:24.652868 13823 sgd_solver.cpp:112] Iteration 71400, lr = 0.0001
I0822 18:13:36.086179 13823 solver.cpp:239] Iteration 71500 (8.74636 iter/s, 11.4333s/100 iters), loss = 0.0317102
I0822 18:13:36.086238 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0317099 (* 1 = 0.0317099 loss)
I0822 18:13:36.086249 13823 sgd_solver.cpp:112] Iteration 71500, lr = 0.0001
I0822 18:13:47.529290 13823 solver.cpp:239] Iteration 71600 (8.73892 iter/s, 11.4431s/100 iters), loss = 0.0295934
I0822 18:13:47.529340 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0295931 (* 1 = 0.0295931 loss)
I0822 18:13:47.529350 13823 sgd_solver.cpp:112] Iteration 71600, lr = 0.0001
I0822 18:13:59.025315 13823 solver.cpp:239] Iteration 71700 (8.69869 iter/s, 11.496s/100 iters), loss = 0.0286139
I0822 18:13:59.025369 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0286136 (* 1 = 0.0286136 loss)
I0822 18:13:59.025379 13823 sgd_solver.cpp:112] Iteration 71700, lr = 0.0001
I0822 18:14:10.737138 13823 solver.cpp:239] Iteration 71800 (8.53841 iter/s, 11.7118s/100 iters), loss = 0.0274153
I0822 18:14:10.737190 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.027415 (* 1 = 0.027415 loss)
I0822 18:14:10.737200 13823 sgd_solver.cpp:112] Iteration 71800, lr = 0.0001
I0822 18:14:22.221588 13823 solver.cpp:239] Iteration 71900 (8.70746 iter/s, 11.4844s/100 iters), loss = 0.0270741
I0822 18:14:22.221652 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0270738 (* 1 = 0.0270738 loss)
I0822 18:14:22.221664 13823 sgd_solver.cpp:112] Iteration 71900, lr = 0.0001
I0822 18:14:33.906383 13823 solver.cpp:239] Iteration 72000 (8.55817 iter/s, 11.6847s/100 iters), loss = 0.0262988
I0822 18:14:33.906440 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0262985 (* 1 = 0.0262985 loss)
I0822 18:14:33.906451 13823 sgd_solver.cpp:112] Iteration 72000, lr = 0.0001
I0822 18:14:45.316825 13823 solver.cpp:239] Iteration 72100 (8.76394 iter/s, 11.4104s/100 iters), loss = 0.0337095
I0822 18:14:45.316887 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0337092 (* 1 = 0.0337092 loss)
I0822 18:14:45.316900 13823 sgd_solver.cpp:112] Iteration 72100, lr = 0.0001
I0822 18:14:57.000047 13823 solver.cpp:239] Iteration 72200 (8.55932 iter/s, 11.6832s/100 iters), loss = 0.0259629
I0822 18:14:57.000100 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0259626 (* 1 = 0.0259626 loss)
I0822 18:14:57.000109 13823 sgd_solver.cpp:112] Iteration 72200, lr = 0.0001
I0822 18:15:08.755592 13823 solver.cpp:239] Iteration 72300 (8.50665 iter/s, 11.7555s/100 iters), loss = 0.0268556
I0822 18:15:08.755654 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0268553 (* 1 = 0.0268553 loss)
I0822 18:15:08.755666 13823 sgd_solver.cpp:112] Iteration 72300, lr = 0.0001
I0822 18:15:20.389053 13823 solver.cpp:239] Iteration 72400 (8.59593 iter/s, 11.6334s/100 iters), loss = 0.029612
I0822 18:15:20.389112 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0296117 (* 1 = 0.0296117 loss)
I0822 18:15:20.389124 13823 sgd_solver.cpp:112] Iteration 72400, lr = 0.0001
I0822 18:15:31.697307 13823 solver.cpp:239] Iteration 72500 (8.84313 iter/s, 11.3082s/100 iters), loss = 0.0282918
I0822 18:15:31.697356 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0282914 (* 1 = 0.0282914 loss)
I0822 18:15:31.697365 13823 sgd_solver.cpp:112] Iteration 72500, lr = 0.0001
I0822 18:15:43.140370 13823 solver.cpp:239] Iteration 72600 (8.73895 iter/s, 11.443s/100 iters), loss = 0.0242889
I0822 18:15:43.140421 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0242885 (* 1 = 0.0242885 loss)
I0822 18:15:43.140430 13823 sgd_solver.cpp:112] Iteration 72600, lr = 0.0001
I0822 18:15:54.599283 13823 solver.cpp:239] Iteration 72700 (8.72686 iter/s, 11.4589s/100 iters), loss = 0.0270806
I0822 18:15:54.599335 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0270803 (* 1 = 0.0270803 loss)
I0822 18:15:54.599344 13823 sgd_solver.cpp:112] Iteration 72700, lr = 0.0001
I0822 18:16:05.976529 13823 solver.cpp:239] Iteration 72800 (8.7895 iter/s, 11.3772s/100 iters), loss = 0.0339273
I0822 18:16:05.976577 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.033927 (* 1 = 0.033927 loss)
I0822 18:16:05.976586 13823 sgd_solver.cpp:112] Iteration 72800, lr = 0.0001
I0822 18:16:17.486577 13823 solver.cpp:239] Iteration 72900 (8.68809 iter/s, 11.51s/100 iters), loss = 0.0284841
I0822 18:16:17.486630 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0284837 (* 1 = 0.0284837 loss)
I0822 18:16:17.486639 13823 sgd_solver.cpp:112] Iteration 72900, lr = 0.0001
I0822 18:16:29.288781 13823 solver.cpp:239] Iteration 73000 (8.47302 iter/s, 11.8022s/100 iters), loss = 0.0278409
I0822 18:16:29.288833 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0278406 (* 1 = 0.0278406 loss)
I0822 18:16:29.288843 13823 sgd_solver.cpp:112] Iteration 73000, lr = 0.0001
I0822 18:16:39.747584 13823 solver.cpp:239] Iteration 73100 (9.56136 iter/s, 10.4588s/100 iters), loss = 0.0303914
I0822 18:16:39.747637 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0303911 (* 1 = 0.0303911 loss)
I0822 18:16:39.747645 13823 sgd_solver.cpp:112] Iteration 73100, lr = 0.0001
I0822 18:16:49.033154 13823 solver.cpp:239] Iteration 73200 (10.7695 iter/s, 9.28552s/100 iters), loss = 0.0289747
I0822 18:16:49.033218 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0289743 (* 1 = 0.0289743 loss)
I0822 18:16:49.033231 13823 sgd_solver.cpp:112] Iteration 73200, lr = 0.0001
I0822 18:16:58.585589 13823 solver.cpp:239] Iteration 73300 (10.4686 iter/s, 9.55238s/100 iters), loss = 0.0287562
I0822 18:16:58.585638 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0287559 (* 1 = 0.0287559 loss)
I0822 18:16:58.585646 13823 sgd_solver.cpp:112] Iteration 73300, lr = 0.0001
I0822 18:17:08.042507 13823 solver.cpp:239] Iteration 73400 (10.5743 iter/s, 9.45688s/100 iters), loss = 0.0312249
I0822 18:17:08.042557 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0312246 (* 1 = 0.0312246 loss)
I0822 18:17:08.042567 13823 sgd_solver.cpp:112] Iteration 73400, lr = 0.0001
I0822 18:17:17.698966 13823 solver.cpp:239] Iteration 73500 (10.3558 iter/s, 9.65642s/100 iters), loss = 0.0285779
I0822 18:17:17.699019 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0285776 (* 1 = 0.0285776 loss)
I0822 18:17:17.699028 13823 sgd_solver.cpp:112] Iteration 73500, lr = 0.0001
I0822 18:17:27.191383 13823 solver.cpp:239] Iteration 73600 (10.5348 iter/s, 9.49237s/100 iters), loss = 0.0270897
I0822 18:17:27.191433 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0270893 (* 1 = 0.0270893 loss)
I0822 18:17:27.191442 13823 sgd_solver.cpp:112] Iteration 73600, lr = 0.0001
I0822 18:17:36.937618 13823 solver.cpp:239] Iteration 73700 (10.2604 iter/s, 9.74619s/100 iters), loss = 0.0280128
I0822 18:17:36.937666 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0280125 (* 1 = 0.0280125 loss)
I0822 18:17:36.937675 13823 sgd_solver.cpp:112] Iteration 73700, lr = 0.0001
I0822 18:17:46.275967 13823 solver.cpp:239] Iteration 73800 (10.7086 iter/s, 9.33831s/100 iters), loss = 0.0273516
I0822 18:17:46.276019 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0273513 (* 1 = 0.0273513 loss)
I0822 18:17:46.276029 13823 sgd_solver.cpp:112] Iteration 73800, lr = 0.0001
I0822 18:17:55.885013 13823 solver.cpp:239] Iteration 73900 (10.4069 iter/s, 9.609s/100 iters), loss = 0.0281982
I0822 18:17:55.885064 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0281978 (* 1 = 0.0281978 loss)
I0822 18:17:55.885073 13823 sgd_solver.cpp:112] Iteration 73900, lr = 0.0001
I0822 18:18:05.749977 13823 solver.cpp:239] Iteration 74000 (10.1369 iter/s, 9.86492s/100 iters), loss = 0.0349701
I0822 18:18:05.750028 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0349698 (* 1 = 0.0349698 loss)
I0822 18:18:05.750037 13823 sgd_solver.cpp:112] Iteration 74000, lr = 0.0001
I0822 18:18:15.552673 13823 solver.cpp:239] Iteration 74100 (10.2013 iter/s, 9.80266s/100 iters), loss = 0.0249736
I0822 18:18:15.552726 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0249732 (* 1 = 0.0249732 loss)
I0822 18:18:15.552736 13823 sgd_solver.cpp:112] Iteration 74100, lr = 0.0001
I0822 18:18:25.285029 13823 solver.cpp:239] Iteration 74200 (10.2751 iter/s, 9.73231s/100 iters), loss = 0.0272681
I0822 18:18:25.285081 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0272678 (* 1 = 0.0272678 loss)
I0822 18:18:25.285091 13823 sgd_solver.cpp:112] Iteration 74200, lr = 0.0001
I0822 18:18:34.809885 13823 solver.cpp:239] Iteration 74300 (10.4989 iter/s, 9.52481s/100 iters), loss = 0.0295962
I0822 18:18:34.809937 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0295959 (* 1 = 0.0295959 loss)
I0822 18:18:34.809945 13823 sgd_solver.cpp:112] Iteration 74300, lr = 0.0001
I0822 18:18:44.399274 13823 solver.cpp:239] Iteration 74400 (10.4282 iter/s, 9.58935s/100 iters), loss = 0.0278781
I0822 18:18:44.399324 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0278777 (* 1 = 0.0278777 loss)
I0822 18:18:44.399333 13823 sgd_solver.cpp:112] Iteration 74400, lr = 0.0001
I0822 18:18:54.254297 13823 solver.cpp:239] Iteration 74500 (10.1472 iter/s, 9.85498s/100 iters), loss = 0.0278634
I0822 18:18:54.254348 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0278631 (* 1 = 0.0278631 loss)
I0822 18:18:54.254359 13823 sgd_solver.cpp:112] Iteration 74500, lr = 0.0001
I0822 18:19:03.848196 13823 solver.cpp:239] Iteration 74600 (10.4233 iter/s, 9.59386s/100 iters), loss = 0.0280188
I0822 18:19:03.848246 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0280184 (* 1 = 0.0280184 loss)
I0822 18:19:03.848255 13823 sgd_solver.cpp:112] Iteration 74600, lr = 0.0001
I0822 18:19:13.271080 13823 solver.cpp:239] Iteration 74700 (10.6125 iter/s, 9.42284s/100 iters), loss = 0.0289188
I0822 18:19:13.271131 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0289184 (* 1 = 0.0289184 loss)
I0822 18:19:13.271139 13823 sgd_solver.cpp:112] Iteration 74700, lr = 0.0001
I0822 18:19:23.055469 13823 solver.cpp:239] Iteration 74800 (10.2204 iter/s, 9.78435s/100 iters), loss = 0.0278204
I0822 18:19:23.055519 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.02782 (* 1 = 0.02782 loss)
I0822 18:19:23.055528 13823 sgd_solver.cpp:112] Iteration 74800, lr = 0.0001
I0822 18:19:32.822131 13823 solver.cpp:239] Iteration 74900 (10.239 iter/s, 9.7666s/100 iters), loss = 0.0290311
I0822 18:19:32.822197 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0290308 (* 1 = 0.0290308 loss)
I0822 18:19:32.822211 13823 sgd_solver.cpp:112] Iteration 74900, lr = 0.0001
I0822 18:19:42.648885 13823 solver.cpp:239] Iteration 75000 (10.1764 iter/s, 9.82668s/100 iters), loss = 0.0287513
I0822 18:19:42.648937 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0287509 (* 1 = 0.0287509 loss)
I0822 18:19:42.648947 13823 sgd_solver.cpp:112] Iteration 75000, lr = 0.0001
I0822 18:19:52.409442 13823 solver.cpp:239] Iteration 75100 (10.2454 iter/s, 9.76049s/100 iters), loss = 0.038628
I0822 18:19:52.409493 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0386276 (* 1 = 0.0386276 loss)
I0822 18:19:52.409502 13823 sgd_solver.cpp:112] Iteration 75100, lr = 0.0001
I0822 18:20:01.904914 13823 solver.cpp:239] Iteration 75200 (10.5314 iter/s, 9.4954s/100 iters), loss = 0.223635
I0822 18:20:01.904963 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.223635 (* 1 = 0.223635 loss)
I0822 18:20:01.904973 13823 sgd_solver.cpp:112] Iteration 75200, lr = 0.0001
I0822 18:20:11.723421 13823 solver.cpp:239] Iteration 75300 (10.1849 iter/s, 9.81844s/100 iters), loss = 0.028913
I0822 18:20:11.723471 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0289127 (* 1 = 0.0289127 loss)
I0822 18:20:11.723481 13823 sgd_solver.cpp:112] Iteration 75300, lr = 0.0001
I0822 18:20:21.586971 13823 solver.cpp:239] Iteration 75400 (10.1384 iter/s, 9.86348s/100 iters), loss = 0.0290588
I0822 18:20:21.587023 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0290585 (* 1 = 0.0290585 loss)
I0822 18:20:21.587031 13823 sgd_solver.cpp:112] Iteration 75400, lr = 0.0001
I0822 18:20:31.163553 13823 solver.cpp:239] Iteration 75500 (10.4422 iter/s, 9.57651s/100 iters), loss = 0.0263149
I0822 18:20:31.163602 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0263145 (* 1 = 0.0263145 loss)
I0822 18:20:31.163611 13823 sgd_solver.cpp:112] Iteration 75500, lr = 0.0001
I0822 18:20:40.877754 13823 solver.cpp:239] Iteration 75600 (10.2943 iter/s, 9.71413s/100 iters), loss = 0.0341372
I0822 18:20:40.877816 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0341369 (* 1 = 0.0341369 loss)
I0822 18:20:40.877828 13823 sgd_solver.cpp:112] Iteration 75600, lr = 0.0001
I0822 18:20:50.584631 13823 solver.cpp:239] Iteration 75700 (10.3021 iter/s, 9.7068s/100 iters), loss = 0.0255287
I0822 18:20:50.584674 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0255283 (* 1 = 0.0255283 loss)
I0822 18:20:50.584681 13823 sgd_solver.cpp:112] Iteration 75700, lr = 0.0001
I0822 18:21:00.197223 13823 solver.cpp:239] Iteration 75800 (10.4031 iter/s, 9.61253s/100 iters), loss = 0.0268633
I0822 18:21:00.197274 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.026863 (* 1 = 0.026863 loss)
I0822 18:21:00.197283 13823 sgd_solver.cpp:112] Iteration 75800, lr = 0.0001
I0822 18:21:10.175557 13823 solver.cpp:239] Iteration 75900 (10.0218 iter/s, 9.97827s/100 iters), loss = 0.026285
I0822 18:21:10.175611 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0262846 (* 1 = 0.0262846 loss)
I0822 18:21:10.175621 13823 sgd_solver.cpp:112] Iteration 75900, lr = 0.0001
I0822 18:21:19.970844 13823 solver.cpp:239] Iteration 76000 (10.2091 iter/s, 9.79522s/100 iters), loss = 0.0259208
I0822 18:21:19.970903 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0259204 (* 1 = 0.0259204 loss)
I0822 18:21:19.970914 13823 sgd_solver.cpp:112] Iteration 76000, lr = 0.0001
I0822 18:21:29.728554 13823 solver.cpp:239] Iteration 76100 (10.2484 iter/s, 9.75764s/100 iters), loss = 0.028083
I0822 18:21:29.728606 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0280827 (* 1 = 0.0280827 loss)
I0822 18:21:29.728615 13823 sgd_solver.cpp:112] Iteration 76100, lr = 0.0001
I0822 18:21:39.626854 13823 solver.cpp:239] Iteration 76200 (10.1028 iter/s, 9.89823s/100 iters), loss = 0.0279057
I0822 18:21:39.626905 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0279053 (* 1 = 0.0279053 loss)
I0822 18:21:39.626914 13823 sgd_solver.cpp:112] Iteration 76200, lr = 0.0001
I0822 18:21:49.592538 13823 solver.cpp:239] Iteration 76300 (10.0345 iter/s, 9.96562s/100 iters), loss = 0.028034
I0822 18:21:49.592579 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0280337 (* 1 = 0.0280337 loss)
I0822 18:21:49.592586 13823 sgd_solver.cpp:112] Iteration 76300, lr = 0.0001
I0822 18:21:59.551951 13823 solver.cpp:239] Iteration 76400 (10.0408 iter/s, 9.95936s/100 iters), loss = 0.0304261
I0822 18:21:59.552003 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0304257 (* 1 = 0.0304257 loss)
I0822 18:21:59.552012 13823 sgd_solver.cpp:112] Iteration 76400, lr = 0.0001
I0822 18:22:09.326663 13823 solver.cpp:239] Iteration 76500 (10.2306 iter/s, 9.77464s/100 iters), loss = 0.0262498
I0822 18:22:09.326714 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0262495 (* 1 = 0.0262495 loss)
I0822 18:22:09.326723 13823 sgd_solver.cpp:112] Iteration 76500, lr = 0.0001
I0822 18:22:18.986591 13823 solver.cpp:239] Iteration 76600 (10.3521 iter/s, 9.65987s/100 iters), loss = 0.0268622
I0822 18:22:18.986639 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0268618 (* 1 = 0.0268618 loss)
I0822 18:22:18.986647 13823 sgd_solver.cpp:112] Iteration 76600, lr = 0.0001
I0822 18:22:29.013489 13823 solver.cpp:239] Iteration 76700 (9.97324 iter/s, 10.0268s/100 iters), loss = 0.0280885
I0822 18:22:29.013540 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0280881 (* 1 = 0.0280881 loss)
I0822 18:22:29.013550 13823 sgd_solver.cpp:112] Iteration 76700, lr = 0.0001
I0822 18:22:38.907868 13823 solver.cpp:239] Iteration 76800 (10.1068 iter/s, 9.89431s/100 iters), loss = 0.0441697
I0822 18:22:38.907936 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0441694 (* 1 = 0.0441694 loss)
I0822 18:22:38.907949 13823 sgd_solver.cpp:112] Iteration 76800, lr = 0.0001
I0822 18:22:49.024629 13823 solver.cpp:239] Iteration 76900 (9.88466 iter/s, 10.1167s/100 iters), loss = 0.0253086
I0822 18:22:49.024680 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0253082 (* 1 = 0.0253082 loss)
I0822 18:22:49.024689 13823 sgd_solver.cpp:112] Iteration 76900, lr = 0.0001
I0822 18:22:59.098079 13823 solver.cpp:239] Iteration 77000 (9.92715 iter/s, 10.0734s/100 iters), loss = 0.0311974
I0822 18:22:59.098139 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.031197 (* 1 = 0.031197 loss)
I0822 18:22:59.098150 13823 sgd_solver.cpp:112] Iteration 77000, lr = 0.0001
I0822 18:23:08.779706 13823 solver.cpp:239] Iteration 77100 (10.3289 iter/s, 9.68156s/100 iters), loss = 0.028557
I0822 18:23:08.779759 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0285567 (* 1 = 0.0285567 loss)
I0822 18:23:08.779768 13823 sgd_solver.cpp:112] Iteration 77100, lr = 0.0001
I0822 18:23:18.860474 13823 solver.cpp:239] Iteration 77200 (9.91994 iter/s, 10.0807s/100 iters), loss = 0.0291886
I0822 18:23:18.860532 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0291883 (* 1 = 0.0291883 loss)
I0822 18:23:18.860541 13823 sgd_solver.cpp:112] Iteration 77200, lr = 0.0001
I0822 18:23:28.545495 13823 solver.cpp:239] Iteration 77300 (10.3253 iter/s, 9.68495s/100 iters), loss = 0.0373998
I0822 18:23:28.545549 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0373995 (* 1 = 0.0373995 loss)
I0822 18:23:28.545559 13823 sgd_solver.cpp:112] Iteration 77300, lr = 0.0001
I0822 18:23:38.455791 13823 solver.cpp:239] Iteration 77400 (10.0906 iter/s, 9.91023s/100 iters), loss = 0.0272806
I0822 18:23:38.455842 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0272803 (* 1 = 0.0272803 loss)
I0822 18:23:38.455850 13823 sgd_solver.cpp:112] Iteration 77400, lr = 0.0001
I0822 18:23:48.297394 13823 solver.cpp:239] Iteration 77500 (10.161 iter/s, 9.84154s/100 iters), loss = 0.0281624
I0822 18:23:48.297446 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.028162 (* 1 = 0.028162 loss)
I0822 18:23:48.297454 13823 sgd_solver.cpp:112] Iteration 77500, lr = 0.0001
I0822 18:23:58.167788 13823 solver.cpp:239] Iteration 77600 (10.1314 iter/s, 9.87033s/100 iters), loss = 0.0267734
I0822 18:23:58.167838 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0267731 (* 1 = 0.0267731 loss)
I0822 18:23:58.167847 13823 sgd_solver.cpp:112] Iteration 77600, lr = 0.0001
I0822 18:24:07.940660 13823 solver.cpp:239] Iteration 77700 (10.2325 iter/s, 9.77281s/100 iters), loss = 0.0466611
I0822 18:24:07.940709 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0466608 (* 1 = 0.0466608 loss)
I0822 18:24:07.940718 13823 sgd_solver.cpp:112] Iteration 77700, lr = 0.0001
I0822 18:24:17.522959 13823 solver.cpp:239] Iteration 77800 (10.436 iter/s, 9.58224s/100 iters), loss = 0.0268652
I0822 18:24:17.523010 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0268649 (* 1 = 0.0268649 loss)
I0822 18:24:17.523017 13823 sgd_solver.cpp:112] Iteration 77800, lr = 0.0001
I0822 18:24:27.449278 13823 solver.cpp:239] Iteration 77900 (10.0743 iter/s, 9.92626s/100 iters), loss = 0.0273474
I0822 18:24:27.449331 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0273471 (* 1 = 0.0273471 loss)
I0822 18:24:27.449340 13823 sgd_solver.cpp:112] Iteration 77900, lr = 0.0001
I0822 18:24:37.749219 13823 solver.cpp:239] Iteration 78000 (9.70885 iter/s, 10.2999s/100 iters), loss = 0.030036
I0822 18:24:37.749271 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0300357 (* 1 = 0.0300357 loss)
I0822 18:24:37.749280 13823 sgd_solver.cpp:112] Iteration 78000, lr = 0.0001
I0822 18:24:47.707407 13823 solver.cpp:239] Iteration 78100 (10.042 iter/s, 9.95813s/100 iters), loss = 0.0273767
I0822 18:24:47.707456 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0273764 (* 1 = 0.0273764 loss)
I0822 18:24:47.707465 13823 sgd_solver.cpp:112] Iteration 78100, lr = 0.0001
I0822 18:24:57.461555 13823 solver.cpp:239] Iteration 78200 (10.2521 iter/s, 9.75409s/100 iters), loss = 0.0256538
I0822 18:24:57.461609 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0256535 (* 1 = 0.0256535 loss)
I0822 18:24:57.461618 13823 sgd_solver.cpp:112] Iteration 78200, lr = 0.0001
I0822 18:25:07.434692 13823 solver.cpp:239] Iteration 78300 (10.027 iter/s, 9.97307s/100 iters), loss = 0.0303837
I0822 18:25:07.434743 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0303833 (* 1 = 0.0303833 loss)
I0822 18:25:07.434752 13823 sgd_solver.cpp:112] Iteration 78300, lr = 0.0001
I0822 18:25:17.387178 13823 solver.cpp:239] Iteration 78400 (10.0478 iter/s, 9.95243s/100 iters), loss = 0.0250491
I0822 18:25:17.387228 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0250488 (* 1 = 0.0250488 loss)
I0822 18:25:17.387238 13823 sgd_solver.cpp:112] Iteration 78400, lr = 0.0001
I0822 18:25:27.033483 13823 solver.cpp:239] Iteration 78500 (10.3667 iter/s, 9.64625s/100 iters), loss = 0.0303545
I0822 18:25:27.033535 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0303541 (* 1 = 0.0303541 loss)
I0822 18:25:27.033542 13823 sgd_solver.cpp:112] Iteration 78500, lr = 0.0001
I0822 18:25:36.788586 13823 solver.cpp:239] Iteration 78600 (10.2511 iter/s, 9.75504s/100 iters), loss = 0.0295325
I0822 18:25:36.788637 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0295322 (* 1 = 0.0295322 loss)
I0822 18:25:36.788646 13823 sgd_solver.cpp:112] Iteration 78600, lr = 0.0001
I0822 18:25:46.833392 13823 solver.cpp:239] Iteration 78700 (9.95545 iter/s, 10.0447s/100 iters), loss = 0.0346492
I0822 18:25:46.833443 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0346489 (* 1 = 0.0346489 loss)
I0822 18:25:46.833452 13823 sgd_solver.cpp:112] Iteration 78700, lr = 0.0001
I0822 18:25:56.857178 13823 solver.cpp:239] Iteration 78800 (9.97633 iter/s, 10.0237s/100 iters), loss = 0.0302588
I0822 18:25:56.857226 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0302585 (* 1 = 0.0302585 loss)
I0822 18:25:56.857235 13823 sgd_solver.cpp:112] Iteration 78800, lr = 0.0001
I0822 18:26:06.548776 13823 solver.cpp:239] Iteration 78900 (10.3183 iter/s, 9.69154s/100 iters), loss = 0.024084
I0822 18:26:06.548826 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0240837 (* 1 = 0.0240837 loss)
I0822 18:26:06.548835 13823 sgd_solver.cpp:112] Iteration 78900, lr = 0.0001
I0822 18:26:16.337373 13823 solver.cpp:239] Iteration 79000 (10.216 iter/s, 9.78854s/100 iters), loss = 0.0281968
I0822 18:26:16.337424 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0281965 (* 1 = 0.0281965 loss)
I0822 18:26:16.337432 13823 sgd_solver.cpp:112] Iteration 79000, lr = 0.0001
I0822 18:26:26.078915 13823 solver.cpp:239] Iteration 79100 (10.2654 iter/s, 9.74149s/100 iters), loss = 0.0289353
I0822 18:26:26.078966 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.028935 (* 1 = 0.028935 loss)
I0822 18:26:26.078975 13823 sgd_solver.cpp:112] Iteration 79100, lr = 0.0001
I0822 18:26:35.783814 13823 solver.cpp:239] Iteration 79200 (10.3041 iter/s, 9.70484s/100 iters), loss = 0.0275623
I0822 18:26:35.783864 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.027562 (* 1 = 0.027562 loss)
I0822 18:26:35.783874 13823 sgd_solver.cpp:112] Iteration 79200, lr = 0.0001
I0822 18:26:45.809257 13823 solver.cpp:239] Iteration 79300 (9.97468 iter/s, 10.0254s/100 iters), loss = 0.0332937
I0822 18:26:45.809305 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0332933 (* 1 = 0.0332933 loss)
I0822 18:26:45.809314 13823 sgd_solver.cpp:112] Iteration 79300, lr = 0.0001
I0822 18:26:55.967803 13823 solver.cpp:239] Iteration 79400 (9.84398 iter/s, 10.1585s/100 iters), loss = 0.0258084
I0822 18:26:55.967856 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0258081 (* 1 = 0.0258081 loss)
I0822 18:26:55.967866 13823 sgd_solver.cpp:112] Iteration 79400, lr = 0.0001
I0822 18:27:06.200482 13823 solver.cpp:239] Iteration 79500 (9.77267 iter/s, 10.2326s/100 iters), loss = 0.0251946
I0822 18:27:06.200531 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0251943 (* 1 = 0.0251943 loss)
I0822 18:27:06.200541 13823 sgd_solver.cpp:112] Iteration 79500, lr = 0.0001
I0822 18:27:16.688318 13823 solver.cpp:239] Iteration 79600 (9.53491 iter/s, 10.4878s/100 iters), loss = 0.0288866
I0822 18:27:16.688380 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0288862 (* 1 = 0.0288862 loss)
I0822 18:27:16.688388 13823 sgd_solver.cpp:112] Iteration 79600, lr = 0.0001
I0822 18:27:27.223115 13823 solver.cpp:239] Iteration 79700 (9.49241 iter/s, 10.5347s/100 iters), loss = 0.0285287
I0822 18:27:27.223174 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0285284 (* 1 = 0.0285284 loss)
I0822 18:27:27.223186 13823 sgd_solver.cpp:112] Iteration 79700, lr = 0.0001
I0822 18:27:37.576125 13823 solver.cpp:239] Iteration 79800 (9.65909 iter/s, 10.3529s/100 iters), loss = 0.0299231
I0822 18:27:37.576187 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0299228 (* 1 = 0.0299228 loss)
I0822 18:27:37.576198 13823 sgd_solver.cpp:112] Iteration 79800, lr = 0.0001
I0822 18:27:47.553494 13823 solver.cpp:239] Iteration 79900 (10.0227 iter/s, 9.9773s/100 iters), loss = 0.0328786
I0822 18:27:47.553544 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0328783 (* 1 = 0.0328783 loss)
I0822 18:27:47.553553 13823 sgd_solver.cpp:112] Iteration 79900, lr = 0.0001
I0822 18:27:57.319162 13823 solver.cpp:464] Snapshotting to binary proto file ./model_112/cascade_mobilenet_112_iter_80000.caffemodel
I0822 18:27:57.362401 13823 sgd_solver.cpp:284] Snapshotting solver state to binary proto file ./model_112/cascade_mobilenet_112_iter_80000.solverstate
I0822 18:27:57.392982 13823 solver.cpp:347] Iteration 80000, Testing net (#0)
I0822 18:29:01.811245 13823 solver.cpp:414]     Test net output #0: landmark_loss = 0.0248906 (* 1 = 0.0248906 loss)
I0822 18:29:01.931910 13823 solver.cpp:239] Iteration 80000 (1.34448 iter/s, 74.3784s/100 iters), loss = 0.0305538
I0822 18:29:01.931967 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0305534 (* 1 = 0.0305534 loss)
I0822 18:29:01.931980 13823 sgd_solver.cpp:50] MultiStep Status: Iteration 80000, step = 2
I0822 18:29:01.931988 13823 sgd_solver.cpp:112] Iteration 80000, lr = 1e-05
I0822 18:29:12.417971 13823 solver.cpp:239] Iteration 80100 (9.53652 iter/s, 10.486s/100 iters), loss = 0.0245481
I0822 18:29:12.418030 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0245478 (* 1 = 0.0245478 loss)
I0822 18:29:12.418041 13823 sgd_solver.cpp:112] Iteration 80100, lr = 1e-05
I0822 18:29:23.191061 13823 solver.cpp:239] Iteration 80200 (9.28243 iter/s, 10.773s/100 iters), loss = 0.0249487
I0822 18:29:23.191112 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0249484 (* 1 = 0.0249484 loss)
I0822 18:29:23.191120 13823 sgd_solver.cpp:112] Iteration 80200, lr = 1e-05
I0822 18:29:33.507522 13823 solver.cpp:239] Iteration 80300 (9.6933 iter/s, 10.3164s/100 iters), loss = 0.0293711
I0822 18:29:33.507581 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0293708 (* 1 = 0.0293708 loss)
I0822 18:29:33.507593 13823 sgd_solver.cpp:112] Iteration 80300, lr = 1e-05
I0822 18:29:43.990936 13823 solver.cpp:239] Iteration 80400 (9.53893 iter/s, 10.4834s/100 iters), loss = 0.0271534
I0822 18:29:43.990993 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0271531 (* 1 = 0.0271531 loss)
I0822 18:29:43.991005 13823 sgd_solver.cpp:112] Iteration 80400, lr = 1e-05
I0822 18:29:54.394413 13823 solver.cpp:239] Iteration 80500 (9.61221 iter/s, 10.4034s/100 iters), loss = 0.0255726
I0822 18:29:54.394454 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0255723 (* 1 = 0.0255723 loss)
I0822 18:29:54.394460 13823 sgd_solver.cpp:112] Iteration 80500, lr = 1e-05
I0822 18:30:04.197224 13823 solver.cpp:239] Iteration 80600 (10.2012 iter/s, 9.80278s/100 iters), loss = 0.0258051
I0822 18:30:04.197265 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0258048 (* 1 = 0.0258048 loss)
I0822 18:30:04.197273 13823 sgd_solver.cpp:112] Iteration 80600, lr = 1e-05
I0822 18:30:14.339273 13823 solver.cpp:239] Iteration 80700 (9.85998 iter/s, 10.142s/100 iters), loss = 0.0276133
I0822 18:30:14.339326 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.027613 (* 1 = 0.027613 loss)
I0822 18:30:14.339335 13823 sgd_solver.cpp:112] Iteration 80700, lr = 1e-05
I0822 18:30:24.821280 13823 solver.cpp:239] Iteration 80800 (9.5402 iter/s, 10.482s/100 iters), loss = 0.0263671
I0822 18:30:24.821321 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0263669 (* 1 = 0.0263669 loss)
I0822 18:30:24.821328 13823 sgd_solver.cpp:112] Iteration 80800, lr = 1e-05
I0822 18:30:34.834900 13823 solver.cpp:239] Iteration 80900 (9.98644 iter/s, 10.0136s/100 iters), loss = 0.0262976
I0822 18:30:34.834942 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0262973 (* 1 = 0.0262973 loss)
I0822 18:30:34.834949 13823 sgd_solver.cpp:112] Iteration 80900, lr = 1e-05
I0822 18:30:45.141870 13823 solver.cpp:239] Iteration 81000 (9.70221 iter/s, 10.3069s/100 iters), loss = 0.029833
I0822 18:30:45.141909 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0298327 (* 1 = 0.0298327 loss)
I0822 18:30:45.141916 13823 sgd_solver.cpp:112] Iteration 81000, lr = 1e-05
I0822 18:30:55.414960 13823 solver.cpp:239] Iteration 81100 (9.73421 iter/s, 10.273s/100 iters), loss = 0.0278341
I0822 18:30:55.415014 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0278338 (* 1 = 0.0278338 loss)
I0822 18:30:55.415024 13823 sgd_solver.cpp:112] Iteration 81100, lr = 1e-05
I0822 18:31:05.651299 13823 solver.cpp:239] Iteration 81200 (9.76917 iter/s, 10.2363s/100 iters), loss = 0.0249655
I0822 18:31:05.651355 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0249652 (* 1 = 0.0249652 loss)
I0822 18:31:05.651365 13823 sgd_solver.cpp:112] Iteration 81200, lr = 1e-05
I0822 18:31:16.353209 13823 solver.cpp:239] Iteration 81300 (9.34417 iter/s, 10.7019s/100 iters), loss = 0.026812
I0822 18:31:16.353260 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0268117 (* 1 = 0.0268117 loss)
I0822 18:31:16.353271 13823 sgd_solver.cpp:112] Iteration 81300, lr = 1e-05
I0822 18:31:26.943938 13823 solver.cpp:239] Iteration 81400 (9.44227 iter/s, 10.5907s/100 iters), loss = 0.0291976
I0822 18:31:26.943987 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0291973 (* 1 = 0.0291973 loss)
I0822 18:31:26.943996 13823 sgd_solver.cpp:112] Iteration 81400, lr = 1e-05
I0822 18:31:37.789752 13823 solver.cpp:239] Iteration 81500 (9.22019 iter/s, 10.8458s/100 iters), loss = 0.0296477
I0822 18:31:37.789803 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0296474 (* 1 = 0.0296474 loss)
I0822 18:31:37.789813 13823 sgd_solver.cpp:112] Iteration 81500, lr = 1e-05
I0822 18:31:48.176262 13823 solver.cpp:239] Iteration 81600 (9.62792 iter/s, 10.3865s/100 iters), loss = 0.0919869
I0822 18:31:48.176327 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0919867 (* 1 = 0.0919867 loss)
I0822 18:31:48.176342 13823 sgd_solver.cpp:112] Iteration 81600, lr = 1e-05
I0822 18:31:59.039320 13823 solver.cpp:239] Iteration 81700 (9.20556 iter/s, 10.863s/100 iters), loss = 0.0266459
I0822 18:31:59.039383 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0266456 (* 1 = 0.0266456 loss)
I0822 18:31:59.039398 13823 sgd_solver.cpp:112] Iteration 81700, lr = 1e-05
I0822 18:32:09.713382 13823 solver.cpp:239] Iteration 81800 (9.36856 iter/s, 10.674s/100 iters), loss = 0.0268031
I0822 18:32:09.713433 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0268028 (* 1 = 0.0268028 loss)
I0822 18:32:09.713441 13823 sgd_solver.cpp:112] Iteration 81800, lr = 1e-05
I0822 18:32:20.395107 13823 solver.cpp:239] Iteration 81900 (9.36183 iter/s, 10.6817s/100 iters), loss = 0.0257801
I0822 18:32:20.395174 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0257798 (* 1 = 0.0257798 loss)
I0822 18:32:20.395190 13823 sgd_solver.cpp:112] Iteration 81900, lr = 1e-05
I0822 18:32:31.031026 13823 solver.cpp:239] Iteration 82000 (9.40216 iter/s, 10.6359s/100 iters), loss = 0.0308514
I0822 18:32:31.031085 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0308511 (* 1 = 0.0308511 loss)
I0822 18:32:31.031098 13823 sgd_solver.cpp:112] Iteration 82000, lr = 1e-05
I0822 18:32:41.748330 13823 solver.cpp:239] Iteration 82100 (9.33075 iter/s, 10.7172s/100 iters), loss = 0.029218
I0822 18:32:41.748380 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0292177 (* 1 = 0.0292177 loss)
I0822 18:32:41.748389 13823 sgd_solver.cpp:112] Iteration 82100, lr = 1e-05
I0822 18:32:52.372411 13823 solver.cpp:239] Iteration 82200 (9.41262 iter/s, 10.624s/100 iters), loss = 0.0263559
I0822 18:32:52.372462 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0263556 (* 1 = 0.0263556 loss)
I0822 18:32:52.372473 13823 sgd_solver.cpp:112] Iteration 82200, lr = 1e-05
I0822 18:33:03.302397 13823 solver.cpp:239] Iteration 82300 (9.14919 iter/s, 10.9299s/100 iters), loss = 0.0254696
I0822 18:33:03.302449 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0254693 (* 1 = 0.0254693 loss)
I0822 18:33:03.302459 13823 sgd_solver.cpp:112] Iteration 82300, lr = 1e-05
I0822 18:33:13.905766 13823 solver.cpp:239] Iteration 82400 (9.43101 iter/s, 10.6033s/100 iters), loss = 0.0258195
I0822 18:33:13.905823 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0258192 (* 1 = 0.0258192 loss)
I0822 18:33:13.905834 13823 sgd_solver.cpp:112] Iteration 82400, lr = 1e-05
I0822 18:33:24.545470 13823 solver.cpp:239] Iteration 82500 (9.39881 iter/s, 10.6396s/100 iters), loss = 0.0233612
I0822 18:33:24.545526 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0233609 (* 1 = 0.0233609 loss)
I0822 18:33:24.545537 13823 sgd_solver.cpp:112] Iteration 82500, lr = 1e-05
I0822 18:33:35.138605 13823 solver.cpp:239] Iteration 82600 (9.44012 iter/s, 10.5931s/100 iters), loss = 0.0337848
I0822 18:33:35.138658 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0337845 (* 1 = 0.0337845 loss)
I0822 18:33:35.138667 13823 sgd_solver.cpp:112] Iteration 82600, lr = 1e-05
I0822 18:33:46.016692 13823 solver.cpp:239] Iteration 82700 (9.19284 iter/s, 10.878s/100 iters), loss = 0.0273991
I0822 18:33:46.016753 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0273988 (* 1 = 0.0273988 loss)
I0822 18:33:46.016764 13823 sgd_solver.cpp:112] Iteration 82700, lr = 1e-05
I0822 18:33:56.785821 13823 solver.cpp:239] Iteration 82800 (9.28585 iter/s, 10.7691s/100 iters), loss = 0.033
I0822 18:33:56.785882 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0329997 (* 1 = 0.0329997 loss)
I0822 18:33:56.785894 13823 sgd_solver.cpp:112] Iteration 82800, lr = 1e-05
I0822 18:34:07.763275 13823 solver.cpp:239] Iteration 82900 (9.10963 iter/s, 10.9774s/100 iters), loss = 0.0292254
I0822 18:34:07.763339 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0292251 (* 1 = 0.0292251 loss)
I0822 18:34:07.763350 13823 sgd_solver.cpp:112] Iteration 82900, lr = 1e-05
I0822 18:34:18.657766 13823 solver.cpp:239] Iteration 83000 (9.179 iter/s, 10.8944s/100 iters), loss = 0.0248718
I0822 18:34:18.657819 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0248715 (* 1 = 0.0248715 loss)
I0822 18:34:18.657827 13823 sgd_solver.cpp:112] Iteration 83000, lr = 1e-05
I0822 18:34:29.459983 13823 solver.cpp:239] Iteration 83100 (9.2574 iter/s, 10.8022s/100 iters), loss = 0.0430768
I0822 18:34:29.460036 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0430765 (* 1 = 0.0430765 loss)
I0822 18:34:29.460045 13823 sgd_solver.cpp:112] Iteration 83100, lr = 1e-05
I0822 18:34:40.192209 13823 solver.cpp:239] Iteration 83200 (9.31778 iter/s, 10.7322s/100 iters), loss = 0.0271644
I0822 18:34:40.192258 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0271641 (* 1 = 0.0271641 loss)
I0822 18:34:40.192267 13823 sgd_solver.cpp:112] Iteration 83200, lr = 1e-05
I0822 18:34:51.178671 13823 solver.cpp:239] Iteration 83300 (9.10215 iter/s, 10.9864s/100 iters), loss = 0.023329
I0822 18:34:51.178721 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0233286 (* 1 = 0.0233286 loss)
I0822 18:34:51.178732 13823 sgd_solver.cpp:112] Iteration 83300, lr = 1e-05
I0822 18:35:02.079810 13823 solver.cpp:239] Iteration 83400 (9.17339 iter/s, 10.9011s/100 iters), loss = 0.0245916
I0822 18:35:02.079861 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0245913 (* 1 = 0.0245913 loss)
I0822 18:35:02.079870 13823 sgd_solver.cpp:112] Iteration 83400, lr = 1e-05
I0822 18:35:13.132263 13823 solver.cpp:239] Iteration 83500 (9.0478 iter/s, 11.0524s/100 iters), loss = 0.0291203
I0822 18:35:13.132313 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.02912 (* 1 = 0.02912 loss)
I0822 18:35:13.132323 13823 sgd_solver.cpp:112] Iteration 83500, lr = 1e-05
I0822 18:35:24.120925 13823 solver.cpp:239] Iteration 83600 (9.10033 iter/s, 10.9886s/100 iters), loss = 0.0251067
I0822 18:35:24.120985 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0251064 (* 1 = 0.0251064 loss)
I0822 18:35:24.120997 13823 sgd_solver.cpp:112] Iteration 83600, lr = 1e-05
I0822 18:35:35.075696 13823 solver.cpp:239] Iteration 83700 (9.12849 iter/s, 10.9547s/100 iters), loss = 0.0268934
I0822 18:35:35.075758 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0268931 (* 1 = 0.0268931 loss)
I0822 18:35:35.075769 13823 sgd_solver.cpp:112] Iteration 83700, lr = 1e-05
I0822 18:35:46.077183 13823 solver.cpp:239] Iteration 83800 (9.08973 iter/s, 11.0014s/100 iters), loss = 0.0246385
I0822 18:35:46.077247 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0246382 (* 1 = 0.0246382 loss)
I0822 18:35:46.077260 13823 sgd_solver.cpp:112] Iteration 83800, lr = 1e-05
I0822 18:35:56.965628 13823 solver.cpp:239] Iteration 83900 (9.1841 iter/s, 10.8884s/100 iters), loss = 0.0261904
I0822 18:35:56.965682 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0261901 (* 1 = 0.0261901 loss)
I0822 18:35:56.965692 13823 sgd_solver.cpp:112] Iteration 83900, lr = 1e-05
I0822 18:36:07.615406 13823 solver.cpp:239] Iteration 84000 (9.38991 iter/s, 10.6497s/100 iters), loss = 0.0317594
I0822 18:36:07.615456 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0317591 (* 1 = 0.0317591 loss)
I0822 18:36:07.615465 13823 sgd_solver.cpp:112] Iteration 84000, lr = 1e-05
I0822 18:36:18.527824 13823 solver.cpp:239] Iteration 84100 (9.16391 iter/s, 10.9124s/100 iters), loss = 0.0269823
I0822 18:36:18.527875 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.026982 (* 1 = 0.026982 loss)
I0822 18:36:18.527884 13823 sgd_solver.cpp:112] Iteration 84100, lr = 1e-05
I0822 18:36:29.246474 13823 solver.cpp:239] Iteration 84200 (9.32958 iter/s, 10.7186s/100 iters), loss = 0.0257391
I0822 18:36:29.246524 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0257388 (* 1 = 0.0257388 loss)
I0822 18:36:29.246533 13823 sgd_solver.cpp:112] Iteration 84200, lr = 1e-05
I0822 18:36:40.063510 13823 solver.cpp:239] Iteration 84300 (9.24472 iter/s, 10.817s/100 iters), loss = 0.025318
I0822 18:36:40.063578 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0253177 (* 1 = 0.0253177 loss)
I0822 18:36:40.063591 13823 sgd_solver.cpp:112] Iteration 84300, lr = 1e-05
I0822 18:36:51.034060 13823 solver.cpp:239] Iteration 84400 (9.11536 iter/s, 10.9705s/100 iters), loss = 0.0264965
I0822 18:36:51.034108 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0264962 (* 1 = 0.0264962 loss)
I0822 18:36:51.034117 13823 sgd_solver.cpp:112] Iteration 84400, lr = 1e-05
I0822 18:37:01.661147 13823 solver.cpp:239] Iteration 84500 (9.40996 iter/s, 10.627s/100 iters), loss = 0.038886
I0822 18:37:01.661197 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0388857 (* 1 = 0.0388857 loss)
I0822 18:37:01.661206 13823 sgd_solver.cpp:112] Iteration 84500, lr = 1e-05
I0822 18:37:12.348974 13823 solver.cpp:239] Iteration 84600 (9.35648 iter/s, 10.6878s/100 iters), loss = 0.0283953
I0822 18:37:12.349016 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.028395 (* 1 = 0.028395 loss)
I0822 18:37:12.349023 13823 sgd_solver.cpp:112] Iteration 84600, lr = 1e-05
I0822 18:37:22.881521 13823 solver.cpp:239] Iteration 84700 (9.49441 iter/s, 10.5325s/100 iters), loss = 0.0291548
I0822 18:37:22.881562 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0291545 (* 1 = 0.0291545 loss)
I0822 18:37:22.881569 13823 sgd_solver.cpp:112] Iteration 84700, lr = 1e-05
I0822 18:37:33.587352 13823 solver.cpp:239] Iteration 84800 (9.34074 iter/s, 10.7058s/100 iters), loss = 0.0243861
I0822 18:37:33.587410 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0243858 (* 1 = 0.0243858 loss)
I0822 18:37:33.587421 13823 sgd_solver.cpp:112] Iteration 84800, lr = 1e-05
I0822 18:37:44.501859 13823 solver.cpp:239] Iteration 84900 (9.16216 iter/s, 10.9145s/100 iters), loss = 0.0267089
I0822 18:37:44.501919 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0267086 (* 1 = 0.0267086 loss)
I0822 18:37:44.501930 13823 sgd_solver.cpp:112] Iteration 84900, lr = 1e-05
I0822 18:37:55.382664 13823 solver.cpp:239] Iteration 85000 (9.19054 iter/s, 10.8808s/100 iters), loss = 0.0285395
I0822 18:37:55.382725 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0285392 (* 1 = 0.0285392 loss)
I0822 18:37:55.382737 13823 sgd_solver.cpp:112] Iteration 85000, lr = 1e-05
I0822 18:38:06.372373 13823 solver.cpp:239] Iteration 85100 (9.09947 iter/s, 10.9897s/100 iters), loss = 0.0266597
I0822 18:38:06.372437 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0266594 (* 1 = 0.0266594 loss)
I0822 18:38:06.372450 13823 sgd_solver.cpp:112] Iteration 85100, lr = 1e-05
I0822 18:38:17.406960 13823 solver.cpp:239] Iteration 85200 (9.06246 iter/s, 11.0345s/100 iters), loss = 0.0249487
I0822 18:38:17.407017 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0249484 (* 1 = 0.0249484 loss)
I0822 18:38:17.407028 13823 sgd_solver.cpp:112] Iteration 85200, lr = 1e-05
I0822 18:38:28.354332 13823 solver.cpp:239] Iteration 85300 (9.13466 iter/s, 10.9473s/100 iters), loss = 0.0273044
I0822 18:38:28.354382 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0273041 (* 1 = 0.0273041 loss)
I0822 18:38:28.354393 13823 sgd_solver.cpp:112] Iteration 85300, lr = 1e-05
I0822 18:38:39.093721 13823 solver.cpp:239] Iteration 85400 (9.31155 iter/s, 10.7393s/100 iters), loss = 0.0256177
I0822 18:38:39.093763 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0256174 (* 1 = 0.0256174 loss)
I0822 18:38:39.093770 13823 sgd_solver.cpp:112] Iteration 85400, lr = 1e-05
I0822 18:38:49.875787 13823 solver.cpp:239] Iteration 85500 (9.2747 iter/s, 10.782s/100 iters), loss = 0.0269208
I0822 18:38:49.875845 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0269205 (* 1 = 0.0269205 loss)
I0822 18:38:49.875855 13823 sgd_solver.cpp:112] Iteration 85500, lr = 1e-05
I0822 18:39:00.872453 13823 solver.cpp:239] Iteration 85600 (9.09371 iter/s, 10.9966s/100 iters), loss = 0.0315608
I0822 18:39:00.872517 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0315605 (* 1 = 0.0315605 loss)
I0822 18:39:00.872531 13823 sgd_solver.cpp:112] Iteration 85600, lr = 1e-05
I0822 18:39:11.924298 13823 solver.cpp:239] Iteration 85700 (9.04831 iter/s, 11.0518s/100 iters), loss = 0.027921
I0822 18:39:11.924376 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0279207 (* 1 = 0.0279207 loss)
I0822 18:39:11.924391 13823 sgd_solver.cpp:112] Iteration 85700, lr = 1e-05
I0822 18:39:23.030323 13823 solver.cpp:239] Iteration 85800 (9.00418 iter/s, 11.106s/100 iters), loss = 0.0247102
I0822 18:39:23.030373 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0247099 (* 1 = 0.0247099 loss)
I0822 18:39:23.030383 13823 sgd_solver.cpp:112] Iteration 85800, lr = 1e-05
I0822 18:39:34.069211 13823 solver.cpp:239] Iteration 85900 (9.05892 iter/s, 11.0388s/100 iters), loss = 0.0259884
I0822 18:39:34.069272 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0259881 (* 1 = 0.0259881 loss)
I0822 18:39:34.069283 13823 sgd_solver.cpp:112] Iteration 85900, lr = 1e-05
I0822 18:39:44.972648 13823 solver.cpp:239] Iteration 86000 (9.17146 iter/s, 10.9034s/100 iters), loss = 0.0268245
I0822 18:39:44.972699 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0268242 (* 1 = 0.0268242 loss)
I0822 18:39:44.972708 13823 sgd_solver.cpp:112] Iteration 86000, lr = 1e-05
I0822 18:39:55.840005 13823 solver.cpp:239] Iteration 86100 (9.20191 iter/s, 10.8673s/100 iters), loss = 0.0255982
I0822 18:39:55.840073 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0255979 (* 1 = 0.0255979 loss)
I0822 18:39:55.840090 13823 sgd_solver.cpp:112] Iteration 86100, lr = 1e-05
I0822 18:40:06.960841 13823 solver.cpp:239] Iteration 86200 (8.99218 iter/s, 11.1208s/100 iters), loss = 0.0243297
I0822 18:40:06.960902 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0243294 (* 1 = 0.0243294 loss)
I0822 18:40:06.960914 13823 sgd_solver.cpp:112] Iteration 86200, lr = 1e-05
I0822 18:40:18.282400 13823 solver.cpp:239] Iteration 86300 (8.83275 iter/s, 11.3215s/100 iters), loss = 0.038737
I0822 18:40:18.282460 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0387367 (* 1 = 0.0387367 loss)
I0822 18:40:18.282471 13823 sgd_solver.cpp:112] Iteration 86300, lr = 1e-05
I0822 18:40:29.164125 13823 solver.cpp:239] Iteration 86400 (9.18976 iter/s, 10.8817s/100 iters), loss = 0.0243018
I0822 18:40:29.164180 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0243015 (* 1 = 0.0243015 loss)
I0822 18:40:29.164189 13823 sgd_solver.cpp:112] Iteration 86400, lr = 1e-05
I0822 18:40:40.472796 13823 solver.cpp:239] Iteration 86500 (8.84281 iter/s, 11.3086s/100 iters), loss = 0.0299429
I0822 18:40:40.472856 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0299426 (* 1 = 0.0299426 loss)
I0822 18:40:40.472868 13823 sgd_solver.cpp:112] Iteration 86500, lr = 1e-05
I0822 18:40:51.540416 13823 solver.cpp:239] Iteration 86600 (9.03541 iter/s, 11.0676s/100 iters), loss = 0.0275985
I0822 18:40:51.540467 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0275982 (* 1 = 0.0275982 loss)
I0822 18:40:51.540477 13823 sgd_solver.cpp:112] Iteration 86600, lr = 1e-05
I0822 18:41:02.355455 13823 solver.cpp:239] Iteration 86700 (9.24642 iter/s, 10.815s/100 iters), loss = 0.0306102
I0822 18:41:02.355506 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0306098 (* 1 = 0.0306098 loss)
I0822 18:41:02.355516 13823 sgd_solver.cpp:112] Iteration 86700, lr = 1e-05
I0822 18:41:13.330915 13823 solver.cpp:239] Iteration 86800 (9.11127 iter/s, 10.9754s/100 iters), loss = 0.0442309
I0822 18:41:13.330957 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0442306 (* 1 = 0.0442306 loss)
I0822 18:41:13.330965 13823 sgd_solver.cpp:112] Iteration 86800, lr = 1e-05
I0822 18:41:24.559253 13823 solver.cpp:239] Iteration 86900 (8.90607 iter/s, 11.2283s/100 iters), loss = 0.0269616
I0822 18:41:24.559316 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0269612 (* 1 = 0.0269612 loss)
I0822 18:41:24.559331 13823 sgd_solver.cpp:112] Iteration 86900, lr = 1e-05
I0822 18:41:36.073220 13823 solver.cpp:239] Iteration 87000 (8.68514 iter/s, 11.5139s/100 iters), loss = 0.035417
I0822 18:41:36.073279 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0354167 (* 1 = 0.0354167 loss)
I0822 18:41:36.073293 13823 sgd_solver.cpp:112] Iteration 87000, lr = 1e-05
I0822 18:41:47.399716 13823 solver.cpp:239] Iteration 87100 (8.8289 iter/s, 11.3264s/100 iters), loss = 0.0256096
I0822 18:41:47.399777 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0256093 (* 1 = 0.0256093 loss)
I0822 18:41:47.399791 13823 sgd_solver.cpp:112] Iteration 87100, lr = 1e-05
I0822 18:41:58.587172 13823 solver.cpp:239] Iteration 87200 (8.93863 iter/s, 11.1874s/100 iters), loss = 0.0260324
I0822 18:41:58.587232 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.026032 (* 1 = 0.026032 loss)
I0822 18:41:58.587244 13823 sgd_solver.cpp:112] Iteration 87200, lr = 1e-05
I0822 18:42:09.975417 13823 solver.cpp:239] Iteration 87300 (8.78102 iter/s, 11.3882s/100 iters), loss = 0.0320473
I0822 18:42:09.975471 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.032047 (* 1 = 0.032047 loss)
I0822 18:42:09.975481 13823 sgd_solver.cpp:112] Iteration 87300, lr = 1e-05
I0822 18:42:21.421066 13823 solver.cpp:239] Iteration 87400 (8.73698 iter/s, 11.4456s/100 iters), loss = 0.027009
I0822 18:42:21.421116 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0270087 (* 1 = 0.0270087 loss)
I0822 18:42:21.421125 13823 sgd_solver.cpp:112] Iteration 87400, lr = 1e-05
I0822 18:42:32.887591 13823 solver.cpp:239] Iteration 87500 (8.72108 iter/s, 11.4665s/100 iters), loss = 0.0264481
I0822 18:42:32.887660 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0264478 (* 1 = 0.0264478 loss)
I0822 18:42:32.887672 13823 sgd_solver.cpp:112] Iteration 87500, lr = 1e-05
I0822 18:42:44.258708 13823 solver.cpp:239] Iteration 87600 (8.79426 iter/s, 11.3711s/100 iters), loss = 0.0277414
I0822 18:42:44.258769 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0277411 (* 1 = 0.0277411 loss)
I0822 18:42:44.258782 13823 sgd_solver.cpp:112] Iteration 87600, lr = 1e-05
I0822 18:42:55.645221 13823 solver.cpp:239] Iteration 87700 (8.78236 iter/s, 11.3865s/100 iters), loss = 0.0260692
I0822 18:42:55.645282 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0260689 (* 1 = 0.0260689 loss)
I0822 18:42:55.645292 13823 sgd_solver.cpp:112] Iteration 87700, lr = 1e-05
I0822 18:43:07.195884 13823 solver.cpp:239] Iteration 87800 (8.65755 iter/s, 11.5506s/100 iters), loss = 0.0302303
I0822 18:43:07.195942 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.03023 (* 1 = 0.03023 loss)
I0822 18:43:07.195953 13823 sgd_solver.cpp:112] Iteration 87800, lr = 1e-05
I0822 18:43:18.494029 13823 solver.cpp:239] Iteration 87900 (8.85105 iter/s, 11.2981s/100 iters), loss = 0.0291893
I0822 18:43:18.494088 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.029189 (* 1 = 0.029189 loss)
I0822 18:43:18.494099 13823 sgd_solver.cpp:112] Iteration 87900, lr = 1e-05
I0822 18:43:29.769979 13823 solver.cpp:239] Iteration 88000 (8.86847 iter/s, 11.2759s/100 iters), loss = 0.022347
I0822 18:43:29.770033 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0223467 (* 1 = 0.0223467 loss)
I0822 18:43:29.770043 13823 sgd_solver.cpp:112] Iteration 88000, lr = 1e-05
I0822 18:43:41.062862 13823 solver.cpp:239] Iteration 88100 (8.85517 iter/s, 11.2928s/100 iters), loss = 0.0289614
I0822 18:43:41.062911 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0289611 (* 1 = 0.0289611 loss)
I0822 18:43:41.062919 13823 sgd_solver.cpp:112] Iteration 88100, lr = 1e-05
I0822 18:43:52.349371 13823 solver.cpp:239] Iteration 88200 (8.86017 iter/s, 11.2865s/100 iters), loss = 0.027981
I0822 18:43:52.349426 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0279807 (* 1 = 0.0279807 loss)
I0822 18:43:52.349436 13823 sgd_solver.cpp:112] Iteration 88200, lr = 1e-05
I0822 18:44:03.461057 13823 solver.cpp:239] Iteration 88300 (8.99958 iter/s, 11.1116s/100 iters), loss = 0.024129
I0822 18:44:03.461118 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0241286 (* 1 = 0.0241286 loss)
I0822 18:44:03.461130 13823 sgd_solver.cpp:112] Iteration 88300, lr = 1e-05
I0822 18:44:14.911157 13823 solver.cpp:239] Iteration 88400 (8.73359 iter/s, 11.45s/100 iters), loss = 0.0292912
I0822 18:44:14.911211 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0292909 (* 1 = 0.0292909 loss)
I0822 18:44:14.911219 13823 sgd_solver.cpp:112] Iteration 88400, lr = 1e-05
I0822 18:44:26.516911 13823 solver.cpp:239] Iteration 88500 (8.61645 iter/s, 11.6057s/100 iters), loss = 0.0271067
I0822 18:44:26.516969 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0271064 (* 1 = 0.0271064 loss)
I0822 18:44:26.516980 13823 sgd_solver.cpp:112] Iteration 88500, lr = 1e-05
I0822 18:44:38.057446 13823 solver.cpp:239] Iteration 88600 (8.66515 iter/s, 11.5405s/100 iters), loss = 0.0261708
I0822 18:44:38.057500 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0261705 (* 1 = 0.0261705 loss)
I0822 18:44:38.057510 13823 sgd_solver.cpp:112] Iteration 88600, lr = 1e-05
I0822 18:44:49.570960 13823 solver.cpp:239] Iteration 88700 (8.68548 iter/s, 11.5135s/100 iters), loss = 0.0246218
I0822 18:44:49.571017 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0246215 (* 1 = 0.0246215 loss)
I0822 18:44:49.571027 13823 sgd_solver.cpp:112] Iteration 88700, lr = 1e-05
I0822 18:45:01.044937 13823 solver.cpp:239] Iteration 88800 (8.71541 iter/s, 11.4739s/100 iters), loss = 0.0284316
I0822 18:45:01.044992 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0284313 (* 1 = 0.0284313 loss)
I0822 18:45:01.045002 13823 sgd_solver.cpp:112] Iteration 88800, lr = 1e-05
I0822 18:45:12.601761 13823 solver.cpp:239] Iteration 88900 (8.65293 iter/s, 11.5568s/100 iters), loss = 0.0250061
I0822 18:45:12.601816 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0250058 (* 1 = 0.0250058 loss)
I0822 18:45:12.601826 13823 sgd_solver.cpp:112] Iteration 88900, lr = 1e-05
I0822 18:45:24.023471 13823 solver.cpp:239] Iteration 89000 (8.75531 iter/s, 11.4216s/100 iters), loss = 0.0224337
I0822 18:45:24.023532 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0224334 (* 1 = 0.0224334 loss)
I0822 18:45:24.023543 13823 sgd_solver.cpp:112] Iteration 89000, lr = 1e-05
I0822 18:45:35.523126 13823 solver.cpp:239] Iteration 89100 (8.69595 iter/s, 11.4996s/100 iters), loss = 0.028271
I0822 18:45:35.523180 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0282707 (* 1 = 0.0282707 loss)
I0822 18:45:35.523190 13823 sgd_solver.cpp:112] Iteration 89100, lr = 1e-05
I0822 18:45:47.304996 13823 solver.cpp:239] Iteration 89200 (8.48765 iter/s, 11.7818s/100 iters), loss = 0.0241497
I0822 18:45:47.305047 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0241494 (* 1 = 0.0241494 loss)
I0822 18:45:47.305055 13823 sgd_solver.cpp:112] Iteration 89200, lr = 1e-05
I0822 18:45:58.854513 13823 solver.cpp:239] Iteration 89300 (8.6584 iter/s, 11.5495s/100 iters), loss = 0.0374916
I0822 18:45:58.854565 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0374913 (* 1 = 0.0374913 loss)
I0822 18:45:58.854574 13823 sgd_solver.cpp:112] Iteration 89300, lr = 1e-05
I0822 18:46:10.125434 13823 solver.cpp:239] Iteration 89400 (8.87243 iter/s, 11.2709s/100 iters), loss = 0.0268818
I0822 18:46:10.125488 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0268816 (* 1 = 0.0268816 loss)
I0822 18:46:10.125497 13823 sgd_solver.cpp:112] Iteration 89400, lr = 1e-05
I0822 18:46:21.336004 13823 solver.cpp:239] Iteration 89500 (8.92019 iter/s, 11.2105s/100 iters), loss = 0.0247159
I0822 18:46:21.336058 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0247156 (* 1 = 0.0247156 loss)
I0822 18:46:21.336068 13823 sgd_solver.cpp:112] Iteration 89500, lr = 1e-05
I0822 18:46:33.126801 13823 solver.cpp:239] Iteration 89600 (8.48123 iter/s, 11.7907s/100 iters), loss = 0.0269772
I0822 18:46:33.126855 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.026977 (* 1 = 0.026977 loss)
I0822 18:46:33.126865 13823 sgd_solver.cpp:112] Iteration 89600, lr = 1e-05
I0822 18:46:44.927168 13823 solver.cpp:239] Iteration 89700 (8.47435 iter/s, 11.8003s/100 iters), loss = 0.0335098
I0822 18:46:44.927220 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0335095 (* 1 = 0.0335095 loss)
I0822 18:46:44.927230 13823 sgd_solver.cpp:112] Iteration 89700, lr = 1e-05
I0822 18:46:56.474241 13823 solver.cpp:239] Iteration 89800 (8.66024 iter/s, 11.547s/100 iters), loss = 0.0247793
I0822 18:46:56.474303 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0247791 (* 1 = 0.0247791 loss)
I0822 18:46:56.474315 13823 sgd_solver.cpp:112] Iteration 89800, lr = 1e-05
I0822 18:47:08.062402 13823 solver.cpp:239] Iteration 89900 (8.62954 iter/s, 11.5881s/100 iters), loss = 0.0231034
I0822 18:47:08.062460 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0231032 (* 1 = 0.0231032 loss)
I0822 18:47:08.062471 13823 sgd_solver.cpp:112] Iteration 89900, lr = 1e-05
I0822 18:47:19.475293 13823 solver.cpp:239] Iteration 90000 (8.76206 iter/s, 11.4128s/100 iters), loss = 0.0243688
I0822 18:47:19.475345 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0243686 (* 1 = 0.0243686 loss)
I0822 18:47:19.475354 13823 sgd_solver.cpp:112] Iteration 90000, lr = 1e-05
I0822 18:47:30.931953 13823 solver.cpp:239] Iteration 90100 (8.72858 iter/s, 11.4566s/100 iters), loss = 0.0283452
I0822 18:47:30.932008 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0283449 (* 1 = 0.0283449 loss)
I0822 18:47:30.932018 13823 sgd_solver.cpp:112] Iteration 90100, lr = 1e-05
I0822 18:47:42.511409 13823 solver.cpp:239] Iteration 90200 (8.63602 iter/s, 11.5794s/100 iters), loss = 0.0289736
I0822 18:47:42.511466 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0289733 (* 1 = 0.0289733 loss)
I0822 18:47:42.511477 13823 sgd_solver.cpp:112] Iteration 90200, lr = 1e-05
I0822 18:47:53.861954 13823 solver.cpp:239] Iteration 90300 (8.81019 iter/s, 11.3505s/100 iters), loss = 0.0313115
I0822 18:47:53.862008 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0313113 (* 1 = 0.0313113 loss)
I0822 18:47:53.862018 13823 sgd_solver.cpp:112] Iteration 90300, lr = 1e-05
I0822 18:48:05.308369 13823 solver.cpp:239] Iteration 90400 (8.7364 iter/s, 11.4464s/100 iters), loss = 0.0312296
I0822 18:48:05.308421 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0312293 (* 1 = 0.0312293 loss)
I0822 18:48:05.308430 13823 sgd_solver.cpp:112] Iteration 90400, lr = 1e-05
I0822 18:48:16.735435 13823 solver.cpp:239] Iteration 90500 (8.75119 iter/s, 11.427s/100 iters), loss = 0.0316998
I0822 18:48:16.735492 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0316996 (* 1 = 0.0316996 loss)
I0822 18:48:16.735503 13823 sgd_solver.cpp:112] Iteration 90500, lr = 1e-05
I0822 18:48:28.358484 13823 solver.cpp:239] Iteration 90600 (8.60363 iter/s, 11.623s/100 iters), loss = 0.0299861
I0822 18:48:28.358541 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0299858 (* 1 = 0.0299858 loss)
I0822 18:48:28.358551 13823 sgd_solver.cpp:112] Iteration 90600, lr = 1e-05
I0822 18:48:40.132742 13823 solver.cpp:239] Iteration 90700 (8.49314 iter/s, 11.7742s/100 iters), loss = 0.0260261
I0822 18:48:40.132802 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0260259 (* 1 = 0.0260259 loss)
I0822 18:48:40.132812 13823 sgd_solver.cpp:112] Iteration 90700, lr = 1e-05
I0822 18:48:51.833153 13823 solver.cpp:239] Iteration 90800 (8.54675 iter/s, 11.7004s/100 iters), loss = 0.0259667
I0822 18:48:51.833205 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0259665 (* 1 = 0.0259665 loss)
I0822 18:48:51.833214 13823 sgd_solver.cpp:112] Iteration 90800, lr = 1e-05
I0822 18:49:03.372448 13823 solver.cpp:239] Iteration 90900 (8.66608 iter/s, 11.5392s/100 iters), loss = 0.0259056
I0822 18:49:03.372507 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0259053 (* 1 = 0.0259053 loss)
I0822 18:49:03.372519 13823 sgd_solver.cpp:112] Iteration 90900, lr = 1e-05
I0822 18:49:15.256799 13823 solver.cpp:239] Iteration 91000 (8.41446 iter/s, 11.8843s/100 iters), loss = 0.0267568
I0822 18:49:15.256853 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0267565 (* 1 = 0.0267565 loss)
I0822 18:49:15.256863 13823 sgd_solver.cpp:112] Iteration 91000, lr = 1e-05
I0822 18:49:27.202283 13823 solver.cpp:239] Iteration 91100 (8.3714 iter/s, 11.9454s/100 iters), loss = 0.027085
I0822 18:49:27.202343 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0270848 (* 1 = 0.0270848 loss)
I0822 18:49:27.202355 13823 sgd_solver.cpp:112] Iteration 91100, lr = 1e-05
I0822 18:49:38.936609 13823 solver.cpp:239] Iteration 91200 (8.52205 iter/s, 11.7343s/100 iters), loss = 0.0292176
I0822 18:49:38.936661 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0292173 (* 1 = 0.0292173 loss)
I0822 18:49:38.936671 13823 sgd_solver.cpp:112] Iteration 91200, lr = 1e-05
I0822 18:49:50.332173 13823 solver.cpp:239] Iteration 91300 (8.77538 iter/s, 11.3955s/100 iters), loss = 0.0276635
I0822 18:49:50.332224 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0276632 (* 1 = 0.0276632 loss)
I0822 18:49:50.332234 13823 sgd_solver.cpp:112] Iteration 91300, lr = 1e-05
I0822 18:49:59.625977 13823 solver.cpp:239] Iteration 91400 (10.7599 iter/s, 9.29375s/100 iters), loss = 0.0292924
I0822 18:49:59.626035 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0292921 (* 1 = 0.0292921 loss)
I0822 18:49:59.626049 13823 sgd_solver.cpp:112] Iteration 91400, lr = 1e-05
I0822 18:50:09.375638 13823 solver.cpp:239] Iteration 91500 (10.2568 iter/s, 9.74961s/100 iters), loss = 0.0270295
I0822 18:50:09.375691 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0270292 (* 1 = 0.0270292 loss)
I0822 18:50:09.375705 13823 sgd_solver.cpp:112] Iteration 91500, lr = 1e-05
I0822 18:50:19.063725 13823 solver.cpp:239] Iteration 91600 (10.322 iter/s, 9.68804s/100 iters), loss = 0.0292949
I0822 18:50:19.063779 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0292946 (* 1 = 0.0292946 loss)
I0822 18:50:19.063789 13823 sgd_solver.cpp:112] Iteration 91600, lr = 1e-05
I0822 18:50:28.575222 13823 solver.cpp:239] Iteration 91700 (10.5137 iter/s, 9.51144s/100 iters), loss = 0.0277227
I0822 18:50:28.575274 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0277224 (* 1 = 0.0277224 loss)
I0822 18:50:28.575284 13823 sgd_solver.cpp:112] Iteration 91700, lr = 1e-05
I0822 18:50:38.351644 13823 solver.cpp:239] Iteration 91800 (10.2287 iter/s, 9.77637s/100 iters), loss = 0.0250871
I0822 18:50:38.351696 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0250868 (* 1 = 0.0250868 loss)
I0822 18:50:38.351706 13823 sgd_solver.cpp:112] Iteration 91800, lr = 1e-05
I0822 18:50:47.931054 13823 solver.cpp:239] Iteration 91900 (10.4391 iter/s, 9.57936s/100 iters), loss = 0.0267811
I0822 18:50:47.931109 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0267808 (* 1 = 0.0267808 loss)
I0822 18:50:47.931120 13823 sgd_solver.cpp:112] Iteration 91900, lr = 1e-05
I0822 18:50:57.654531 13823 solver.cpp:239] Iteration 92000 (10.2844 iter/s, 9.72342s/100 iters), loss = 0.0301075
I0822 18:50:57.654582 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0301073 (* 1 = 0.0301073 loss)
I0822 18:50:57.654590 13823 sgd_solver.cpp:112] Iteration 92000, lr = 1e-05
I0822 18:51:07.184068 13823 solver.cpp:239] Iteration 92100 (10.4937 iter/s, 9.5295s/100 iters), loss = 0.0289501
I0822 18:51:07.184109 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0289498 (* 1 = 0.0289498 loss)
I0822 18:51:07.184118 13823 sgd_solver.cpp:112] Iteration 92100, lr = 1e-05
I0822 18:51:17.033016 13823 solver.cpp:239] Iteration 92200 (10.1534 iter/s, 9.84891s/100 iters), loss = 0.0290066
I0822 18:51:17.033071 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0290064 (* 1 = 0.0290064 loss)
I0822 18:51:17.033083 13823 sgd_solver.cpp:112] Iteration 92200, lr = 1e-05
I0822 18:51:26.549180 13823 solver.cpp:239] Iteration 92300 (10.5085 iter/s, 9.51611s/100 iters), loss = 0.0264524
I0822 18:51:26.549228 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0264522 (* 1 = 0.0264522 loss)
I0822 18:51:26.549237 13823 sgd_solver.cpp:112] Iteration 92300, lr = 1e-05
I0822 18:51:36.186628 13823 solver.cpp:239] Iteration 92400 (10.3762 iter/s, 9.63741s/100 iters), loss = 0.0294036
I0822 18:51:36.186669 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0294033 (* 1 = 0.0294033 loss)
I0822 18:51:36.186677 13823 sgd_solver.cpp:112] Iteration 92400, lr = 1e-05
I0822 18:51:45.619709 13823 solver.cpp:239] Iteration 92500 (10.601 iter/s, 9.43304s/100 iters), loss = 0.0310753
I0822 18:51:45.619761 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.031075 (* 1 = 0.031075 loss)
I0822 18:51:45.619772 13823 sgd_solver.cpp:112] Iteration 92500, lr = 1e-05
I0822 18:51:55.563319 13823 solver.cpp:239] Iteration 92600 (10.0568 iter/s, 9.94356s/100 iters), loss = 0.0265063
I0822 18:51:55.563370 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.026506 (* 1 = 0.026506 loss)
I0822 18:51:55.563378 13823 sgd_solver.cpp:112] Iteration 92600, lr = 1e-05
I0822 18:52:04.951800 13823 solver.cpp:239] Iteration 92700 (10.6514 iter/s, 9.38843s/100 iters), loss = 0.0300767
I0822 18:52:04.951853 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0300765 (* 1 = 0.0300765 loss)
I0822 18:52:04.951861 13823 sgd_solver.cpp:112] Iteration 92700, lr = 1e-05
I0822 18:52:14.704300 13823 solver.cpp:239] Iteration 92800 (10.2538 iter/s, 9.75245s/100 iters), loss = 0.0525233
I0822 18:52:14.704354 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.052523 (* 1 = 0.052523 loss)
I0822 18:52:14.704362 13823 sgd_solver.cpp:112] Iteration 92800, lr = 1e-05
I0822 18:52:24.241822 13823 solver.cpp:239] Iteration 92900 (10.485 iter/s, 9.53747s/100 iters), loss = 0.0306887
I0822 18:52:24.241874 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0306884 (* 1 = 0.0306884 loss)
I0822 18:52:24.241883 13823 sgd_solver.cpp:112] Iteration 92900, lr = 1e-05
I0822 18:52:34.056434 13823 solver.cpp:239] Iteration 93000 (10.1889 iter/s, 9.81456s/100 iters), loss = 0.0271206
I0822 18:52:34.056483 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0271203 (* 1 = 0.0271203 loss)
I0822 18:52:34.056491 13823 sgd_solver.cpp:112] Iteration 93000, lr = 1e-05
I0822 18:52:43.877805 13823 solver.cpp:239] Iteration 93100 (10.1819 iter/s, 9.82132s/100 iters), loss = 0.0274032
I0822 18:52:43.877856 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0274029 (* 1 = 0.0274029 loss)
I0822 18:52:43.877866 13823 sgd_solver.cpp:112] Iteration 93100, lr = 1e-05
I0822 18:52:53.678602 13823 solver.cpp:239] Iteration 93200 (10.2033 iter/s, 9.80075s/100 iters), loss = 0.0293545
I0822 18:52:53.678653 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0293543 (* 1 = 0.0293543 loss)
I0822 18:52:53.678663 13823 sgd_solver.cpp:112] Iteration 93200, lr = 1e-05
I0822 18:53:03.213755 13823 solver.cpp:239] Iteration 93300 (10.4876 iter/s, 9.5351s/100 iters), loss = 0.0289229
I0822 18:53:03.213806 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0289227 (* 1 = 0.0289227 loss)
I0822 18:53:03.213815 13823 sgd_solver.cpp:112] Iteration 93300, lr = 1e-05
I0822 18:53:12.766947 13823 solver.cpp:239] Iteration 93400 (10.4678 iter/s, 9.55314s/100 iters), loss = 0.0418623
I0822 18:53:12.767002 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.041862 (* 1 = 0.041862 loss)
I0822 18:53:12.767012 13823 sgd_solver.cpp:112] Iteration 93400, lr = 1e-05
I0822 18:53:22.642527 13823 solver.cpp:239] Iteration 93500 (10.126 iter/s, 9.87553s/100 iters), loss = 0.035874
I0822 18:53:22.642586 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0358738 (* 1 = 0.0358738 loss)
I0822 18:53:22.642597 13823 sgd_solver.cpp:112] Iteration 93500, lr = 1e-05
I0822 18:53:32.699877 13823 solver.cpp:239] Iteration 93600 (9.94303 iter/s, 10.0573s/100 iters), loss = 0.0267411
I0822 18:53:32.699928 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0267408 (* 1 = 0.0267408 loss)
I0822 18:53:32.699937 13823 sgd_solver.cpp:112] Iteration 93600, lr = 1e-05
I0822 18:53:42.123293 13823 solver.cpp:239] Iteration 93700 (10.6118 iter/s, 9.42351s/100 iters), loss = 0.0256902
I0822 18:53:42.123342 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.02569 (* 1 = 0.02569 loss)
I0822 18:53:42.123350 13823 sgd_solver.cpp:112] Iteration 93700, lr = 1e-05
I0822 18:53:51.780994 13823 solver.cpp:239] Iteration 93800 (10.3543 iter/s, 9.65782s/100 iters), loss = 0.0274565
I0822 18:53:51.781044 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0274563 (* 1 = 0.0274563 loss)
I0822 18:53:51.781052 13823 sgd_solver.cpp:112] Iteration 93800, lr = 1e-05
I0822 18:54:01.460034 13823 solver.cpp:239] Iteration 93900 (10.3315 iter/s, 9.67915s/100 iters), loss = 0.0369466
I0822 18:54:01.460086 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0369464 (* 1 = 0.0369464 loss)
I0822 18:54:01.460095 13823 sgd_solver.cpp:112] Iteration 93900, lr = 1e-05
I0822 18:54:11.279045 13823 solver.cpp:239] Iteration 94000 (10.1842 iter/s, 9.81912s/100 iters), loss = 0.0305214
I0822 18:54:11.279101 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0305212 (* 1 = 0.0305212 loss)
I0822 18:54:11.279111 13823 sgd_solver.cpp:112] Iteration 94000, lr = 1e-05
I0822 18:54:20.940387 13823 solver.cpp:239] Iteration 94100 (10.3504 iter/s, 9.66144s/100 iters), loss = 0.0326204
I0822 18:54:20.940438 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0326201 (* 1 = 0.0326201 loss)
I0822 18:54:20.940446 13823 sgd_solver.cpp:112] Iteration 94100, lr = 1e-05
I0822 18:54:30.817389 13823 solver.cpp:239] Iteration 94200 (10.1244 iter/s, 9.87711s/100 iters), loss = 0.0251514
I0822 18:54:30.817454 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0251512 (* 1 = 0.0251512 loss)
I0822 18:54:30.817467 13823 sgd_solver.cpp:112] Iteration 94200, lr = 1e-05
I0822 18:54:40.500977 13823 solver.cpp:239] Iteration 94300 (10.3267 iter/s, 9.68367s/100 iters), loss = 0.0348991
I0822 18:54:40.501039 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0348989 (* 1 = 0.0348989 loss)
I0822 18:54:40.501050 13823 sgd_solver.cpp:112] Iteration 94300, lr = 1e-05
I0822 18:54:50.392907 13823 solver.cpp:239] Iteration 94400 (10.1092 iter/s, 9.89202s/100 iters), loss = 0.0272418
I0822 18:54:50.392958 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0272416 (* 1 = 0.0272416 loss)
I0822 18:54:50.392967 13823 sgd_solver.cpp:112] Iteration 94400, lr = 1e-05
I0822 18:54:59.882658 13823 solver.cpp:239] Iteration 94500 (10.5376 iter/s, 9.48984s/100 iters), loss = 0.0261749
I0822 18:54:59.882706 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0261747 (* 1 = 0.0261747 loss)
I0822 18:54:59.882715 13823 sgd_solver.cpp:112] Iteration 94500, lr = 1e-05
I0822 18:55:09.691519 13823 solver.cpp:239] Iteration 94600 (10.1948 iter/s, 9.80896s/100 iters), loss = 0.0364322
I0822 18:55:09.691572 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0364319 (* 1 = 0.0364319 loss)
I0822 18:55:09.691581 13823 sgd_solver.cpp:112] Iteration 94600, lr = 1e-05
I0822 18:55:19.602480 13823 solver.cpp:239] Iteration 94700 (10.0897 iter/s, 9.91105s/100 iters), loss = 0.0310667
I0822 18:55:19.602532 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0310664 (* 1 = 0.0310664 loss)
I0822 18:55:19.602541 13823 sgd_solver.cpp:112] Iteration 94700, lr = 1e-05
I0822 18:55:29.291162 13823 solver.cpp:239] Iteration 94800 (10.3212 iter/s, 9.68877s/100 iters), loss = 0.0267214
I0822 18:55:29.291216 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0267211 (* 1 = 0.0267211 loss)
I0822 18:55:29.291225 13823 sgd_solver.cpp:112] Iteration 94800, lr = 1e-05
I0822 18:55:39.218663 13823 solver.cpp:239] Iteration 94900 (10.0729 iter/s, 9.92759s/100 iters), loss = 0.0277828
I0822 18:55:39.218717 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0277826 (* 1 = 0.0277826 loss)
I0822 18:55:39.218726 13823 sgd_solver.cpp:112] Iteration 94900, lr = 1e-05
I0822 18:55:49.194624 13823 solver.cpp:239] Iteration 95000 (10.024 iter/s, 9.97605s/100 iters), loss = 0.0259977
I0822 18:55:49.194676 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0259974 (* 1 = 0.0259974 loss)
I0822 18:55:49.194686 13823 sgd_solver.cpp:112] Iteration 95000, lr = 1e-05
I0822 18:55:58.823217 13823 solver.cpp:239] Iteration 95100 (10.3856 iter/s, 9.62867s/100 iters), loss = 0.0268689
I0822 18:55:58.823274 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0268686 (* 1 = 0.0268686 loss)
I0822 18:55:58.823287 13823 sgd_solver.cpp:112] Iteration 95100, lr = 1e-05
I0822 18:56:08.751320 13823 solver.cpp:239] Iteration 95200 (10.0723 iter/s, 9.92818s/100 iters), loss = 0.0281989
I0822 18:56:08.751377 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0281986 (* 1 = 0.0281986 loss)
I0822 18:56:08.751389 13823 sgd_solver.cpp:112] Iteration 95200, lr = 1e-05
I0822 18:56:18.454165 13823 solver.cpp:239] Iteration 95300 (10.3062 iter/s, 9.70292s/100 iters), loss = 0.0339255
I0822 18:56:18.454214 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0339253 (* 1 = 0.0339253 loss)
I0822 18:56:18.454224 13823 sgd_solver.cpp:112] Iteration 95300, lr = 1e-05
I0822 18:56:28.155488 13823 solver.cpp:239] Iteration 95400 (10.3078 iter/s, 9.7014s/100 iters), loss = 0.0309227
I0822 18:56:28.155547 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0309224 (* 1 = 0.0309224 loss)
I0822 18:56:28.155561 13823 sgd_solver.cpp:112] Iteration 95400, lr = 1e-05
I0822 18:56:37.850464 13823 solver.cpp:239] Iteration 95500 (10.3145 iter/s, 9.69505s/100 iters), loss = 0.0251647
I0822 18:56:37.850518 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0251644 (* 1 = 0.0251644 loss)
I0822 18:56:37.850528 13823 sgd_solver.cpp:112] Iteration 95500, lr = 1e-05
I0822 18:56:47.835537 13823 solver.cpp:239] Iteration 95600 (10.0149 iter/s, 9.98515s/100 iters), loss = 0.0352488
I0822 18:56:47.835588 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0352486 (* 1 = 0.0352486 loss)
I0822 18:56:47.835597 13823 sgd_solver.cpp:112] Iteration 95600, lr = 1e-05
I0822 18:56:57.772320 13823 solver.cpp:239] Iteration 95700 (10.0635 iter/s, 9.93686s/100 iters), loss = 0.0356867
I0822 18:56:57.772372 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0356864 (* 1 = 0.0356864 loss)
I0822 18:56:57.772382 13823 sgd_solver.cpp:112] Iteration 95700, lr = 1e-05
I0822 18:57:07.466449 13823 solver.cpp:239] Iteration 95800 (10.3154 iter/s, 9.6942s/100 iters), loss = 0.0282214
I0822 18:57:07.466496 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0282211 (* 1 = 0.0282211 loss)
I0822 18:57:07.466506 13823 sgd_solver.cpp:112] Iteration 95800, lr = 1e-05
I0822 18:57:17.371774 13823 solver.cpp:239] Iteration 95900 (10.0955 iter/s, 9.9054s/100 iters), loss = 0.0271442
I0822 18:57:17.371826 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0271439 (* 1 = 0.0271439 loss)
I0822 18:57:17.371835 13823 sgd_solver.cpp:112] Iteration 95900, lr = 1e-05
I0822 18:57:27.139227 13823 solver.cpp:239] Iteration 96000 (10.238 iter/s, 9.76752s/100 iters), loss = 0.0275303
I0822 18:57:27.139277 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.02753 (* 1 = 0.02753 loss)
I0822 18:57:27.139286 13823 sgd_solver.cpp:112] Iteration 96000, lr = 1e-05
I0822 18:57:37.188766 13823 solver.cpp:239] Iteration 96100 (9.95064 iter/s, 10.0496s/100 iters), loss = 0.0283293
I0822 18:57:37.188818 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0283291 (* 1 = 0.0283291 loss)
I0822 18:57:37.188827 13823 sgd_solver.cpp:112] Iteration 96100, lr = 1e-05
I0822 18:57:47.016304 13823 solver.cpp:239] Iteration 96200 (10.1754 iter/s, 9.8276s/100 iters), loss = 0.0268204
I0822 18:57:47.016360 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0268201 (* 1 = 0.0268201 loss)
I0822 18:57:47.016373 13823 sgd_solver.cpp:112] Iteration 96200, lr = 1e-05
I0822 18:57:57.039075 13823 solver.cpp:239] Iteration 96300 (9.97723 iter/s, 10.0228s/100 iters), loss = 0.0269406
I0822 18:57:57.039121 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0269404 (* 1 = 0.0269404 loss)
I0822 18:57:57.039130 13823 sgd_solver.cpp:112] Iteration 96300, lr = 1e-05
I0822 18:58:06.969933 13823 solver.cpp:239] Iteration 96400 (10.0696 iter/s, 9.93092s/100 iters), loss = 0.0317327
I0822 18:58:06.969985 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0317324 (* 1 = 0.0317324 loss)
I0822 18:58:06.969993 13823 sgd_solver.cpp:112] Iteration 96400, lr = 1e-05
I0822 18:58:16.927281 13823 solver.cpp:239] Iteration 96500 (10.0428 iter/s, 9.95741s/100 iters), loss = 0.0352694
I0822 18:58:16.927335 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0352691 (* 1 = 0.0352691 loss)
I0822 18:58:16.927345 13823 sgd_solver.cpp:112] Iteration 96500, lr = 1e-05
I0822 18:58:26.996081 13823 solver.cpp:239] Iteration 96600 (9.93161 iter/s, 10.0689s/100 iters), loss = 0.0232856
I0822 18:58:26.996137 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0232853 (* 1 = 0.0232853 loss)
I0822 18:58:26.996147 13823 sgd_solver.cpp:112] Iteration 96600, lr = 1e-05
I0822 18:58:36.876698 13823 solver.cpp:239] Iteration 96700 (10.1208 iter/s, 9.88066s/100 iters), loss = 0.0270398
I0822 18:58:36.876773 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0270395 (* 1 = 0.0270395 loss)
I0822 18:58:36.876785 13823 sgd_solver.cpp:112] Iteration 96700, lr = 1e-05
I0822 18:58:46.966354 13823 solver.cpp:239] Iteration 96800 (9.91111 iter/s, 10.0897s/100 iters), loss = 0.0281442
I0822 18:58:46.966403 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0281439 (* 1 = 0.0281439 loss)
I0822 18:58:46.966413 13823 sgd_solver.cpp:112] Iteration 96800, lr = 1e-05
I0822 18:58:56.884977 13823 solver.cpp:239] Iteration 96900 (10.082 iter/s, 9.91868s/100 iters), loss = 0.0472888
I0822 18:58:56.885028 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0472885 (* 1 = 0.0472885 loss)
I0822 18:58:56.885037 13823 sgd_solver.cpp:112] Iteration 96900, lr = 1e-05
I0822 18:59:06.790359 13823 solver.cpp:239] Iteration 97000 (10.0955 iter/s, 9.90543s/100 iters), loss = 0.0272993
I0822 18:59:06.790410 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.027299 (* 1 = 0.027299 loss)
I0822 18:59:06.790419 13823 sgd_solver.cpp:112] Iteration 97000, lr = 1e-05
I0822 18:59:16.947623 13823 solver.cpp:239] Iteration 97100 (9.84512 iter/s, 10.1573s/100 iters), loss = 0.0372697
I0822 18:59:16.947671 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0372694 (* 1 = 0.0372694 loss)
I0822 18:59:16.947681 13823 sgd_solver.cpp:112] Iteration 97100, lr = 1e-05
I0822 18:59:26.764022 13823 solver.cpp:239] Iteration 97200 (10.187 iter/s, 9.81644s/100 iters), loss = 0.0344197
I0822 18:59:26.764077 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0344194 (* 1 = 0.0344194 loss)
I0822 18:59:26.764087 13823 sgd_solver.cpp:112] Iteration 97200, lr = 1e-05
I0822 18:59:36.585633 13823 solver.cpp:239] Iteration 97300 (10.1816 iter/s, 9.82165s/100 iters), loss = 0.0279025
I0822 18:59:36.585685 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0279022 (* 1 = 0.0279022 loss)
I0822 18:59:36.585695 13823 sgd_solver.cpp:112] Iteration 97300, lr = 1e-05
I0822 18:59:46.647553 13823 solver.cpp:239] Iteration 97400 (9.93842 iter/s, 10.062s/100 iters), loss = 0.0232955
I0822 18:59:46.647605 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0232953 (* 1 = 0.0232953 loss)
I0822 18:59:46.647614 13823 sgd_solver.cpp:112] Iteration 97400, lr = 1e-05
I0822 18:59:56.732759 13823 solver.cpp:239] Iteration 97500 (9.91547 iter/s, 10.0852s/100 iters), loss = 0.276743
I0822 18:59:56.732810 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.276743 (* 1 = 0.276743 loss)
I0822 18:59:56.732818 13823 sgd_solver.cpp:112] Iteration 97500, lr = 1e-05
I0822 19:00:06.988229 13823 solver.cpp:239] Iteration 97600 (9.75085 iter/s, 10.2555s/100 iters), loss = 0.0256028
I0822 19:00:06.988281 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0256025 (* 1 = 0.0256025 loss)
I0822 19:00:06.988289 13823 sgd_solver.cpp:112] Iteration 97600, lr = 1e-05
I0822 19:00:17.045166 13823 solver.cpp:239] Iteration 97700 (9.94334 iter/s, 10.057s/100 iters), loss = 0.0236248
I0822 19:00:17.045217 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0236245 (* 1 = 0.0236245 loss)
I0822 19:00:17.045226 13823 sgd_solver.cpp:112] Iteration 97700, lr = 1e-05
I0822 19:00:26.924059 13823 solver.cpp:239] Iteration 97800 (10.1226 iter/s, 9.87893s/100 iters), loss = 0.0243801
I0822 19:00:26.924111 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0243798 (* 1 = 0.0243798 loss)
I0822 19:00:26.924120 13823 sgd_solver.cpp:112] Iteration 97800, lr = 1e-05
I0822 19:00:36.877377 13823 solver.cpp:239] Iteration 97900 (10.0469 iter/s, 9.95335s/100 iters), loss = 0.0350125
I0822 19:00:36.877427 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0350122 (* 1 = 0.0350122 loss)
I0822 19:00:36.877436 13823 sgd_solver.cpp:112] Iteration 97900, lr = 1e-05
I0822 19:00:46.944849 13823 solver.cpp:239] Iteration 98000 (9.93294 iter/s, 10.0675s/100 iters), loss = 0.0381069
I0822 19:00:46.944900 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0381066 (* 1 = 0.0381066 loss)
I0822 19:00:46.944909 13823 sgd_solver.cpp:112] Iteration 98000, lr = 1e-05
I0822 19:00:56.944329 13823 solver.cpp:239] Iteration 98100 (10.0005 iter/s, 9.99952s/100 iters), loss = 0.0253004
I0822 19:00:56.944380 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0253001 (* 1 = 0.0253001 loss)
I0822 19:00:56.944389 13823 sgd_solver.cpp:112] Iteration 98100, lr = 1e-05
I0822 19:01:07.250748 13823 solver.cpp:239] Iteration 98200 (9.70266 iter/s, 10.3065s/100 iters), loss = 0.0269004
I0822 19:01:07.250800 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0269001 (* 1 = 0.0269001 loss)
I0822 19:01:07.250810 13823 sgd_solver.cpp:112] Iteration 98200, lr = 1e-05
I0822 19:01:17.287956 13823 solver.cpp:239] Iteration 98300 (9.9629 iter/s, 10.0372s/100 iters), loss = 0.0250713
I0822 19:01:17.288007 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.025071 (* 1 = 0.025071 loss)
I0822 19:01:17.288017 13823 sgd_solver.cpp:112] Iteration 98300, lr = 1e-05
I0822 19:01:27.641680 13823 solver.cpp:239] Iteration 98400 (9.65833 iter/s, 10.3538s/100 iters), loss = 0.0280942
I0822 19:01:27.641741 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0280939 (* 1 = 0.0280939 loss)
I0822 19:01:27.641752 13823 sgd_solver.cpp:112] Iteration 98400, lr = 1e-05
I0822 19:01:37.767848 13823 solver.cpp:239] Iteration 98500 (9.87538 iter/s, 10.1262s/100 iters), loss = 0.0259447
I0822 19:01:37.767899 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0259444 (* 1 = 0.0259444 loss)
I0822 19:01:37.767910 13823 sgd_solver.cpp:112] Iteration 98500, lr = 1e-05
I0822 19:01:47.976603 13823 solver.cpp:239] Iteration 98600 (9.79548 iter/s, 10.2088s/100 iters), loss = 0.0313
I0822 19:01:47.976660 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0312997 (* 1 = 0.0312997 loss)
I0822 19:01:47.976671 13823 sgd_solver.cpp:112] Iteration 98600, lr = 1e-05
I0822 19:01:57.902326 13823 solver.cpp:239] Iteration 98700 (10.0748 iter/s, 9.92575s/100 iters), loss = 0.0239033
I0822 19:01:57.902379 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.023903 (* 1 = 0.023903 loss)
I0822 19:01:57.902390 13823 sgd_solver.cpp:112] Iteration 98700, lr = 1e-05
I0822 19:02:08.201128 13823 solver.cpp:239] Iteration 98800 (9.70984 iter/s, 10.2988s/100 iters), loss = 0.0231015
I0822 19:02:08.201180 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0231012 (* 1 = 0.0231012 loss)
I0822 19:02:08.201189 13823 sgd_solver.cpp:112] Iteration 98800, lr = 1e-05
I0822 19:02:18.127131 13823 solver.cpp:239] Iteration 98900 (10.0745 iter/s, 9.92603s/100 iters), loss = 0.0275041
I0822 19:02:18.127188 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0275039 (* 1 = 0.0275039 loss)
I0822 19:02:18.127202 13823 sgd_solver.cpp:112] Iteration 98900, lr = 1e-05
I0822 19:02:28.083037 13823 solver.cpp:239] Iteration 99000 (10.0443 iter/s, 9.95593s/100 iters), loss = 0.0282821
I0822 19:02:28.083088 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0282818 (* 1 = 0.0282818 loss)
I0822 19:02:28.083097 13823 sgd_solver.cpp:112] Iteration 99000, lr = 1e-05
I0822 19:02:38.355208 13823 solver.cpp:239] Iteration 99100 (9.73501 iter/s, 10.2722s/100 iters), loss = 0.0253305
I0822 19:02:38.355260 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0253302 (* 1 = 0.0253302 loss)
I0822 19:02:38.355270 13823 sgd_solver.cpp:112] Iteration 99100, lr = 1e-05
I0822 19:02:48.602643 13823 solver.cpp:239] Iteration 99200 (9.75852 iter/s, 10.2475s/100 iters), loss = 0.0253962
I0822 19:02:48.602700 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0253959 (* 1 = 0.0253959 loss)
I0822 19:02:48.602711 13823 sgd_solver.cpp:112] Iteration 99200, lr = 1e-05
I0822 19:02:58.996850 13823 solver.cpp:239] Iteration 99300 (9.62073 iter/s, 10.3942s/100 iters), loss = 0.0270727
I0822 19:02:58.996901 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0270724 (* 1 = 0.0270724 loss)
I0822 19:02:58.996909 13823 sgd_solver.cpp:112] Iteration 99300, lr = 1e-05
I0822 19:03:09.267129 13823 solver.cpp:239] Iteration 99400 (9.73681 iter/s, 10.2703s/100 iters), loss = 0.0391014
I0822 19:03:09.267184 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.039101 (* 1 = 0.039101 loss)
I0822 19:03:09.267196 13823 sgd_solver.cpp:112] Iteration 99400, lr = 1e-05
I0822 19:03:19.571059 13823 solver.cpp:239] Iteration 99500 (9.70502 iter/s, 10.304s/100 iters), loss = 0.0241564
I0822 19:03:19.571117 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0241561 (* 1 = 0.0241561 loss)
I0822 19:03:19.571130 13823 sgd_solver.cpp:112] Iteration 99500, lr = 1e-05
I0822 19:03:30.048723 13823 solver.cpp:239] Iteration 99600 (9.5441 iter/s, 10.4777s/100 iters), loss = 0.0267024
I0822 19:03:30.048787 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.026702 (* 1 = 0.026702 loss)
I0822 19:03:30.048799 13823 sgd_solver.cpp:112] Iteration 99600, lr = 1e-05
I0822 19:03:40.339578 13823 solver.cpp:239] Iteration 99700 (9.71736 iter/s, 10.2909s/100 iters), loss = 0.0260407
I0822 19:03:40.339637 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0260403 (* 1 = 0.0260403 loss)
I0822 19:03:40.339648 13823 sgd_solver.cpp:112] Iteration 99700, lr = 1e-05
I0822 19:03:50.677673 13823 solver.cpp:239] Iteration 99800 (9.67295 iter/s, 10.3381s/100 iters), loss = 0.0337047
I0822 19:03:50.677728 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0337044 (* 1 = 0.0337044 loss)
I0822 19:03:50.677737 13823 sgd_solver.cpp:112] Iteration 99800, lr = 1e-05
I0822 19:04:00.838567 13823 solver.cpp:239] Iteration 99900 (9.84164 iter/s, 10.1609s/100 iters), loss = 0.0307037
I0822 19:04:00.838634 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0307033 (* 1 = 0.0307033 loss)
I0822 19:04:00.838645 13823 sgd_solver.cpp:112] Iteration 99900, lr = 1e-05
I0822 19:04:11.166410 13823 solver.cpp:464] Snapshotting to binary proto file ./model_112/cascade_mobilenet_112_iter_100000.caffemodel
I0822 19:04:11.244988 13823 sgd_solver.cpp:284] Snapshotting solver state to binary proto file ./model_112/cascade_mobilenet_112_iter_100000.solverstate
I0822 19:04:11.288046 13823 solver.cpp:347] Iteration 100000, Testing net (#0)
I0822 19:05:14.330525 13823 solver.cpp:414]     Test net output #0: landmark_loss = 0.0224705 (* 1 = 0.0224705 loss)
I0822 19:05:14.446841 13823 solver.cpp:239] Iteration 100000 (1.35853 iter/s, 73.6087s/100 iters), loss = 0.0270201
I0822 19:05:14.446882 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0270197 (* 1 = 0.0270197 loss)
I0822 19:05:14.446893 13823 sgd_solver.cpp:112] Iteration 100000, lr = 1e-05
I0822 19:05:24.950400 13823 solver.cpp:239] Iteration 100100 (9.52056 iter/s, 10.5036s/100 iters), loss = 0.0286123
I0822 19:05:24.950457 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.028612 (* 1 = 0.028612 loss)
I0822 19:05:24.950469 13823 sgd_solver.cpp:112] Iteration 100100, lr = 1e-05
I0822 19:05:35.654054 13823 solver.cpp:239] Iteration 100200 (9.34259 iter/s, 10.7037s/100 iters), loss = 0.0329513
I0822 19:05:35.654110 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.032951 (* 1 = 0.032951 loss)
I0822 19:05:35.654121 13823 sgd_solver.cpp:112] Iteration 100200, lr = 1e-05
I0822 19:05:46.244511 13823 solver.cpp:239] Iteration 100300 (9.44245 iter/s, 10.5905s/100 iters), loss = 0.227077
I0822 19:05:46.244561 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.227077 (* 1 = 0.227077 loss)
I0822 19:05:46.244570 13823 sgd_solver.cpp:112] Iteration 100300, lr = 1e-05
I0822 19:05:57.383314 13823 solver.cpp:239] Iteration 100400 (8.97761 iter/s, 11.1388s/100 iters), loss = 0.0532319
I0822 19:05:57.383375 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0532316 (* 1 = 0.0532316 loss)
I0822 19:05:57.383388 13823 sgd_solver.cpp:112] Iteration 100400, lr = 1e-05
I0822 19:06:08.065568 13823 solver.cpp:239] Iteration 100500 (9.36131 iter/s, 10.6823s/100 iters), loss = 0.0290567
I0822 19:06:08.065620 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0290564 (* 1 = 0.0290564 loss)
I0822 19:06:08.065629 13823 sgd_solver.cpp:112] Iteration 100500, lr = 1e-05
I0822 19:06:18.777243 13823 solver.cpp:239] Iteration 100600 (9.33559 iter/s, 10.7117s/100 iters), loss = 0.0247556
I0822 19:06:18.777293 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0247553 (* 1 = 0.0247553 loss)
I0822 19:06:18.777302 13823 sgd_solver.cpp:112] Iteration 100600, lr = 1e-05
I0822 19:06:29.044720 13823 solver.cpp:239] Iteration 100700 (9.73948 iter/s, 10.2675s/100 iters), loss = 0.0260403
I0822 19:06:29.044770 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.02604 (* 1 = 0.02604 loss)
I0822 19:06:29.044777 13823 sgd_solver.cpp:112] Iteration 100700, lr = 1e-05
I0822 19:06:39.835124 13823 solver.cpp:239] Iteration 100800 (9.26748 iter/s, 10.7904s/100 iters), loss = 0.0238139
I0822 19:06:39.835175 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0238136 (* 1 = 0.0238136 loss)
I0822 19:06:39.835184 13823 sgd_solver.cpp:112] Iteration 100800, lr = 1e-05
I0822 19:06:50.224418 13823 solver.cpp:239] Iteration 100900 (9.62528 iter/s, 10.3893s/100 iters), loss = 0.0228832
I0822 19:06:50.224478 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0228829 (* 1 = 0.0228829 loss)
I0822 19:06:50.224488 13823 sgd_solver.cpp:112] Iteration 100900, lr = 1e-05
I0822 19:07:00.990078 13823 solver.cpp:239] Iteration 101000 (9.28879 iter/s, 10.7657s/100 iters), loss = 0.0231718
I0822 19:07:00.990134 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0231715 (* 1 = 0.0231715 loss)
I0822 19:07:00.990144 13823 sgd_solver.cpp:112] Iteration 101000, lr = 1e-05
I0822 19:07:11.895869 13823 solver.cpp:239] Iteration 101100 (9.16943 iter/s, 10.9058s/100 iters), loss = 0.0260473
I0822 19:07:11.895920 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.026047 (* 1 = 0.026047 loss)
I0822 19:07:11.895928 13823 sgd_solver.cpp:112] Iteration 101100, lr = 1e-05
I0822 19:07:22.968241 13823 solver.cpp:239] Iteration 101200 (9.03148 iter/s, 11.0724s/100 iters), loss = 0.0313019
I0822 19:07:22.968294 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0313016 (* 1 = 0.0313016 loss)
I0822 19:07:22.968303 13823 sgd_solver.cpp:112] Iteration 101200, lr = 1e-05
I0822 19:07:33.835496 13823 solver.cpp:239] Iteration 101300 (9.20195 iter/s, 10.8673s/100 iters), loss = 0.0268097
I0822 19:07:33.835549 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0268094 (* 1 = 0.0268094 loss)
I0822 19:07:33.835559 13823 sgd_solver.cpp:112] Iteration 101300, lr = 1e-05
I0822 19:07:44.624511 13823 solver.cpp:239] Iteration 101400 (9.26868 iter/s, 10.789s/100 iters), loss = 0.0256082
I0822 19:07:44.624564 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0256079 (* 1 = 0.0256079 loss)
I0822 19:07:44.624574 13823 sgd_solver.cpp:112] Iteration 101400, lr = 1e-05
I0822 19:07:55.543223 13823 solver.cpp:239] Iteration 101500 (9.15858 iter/s, 10.9187s/100 iters), loss = 0.0287651
I0822 19:07:55.543273 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0287648 (* 1 = 0.0287648 loss)
I0822 19:07:55.543282 13823 sgd_solver.cpp:112] Iteration 101500, lr = 1e-05
I0822 19:08:06.246986 13823 solver.cpp:239] Iteration 101600 (9.3425 iter/s, 10.7038s/100 iters), loss = 0.0244901
I0822 19:08:06.247040 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0244897 (* 1 = 0.0244897 loss)
I0822 19:08:06.247048 13823 sgd_solver.cpp:112] Iteration 101600, lr = 1e-05
I0822 19:08:17.001003 13823 solver.cpp:239] Iteration 101700 (9.29885 iter/s, 10.754s/100 iters), loss = 0.0231223
I0822 19:08:17.001060 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.023122 (* 1 = 0.023122 loss)
I0822 19:08:17.001070 13823 sgd_solver.cpp:112] Iteration 101700, lr = 1e-05
I0822 19:08:27.927484 13823 solver.cpp:239] Iteration 101800 (9.15208 iter/s, 10.9265s/100 iters), loss = 0.0348867
I0822 19:08:27.927539 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0348864 (* 1 = 0.0348864 loss)
I0822 19:08:27.927549 13823 sgd_solver.cpp:112] Iteration 101800, lr = 1e-05
I0822 19:08:38.413012 13823 solver.cpp:239] Iteration 101900 (9.53695 iter/s, 10.4855s/100 iters), loss = 0.0417384
I0822 19:08:38.413060 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0417381 (* 1 = 0.0417381 loss)
I0822 19:08:38.413069 13823 sgd_solver.cpp:112] Iteration 101900, lr = 1e-05
I0822 19:08:49.339457 13823 solver.cpp:239] Iteration 102000 (9.1521 iter/s, 10.9265s/100 iters), loss = 0.0274036
I0822 19:08:49.339507 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0274033 (* 1 = 0.0274033 loss)
I0822 19:08:49.339516 13823 sgd_solver.cpp:112] Iteration 102000, lr = 1e-05
I0822 19:08:59.851141 13823 solver.cpp:239] Iteration 102100 (9.51322 iter/s, 10.5117s/100 iters), loss = 0.0261625
I0822 19:08:59.851183 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0261622 (* 1 = 0.0261622 loss)
I0822 19:08:59.851191 13823 sgd_solver.cpp:112] Iteration 102100, lr = 1e-05
I0822 19:09:10.774317 13823 solver.cpp:239] Iteration 102200 (9.15484 iter/s, 10.9232s/100 iters), loss = 0.0284146
I0822 19:09:10.774369 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0284143 (* 1 = 0.0284143 loss)
I0822 19:09:10.774379 13823 sgd_solver.cpp:112] Iteration 102200, lr = 1e-05
I0822 19:09:21.792249 13823 solver.cpp:239] Iteration 102300 (9.07611 iter/s, 11.0179s/100 iters), loss = 0.0267944
I0822 19:09:21.792300 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0267941 (* 1 = 0.0267941 loss)
I0822 19:09:21.792309 13823 sgd_solver.cpp:112] Iteration 102300, lr = 1e-05
I0822 19:09:32.371451 13823 solver.cpp:239] Iteration 102400 (9.45251 iter/s, 10.5792s/100 iters), loss = 0.0273726
I0822 19:09:32.371500 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0273723 (* 1 = 0.0273723 loss)
I0822 19:09:32.371510 13823 sgd_solver.cpp:112] Iteration 102400, lr = 1e-05
I0822 19:09:43.087766 13823 solver.cpp:239] Iteration 102500 (9.33156 iter/s, 10.7163s/100 iters), loss = 0.0367833
I0822 19:09:43.087815 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.036783 (* 1 = 0.036783 loss)
I0822 19:09:43.087823 13823 sgd_solver.cpp:112] Iteration 102500, lr = 1e-05
I0822 19:09:53.724766 13823 solver.cpp:239] Iteration 102600 (9.40115 iter/s, 10.637s/100 iters), loss = 0.0262838
I0822 19:09:53.724828 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0262835 (* 1 = 0.0262835 loss)
I0822 19:09:53.724838 13823 sgd_solver.cpp:112] Iteration 102600, lr = 1e-05
I0822 19:10:04.614454 13823 solver.cpp:239] Iteration 102700 (9.18301 iter/s, 10.8897s/100 iters), loss = 0.0251388
I0822 19:10:04.614507 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0251385 (* 1 = 0.0251385 loss)
I0822 19:10:04.614516 13823 sgd_solver.cpp:112] Iteration 102700, lr = 1e-05
I0822 19:10:15.495910 13823 solver.cpp:239] Iteration 102800 (9.18995 iter/s, 10.8815s/100 iters), loss = 0.0287086
I0822 19:10:15.495962 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0287083 (* 1 = 0.0287083 loss)
I0822 19:10:15.495972 13823 sgd_solver.cpp:112] Iteration 102800, lr = 1e-05
I0822 19:10:26.381166 13823 solver.cpp:239] Iteration 102900 (9.18674 iter/s, 10.8853s/100 iters), loss = 0.0327053
I0822 19:10:26.381213 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.032705 (* 1 = 0.032705 loss)
I0822 19:10:26.381223 13823 sgd_solver.cpp:112] Iteration 102900, lr = 1e-05
I0822 19:10:37.154242 13823 solver.cpp:239] Iteration 103000 (9.2824 iter/s, 10.7731s/100 iters), loss = 0.0260283
I0822 19:10:37.154290 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.026028 (* 1 = 0.026028 loss)
I0822 19:10:37.154299 13823 sgd_solver.cpp:112] Iteration 103000, lr = 1e-05
I0822 19:10:47.832741 13823 solver.cpp:239] Iteration 103100 (9.36462 iter/s, 10.6785s/100 iters), loss = 0.0280609
I0822 19:10:47.832798 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0280606 (* 1 = 0.0280606 loss)
I0822 19:10:47.832808 13823 sgd_solver.cpp:112] Iteration 103100, lr = 1e-05
I0822 19:10:59.057123 13823 solver.cpp:239] Iteration 103200 (8.90918 iter/s, 11.2244s/100 iters), loss = 0.031565
I0822 19:10:59.057180 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0315647 (* 1 = 0.0315647 loss)
I0822 19:10:59.057191 13823 sgd_solver.cpp:112] Iteration 103200, lr = 1e-05
I0822 19:11:10.013013 13823 solver.cpp:239] Iteration 103300 (9.12752 iter/s, 10.9559s/100 iters), loss = 0.0308334
I0822 19:11:10.013062 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0308331 (* 1 = 0.0308331 loss)
I0822 19:11:10.013070 13823 sgd_solver.cpp:112] Iteration 103300, lr = 1e-05
I0822 19:11:21.154994 13823 solver.cpp:239] Iteration 103400 (8.97507 iter/s, 11.142s/100 iters), loss = 0.0428475
I0822 19:11:21.155053 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0428472 (* 1 = 0.0428472 loss)
I0822 19:11:21.155066 13823 sgd_solver.cpp:112] Iteration 103400, lr = 1e-05
I0822 19:11:32.262795 13823 solver.cpp:239] Iteration 103500 (9.00269 iter/s, 11.1078s/100 iters), loss = 0.0268573
I0822 19:11:32.262852 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.026857 (* 1 = 0.026857 loss)
I0822 19:11:32.262862 13823 sgd_solver.cpp:112] Iteration 103500, lr = 1e-05
I0822 19:11:43.310446 13823 solver.cpp:239] Iteration 103600 (9.05171 iter/s, 11.0476s/100 iters), loss = 0.033587
I0822 19:11:43.310495 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0335867 (* 1 = 0.0335867 loss)
I0822 19:11:43.310504 13823 sgd_solver.cpp:112] Iteration 103600, lr = 1e-05
I0822 19:11:54.660773 13823 solver.cpp:239] Iteration 103700 (8.81032 iter/s, 11.3503s/100 iters), loss = 0.0247814
I0822 19:11:54.660830 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0247811 (* 1 = 0.0247811 loss)
I0822 19:11:54.660842 13823 sgd_solver.cpp:112] Iteration 103700, lr = 1e-05
I0822 19:12:05.619000 13823 solver.cpp:239] Iteration 103800 (9.12557 iter/s, 10.9582s/100 iters), loss = 0.0251005
I0822 19:12:05.619052 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0251002 (* 1 = 0.0251002 loss)
I0822 19:12:05.619061 13823 sgd_solver.cpp:112] Iteration 103800, lr = 1e-05
I0822 19:12:16.502648 13823 solver.cpp:239] Iteration 103900 (9.1881 iter/s, 10.8836s/100 iters), loss = 0.0275313
I0822 19:12:16.502699 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.027531 (* 1 = 0.027531 loss)
I0822 19:12:16.502708 13823 sgd_solver.cpp:112] Iteration 103900, lr = 1e-05
I0822 19:12:27.231272 13823 solver.cpp:239] Iteration 104000 (9.32087 iter/s, 10.7286s/100 iters), loss = 0.0282121
I0822 19:12:27.231326 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0282118 (* 1 = 0.0282118 loss)
I0822 19:12:27.231336 13823 sgd_solver.cpp:112] Iteration 104000, lr = 1e-05
I0822 19:12:38.309542 13823 solver.cpp:239] Iteration 104100 (9.02669 iter/s, 11.0783s/100 iters), loss = 0.027504
I0822 19:12:38.309595 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0275038 (* 1 = 0.0275038 loss)
I0822 19:12:38.309604 13823 sgd_solver.cpp:112] Iteration 104100, lr = 1e-05
I0822 19:12:49.111205 13823 solver.cpp:239] Iteration 104200 (9.25784 iter/s, 10.8017s/100 iters), loss = 0.0260204
I0822 19:12:49.111258 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0260201 (* 1 = 0.0260201 loss)
I0822 19:12:49.111266 13823 sgd_solver.cpp:112] Iteration 104200, lr = 1e-05
I0822 19:13:00.160010 13823 solver.cpp:239] Iteration 104300 (9.05076 iter/s, 11.0488s/100 iters), loss = 0.0255079
I0822 19:13:00.160060 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0255076 (* 1 = 0.0255076 loss)
I0822 19:13:00.160069 13823 sgd_solver.cpp:112] Iteration 104300, lr = 1e-05
I0822 19:13:10.742328 13823 solver.cpp:239] Iteration 104400 (9.44973 iter/s, 10.5823s/100 iters), loss = 0.0425714
I0822 19:13:10.742380 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0425711 (* 1 = 0.0425711 loss)
I0822 19:13:10.742390 13823 sgd_solver.cpp:112] Iteration 104400, lr = 1e-05
I0822 19:13:21.909938 13823 solver.cpp:239] Iteration 104500 (8.95448 iter/s, 11.1676s/100 iters), loss = 0.037106
I0822 19:13:21.909992 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0371057 (* 1 = 0.0371057 loss)
I0822 19:13:21.910002 13823 sgd_solver.cpp:112] Iteration 104500, lr = 1e-05
I0822 19:13:32.961365 13823 solver.cpp:239] Iteration 104600 (9.04861 iter/s, 11.0514s/100 iters), loss = 0.0264778
I0822 19:13:32.961416 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0264775 (* 1 = 0.0264775 loss)
I0822 19:13:32.961426 13823 sgd_solver.cpp:112] Iteration 104600, lr = 1e-05
I0822 19:13:43.692214 13823 solver.cpp:239] Iteration 104700 (9.31893 iter/s, 10.7308s/100 iters), loss = 0.0255756
I0822 19:13:43.692265 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0255753 (* 1 = 0.0255753 loss)
I0822 19:13:43.692275 13823 sgd_solver.cpp:112] Iteration 104700, lr = 1e-05
I0822 19:13:54.987418 13823 solver.cpp:239] Iteration 104800 (8.85332 iter/s, 11.2952s/100 iters), loss = 0.0472982
I0822 19:13:54.987483 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0472979 (* 1 = 0.0472979 loss)
I0822 19:13:54.987496 13823 sgd_solver.cpp:112] Iteration 104800, lr = 1e-05
I0822 19:14:06.095926 13823 solver.cpp:239] Iteration 104900 (9.00213 iter/s, 11.1085s/100 iters), loss = 0.0246772
I0822 19:14:06.095979 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.024677 (* 1 = 0.024677 loss)
I0822 19:14:06.095988 13823 sgd_solver.cpp:112] Iteration 104900, lr = 1e-05
I0822 19:14:17.416337 13823 solver.cpp:239] Iteration 105000 (8.83361 iter/s, 11.3204s/100 iters), loss = 0.0266538
I0822 19:14:17.416395 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0266535 (* 1 = 0.0266535 loss)
I0822 19:14:17.416406 13823 sgd_solver.cpp:112] Iteration 105000, lr = 1e-05
I0822 19:14:28.769390 13823 solver.cpp:239] Iteration 105100 (8.80821 iter/s, 11.353s/100 iters), loss = 0.0245974
I0822 19:14:28.769450 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0245971 (* 1 = 0.0245971 loss)
I0822 19:14:28.769460 13823 sgd_solver.cpp:112] Iteration 105100, lr = 1e-05
I0822 19:14:40.139539 13823 solver.cpp:239] Iteration 105200 (8.79497 iter/s, 11.3701s/100 iters), loss = 0.0280698
I0822 19:14:40.139596 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0280695 (* 1 = 0.0280695 loss)
I0822 19:14:40.139607 13823 sgd_solver.cpp:112] Iteration 105200, lr = 1e-05
I0822 19:14:51.383834 13823 solver.cpp:239] Iteration 105300 (8.89341 iter/s, 11.2443s/100 iters), loss = 0.036799
I0822 19:14:51.383890 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0367987 (* 1 = 0.0367987 loss)
I0822 19:14:51.383900 13823 sgd_solver.cpp:112] Iteration 105300, lr = 1e-05
I0822 19:15:02.775131 13823 solver.cpp:239] Iteration 105400 (8.77864 iter/s, 11.3913s/100 iters), loss = 0.0341751
I0822 19:15:02.775194 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0341748 (* 1 = 0.0341748 loss)
I0822 19:15:02.775207 13823 sgd_solver.cpp:112] Iteration 105400, lr = 1e-05
I0822 19:15:13.969769 13823 solver.cpp:239] Iteration 105500 (8.93287 iter/s, 11.1946s/100 iters), loss = 0.03116
I0822 19:15:13.969821 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0311597 (* 1 = 0.0311597 loss)
I0822 19:15:13.969831 13823 sgd_solver.cpp:112] Iteration 105500, lr = 1e-05
I0822 19:15:25.053061 13823 solver.cpp:239] Iteration 105600 (9.0226 iter/s, 11.0833s/100 iters), loss = 0.0302897
I0822 19:15:25.053113 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0302894 (* 1 = 0.0302894 loss)
I0822 19:15:25.053122 13823 sgd_solver.cpp:112] Iteration 105600, lr = 1e-05
I0822 19:15:36.390012 13823 solver.cpp:239] Iteration 105700 (8.82072 iter/s, 11.3369s/100 iters), loss = 0.0282137
I0822 19:15:36.390063 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0282134 (* 1 = 0.0282134 loss)
I0822 19:15:36.390071 13823 sgd_solver.cpp:112] Iteration 105700, lr = 1e-05
I0822 19:15:47.741951 13823 solver.cpp:239] Iteration 105800 (8.80908 iter/s, 11.3519s/100 iters), loss = 0.025598
I0822 19:15:47.742007 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0255978 (* 1 = 0.0255978 loss)
I0822 19:15:47.742017 13823 sgd_solver.cpp:112] Iteration 105800, lr = 1e-05
I0822 19:15:59.094269 13823 solver.cpp:239] Iteration 105900 (8.80879 iter/s, 11.3523s/100 iters), loss = 0.0254385
I0822 19:15:59.094323 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0254382 (* 1 = 0.0254382 loss)
I0822 19:15:59.094333 13823 sgd_solver.cpp:112] Iteration 105900, lr = 1e-05
I0822 19:16:10.436873 13823 solver.cpp:239] Iteration 106000 (8.81633 iter/s, 11.3426s/100 iters), loss = 0.02669
I0822 19:16:10.436921 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0266898 (* 1 = 0.0266898 loss)
I0822 19:16:10.436930 13823 sgd_solver.cpp:112] Iteration 106000, lr = 1e-05
I0822 19:16:21.830458 13823 solver.cpp:239] Iteration 106100 (8.77688 iter/s, 11.3936s/100 iters), loss = 0.024714
I0822 19:16:21.830515 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0247138 (* 1 = 0.0247138 loss)
I0822 19:16:21.830526 13823 sgd_solver.cpp:112] Iteration 106100, lr = 1e-05
I0822 19:16:33.075106 13823 solver.cpp:239] Iteration 106200 (8.89313 iter/s, 11.2446s/100 iters), loss = 0.025722
I0822 19:16:33.075160 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0257217 (* 1 = 0.0257217 loss)
I0822 19:16:33.075170 13823 sgd_solver.cpp:112] Iteration 106200, lr = 1e-05
I0822 19:16:44.183427 13823 solver.cpp:239] Iteration 106300 (9.00227 iter/s, 11.1083s/100 iters), loss = 0.0305504
I0822 19:16:44.183477 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0305501 (* 1 = 0.0305501 loss)
I0822 19:16:44.183487 13823 sgd_solver.cpp:112] Iteration 106300, lr = 1e-05
I0822 19:16:55.279956 13823 solver.cpp:239] Iteration 106400 (9.01184 iter/s, 11.0965s/100 iters), loss = 0.0241248
I0822 19:16:55.280017 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0241245 (* 1 = 0.0241245 loss)
I0822 19:16:55.280028 13823 sgd_solver.cpp:112] Iteration 106400, lr = 1e-05
I0822 19:17:06.419989 13823 solver.cpp:239] Iteration 106500 (8.97665 iter/s, 11.14s/100 iters), loss = 0.0284433
I0822 19:17:06.420039 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.028443 (* 1 = 0.028443 loss)
I0822 19:17:06.420048 13823 sgd_solver.cpp:112] Iteration 106500, lr = 1e-05
I0822 19:17:17.408502 13823 solver.cpp:239] Iteration 106600 (9.10042 iter/s, 10.9885s/100 iters), loss = 0.0259963
I0822 19:17:17.408553 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0259961 (* 1 = 0.0259961 loss)
I0822 19:17:17.408562 13823 sgd_solver.cpp:112] Iteration 106600, lr = 1e-05
I0822 19:17:28.587625 13823 solver.cpp:239] Iteration 106700 (8.94526 iter/s, 11.1791s/100 iters), loss = 0.0294679
I0822 19:17:28.587680 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0294676 (* 1 = 0.0294676 loss)
I0822 19:17:28.587690 13823 sgd_solver.cpp:112] Iteration 106700, lr = 1e-05
I0822 19:17:39.590050 13823 solver.cpp:239] Iteration 106800 (9.08892 iter/s, 11.0024s/100 iters), loss = 0.0256474
I0822 19:17:39.590103 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0256471 (* 1 = 0.0256471 loss)
I0822 19:17:39.590112 13823 sgd_solver.cpp:112] Iteration 106800, lr = 1e-05
I0822 19:17:51.018668 13823 solver.cpp:239] Iteration 106900 (8.74998 iter/s, 11.4286s/100 iters), loss = 0.0355826
I0822 19:17:51.018719 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0355824 (* 1 = 0.0355824 loss)
I0822 19:17:51.018728 13823 sgd_solver.cpp:112] Iteration 106900, lr = 1e-05
I0822 19:18:02.565663 13823 solver.cpp:239] Iteration 107000 (8.66027 iter/s, 11.547s/100 iters), loss = 0.02765
I0822 19:18:02.565713 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0276498 (* 1 = 0.0276498 loss)
I0822 19:18:02.565722 13823 sgd_solver.cpp:112] Iteration 107000, lr = 1e-05
I0822 19:18:13.836236 13823 solver.cpp:239] Iteration 107100 (8.87268 iter/s, 11.2706s/100 iters), loss = 0.0263341
I0822 19:18:13.836292 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0263339 (* 1 = 0.0263339 loss)
I0822 19:18:13.836303 13823 sgd_solver.cpp:112] Iteration 107100, lr = 1e-05
I0822 19:18:25.271819 13823 solver.cpp:239] Iteration 107200 (8.74465 iter/s, 11.4356s/100 iters), loss = 0.0260031
I0822 19:18:25.271874 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0260029 (* 1 = 0.0260029 loss)
I0822 19:18:25.271884 13823 sgd_solver.cpp:112] Iteration 107200, lr = 1e-05
I0822 19:18:36.834265 13823 solver.cpp:239] Iteration 107300 (8.6487 iter/s, 11.5624s/100 iters), loss = 0.0288776
I0822 19:18:36.834324 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0288774 (* 1 = 0.0288774 loss)
I0822 19:18:36.834336 13823 sgd_solver.cpp:112] Iteration 107300, lr = 1e-05
I0822 19:18:48.375371 13823 solver.cpp:239] Iteration 107400 (8.66469 iter/s, 11.5411s/100 iters), loss = 0.028614
I0822 19:18:48.375421 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0286138 (* 1 = 0.0286138 loss)
I0822 19:18:48.375430 13823 sgd_solver.cpp:112] Iteration 107400, lr = 1e-05
I0822 19:18:59.818562 13823 solver.cpp:239] Iteration 107500 (8.73883 iter/s, 11.4432s/100 iters), loss = 0.0241828
I0822 19:18:59.818611 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0241825 (* 1 = 0.0241825 loss)
I0822 19:18:59.818619 13823 sgd_solver.cpp:112] Iteration 107500, lr = 1e-05
I0822 19:19:10.968271 13823 solver.cpp:239] Iteration 107600 (8.96885 iter/s, 11.1497s/100 iters), loss = 0.0248339
I0822 19:19:10.968324 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0248336 (* 1 = 0.0248336 loss)
I0822 19:19:10.968334 13823 sgd_solver.cpp:112] Iteration 107600, lr = 1e-05
I0822 19:19:22.057209 13823 solver.cpp:239] Iteration 107700 (9.01801 iter/s, 11.0889s/100 iters), loss = 0.0343847
I0822 19:19:22.057267 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0343844 (* 1 = 0.0343844 loss)
I0822 19:19:22.057278 13823 sgd_solver.cpp:112] Iteration 107700, lr = 1e-05
I0822 19:19:33.393173 13823 solver.cpp:239] Iteration 107800 (8.8215 iter/s, 11.3359s/100 iters), loss = 0.0270261
I0822 19:19:33.393224 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0270258 (* 1 = 0.0270258 loss)
I0822 19:19:33.393231 13823 sgd_solver.cpp:112] Iteration 107800, lr = 1e-05
I0822 19:19:44.842177 13823 solver.cpp:239] Iteration 107900 (8.73439 iter/s, 11.449s/100 iters), loss = 0.0301554
I0822 19:19:44.842228 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0301551 (* 1 = 0.0301551 loss)
I0822 19:19:44.842237 13823 sgd_solver.cpp:112] Iteration 107900, lr = 1e-05
I0822 19:19:56.306886 13823 solver.cpp:239] Iteration 108000 (8.72243 iter/s, 11.4647s/100 iters), loss = 0.027099
I0822 19:19:56.306944 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0270987 (* 1 = 0.0270987 loss)
I0822 19:19:56.306955 13823 sgd_solver.cpp:112] Iteration 108000, lr = 1e-05
I0822 19:20:07.641047 13823 solver.cpp:239] Iteration 108100 (8.8229 iter/s, 11.3341s/100 iters), loss = 0.0251913
I0822 19:20:07.641098 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.025191 (* 1 = 0.025191 loss)
I0822 19:20:07.641108 13823 sgd_solver.cpp:112] Iteration 108100, lr = 1e-05
I0822 19:20:18.943346 13823 solver.cpp:239] Iteration 108200 (8.84777 iter/s, 11.3023s/100 iters), loss = 0.0261815
I0822 19:20:18.943401 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0261812 (* 1 = 0.0261812 loss)
I0822 19:20:18.943413 13823 sgd_solver.cpp:112] Iteration 108200, lr = 1e-05
I0822 19:20:30.447194 13823 solver.cpp:239] Iteration 108300 (8.69276 iter/s, 11.5038s/100 iters), loss = 0.033759
I0822 19:20:30.447245 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0337587 (* 1 = 0.0337587 loss)
I0822 19:20:30.447254 13823 sgd_solver.cpp:112] Iteration 108300, lr = 1e-05
I0822 19:20:42.102875 13823 solver.cpp:239] Iteration 108400 (8.57952 iter/s, 11.6557s/100 iters), loss = 0.0322582
I0822 19:20:42.102932 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0322579 (* 1 = 0.0322579 loss)
I0822 19:20:42.102944 13823 sgd_solver.cpp:112] Iteration 108400, lr = 1e-05
I0822 19:20:53.639870 13823 solver.cpp:239] Iteration 108500 (8.66778 iter/s, 11.537s/100 iters), loss = 0.0269725
I0822 19:20:53.639921 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0269722 (* 1 = 0.0269722 loss)
I0822 19:20:53.639930 13823 sgd_solver.cpp:112] Iteration 108500, lr = 1e-05
I0822 19:21:05.331296 13823 solver.cpp:239] Iteration 108600 (8.55329 iter/s, 11.6914s/100 iters), loss = 0.0282356
I0822 19:21:05.331354 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0282353 (* 1 = 0.0282353 loss)
I0822 19:21:05.331365 13823 sgd_solver.cpp:112] Iteration 108600, lr = 1e-05
I0822 19:21:16.757192 13823 solver.cpp:239] Iteration 108700 (8.75207 iter/s, 11.4259s/100 iters), loss = 0.0272493
I0822 19:21:16.757252 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.027249 (* 1 = 0.027249 loss)
I0822 19:21:16.757263 13823 sgd_solver.cpp:112] Iteration 108700, lr = 1e-05
I0822 19:21:28.274683 13823 solver.cpp:239] Iteration 108800 (8.68246 iter/s, 11.5175s/100 iters), loss = 0.0327307
I0822 19:21:28.274739 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0327304 (* 1 = 0.0327304 loss)
I0822 19:21:28.274749 13823 sgd_solver.cpp:112] Iteration 108800, lr = 1e-05
I0822 19:21:39.711169 13823 solver.cpp:239] Iteration 108900 (8.74396 iter/s, 11.4365s/100 iters), loss = 0.0279667
I0822 19:21:39.711218 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0279664 (* 1 = 0.0279664 loss)
I0822 19:21:39.711227 13823 sgd_solver.cpp:112] Iteration 108900, lr = 1e-05
I0822 19:21:51.122889 13823 solver.cpp:239] Iteration 109000 (8.76293 iter/s, 11.4117s/100 iters), loss = 0.0249421
I0822 19:21:51.122946 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0249418 (* 1 = 0.0249418 loss)
I0822 19:21:51.122957 13823 sgd_solver.cpp:112] Iteration 109000, lr = 1e-05
I0822 19:22:02.916648 13823 solver.cpp:239] Iteration 109100 (8.47908 iter/s, 11.7937s/100 iters), loss = 0.0323196
I0822 19:22:02.916704 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0323193 (* 1 = 0.0323193 loss)
I0822 19:22:02.916714 13823 sgd_solver.cpp:112] Iteration 109100, lr = 1e-05
I0822 19:22:14.776242 13823 solver.cpp:239] Iteration 109200 (8.43201 iter/s, 11.8596s/100 iters), loss = 0.0314294
I0822 19:22:14.776304 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0314291 (* 1 = 0.0314291 loss)
I0822 19:22:14.776315 13823 sgd_solver.cpp:112] Iteration 109200, lr = 1e-05
I0822 19:22:26.413069 13823 solver.cpp:239] Iteration 109300 (8.59343 iter/s, 11.6368s/100 iters), loss = 0.025977
I0822 19:22:26.413128 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0259767 (* 1 = 0.0259767 loss)
I0822 19:22:26.413139 13823 sgd_solver.cpp:112] Iteration 109300, lr = 1e-05
I0822 19:22:38.014346 13823 solver.cpp:239] Iteration 109400 (8.61976 iter/s, 11.6013s/100 iters), loss = 0.0272755
I0822 19:22:38.014394 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0272752 (* 1 = 0.0272752 loss)
I0822 19:22:38.014403 13823 sgd_solver.cpp:112] Iteration 109400, lr = 1e-05
I0822 19:22:49.765195 13823 solver.cpp:239] Iteration 109500 (8.51003 iter/s, 11.7508s/100 iters), loss = 0.028278
I0822 19:22:49.765250 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0282777 (* 1 = 0.0282777 loss)
I0822 19:22:49.765260 13823 sgd_solver.cpp:112] Iteration 109500, lr = 1e-05
I0822 19:23:00.608019 13823 solver.cpp:239] Iteration 109600 (9.22271 iter/s, 10.8428s/100 iters), loss = 0.0257867
I0822 19:23:00.608078 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0257864 (* 1 = 0.0257864 loss)
I0822 19:23:00.608089 13823 sgd_solver.cpp:112] Iteration 109600, lr = 1e-05
I0822 19:23:10.238199 13823 solver.cpp:239] Iteration 109700 (10.3841 iter/s, 9.63015s/100 iters), loss = 0.0288646
I0822 19:23:10.238250 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0288643 (* 1 = 0.0288643 loss)
I0822 19:23:10.238257 13823 sgd_solver.cpp:112] Iteration 109700, lr = 1e-05
I0822 19:23:19.589915 13823 solver.cpp:239] Iteration 109800 (10.6933 iter/s, 9.35169s/100 iters), loss = 0.0297703
I0822 19:23:19.589967 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.02977 (* 1 = 0.02977 loss)
I0822 19:23:19.589977 13823 sgd_solver.cpp:112] Iteration 109800, lr = 1e-05
I0822 19:23:28.926208 13823 solver.cpp:239] Iteration 109900 (10.7109 iter/s, 9.33627s/100 iters), loss = 0.0279055
I0822 19:23:28.926251 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0279052 (* 1 = 0.0279052 loss)
I0822 19:23:28.926259 13823 sgd_solver.cpp:112] Iteration 109900, lr = 1e-05
I0822 19:23:38.781110 13823 solver.cpp:239] Iteration 110000 (10.1472 iter/s, 9.85489s/100 iters), loss = 0.0247645
I0822 19:23:38.781159 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0247642 (* 1 = 0.0247642 loss)
I0822 19:23:38.781168 13823 sgd_solver.cpp:112] Iteration 110000, lr = 1e-05
I0822 19:23:48.719597 13823 solver.cpp:239] Iteration 110100 (10.0619 iter/s, 9.93846s/100 iters), loss = 0.025334
I0822 19:23:48.719657 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0253337 (* 1 = 0.0253337 loss)
I0822 19:23:48.719669 13823 sgd_solver.cpp:112] Iteration 110100, lr = 1e-05
I0822 19:23:58.141525 13823 solver.cpp:239] Iteration 110200 (10.6136 iter/s, 9.4219s/100 iters), loss = 0.0268268
I0822 19:23:58.141572 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0268265 (* 1 = 0.0268265 loss)
I0822 19:23:58.141582 13823 sgd_solver.cpp:112] Iteration 110200, lr = 1e-05
I0822 19:24:07.539753 13823 solver.cpp:239] Iteration 110300 (10.6403 iter/s, 9.39821s/100 iters), loss = 0.0364905
I0822 19:24:07.539798 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0364902 (* 1 = 0.0364902 loss)
I0822 19:24:07.539804 13823 sgd_solver.cpp:112] Iteration 110300, lr = 1e-05
I0822 19:24:17.360832 13823 solver.cpp:239] Iteration 110400 (10.1822 iter/s, 9.82106s/100 iters), loss = 0.0287994
I0822 19:24:17.360884 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0287991 (* 1 = 0.0287991 loss)
I0822 19:24:17.360894 13823 sgd_solver.cpp:112] Iteration 110400, lr = 1e-05
I0822 19:24:26.909914 13823 solver.cpp:239] Iteration 110500 (10.4722 iter/s, 9.54906s/100 iters), loss = 0.0251924
I0822 19:24:26.909965 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0251921 (* 1 = 0.0251921 loss)
I0822 19:24:26.909973 13823 sgd_solver.cpp:112] Iteration 110500, lr = 1e-05
I0822 19:24:36.400835 13823 solver.cpp:239] Iteration 110600 (10.5364 iter/s, 9.4909s/100 iters), loss = 0.0285229
I0822 19:24:36.400892 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0285226 (* 1 = 0.0285226 loss)
I0822 19:24:36.400902 13823 sgd_solver.cpp:112] Iteration 110600, lr = 1e-05
I0822 19:24:46.431764 13823 solver.cpp:239] Iteration 110700 (9.9692 iter/s, 10.0309s/100 iters), loss = 0.0301312
I0822 19:24:46.431823 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0301309 (* 1 = 0.0301309 loss)
I0822 19:24:46.431835 13823 sgd_solver.cpp:112] Iteration 110700, lr = 1e-05
I0822 19:24:55.984462 13823 solver.cpp:239] Iteration 110800 (10.4683 iter/s, 9.55266s/100 iters), loss = 0.0252297
I0822 19:24:55.984522 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0252294 (* 1 = 0.0252294 loss)
I0822 19:24:55.984535 13823 sgd_solver.cpp:112] Iteration 110800, lr = 1e-05
I0822 19:25:05.450418 13823 solver.cpp:239] Iteration 110900 (10.5642 iter/s, 9.46592s/100 iters), loss = 0.0285885
I0822 19:25:05.450467 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0285882 (* 1 = 0.0285882 loss)
I0822 19:25:05.450476 13823 sgd_solver.cpp:112] Iteration 110900, lr = 1e-05
I0822 19:25:15.422263 13823 solver.cpp:239] Iteration 111000 (10.0283 iter/s, 9.97182s/100 iters), loss = 0.0247763
I0822 19:25:15.422323 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.024776 (* 1 = 0.024776 loss)
I0822 19:25:15.422335 13823 sgd_solver.cpp:112] Iteration 111000, lr = 1e-05
I0822 19:25:25.166031 13823 solver.cpp:239] Iteration 111100 (10.263 iter/s, 9.74373s/100 iters), loss = 0.0274254
I0822 19:25:25.166083 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0274251 (* 1 = 0.0274251 loss)
I0822 19:25:25.166092 13823 sgd_solver.cpp:112] Iteration 111100, lr = 1e-05
I0822 19:25:34.889030 13823 solver.cpp:239] Iteration 111200 (10.2849 iter/s, 9.72297s/100 iters), loss = 0.0229777
I0822 19:25:34.889081 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0229773 (* 1 = 0.0229773 loss)
I0822 19:25:34.889089 13823 sgd_solver.cpp:112] Iteration 111200, lr = 1e-05
I0822 19:25:44.903776 13823 solver.cpp:239] Iteration 111300 (9.9853 iter/s, 10.0147s/100 iters), loss = 0.0278936
I0822 19:25:44.903828 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0278932 (* 1 = 0.0278932 loss)
I0822 19:25:44.903837 13823 sgd_solver.cpp:112] Iteration 111300, lr = 1e-05
I0822 19:25:54.508219 13823 solver.cpp:239] Iteration 111400 (10.4119 iter/s, 9.60441s/100 iters), loss = 0.0275768
I0822 19:25:54.508270 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0275765 (* 1 = 0.0275765 loss)
I0822 19:25:54.508280 13823 sgd_solver.cpp:112] Iteration 111400, lr = 1e-05
I0822 19:26:04.149564 13823 solver.cpp:239] Iteration 111500 (10.372 iter/s, 9.64132s/100 iters), loss = 0.0252915
I0822 19:26:04.149613 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0252911 (* 1 = 0.0252911 loss)
I0822 19:26:04.149621 13823 sgd_solver.cpp:112] Iteration 111500, lr = 1e-05
I0822 19:26:14.138348 13823 solver.cpp:239] Iteration 111600 (10.0113 iter/s, 9.98876s/100 iters), loss = 0.0291645
I0822 19:26:14.138398 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0291641 (* 1 = 0.0291641 loss)
I0822 19:26:14.138407 13823 sgd_solver.cpp:112] Iteration 111600, lr = 1e-05
I0822 19:26:24.094488 13823 solver.cpp:239] Iteration 111700 (10.0441 iter/s, 9.95612s/100 iters), loss = 0.0287243
I0822 19:26:24.094539 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.028724 (* 1 = 0.028724 loss)
I0822 19:26:24.094548 13823 sgd_solver.cpp:112] Iteration 111700, lr = 1e-05
I0822 19:26:34.007047 13823 solver.cpp:239] Iteration 111800 (10.0882 iter/s, 9.91253s/100 iters), loss = 0.0281299
I0822 19:26:34.007098 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0281296 (* 1 = 0.0281296 loss)
I0822 19:26:34.007108 13823 sgd_solver.cpp:112] Iteration 111800, lr = 1e-05
I0822 19:26:44.036022 13823 solver.cpp:239] Iteration 111900 (9.97114 iter/s, 10.0289s/100 iters), loss = 0.0269756
I0822 19:26:44.036072 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0269753 (* 1 = 0.0269753 loss)
I0822 19:26:44.036082 13823 sgd_solver.cpp:112] Iteration 111900, lr = 1e-05
I0822 19:26:53.695031 13823 solver.cpp:239] Iteration 112000 (10.3531 iter/s, 9.65898s/100 iters), loss = 0.0255458
I0822 19:26:53.695080 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0255455 (* 1 = 0.0255455 loss)
I0822 19:26:53.695088 13823 sgd_solver.cpp:112] Iteration 112000, lr = 1e-05
I0822 19:27:03.315867 13823 solver.cpp:239] Iteration 112100 (10.3941 iter/s, 9.62081s/100 iters), loss = 0.0254795
I0822 19:27:03.315919 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0254791 (* 1 = 0.0254791 loss)
I0822 19:27:03.315928 13823 sgd_solver.cpp:112] Iteration 112100, lr = 1e-05
I0822 19:27:12.988200 13823 solver.cpp:239] Iteration 112200 (10.3388 iter/s, 9.67231s/100 iters), loss = 0.0273721
I0822 19:27:12.988250 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0273717 (* 1 = 0.0273717 loss)
I0822 19:27:12.988260 13823 sgd_solver.cpp:112] Iteration 112200, lr = 1e-05
I0822 19:27:22.666663 13823 solver.cpp:239] Iteration 112300 (10.3322 iter/s, 9.67844s/100 iters), loss = 0.0299633
I0822 19:27:22.666721 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0299629 (* 1 = 0.0299629 loss)
I0822 19:27:22.666731 13823 sgd_solver.cpp:112] Iteration 112300, lr = 1e-05
I0822 19:27:32.445654 13823 solver.cpp:239] Iteration 112400 (10.226 iter/s, 9.77896s/100 iters), loss = 0.0270388
I0822 19:27:32.445715 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0270384 (* 1 = 0.0270384 loss)
I0822 19:27:32.445726 13823 sgd_solver.cpp:112] Iteration 112400, lr = 1e-05
I0822 19:27:42.472427 13823 solver.cpp:239] Iteration 112500 (9.97333 iter/s, 10.0267s/100 iters), loss = 0.0248558
I0822 19:27:42.472472 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0248554 (* 1 = 0.0248554 loss)
I0822 19:27:42.472481 13823 sgd_solver.cpp:112] Iteration 112500, lr = 1e-05
I0822 19:27:52.149421 13823 solver.cpp:239] Iteration 112600 (10.3338 iter/s, 9.67695s/100 iters), loss = 0.0213284
I0822 19:27:52.149480 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0213281 (* 1 = 0.0213281 loss)
I0822 19:27:52.149492 13823 sgd_solver.cpp:112] Iteration 112600, lr = 1e-05
I0822 19:28:01.838526 13823 solver.cpp:239] Iteration 112700 (10.3209 iter/s, 9.68905s/100 iters), loss = 0.0452991
I0822 19:28:01.838575 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0452988 (* 1 = 0.0452988 loss)
I0822 19:28:01.838584 13823 sgd_solver.cpp:112] Iteration 112700, lr = 1e-05
I0822 19:28:11.752842 13823 solver.cpp:239] Iteration 112800 (10.0865 iter/s, 9.91427s/100 iters), loss = 0.039147
I0822 19:28:11.752898 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0391467 (* 1 = 0.0391467 loss)
I0822 19:28:11.752908 13823 sgd_solver.cpp:112] Iteration 112800, lr = 1e-05
I0822 19:28:21.739135 13823 solver.cpp:239] Iteration 112900 (10.0138 iter/s, 9.98624s/100 iters), loss = 0.0266541
I0822 19:28:21.739187 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0266538 (* 1 = 0.0266538 loss)
I0822 19:28:21.739197 13823 sgd_solver.cpp:112] Iteration 112900, lr = 1e-05
I0822 19:28:31.520323 13823 solver.cpp:239] Iteration 113000 (10.2238 iter/s, 9.78114s/100 iters), loss = 0.0285095
I0822 19:28:31.520375 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0285092 (* 1 = 0.0285092 loss)
I0822 19:28:31.520383 13823 sgd_solver.cpp:112] Iteration 113000, lr = 1e-05
I0822 19:28:41.288656 13823 solver.cpp:239] Iteration 113100 (10.2372 iter/s, 9.76828s/100 iters), loss = 0.0335205
I0822 19:28:41.288708 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0335202 (* 1 = 0.0335202 loss)
I0822 19:28:41.288717 13823 sgd_solver.cpp:112] Iteration 113100, lr = 1e-05
I0822 19:28:51.220719 13823 solver.cpp:239] Iteration 113200 (10.0684 iter/s, 9.93202s/100 iters), loss = 0.0272496
I0822 19:28:51.220770 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0272493 (* 1 = 0.0272493 loss)
I0822 19:28:51.220779 13823 sgd_solver.cpp:112] Iteration 113200, lr = 1e-05
I0822 19:29:01.151216 13823 solver.cpp:239] Iteration 113300 (10.07 iter/s, 9.93045s/100 iters), loss = 0.0301671
I0822 19:29:01.151279 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0301668 (* 1 = 0.0301668 loss)
I0822 19:29:01.151289 13823 sgd_solver.cpp:112] Iteration 113300, lr = 1e-05
I0822 19:29:11.054524 13823 solver.cpp:239] Iteration 113400 (10.0977 iter/s, 9.90325s/100 iters), loss = 0.034257
I0822 19:29:11.054575 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0342567 (* 1 = 0.0342567 loss)
I0822 19:29:11.054584 13823 sgd_solver.cpp:112] Iteration 113400, lr = 1e-05
I0822 19:29:21.008651 13823 solver.cpp:239] Iteration 113500 (10.0461 iter/s, 9.95408s/100 iters), loss = 0.025471
I0822 19:29:21.008702 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0254706 (* 1 = 0.0254706 loss)
I0822 19:29:21.008711 13823 sgd_solver.cpp:112] Iteration 113500, lr = 1e-05
I0822 19:29:30.994385 13823 solver.cpp:239] Iteration 113600 (10.0143 iter/s, 9.98569s/100 iters), loss = 0.0253187
I0822 19:29:30.994437 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0253184 (* 1 = 0.0253184 loss)
I0822 19:29:30.994446 13823 sgd_solver.cpp:112] Iteration 113600, lr = 1e-05
I0822 19:29:40.834275 13823 solver.cpp:239] Iteration 113700 (10.1628 iter/s, 9.83984s/100 iters), loss = 0.0301783
I0822 19:29:40.834326 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.030178 (* 1 = 0.030178 loss)
I0822 19:29:40.834334 13823 sgd_solver.cpp:112] Iteration 113700, lr = 1e-05
I0822 19:29:50.558013 13823 solver.cpp:239] Iteration 113800 (10.2842 iter/s, 9.7237s/100 iters), loss = 0.0249583
I0822 19:29:50.558054 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0249579 (* 1 = 0.0249579 loss)
I0822 19:29:50.558061 13823 sgd_solver.cpp:112] Iteration 113800, lr = 1e-05
I0822 19:30:00.244889 13823 solver.cpp:239] Iteration 113900 (10.3233 iter/s, 9.68684s/100 iters), loss = 0.034564
I0822 19:30:00.244941 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0345637 (* 1 = 0.0345637 loss)
I0822 19:30:00.244951 13823 sgd_solver.cpp:112] Iteration 113900, lr = 1e-05
I0822 19:30:09.847981 13823 solver.cpp:239] Iteration 114000 (10.4134 iter/s, 9.60305s/100 iters), loss = 0.0300274
I0822 19:30:09.848032 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0300271 (* 1 = 0.0300271 loss)
I0822 19:30:09.848042 13823 sgd_solver.cpp:112] Iteration 114000, lr = 1e-05
I0822 19:30:19.761165 13823 solver.cpp:239] Iteration 114100 (10.0876 iter/s, 9.91314s/100 iters), loss = 0.0313922
I0822 19:30:19.761215 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0313919 (* 1 = 0.0313919 loss)
I0822 19:30:19.761224 13823 sgd_solver.cpp:112] Iteration 114100, lr = 1e-05
I0822 19:30:29.560412 13823 solver.cpp:239] Iteration 114200 (10.2049 iter/s, 9.7992s/100 iters), loss = 0.029136
I0822 19:30:29.560470 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0291357 (* 1 = 0.0291357 loss)
I0822 19:30:29.560482 13823 sgd_solver.cpp:112] Iteration 114200, lr = 1e-05
I0822 19:30:39.587795 13823 solver.cpp:239] Iteration 114300 (9.97274 iter/s, 10.0273s/100 iters), loss = 0.0242892
I0822 19:30:39.587859 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0242888 (* 1 = 0.0242888 loss)
I0822 19:30:39.587872 13823 sgd_solver.cpp:112] Iteration 114300, lr = 1e-05
I0822 19:30:49.481878 13823 solver.cpp:239] Iteration 114400 (10.1071 iter/s, 9.89403s/100 iters), loss = 0.0300968
I0822 19:30:49.481930 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0300965 (* 1 = 0.0300965 loss)
I0822 19:30:49.481938 13823 sgd_solver.cpp:112] Iteration 114400, lr = 1e-05
I0822 19:30:59.335774 13823 solver.cpp:239] Iteration 114500 (10.1483 iter/s, 9.85385s/100 iters), loss = 0.0288222
I0822 19:30:59.335824 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0288219 (* 1 = 0.0288219 loss)
I0822 19:30:59.335834 13823 sgd_solver.cpp:112] Iteration 114500, lr = 1e-05
I0822 19:31:09.226670 13823 solver.cpp:239] Iteration 114600 (10.1104 iter/s, 9.89085s/100 iters), loss = 0.0251823
I0822 19:31:09.226719 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.025182 (* 1 = 0.025182 loss)
I0822 19:31:09.226728 13823 sgd_solver.cpp:112] Iteration 114600, lr = 1e-05
I0822 19:31:18.961163 13823 solver.cpp:239] Iteration 114700 (10.2728 iter/s, 9.73445s/100 iters), loss = 0.0267271
I0822 19:31:18.961216 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0267268 (* 1 = 0.0267268 loss)
I0822 19:31:18.961225 13823 sgd_solver.cpp:112] Iteration 114700, lr = 1e-05
I0822 19:31:28.666105 13823 solver.cpp:239] Iteration 114800 (10.3041 iter/s, 9.7049s/100 iters), loss = 0.0235682
I0822 19:31:28.666167 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0235679 (* 1 = 0.0235679 loss)
I0822 19:31:28.666177 13823 sgd_solver.cpp:112] Iteration 114800, lr = 1e-05
I0822 19:31:38.887496 13823 solver.cpp:239] Iteration 114900 (9.78345 iter/s, 10.2213s/100 iters), loss = 0.0310861
I0822 19:31:38.887547 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0310858 (* 1 = 0.0310858 loss)
I0822 19:31:38.887555 13823 sgd_solver.cpp:112] Iteration 114900, lr = 1e-05
I0822 19:31:49.104228 13823 solver.cpp:239] Iteration 115000 (9.78791 iter/s, 10.2167s/100 iters), loss = 0.0378165
I0822 19:31:49.104287 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0378162 (* 1 = 0.0378162 loss)
I0822 19:31:49.104298 13823 sgd_solver.cpp:112] Iteration 115000, lr = 1e-05
I0822 19:31:59.194521 13823 solver.cpp:239] Iteration 115100 (9.91056 iter/s, 10.0902s/100 iters), loss = 0.029793
I0822 19:31:59.194571 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0297927 (* 1 = 0.0297927 loss)
I0822 19:31:59.194581 13823 sgd_solver.cpp:112] Iteration 115100, lr = 1e-05
I0822 19:32:09.374305 13823 solver.cpp:239] Iteration 115200 (9.82343 iter/s, 10.1797s/100 iters), loss = 0.023045
I0822 19:32:09.374356 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0230447 (* 1 = 0.0230447 loss)
I0822 19:32:09.374366 13823 sgd_solver.cpp:112] Iteration 115200, lr = 1e-05
I0822 19:32:19.522150 13823 solver.cpp:239] Iteration 115300 (9.85435 iter/s, 10.1478s/100 iters), loss = 0.0252128
I0822 19:32:19.522198 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0252124 (* 1 = 0.0252124 loss)
I0822 19:32:19.522207 13823 sgd_solver.cpp:112] Iteration 115300, lr = 1e-05
I0822 19:32:29.774983 13823 solver.cpp:239] Iteration 115400 (9.75344 iter/s, 10.2528s/100 iters), loss = 0.0278275
I0822 19:32:29.775032 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0278271 (* 1 = 0.0278271 loss)
I0822 19:32:29.775040 13823 sgd_solver.cpp:112] Iteration 115400, lr = 1e-05
I0822 19:32:40.157774 13823 solver.cpp:239] Iteration 115500 (9.63136 iter/s, 10.3827s/100 iters), loss = 0.0245606
I0822 19:32:40.157840 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0245602 (* 1 = 0.0245602 loss)
I0822 19:32:40.157851 13823 sgd_solver.cpp:112] Iteration 115500, lr = 1e-05
I0822 19:32:50.286089 13823 solver.cpp:239] Iteration 115600 (9.87336 iter/s, 10.1283s/100 iters), loss = 0.0262907
I0822 19:32:50.286139 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0262903 (* 1 = 0.0262903 loss)
I0822 19:32:50.286149 13823 sgd_solver.cpp:112] Iteration 115600, lr = 1e-05
I0822 19:33:00.338935 13823 solver.cpp:239] Iteration 115700 (9.94747 iter/s, 10.0528s/100 iters), loss = 0.0370523
I0822 19:33:00.338986 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0370519 (* 1 = 0.0370519 loss)
I0822 19:33:00.338995 13823 sgd_solver.cpp:112] Iteration 115700, lr = 1e-05
I0822 19:33:10.423840 13823 solver.cpp:239] Iteration 115800 (9.91585 iter/s, 10.0849s/100 iters), loss = 0.0262669
I0822 19:33:10.423892 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0262665 (* 1 = 0.0262665 loss)
I0822 19:33:10.423902 13823 sgd_solver.cpp:112] Iteration 115800, lr = 1e-05
I0822 19:33:20.730197 13823 solver.cpp:239] Iteration 115900 (9.70279 iter/s, 10.3063s/100 iters), loss = 0.0268711
I0822 19:33:20.730248 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0268707 (* 1 = 0.0268707 loss)
I0822 19:33:20.730258 13823 sgd_solver.cpp:112] Iteration 115900, lr = 1e-05
I0822 19:33:30.874178 13823 solver.cpp:239] Iteration 116000 (9.8581 iter/s, 10.1439s/100 iters), loss = 0.0258509
I0822 19:33:30.874230 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0258506 (* 1 = 0.0258506 loss)
I0822 19:33:30.874240 13823 sgd_solver.cpp:112] Iteration 116000, lr = 1e-05
I0822 19:33:41.128914 13823 solver.cpp:239] Iteration 116100 (9.75163 iter/s, 10.2547s/100 iters), loss = 0.0274792
I0822 19:33:41.128964 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0274789 (* 1 = 0.0274789 loss)
I0822 19:33:41.128973 13823 sgd_solver.cpp:112] Iteration 116100, lr = 1e-05
I0822 19:33:51.562393 13823 solver.cpp:239] Iteration 116200 (9.58457 iter/s, 10.4334s/100 iters), loss = 0.0255594
I0822 19:33:51.562461 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.025559 (* 1 = 0.025559 loss)
I0822 19:33:51.562475 13823 sgd_solver.cpp:112] Iteration 116200, lr = 1e-05
I0822 19:34:01.701762 13823 solver.cpp:239] Iteration 116300 (9.8626 iter/s, 10.1393s/100 iters), loss = 0.0250209
I0822 19:34:01.701812 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0250206 (* 1 = 0.0250206 loss)
I0822 19:34:01.701822 13823 sgd_solver.cpp:112] Iteration 116300, lr = 1e-05
I0822 19:34:12.172060 13823 solver.cpp:239] Iteration 116400 (9.55086 iter/s, 10.4703s/100 iters), loss = 0.0857843
I0822 19:34:12.172109 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0857839 (* 1 = 0.0857839 loss)
I0822 19:34:12.172119 13823 sgd_solver.cpp:112] Iteration 116400, lr = 1e-05
I0822 19:34:22.423851 13823 solver.cpp:239] Iteration 116500 (9.75443 iter/s, 10.2518s/100 iters), loss = 0.0265671
I0822 19:34:22.423900 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0265668 (* 1 = 0.0265668 loss)
I0822 19:34:22.423909 13823 sgd_solver.cpp:112] Iteration 116500, lr = 1e-05
I0822 19:34:32.713618 13823 solver.cpp:239] Iteration 116600 (9.71843 iter/s, 10.2897s/100 iters), loss = 0.0254661
I0822 19:34:32.713680 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0254658 (* 1 = 0.0254658 loss)
I0822 19:34:32.713691 13823 sgd_solver.cpp:112] Iteration 116600, lr = 1e-05
I0822 19:34:42.752341 13823 solver.cpp:239] Iteration 116700 (9.96147 iter/s, 10.0387s/100 iters), loss = 0.0260157
I0822 19:34:42.752390 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0260154 (* 1 = 0.0260154 loss)
I0822 19:34:42.752399 13823 sgd_solver.cpp:112] Iteration 116700, lr = 1e-05
I0822 19:34:52.760145 13823 solver.cpp:239] Iteration 116800 (9.99223 iter/s, 10.0078s/100 iters), loss = 0.0337326
I0822 19:34:52.760191 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0337323 (* 1 = 0.0337323 loss)
I0822 19:34:52.760200 13823 sgd_solver.cpp:112] Iteration 116800, lr = 1e-05
I0822 19:35:02.852664 13823 solver.cpp:239] Iteration 116900 (9.90836 iter/s, 10.0925s/100 iters), loss = 0.0375747
I0822 19:35:02.852712 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0375743 (* 1 = 0.0375743 loss)
I0822 19:35:02.852721 13823 sgd_solver.cpp:112] Iteration 116900, lr = 1e-05
I0822 19:35:13.176805 13823 solver.cpp:239] Iteration 117000 (9.68607 iter/s, 10.3241s/100 iters), loss = 0.0248083
I0822 19:35:13.176856 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0248079 (* 1 = 0.0248079 loss)
I0822 19:35:13.176864 13823 sgd_solver.cpp:112] Iteration 117000, lr = 1e-05
I0822 19:35:23.096760 13823 solver.cpp:239] Iteration 117100 (10.0807 iter/s, 9.91992s/100 iters), loss = 0.0317615
I0822 19:35:23.096812 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0317611 (* 1 = 0.0317611 loss)
I0822 19:35:23.096820 13823 sgd_solver.cpp:112] Iteration 117100, lr = 1e-05
I0822 19:35:33.307765 13823 solver.cpp:239] Iteration 117200 (9.79339 iter/s, 10.211s/100 iters), loss = 0.0261358
I0822 19:35:33.307814 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0261355 (* 1 = 0.0261355 loss)
I0822 19:35:33.307823 13823 sgd_solver.cpp:112] Iteration 117200, lr = 1e-05
I0822 19:35:43.736464 13823 solver.cpp:239] Iteration 117300 (9.58896 iter/s, 10.4287s/100 iters), loss = 0.0277794
I0822 19:35:43.736524 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.027779 (* 1 = 0.027779 loss)
I0822 19:35:43.736536 13823 sgd_solver.cpp:112] Iteration 117300, lr = 1e-05
I0822 19:35:54.139439 13823 solver.cpp:239] Iteration 117400 (9.61268 iter/s, 10.4029s/100 iters), loss = 0.0302323
I0822 19:35:54.139497 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0302319 (* 1 = 0.0302319 loss)
I0822 19:35:54.139509 13823 sgd_solver.cpp:112] Iteration 117400, lr = 1e-05
I0822 19:36:04.431697 13823 solver.cpp:239] Iteration 117500 (9.71608 iter/s, 10.2922s/100 iters), loss = 0.0285999
I0822 19:36:04.431754 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0285995 (* 1 = 0.0285995 loss)
I0822 19:36:04.431767 13823 sgd_solver.cpp:112] Iteration 117500, lr = 1e-05
I0822 19:36:14.831899 13823 solver.cpp:239] Iteration 117600 (9.61524 iter/s, 10.4002s/100 iters), loss = 0.0301796
I0822 19:36:14.831955 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0301792 (* 1 = 0.0301792 loss)
I0822 19:36:14.831969 13823 sgd_solver.cpp:112] Iteration 117600, lr = 1e-05
I0822 19:36:25.140734 13823 solver.cpp:239] Iteration 117700 (9.70045 iter/s, 10.3088s/100 iters), loss = 0.0239064
I0822 19:36:25.140787 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.023906 (* 1 = 0.023906 loss)
I0822 19:36:25.140796 13823 sgd_solver.cpp:112] Iteration 117700, lr = 1e-05
I0822 19:36:35.737898 13823 solver.cpp:239] Iteration 117800 (9.43652 iter/s, 10.5971s/100 iters), loss = 0.0255777
I0822 19:36:35.737972 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0255773 (* 1 = 0.0255773 loss)
I0822 19:36:35.737989 13823 sgd_solver.cpp:112] Iteration 117800, lr = 1e-05
I0822 19:36:46.068450 13823 solver.cpp:239] Iteration 117900 (9.68007 iter/s, 10.3305s/100 iters), loss = 0.032621
I0822 19:36:46.068507 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0326207 (* 1 = 0.0326207 loss)
I0822 19:36:46.068519 13823 sgd_solver.cpp:112] Iteration 117900, lr = 1e-05
I0822 19:36:56.307694 13823 solver.cpp:239] Iteration 118000 (9.76638 iter/s, 10.2392s/100 iters), loss = 0.0265307
I0822 19:36:56.307750 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0265303 (* 1 = 0.0265303 loss)
I0822 19:36:56.307762 13823 sgd_solver.cpp:112] Iteration 118000, lr = 1e-05
I0822 19:37:06.801899 13823 solver.cpp:239] Iteration 118100 (9.5291 iter/s, 10.4942s/100 iters), loss = 0.0255293
I0822 19:37:06.801959 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0255289 (* 1 = 0.0255289 loss)
I0822 19:37:06.801972 13823 sgd_solver.cpp:112] Iteration 118100, lr = 1e-05
I0822 19:37:17.285946 13823 solver.cpp:239] Iteration 118200 (9.53834 iter/s, 10.484s/100 iters), loss = 0.0257026
I0822 19:37:17.286005 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0257022 (* 1 = 0.0257022 loss)
I0822 19:37:17.286017 13823 sgd_solver.cpp:112] Iteration 118200, lr = 1e-05
I0822 19:37:27.686988 13823 solver.cpp:239] Iteration 118300 (9.61446 iter/s, 10.401s/100 iters), loss = 0.0252357
I0822 19:37:27.687052 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0252353 (* 1 = 0.0252353 loss)
I0822 19:37:27.687064 13823 sgd_solver.cpp:112] Iteration 118300, lr = 1e-05
I0822 19:37:38.117568 13823 solver.cpp:239] Iteration 118400 (9.58724 iter/s, 10.4305s/100 iters), loss = 0.0299536
I0822 19:37:38.117619 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0299532 (* 1 = 0.0299532 loss)
I0822 19:37:38.117628 13823 sgd_solver.cpp:112] Iteration 118400, lr = 1e-05
I0822 19:37:48.608283 13823 solver.cpp:239] Iteration 118500 (9.53227 iter/s, 10.4907s/100 iters), loss = 0.024718
I0822 19:37:48.608336 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0247176 (* 1 = 0.0247176 loss)
I0822 19:37:48.608345 13823 sgd_solver.cpp:112] Iteration 118500, lr = 1e-05
I0822 19:37:58.777139 13823 solver.cpp:239] Iteration 118600 (9.83399 iter/s, 10.1688s/100 iters), loss = 0.0262718
I0822 19:37:58.777199 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0262714 (* 1 = 0.0262714 loss)
I0822 19:37:58.777213 13823 sgd_solver.cpp:112] Iteration 118600, lr = 1e-05
I0822 19:38:09.117231 13823 solver.cpp:239] Iteration 118700 (9.67113 iter/s, 10.34s/100 iters), loss = 0.0229396
I0822 19:38:09.117286 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0229392 (* 1 = 0.0229392 loss)
I0822 19:38:09.117298 13823 sgd_solver.cpp:112] Iteration 118700, lr = 1e-05
I0822 19:38:19.675856 13823 solver.cpp:239] Iteration 118800 (9.47097 iter/s, 10.5586s/100 iters), loss = 0.0235384
I0822 19:38:19.675930 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.023538 (* 1 = 0.023538 loss)
I0822 19:38:19.675946 13823 sgd_solver.cpp:112] Iteration 118800, lr = 1e-05
I0822 19:38:30.041589 13823 solver.cpp:239] Iteration 118900 (9.64722 iter/s, 10.3657s/100 iters), loss = 0.0313138
I0822 19:38:30.041647 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0313134 (* 1 = 0.0313134 loss)
I0822 19:38:30.041661 13823 sgd_solver.cpp:112] Iteration 118900, lr = 1e-05
I0822 19:38:40.579318 13823 solver.cpp:239] Iteration 119000 (9.48975 iter/s, 10.5377s/100 iters), loss = 0.0368917
I0822 19:38:40.579377 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0368913 (* 1 = 0.0368913 loss)
I0822 19:38:40.579388 13823 sgd_solver.cpp:112] Iteration 119000, lr = 1e-05
I0822 19:38:51.058686 13823 solver.cpp:239] Iteration 119100 (9.5426 iter/s, 10.4793s/100 iters), loss = 0.0249008
I0822 19:38:51.058745 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0249004 (* 1 = 0.0249004 loss)
I0822 19:38:51.058755 13823 sgd_solver.cpp:112] Iteration 119100, lr = 1e-05
I0822 19:39:01.385030 13823 solver.cpp:239] Iteration 119200 (9.68401 iter/s, 10.3263s/100 iters), loss = 0.023876
I0822 19:39:01.385079 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0238756 (* 1 = 0.0238756 loss)
I0822 19:39:01.385089 13823 sgd_solver.cpp:112] Iteration 119200, lr = 1e-05
I0822 19:39:12.078794 13823 solver.cpp:239] Iteration 119300 (9.35127 iter/s, 10.6937s/100 iters), loss = 0.0863478
I0822 19:39:12.078845 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0863474 (* 1 = 0.0863474 loss)
I0822 19:39:12.078855 13823 sgd_solver.cpp:112] Iteration 119300, lr = 1e-05
I0822 19:39:21.945297 13823 solver.cpp:239] Iteration 119400 (10.1353 iter/s, 9.86647s/100 iters), loss = 0.0237923
I0822 19:39:21.945338 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0237919 (* 1 = 0.0237919 loss)
I0822 19:39:21.945345 13823 sgd_solver.cpp:112] Iteration 119400, lr = 1e-05
I0822 19:39:32.233409 13823 solver.cpp:239] Iteration 119500 (9.71998 iter/s, 10.2881s/100 iters), loss = 0.02894
I0822 19:39:32.233458 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0289396 (* 1 = 0.0289396 loss)
I0822 19:39:32.233467 13823 sgd_solver.cpp:112] Iteration 119500, lr = 1e-05
I0822 19:39:42.276448 13823 solver.cpp:239] Iteration 119600 (9.95717 iter/s, 10.043s/100 iters), loss = 0.0277826
I0822 19:39:42.276489 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0277822 (* 1 = 0.0277822 loss)
I0822 19:39:42.276497 13823 sgd_solver.cpp:112] Iteration 119600, lr = 1e-05
I0822 19:39:52.772630 13823 solver.cpp:239] Iteration 119700 (9.52729 iter/s, 10.4962s/100 iters), loss = 0.0266184
I0822 19:39:52.772672 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.026618 (* 1 = 0.026618 loss)
I0822 19:39:52.772680 13823 sgd_solver.cpp:112] Iteration 119700, lr = 1e-05
I0822 19:40:03.223387 13823 solver.cpp:239] Iteration 119800 (9.56871 iter/s, 10.4507s/100 iters), loss = 0.0239044
I0822 19:40:03.223444 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.023904 (* 1 = 0.023904 loss)
I0822 19:40:03.223456 13823 sgd_solver.cpp:112] Iteration 119800, lr = 1e-05
I0822 19:40:13.791955 13823 solver.cpp:239] Iteration 119900 (9.46205 iter/s, 10.5685s/100 iters), loss = 0.027402
I0822 19:40:13.792006 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0274016 (* 1 = 0.0274016 loss)
I0822 19:40:13.792016 13823 sgd_solver.cpp:112] Iteration 119900, lr = 1e-05
I0822 19:40:24.143847 13823 solver.cpp:464] Snapshotting to binary proto file ./model_112/cascade_mobilenet_112_iter_120000.caffemodel
I0822 19:40:24.187042 13823 sgd_solver.cpp:284] Snapshotting solver state to binary proto file ./model_112/cascade_mobilenet_112_iter_120000.solverstate
I0822 19:40:24.217839 13823 solver.cpp:347] Iteration 120000, Testing net (#0)
I0822 19:41:27.438385 13823 solver.cpp:414]     Test net output #0: landmark_loss = 0.0222458 (* 1 = 0.0222458 loss)
I0822 19:41:27.560828 13823 solver.cpp:239] Iteration 120000 (1.35558 iter/s, 73.769s/100 iters), loss = 0.0265998
I0822 19:41:27.560892 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0265994 (* 1 = 0.0265994 loss)
I0822 19:41:27.560914 13823 sgd_solver.cpp:112] Iteration 120000, lr = 1e-05
I0822 19:41:38.361780 13823 solver.cpp:239] Iteration 120100 (9.25847 iter/s, 10.8009s/100 iters), loss = 0.0261173
I0822 19:41:38.361832 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0261168 (* 1 = 0.0261168 loss)
I0822 19:41:38.361842 13823 sgd_solver.cpp:112] Iteration 120100, lr = 1e-05
I0822 19:41:49.362108 13823 solver.cpp:239] Iteration 120200 (9.09066 iter/s, 11.0003s/100 iters), loss = 0.0330056
I0822 19:41:49.362167 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0330052 (* 1 = 0.0330052 loss)
I0822 19:41:49.362180 13823 sgd_solver.cpp:112] Iteration 120200, lr = 1e-05
I0822 19:42:00.074766 13823 solver.cpp:239] Iteration 120300 (9.33478 iter/s, 10.7126s/100 iters), loss = 0.0277007
I0822 19:42:00.074829 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0277003 (* 1 = 0.0277003 loss)
I0822 19:42:00.074841 13823 sgd_solver.cpp:112] Iteration 120300, lr = 1e-05
I0822 19:42:10.948204 13823 solver.cpp:239] Iteration 120400 (9.19676 iter/s, 10.8734s/100 iters), loss = 0.0254619
I0822 19:42:10.948253 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0254614 (* 1 = 0.0254614 loss)
I0822 19:42:10.948262 13823 sgd_solver.cpp:112] Iteration 120400, lr = 1e-05
I0822 19:42:21.546751 13823 solver.cpp:239] Iteration 120500 (9.43527 iter/s, 10.5985s/100 iters), loss = 0.0253302
I0822 19:42:21.546792 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0253297 (* 1 = 0.0253297 loss)
I0822 19:42:21.546798 13823 sgd_solver.cpp:112] Iteration 120500, lr = 1e-05
I0822 19:42:32.263958 13823 solver.cpp:239] Iteration 120600 (9.33081 iter/s, 10.7172s/100 iters), loss = 0.0268426
I0822 19:42:32.264008 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0268422 (* 1 = 0.0268422 loss)
I0822 19:42:32.264017 13823 sgd_solver.cpp:112] Iteration 120600, lr = 1e-05
I0822 19:42:43.103408 13823 solver.cpp:239] Iteration 120700 (9.22558 iter/s, 10.8394s/100 iters), loss = 0.0265047
I0822 19:42:43.103473 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0265042 (* 1 = 0.0265042 loss)
I0822 19:42:43.103485 13823 sgd_solver.cpp:112] Iteration 120700, lr = 1e-05
I0822 19:42:54.066673 13823 solver.cpp:239] Iteration 120800 (9.1214 iter/s, 10.9632s/100 iters), loss = 0.0284899
I0822 19:42:54.066732 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0284894 (* 1 = 0.0284894 loss)
I0822 19:42:54.066742 13823 sgd_solver.cpp:112] Iteration 120800, lr = 1e-05
I0822 19:43:04.950592 13823 solver.cpp:239] Iteration 120900 (9.1879 iter/s, 10.8839s/100 iters), loss = 0.0269414
I0822 19:43:04.950652 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.026941 (* 1 = 0.026941 loss)
I0822 19:43:04.950667 13823 sgd_solver.cpp:112] Iteration 120900, lr = 1e-05
I0822 19:43:15.814679 13823 solver.cpp:239] Iteration 121000 (9.20467 iter/s, 10.8641s/100 iters), loss = 0.0238085
I0822 19:43:15.814730 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0238081 (* 1 = 0.0238081 loss)
I0822 19:43:15.814739 13823 sgd_solver.cpp:112] Iteration 121000, lr = 1e-05
I0822 19:43:26.401806 13823 solver.cpp:239] Iteration 121100 (9.44545 iter/s, 10.5871s/100 iters), loss = 0.0267049
I0822 19:43:26.401859 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0267044 (* 1 = 0.0267044 loss)
I0822 19:43:26.401867 13823 sgd_solver.cpp:112] Iteration 121100, lr = 1e-05
I0822 19:43:37.077149 13823 solver.cpp:239] Iteration 121200 (9.36741 iter/s, 10.6753s/100 iters), loss = 0.02686
I0822 19:43:37.077199 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0268596 (* 1 = 0.0268596 loss)
I0822 19:43:37.077209 13823 sgd_solver.cpp:112] Iteration 121200, lr = 1e-05
I0822 19:43:47.879189 13823 solver.cpp:239] Iteration 121300 (9.25753 iter/s, 10.802s/100 iters), loss = 0.0270868
I0822 19:43:47.879247 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0270864 (* 1 = 0.0270864 loss)
I0822 19:43:47.879257 13823 sgd_solver.cpp:112] Iteration 121300, lr = 1e-05
I0822 19:43:58.950610 13823 solver.cpp:239] Iteration 121400 (9.03229 iter/s, 11.0714s/100 iters), loss = 0.0385372
I0822 19:43:58.950670 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0385368 (* 1 = 0.0385368 loss)
I0822 19:43:58.950682 13823 sgd_solver.cpp:112] Iteration 121400, lr = 1e-05
I0822 19:44:10.082906 13823 solver.cpp:239] Iteration 121500 (8.9829 iter/s, 11.1323s/100 iters), loss = 0.0253189
I0822 19:44:10.082963 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0253185 (* 1 = 0.0253185 loss)
I0822 19:44:10.082978 13823 sgd_solver.cpp:112] Iteration 121500, lr = 1e-05
I0822 19:44:21.131058 13823 solver.cpp:239] Iteration 121600 (9.05131 iter/s, 11.0481s/100 iters), loss = 0.0387824
I0822 19:44:21.131115 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.038782 (* 1 = 0.038782 loss)
I0822 19:44:21.131126 13823 sgd_solver.cpp:112] Iteration 121600, lr = 1e-05
I0822 19:44:32.215911 13823 solver.cpp:239] Iteration 121700 (9.02135 iter/s, 11.0848s/100 iters), loss = 0.0297741
I0822 19:44:32.215968 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0297737 (* 1 = 0.0297737 loss)
I0822 19:44:32.215981 13823 sgd_solver.cpp:112] Iteration 121700, lr = 1e-05
I0822 19:44:43.203709 13823 solver.cpp:239] Iteration 121800 (9.10103 iter/s, 10.9878s/100 iters), loss = 0.0285691
I0822 19:44:43.203766 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0285687 (* 1 = 0.0285687 loss)
I0822 19:44:43.203779 13823 sgd_solver.cpp:112] Iteration 121800, lr = 1e-05
I0822 19:44:54.371213 13823 solver.cpp:239] Iteration 121900 (8.95458 iter/s, 11.1675s/100 iters), loss = 0.0220995
I0822 19:44:54.371263 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.022099 (* 1 = 0.022099 loss)
I0822 19:44:54.371273 13823 sgd_solver.cpp:112] Iteration 121900, lr = 1e-05
I0822 19:45:05.495944 13823 solver.cpp:239] Iteration 122000 (8.989 iter/s, 11.1247s/100 iters), loss = 0.0259225
I0822 19:45:05.496003 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0259221 (* 1 = 0.0259221 loss)
I0822 19:45:05.496017 13823 sgd_solver.cpp:112] Iteration 122000, lr = 1e-05
I0822 19:45:16.519721 13823 solver.cpp:239] Iteration 122100 (9.07133 iter/s, 11.0237s/100 iters), loss = 0.02644
I0822 19:45:16.519773 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0264396 (* 1 = 0.0264396 loss)
I0822 19:45:16.519781 13823 sgd_solver.cpp:112] Iteration 122100, lr = 1e-05
I0822 19:45:27.290475 13823 solver.cpp:239] Iteration 122200 (9.28442 iter/s, 10.7707s/100 iters), loss = 0.0332511
I0822 19:45:27.290529 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0332506 (* 1 = 0.0332506 loss)
I0822 19:45:27.290536 13823 sgd_solver.cpp:112] Iteration 122200, lr = 1e-05
I0822 19:45:38.532238 13823 solver.cpp:239] Iteration 122300 (8.89542 iter/s, 11.2417s/100 iters), loss = 0.0292228
I0822 19:45:38.532289 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0292224 (* 1 = 0.0292224 loss)
I0822 19:45:38.532299 13823 sgd_solver.cpp:112] Iteration 122300, lr = 1e-05
I0822 19:45:49.691548 13823 solver.cpp:239] Iteration 122400 (8.96115 iter/s, 11.1593s/100 iters), loss = 0.0328425
I0822 19:45:49.691597 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0328421 (* 1 = 0.0328421 loss)
I0822 19:45:49.691606 13823 sgd_solver.cpp:112] Iteration 122400, lr = 1e-05
I0822 19:46:00.529664 13823 solver.cpp:239] Iteration 122500 (9.22672 iter/s, 10.8381s/100 iters), loss = 0.0224335
I0822 19:46:00.529716 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.022433 (* 1 = 0.022433 loss)
I0822 19:46:00.529726 13823 sgd_solver.cpp:112] Iteration 122500, lr = 1e-05
I0822 19:46:11.497211 13823 solver.cpp:239] Iteration 122600 (9.11783 iter/s, 10.9675s/100 iters), loss = 0.0336654
I0822 19:46:11.497274 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0336649 (* 1 = 0.0336649 loss)
I0822 19:46:11.497287 13823 sgd_solver.cpp:112] Iteration 122600, lr = 1e-05
I0822 19:46:22.775120 13823 solver.cpp:239] Iteration 122700 (8.86692 iter/s, 11.2779s/100 iters), loss = 0.0270571
I0822 19:46:22.775177 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0270567 (* 1 = 0.0270567 loss)
I0822 19:46:22.775187 13823 sgd_solver.cpp:112] Iteration 122700, lr = 1e-05
I0822 19:46:34.133385 13823 solver.cpp:239] Iteration 122800 (8.80419 iter/s, 11.3582s/100 iters), loss = 0.196257
I0822 19:46:34.133450 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.196257 (* 1 = 0.196257 loss)
I0822 19:46:34.133461 13823 sgd_solver.cpp:112] Iteration 122800, lr = 1e-05
I0822 19:46:45.004089 13823 solver.cpp:239] Iteration 122900 (9.19907 iter/s, 10.8707s/100 iters), loss = 0.0272753
I0822 19:46:45.004146 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0272748 (* 1 = 0.0272748 loss)
I0822 19:46:45.004156 13823 sgd_solver.cpp:112] Iteration 122900, lr = 1e-05
I0822 19:46:56.118247 13823 solver.cpp:239] Iteration 123000 (8.99756 iter/s, 11.1141s/100 iters), loss = 0.0248387
I0822 19:46:56.118297 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0248382 (* 1 = 0.0248382 loss)
I0822 19:46:56.118306 13823 sgd_solver.cpp:112] Iteration 123000, lr = 1e-05
I0822 19:47:07.425568 13823 solver.cpp:239] Iteration 123100 (8.84385 iter/s, 11.3073s/100 iters), loss = 0.0315952
I0822 19:47:07.425628 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0315947 (* 1 = 0.0315947 loss)
I0822 19:47:07.425639 13823 sgd_solver.cpp:112] Iteration 123100, lr = 1e-05
I0822 19:47:18.472242 13823 solver.cpp:239] Iteration 123200 (9.05253 iter/s, 11.0466s/100 iters), loss = 0.0266377
I0822 19:47:18.472293 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0266372 (* 1 = 0.0266372 loss)
I0822 19:47:18.472303 13823 sgd_solver.cpp:112] Iteration 123200, lr = 1e-05
I0822 19:47:29.758378 13823 solver.cpp:239] Iteration 123300 (8.86045 iter/s, 11.2861s/100 iters), loss = 0.0280951
I0822 19:47:29.758438 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0280947 (* 1 = 0.0280947 loss)
I0822 19:47:29.758451 13823 sgd_solver.cpp:112] Iteration 123300, lr = 1e-05
I0822 19:47:41.135382 13823 solver.cpp:239] Iteration 123400 (8.78969 iter/s, 11.377s/100 iters), loss = 0.0277634
I0822 19:47:41.135432 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.027763 (* 1 = 0.027763 loss)
I0822 19:47:41.135442 13823 sgd_solver.cpp:112] Iteration 123400, lr = 1e-05
I0822 19:47:52.455914 13823 solver.cpp:239] Iteration 123500 (8.83353 iter/s, 11.3205s/100 iters), loss = 0.0326328
I0822 19:47:52.455978 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0326323 (* 1 = 0.0326323 loss)
I0822 19:47:52.455994 13823 sgd_solver.cpp:112] Iteration 123500, lr = 1e-05
I0822 19:48:03.842939 13823 solver.cpp:239] Iteration 123600 (8.78195 iter/s, 11.387s/100 iters), loss = 0.0335195
I0822 19:48:03.842998 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.033519 (* 1 = 0.033519 loss)
I0822 19:48:03.843008 13823 sgd_solver.cpp:112] Iteration 123600, lr = 1e-05
I0822 19:48:15.240795 13823 solver.cpp:239] Iteration 123700 (8.77361 iter/s, 11.3978s/100 iters), loss = 0.0328337
I0822 19:48:15.240845 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0328332 (* 1 = 0.0328332 loss)
I0822 19:48:15.240855 13823 sgd_solver.cpp:112] Iteration 123700, lr = 1e-05
I0822 19:48:26.492916 13823 solver.cpp:239] Iteration 123800 (8.88724 iter/s, 11.2521s/100 iters), loss = 0.0263263
I0822 19:48:26.492972 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0263259 (* 1 = 0.0263259 loss)
I0822 19:48:26.492983 13823 sgd_solver.cpp:112] Iteration 123800, lr = 1e-05
I0822 19:48:37.847625 13823 solver.cpp:239] Iteration 123900 (8.80694 iter/s, 11.3547s/100 iters), loss = 0.0223325
I0822 19:48:37.847683 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.022332 (* 1 = 0.022332 loss)
I0822 19:48:37.847694 13823 sgd_solver.cpp:112] Iteration 123900, lr = 1e-05
I0822 19:48:49.223568 13823 solver.cpp:239] Iteration 124000 (8.79051 iter/s, 11.3759s/100 iters), loss = 0.0279844
I0822 19:48:49.223628 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.027984 (* 1 = 0.027984 loss)
I0822 19:48:49.223639 13823 sgd_solver.cpp:112] Iteration 124000, lr = 1e-05
I0822 19:49:00.689916 13823 solver.cpp:239] Iteration 124100 (8.7212 iter/s, 11.4663s/100 iters), loss = 0.0248164
I0822 19:49:00.689970 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0248159 (* 1 = 0.0248159 loss)
I0822 19:49:00.689980 13823 sgd_solver.cpp:112] Iteration 124100, lr = 1e-05
I0822 19:49:12.033882 13823 solver.cpp:239] Iteration 124200 (8.81528 iter/s, 11.3439s/100 iters), loss = 0.0288431
I0822 19:49:12.033931 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0288426 (* 1 = 0.0288426 loss)
I0822 19:49:12.033941 13823 sgd_solver.cpp:112] Iteration 124200, lr = 1e-05
I0822 19:49:23.099261 13823 solver.cpp:239] Iteration 124300 (9.03721 iter/s, 11.0654s/100 iters), loss = 0.0318179
I0822 19:49:23.099303 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0318174 (* 1 = 0.0318174 loss)
I0822 19:49:23.099310 13823 sgd_solver.cpp:112] Iteration 124300, lr = 1e-05
I0822 19:49:34.196821 13823 solver.cpp:239] Iteration 124400 (9.01101 iter/s, 11.0975s/100 iters), loss = 0.0286383
I0822 19:49:34.196879 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0286379 (* 1 = 0.0286379 loss)
I0822 19:49:34.196892 13823 sgd_solver.cpp:112] Iteration 124400, lr = 1e-05
I0822 19:49:45.581086 13823 solver.cpp:239] Iteration 124500 (8.78408 iter/s, 11.3842s/100 iters), loss = 0.0255311
I0822 19:49:45.581154 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0255306 (* 1 = 0.0255306 loss)
I0822 19:49:45.581171 13823 sgd_solver.cpp:112] Iteration 124500, lr = 1e-05
I0822 19:49:57.025468 13823 solver.cpp:239] Iteration 124600 (8.73794 iter/s, 11.4443s/100 iters), loss = 0.0381633
I0822 19:49:57.025526 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0381628 (* 1 = 0.0381628 loss)
I0822 19:49:57.025535 13823 sgd_solver.cpp:112] Iteration 124600, lr = 1e-05
I0822 19:50:08.364296 13823 solver.cpp:239] Iteration 124700 (8.81928 iter/s, 11.3388s/100 iters), loss = 0.0224041
I0822 19:50:08.364362 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0224036 (* 1 = 0.0224036 loss)
I0822 19:50:08.364375 13823 sgd_solver.cpp:112] Iteration 124700, lr = 1e-05
I0822 19:50:19.679875 13823 solver.cpp:239] Iteration 124800 (8.83741 iter/s, 11.3155s/100 iters), loss = 0.0288464
I0822 19:50:19.679939 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.028846 (* 1 = 0.028846 loss)
I0822 19:50:19.679951 13823 sgd_solver.cpp:112] Iteration 124800, lr = 1e-05
I0822 19:50:30.939447 13823 solver.cpp:239] Iteration 124900 (8.88136 iter/s, 11.2595s/100 iters), loss = 0.0333687
I0822 19:50:30.939505 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0333682 (* 1 = 0.0333682 loss)
I0822 19:50:30.939518 13823 sgd_solver.cpp:112] Iteration 124900, lr = 1e-05
I0822 19:50:42.141778 13823 solver.cpp:239] Iteration 125000 (8.92674 iter/s, 11.2023s/100 iters), loss = 0.0294334
I0822 19:50:42.141836 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0294329 (* 1 = 0.0294329 loss)
I0822 19:50:42.141851 13823 sgd_solver.cpp:112] Iteration 125000, lr = 1e-05
I0822 19:50:53.599989 13823 solver.cpp:239] Iteration 125100 (8.72739 iter/s, 11.4582s/100 iters), loss = 0.0261029
I0822 19:50:53.600052 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0261025 (* 1 = 0.0261025 loss)
I0822 19:50:53.600064 13823 sgd_solver.cpp:112] Iteration 125100, lr = 1e-05
I0822 19:51:04.722810 13823 solver.cpp:239] Iteration 125200 (8.99055 iter/s, 11.1228s/100 iters), loss = 0.0296439
I0822 19:51:04.722863 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0296434 (* 1 = 0.0296434 loss)
I0822 19:51:04.722872 13823 sgd_solver.cpp:112] Iteration 125200, lr = 1e-05
I0822 19:51:15.879001 13823 solver.cpp:239] Iteration 125300 (8.96366 iter/s, 11.1562s/100 iters), loss = 0.033451
I0822 19:51:15.879051 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0334505 (* 1 = 0.0334505 loss)
I0822 19:51:15.879060 13823 sgd_solver.cpp:112] Iteration 125300, lr = 1e-05
I0822 19:51:27.002213 13823 solver.cpp:239] Iteration 125400 (8.99023 iter/s, 11.1232s/100 iters), loss = 0.0297046
I0822 19:51:27.002265 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0297041 (* 1 = 0.0297041 loss)
I0822 19:51:27.002275 13823 sgd_solver.cpp:112] Iteration 125400, lr = 1e-05
I0822 19:51:38.372295 13823 solver.cpp:239] Iteration 125500 (8.79503 iter/s, 11.3701s/100 iters), loss = 0.022806
I0822 19:51:38.372349 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0228055 (* 1 = 0.0228055 loss)
I0822 19:51:38.372357 13823 sgd_solver.cpp:112] Iteration 125500, lr = 1e-05
I0822 19:51:49.976874 13823 solver.cpp:239] Iteration 125600 (8.61731 iter/s, 11.6045s/100 iters), loss = 0.0243337
I0822 19:51:49.976936 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0243332 (* 1 = 0.0243332 loss)
I0822 19:51:49.976948 13823 sgd_solver.cpp:112] Iteration 125600, lr = 1e-05
I0822 19:52:01.523991 13823 solver.cpp:239] Iteration 125700 (8.6602 iter/s, 11.5471s/100 iters), loss = 0.0285641
I0822 19:52:01.524047 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0285636 (* 1 = 0.0285636 loss)
I0822 19:52:01.524058 13823 sgd_solver.cpp:112] Iteration 125700, lr = 1e-05
I0822 19:52:13.083789 13823 solver.cpp:239] Iteration 125800 (8.65069 iter/s, 11.5598s/100 iters), loss = 0.0268966
I0822 19:52:13.083851 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0268961 (* 1 = 0.0268961 loss)
I0822 19:52:13.083863 13823 sgd_solver.cpp:112] Iteration 125800, lr = 1e-05
I0822 19:52:24.628127 13823 solver.cpp:239] Iteration 125900 (8.66228 iter/s, 11.5443s/100 iters), loss = 0.0267566
I0822 19:52:24.628192 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0267561 (* 1 = 0.0267561 loss)
I0822 19:52:24.628203 13823 sgd_solver.cpp:112] Iteration 125900, lr = 1e-05
I0822 19:52:36.058099 13823 solver.cpp:239] Iteration 126000 (8.74896 iter/s, 11.4299s/100 iters), loss = 0.0345145
I0822 19:52:36.058151 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0345141 (* 1 = 0.0345141 loss)
I0822 19:52:36.058161 13823 sgd_solver.cpp:112] Iteration 126000, lr = 1e-05
I0822 19:52:47.499281 13823 solver.cpp:239] Iteration 126100 (8.74038 iter/s, 11.4412s/100 iters), loss = 0.0469026
I0822 19:52:47.499332 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0469021 (* 1 = 0.0469021 loss)
I0822 19:52:47.499341 13823 sgd_solver.cpp:112] Iteration 126100, lr = 1e-05
I0822 19:52:59.079751 13823 solver.cpp:239] Iteration 126200 (8.63525 iter/s, 11.5804s/100 iters), loss = 0.0294522
I0822 19:52:59.079813 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0294518 (* 1 = 0.0294518 loss)
I0822 19:52:59.079825 13823 sgd_solver.cpp:112] Iteration 126200, lr = 1e-05
I0822 19:53:10.703912 13823 solver.cpp:239] Iteration 126300 (8.6028 iter/s, 11.6241s/100 iters), loss = 0.0287069
I0822 19:53:10.703966 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0287064 (* 1 = 0.0287064 loss)
I0822 19:53:10.703976 13823 sgd_solver.cpp:112] Iteration 126300, lr = 1e-05
I0822 19:53:22.166761 13823 solver.cpp:239] Iteration 126400 (8.72386 iter/s, 11.4628s/100 iters), loss = 0.028511
I0822 19:53:22.166829 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0285105 (* 1 = 0.0285105 loss)
I0822 19:53:22.166846 13823 sgd_solver.cpp:112] Iteration 126400, lr = 1e-05
I0822 19:53:33.767887 13823 solver.cpp:239] Iteration 126500 (8.61988 iter/s, 11.6011s/100 iters), loss = 0.0253338
I0822 19:53:33.767949 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0253333 (* 1 = 0.0253333 loss)
I0822 19:53:33.767961 13823 sgd_solver.cpp:112] Iteration 126500, lr = 1e-05
I0822 19:53:45.218307 13823 solver.cpp:239] Iteration 126600 (8.73333 iter/s, 11.4504s/100 iters), loss = 0.0233741
I0822 19:53:45.218364 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0233736 (* 1 = 0.0233736 loss)
I0822 19:53:45.218377 13823 sgd_solver.cpp:112] Iteration 126600, lr = 1e-05
I0822 19:53:56.543150 13823 solver.cpp:239] Iteration 126700 (8.83017 iter/s, 11.3248s/100 iters), loss = 0.0264782
I0822 19:53:56.543200 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0264777 (* 1 = 0.0264777 loss)
I0822 19:53:56.543208 13823 sgd_solver.cpp:112] Iteration 126700, lr = 1e-05
I0822 19:54:07.679738 13823 solver.cpp:239] Iteration 126800 (8.97943 iter/s, 11.1366s/100 iters), loss = 0.0265723
I0822 19:54:07.679787 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0265719 (* 1 = 0.0265719 loss)
I0822 19:54:07.679796 13823 sgd_solver.cpp:112] Iteration 126800, lr = 1e-05
I0822 19:54:19.219360 13823 solver.cpp:239] Iteration 126900 (8.66582 iter/s, 11.5396s/100 iters), loss = 0.0245343
I0822 19:54:19.219421 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0245338 (* 1 = 0.0245338 loss)
I0822 19:54:19.219432 13823 sgd_solver.cpp:112] Iteration 126900, lr = 1e-05
I0822 19:54:30.961256 13823 solver.cpp:239] Iteration 127000 (8.51654 iter/s, 11.7419s/100 iters), loss = 0.0241536
I0822 19:54:30.961309 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0241531 (* 1 = 0.0241531 loss)
I0822 19:54:30.961319 13823 sgd_solver.cpp:112] Iteration 127000, lr = 1e-05
I0822 19:54:42.449200 13823 solver.cpp:239] Iteration 127100 (8.7048 iter/s, 11.4879s/100 iters), loss = 0.027396
I0822 19:54:42.449252 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0273955 (* 1 = 0.0273955 loss)
I0822 19:54:42.449262 13823 sgd_solver.cpp:112] Iteration 127100, lr = 1e-05
I0822 19:54:53.790369 13823 solver.cpp:239] Iteration 127200 (8.81746 iter/s, 11.3411s/100 iters), loss = 0.0261031
I0822 19:54:53.790429 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0261026 (* 1 = 0.0261026 loss)
I0822 19:54:53.790441 13823 sgd_solver.cpp:112] Iteration 127200, lr = 1e-05
I0822 19:55:05.060068 13823 solver.cpp:239] Iteration 127300 (8.87338 iter/s, 11.2697s/100 iters), loss = 0.0248537
I0822 19:55:05.060119 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0248532 (* 1 = 0.0248532 loss)
I0822 19:55:05.060129 13823 sgd_solver.cpp:112] Iteration 127300, lr = 1e-05
I0822 19:55:16.698582 13823 solver.cpp:239] Iteration 127400 (8.59218 iter/s, 11.6385s/100 iters), loss = 0.0242485
I0822 19:55:16.698642 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0242481 (* 1 = 0.0242481 loss)
I0822 19:55:16.698652 13823 sgd_solver.cpp:112] Iteration 127400, lr = 1e-05
I0822 19:55:28.212919 13823 solver.cpp:239] Iteration 127500 (8.68485 iter/s, 11.5143s/100 iters), loss = 0.0272215
I0822 19:55:28.212973 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.027221 (* 1 = 0.027221 loss)
I0822 19:55:28.212983 13823 sgd_solver.cpp:112] Iteration 127500, lr = 1e-05
I0822 19:55:39.540561 13823 solver.cpp:239] Iteration 127600 (8.82798 iter/s, 11.3276s/100 iters), loss = 0.0258232
I0822 19:55:39.540614 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0258228 (* 1 = 0.0258228 loss)
I0822 19:55:39.540623 13823 sgd_solver.cpp:112] Iteration 127600, lr = 1e-05
I0822 19:55:51.152604 13823 solver.cpp:239] Iteration 127700 (8.61177 iter/s, 11.612s/100 iters), loss = 0.0249644
I0822 19:55:51.152657 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.024964 (* 1 = 0.024964 loss)
I0822 19:55:51.152665 13823 sgd_solver.cpp:112] Iteration 127700, lr = 1e-05
I0822 19:56:02.894235 13823 solver.cpp:239] Iteration 127800 (8.51672 iter/s, 11.7416s/100 iters), loss = 0.0308099
I0822 19:56:02.894286 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0308094 (* 1 = 0.0308094 loss)
I0822 19:56:02.894296 13823 sgd_solver.cpp:112] Iteration 127800, lr = 1e-05
I0822 19:56:12.731695 13823 solver.cpp:239] Iteration 127900 (10.1653 iter/s, 9.83744s/100 iters), loss = 0.0306834
I0822 19:56:12.731736 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.030683 (* 1 = 0.030683 loss)
I0822 19:56:12.731743 13823 sgd_solver.cpp:112] Iteration 127900, lr = 1e-05
I0822 19:56:22.019830 13823 solver.cpp:239] Iteration 128000 (10.7664 iter/s, 9.28811s/100 iters), loss = 0.0251137
I0822 19:56:22.019878 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0251132 (* 1 = 0.0251132 loss)
I0822 19:56:22.019887 13823 sgd_solver.cpp:112] Iteration 128000, lr = 1e-05
I0822 19:56:31.235961 13823 solver.cpp:239] Iteration 128100 (10.8506 iter/s, 9.2161s/100 iters), loss = 0.026093
I0822 19:56:31.236012 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0260925 (* 1 = 0.0260925 loss)
I0822 19:56:31.236021 13823 sgd_solver.cpp:112] Iteration 128100, lr = 1e-05
I0822 19:56:41.060729 13823 solver.cpp:239] Iteration 128200 (10.1784 iter/s, 9.82474s/100 iters), loss = 0.0377802
I0822 19:56:41.060781 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0377797 (* 1 = 0.0377797 loss)
I0822 19:56:41.060789 13823 sgd_solver.cpp:112] Iteration 128200, lr = 1e-05
I0822 19:56:50.721310 13823 solver.cpp:239] Iteration 128300 (10.3514 iter/s, 9.66055s/100 iters), loss = 0.0279323
I0822 19:56:50.721362 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0279318 (* 1 = 0.0279318 loss)
I0822 19:56:50.721371 13823 sgd_solver.cpp:112] Iteration 128300, lr = 1e-05
I0822 19:57:00.426632 13823 solver.cpp:239] Iteration 128400 (10.3037 iter/s, 9.70529s/100 iters), loss = 0.0362906
I0822 19:57:00.426692 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0362902 (* 1 = 0.0362902 loss)
I0822 19:57:00.426702 13823 sgd_solver.cpp:112] Iteration 128400, lr = 1e-05
I0822 19:57:10.239003 13823 solver.cpp:239] Iteration 128500 (10.1913 iter/s, 9.81234s/100 iters), loss = 0.0300253
I0822 19:57:10.239045 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0300249 (* 1 = 0.0300249 loss)
I0822 19:57:10.239053 13823 sgd_solver.cpp:112] Iteration 128500, lr = 1e-05
I0822 19:57:19.665143 13823 solver.cpp:239] Iteration 128600 (10.6088 iter/s, 9.42612s/100 iters), loss = 0.0293731
I0822 19:57:19.665184 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0293726 (* 1 = 0.0293726 loss)
I0822 19:57:19.665191 13823 sgd_solver.cpp:112] Iteration 128600, lr = 1e-05
I0822 19:57:29.342895 13823 solver.cpp:239] Iteration 128700 (10.333 iter/s, 9.67773s/100 iters), loss = 0.0292537
I0822 19:57:29.342945 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0292532 (* 1 = 0.0292532 loss)
I0822 19:57:29.342954 13823 sgd_solver.cpp:112] Iteration 128700, lr = 1e-05
I0822 19:57:38.800107 13823 solver.cpp:239] Iteration 128800 (10.574 iter/s, 9.45718s/100 iters), loss = 0.0254598
I0822 19:57:38.800163 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0254594 (* 1 = 0.0254594 loss)
I0822 19:57:38.800173 13823 sgd_solver.cpp:112] Iteration 128800, lr = 1e-05
I0822 19:57:48.635507 13823 solver.cpp:239] Iteration 128900 (10.1674 iter/s, 9.83536s/100 iters), loss = 0.0335061
I0822 19:57:48.635560 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0335056 (* 1 = 0.0335056 loss)
I0822 19:57:48.635568 13823 sgd_solver.cpp:112] Iteration 128900, lr = 1e-05
I0822 19:57:58.282112 13823 solver.cpp:239] Iteration 129000 (10.3664 iter/s, 9.64657s/100 iters), loss = 0.0391469
I0822 19:57:58.282161 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0391464 (* 1 = 0.0391464 loss)
I0822 19:57:58.282171 13823 sgd_solver.cpp:112] Iteration 129000, lr = 1e-05
I0822 19:58:08.252292 13823 solver.cpp:239] Iteration 129100 (10.0299 iter/s, 9.97015s/100 iters), loss = 0.0305315
I0822 19:58:08.252346 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0305309 (* 1 = 0.0305309 loss)
I0822 19:58:08.252355 13823 sgd_solver.cpp:112] Iteration 129100, lr = 1e-05
I0822 19:58:17.862702 13823 solver.cpp:239] Iteration 129200 (10.4054 iter/s, 9.61037s/100 iters), loss = 0.0286178
I0822 19:58:17.862761 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0286173 (* 1 = 0.0286173 loss)
I0822 19:58:17.862773 13823 sgd_solver.cpp:112] Iteration 129200, lr = 1e-05
I0822 19:58:27.342528 13823 solver.cpp:239] Iteration 129300 (10.5488 iter/s, 9.47978s/100 iters), loss = 0.0326983
I0822 19:58:27.342588 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0326978 (* 1 = 0.0326978 loss)
I0822 19:58:27.342599 13823 sgd_solver.cpp:112] Iteration 129300, lr = 1e-05
I0822 19:58:37.129078 13823 solver.cpp:239] Iteration 129400 (10.2181 iter/s, 9.78651s/100 iters), loss = 0.0280997
I0822 19:58:37.129129 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0280992 (* 1 = 0.0280992 loss)
I0822 19:58:37.129138 13823 sgd_solver.cpp:112] Iteration 129400, lr = 1e-05
I0822 19:58:46.240840 13823 solver.cpp:239] Iteration 129500 (10.9749 iter/s, 9.11173s/100 iters), loss = 0.0330595
I0822 19:58:46.240888 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.033059 (* 1 = 0.033059 loss)
I0822 19:58:46.240896 13823 sgd_solver.cpp:112] Iteration 129500, lr = 1e-05
I0822 19:58:55.680655 13823 solver.cpp:239] Iteration 129600 (10.5935 iter/s, 9.43979s/100 iters), loss = 0.0245061
I0822 19:58:55.680706 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0245056 (* 1 = 0.0245056 loss)
I0822 19:58:55.680713 13823 sgd_solver.cpp:112] Iteration 129600, lr = 1e-05
I0822 19:59:05.365764 13823 solver.cpp:239] Iteration 129700 (10.3252 iter/s, 9.68508s/100 iters), loss = 0.0278523
I0822 19:59:05.365814 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0278518 (* 1 = 0.0278518 loss)
I0822 19:59:05.365824 13823 sgd_solver.cpp:112] Iteration 129700, lr = 1e-05
I0822 19:59:15.351997 13823 solver.cpp:239] Iteration 129800 (10.0138 iter/s, 9.9862s/100 iters), loss = 0.0314233
I0822 19:59:15.352046 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0314228 (* 1 = 0.0314228 loss)
I0822 19:59:15.352056 13823 sgd_solver.cpp:112] Iteration 129800, lr = 1e-05
I0822 19:59:25.419210 13823 solver.cpp:239] Iteration 129900 (9.93327 iter/s, 10.0672s/100 iters), loss = 0.0262158
I0822 19:59:25.419260 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0262153 (* 1 = 0.0262153 loss)
I0822 19:59:25.419268 13823 sgd_solver.cpp:112] Iteration 129900, lr = 1e-05
I0822 19:59:35.123433 13823 solver.cpp:239] Iteration 130000 (10.3048 iter/s, 9.7042s/100 iters), loss = 0.0310213
I0822 19:59:35.123486 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0310208 (* 1 = 0.0310208 loss)
I0822 19:59:35.123493 13823 sgd_solver.cpp:112] Iteration 130000, lr = 1e-05
I0822 19:59:44.810497 13823 solver.cpp:239] Iteration 130100 (10.3231 iter/s, 9.68703s/100 iters), loss = 0.0276433
I0822 19:59:44.810546 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0276428 (* 1 = 0.0276428 loss)
I0822 19:59:44.810556 13823 sgd_solver.cpp:112] Iteration 130100, lr = 1e-05
I0822 19:59:54.379210 13823 solver.cpp:239] Iteration 130200 (10.4508 iter/s, 9.56868s/100 iters), loss = 0.028404
I0822 19:59:54.379259 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0284034 (* 1 = 0.0284034 loss)
I0822 19:59:54.379268 13823 sgd_solver.cpp:112] Iteration 130200, lr = 1e-05
I0822 20:00:04.243412 13823 solver.cpp:239] Iteration 130300 (10.1377 iter/s, 9.86417s/100 iters), loss = 0.0234899
I0822 20:00:04.243466 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0234894 (* 1 = 0.0234894 loss)
I0822 20:00:04.243475 13823 sgd_solver.cpp:112] Iteration 130300, lr = 1e-05
I0822 20:00:13.896870 13823 solver.cpp:239] Iteration 130400 (10.359 iter/s, 9.65342s/100 iters), loss = 0.0286694
I0822 20:00:13.896921 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0286689 (* 1 = 0.0286689 loss)
I0822 20:00:13.896930 13823 sgd_solver.cpp:112] Iteration 130400, lr = 1e-05
I0822 20:00:23.729291 13823 solver.cpp:239] Iteration 130500 (10.1705 iter/s, 9.83239s/100 iters), loss = 0.0238736
I0822 20:00:23.729341 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0238731 (* 1 = 0.0238731 loss)
I0822 20:00:23.729349 13823 sgd_solver.cpp:112] Iteration 130500, lr = 1e-05
I0822 20:00:33.714293 13823 solver.cpp:239] Iteration 130600 (10.0151 iter/s, 9.98497s/100 iters), loss = 0.0225552
I0822 20:00:33.714342 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0225546 (* 1 = 0.0225546 loss)
I0822 20:00:33.714351 13823 sgd_solver.cpp:112] Iteration 130600, lr = 1e-05
I0822 20:00:43.120224 13823 solver.cpp:239] Iteration 130700 (10.6316 iter/s, 9.4059s/100 iters), loss = 0.0251781
I0822 20:00:43.120276 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0251775 (* 1 = 0.0251775 loss)
I0822 20:00:43.120286 13823 sgd_solver.cpp:112] Iteration 130700, lr = 1e-05
I0822 20:00:53.160425 13823 solver.cpp:239] Iteration 130800 (9.95999 iter/s, 10.0402s/100 iters), loss = 0.0262004
I0822 20:00:53.160481 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0261998 (* 1 = 0.0261998 loss)
I0822 20:00:53.160491 13823 sgd_solver.cpp:112] Iteration 130800, lr = 1e-05
I0822 20:01:02.845088 13823 solver.cpp:239] Iteration 130900 (10.3256 iter/s, 9.68462s/100 iters), loss = 0.0452155
I0822 20:01:02.845139 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.045215 (* 1 = 0.045215 loss)
I0822 20:01:02.845149 13823 sgd_solver.cpp:112] Iteration 130900, lr = 1e-05
I0822 20:01:12.687631 13823 solver.cpp:239] Iteration 131000 (10.16 iter/s, 9.84251s/100 iters), loss = 0.0282702
I0822 20:01:12.687682 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0282697 (* 1 = 0.0282697 loss)
I0822 20:01:12.687690 13823 sgd_solver.cpp:112] Iteration 131000, lr = 1e-05
I0822 20:01:22.509409 13823 solver.cpp:239] Iteration 131100 (10.1815 iter/s, 9.82174s/100 iters), loss = 0.0277107
I0822 20:01:22.509461 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0277102 (* 1 = 0.0277102 loss)
I0822 20:01:22.509470 13823 sgd_solver.cpp:112] Iteration 131100, lr = 1e-05
I0822 20:01:32.227478 13823 solver.cpp:239] Iteration 131200 (10.2902 iter/s, 9.71803s/100 iters), loss = 0.0251687
I0822 20:01:32.227541 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0251682 (* 1 = 0.0251682 loss)
I0822 20:01:32.227555 13823 sgd_solver.cpp:112] Iteration 131200, lr = 1e-05
I0822 20:01:42.258198 13823 solver.cpp:239] Iteration 131300 (9.96942 iter/s, 10.0307s/100 iters), loss = 0.0315202
I0822 20:01:42.258246 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0315197 (* 1 = 0.0315197 loss)
I0822 20:01:42.258255 13823 sgd_solver.cpp:112] Iteration 131300, lr = 1e-05
I0822 20:01:52.086441 13823 solver.cpp:239] Iteration 131400 (10.1748 iter/s, 9.82822s/100 iters), loss = 0.0269394
I0822 20:01:52.086488 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0269389 (* 1 = 0.0269389 loss)
I0822 20:01:52.086498 13823 sgd_solver.cpp:112] Iteration 131400, lr = 1e-05
I0822 20:02:01.965472 13823 solver.cpp:239] Iteration 131500 (10.1224 iter/s, 9.87906s/100 iters), loss = 0.0248045
I0822 20:02:01.965530 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0248039 (* 1 = 0.0248039 loss)
I0822 20:02:01.965541 13823 sgd_solver.cpp:112] Iteration 131500, lr = 1e-05
I0822 20:02:12.143827 13823 solver.cpp:239] Iteration 131600 (9.82475 iter/s, 10.1784s/100 iters), loss = 0.0280732
I0822 20:02:12.143878 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0280727 (* 1 = 0.0280727 loss)
I0822 20:02:12.143887 13823 sgd_solver.cpp:112] Iteration 131600, lr = 1e-05
I0822 20:02:21.920789 13823 solver.cpp:239] Iteration 131700 (10.2281 iter/s, 9.77699s/100 iters), loss = 0.0243891
I0822 20:02:21.920836 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0243886 (* 1 = 0.0243886 loss)
I0822 20:02:21.920845 13823 sgd_solver.cpp:112] Iteration 131700, lr = 1e-05
I0822 20:02:31.856320 13823 solver.cpp:239] Iteration 131800 (10.0649 iter/s, 9.93556s/100 iters), loss = 0.0246328
I0822 20:02:31.856379 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0246323 (* 1 = 0.0246323 loss)
I0822 20:02:31.856390 13823 sgd_solver.cpp:112] Iteration 131800, lr = 1e-05
I0822 20:02:41.868489 13823 solver.cpp:239] Iteration 131900 (9.98783 iter/s, 10.0122s/100 iters), loss = 0.0253948
I0822 20:02:41.868541 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0253943 (* 1 = 0.0253943 loss)
I0822 20:02:41.868551 13823 sgd_solver.cpp:112] Iteration 131900, lr = 1e-05
I0822 20:02:51.768401 13823 solver.cpp:239] Iteration 132000 (10.1011 iter/s, 9.89993s/100 iters), loss = 0.0258225
I0822 20:02:51.768453 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.025822 (* 1 = 0.025822 loss)
I0822 20:02:51.768462 13823 sgd_solver.cpp:112] Iteration 132000, lr = 1e-05
I0822 20:03:01.913893 13823 solver.cpp:239] Iteration 132100 (9.85657 iter/s, 10.1455s/100 iters), loss = 0.0257603
I0822 20:03:01.913944 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0257597 (* 1 = 0.0257597 loss)
I0822 20:03:01.913954 13823 sgd_solver.cpp:112] Iteration 132100, lr = 1e-05
I0822 20:03:11.511205 13823 solver.cpp:239] Iteration 132200 (10.4196 iter/s, 9.59733s/100 iters), loss = 0.0366492
I0822 20:03:11.511257 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0366487 (* 1 = 0.0366487 loss)
I0822 20:03:11.511267 13823 sgd_solver.cpp:112] Iteration 132200, lr = 1e-05
I0822 20:03:21.507557 13823 solver.cpp:239] Iteration 132300 (10.0036 iter/s, 9.99637s/100 iters), loss = 0.0372522
I0822 20:03:21.507616 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0372517 (* 1 = 0.0372517 loss)
I0822 20:03:21.507627 13823 sgd_solver.cpp:112] Iteration 132300, lr = 1e-05
I0822 20:03:31.100742 13823 solver.cpp:239] Iteration 132400 (10.4241 iter/s, 9.5932s/100 iters), loss = 0.027302
I0822 20:03:31.100795 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0273015 (* 1 = 0.0273015 loss)
I0822 20:03:31.100803 13823 sgd_solver.cpp:112] Iteration 132400, lr = 1e-05
I0822 20:03:40.736755 13823 solver.cpp:239] Iteration 132500 (10.3777 iter/s, 9.63603s/100 iters), loss = 0.0294693
I0822 20:03:40.736805 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0294687 (* 1 = 0.0294687 loss)
I0822 20:03:40.736814 13823 sgd_solver.cpp:112] Iteration 132500, lr = 1e-05
I0822 20:03:50.457707 13823 solver.cpp:239] Iteration 132600 (10.287 iter/s, 9.72097s/100 iters), loss = 0.0296288
I0822 20:03:50.457760 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0296283 (* 1 = 0.0296283 loss)
I0822 20:03:50.457769 13823 sgd_solver.cpp:112] Iteration 132600, lr = 1e-05
I0822 20:04:00.474555 13823 solver.cpp:239] Iteration 132700 (9.98316 iter/s, 10.0169s/100 iters), loss = 0.0295467
I0822 20:04:00.474606 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0295462 (* 1 = 0.0295462 loss)
I0822 20:04:00.474615 13823 sgd_solver.cpp:112] Iteration 132700, lr = 1e-05
I0822 20:04:10.200651 13823 solver.cpp:239] Iteration 132800 (10.2816 iter/s, 9.72611s/100 iters), loss = 0.0258069
I0822 20:04:10.200700 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0258064 (* 1 = 0.0258064 loss)
I0822 20:04:10.200711 13823 sgd_solver.cpp:112] Iteration 132800, lr = 1e-05
I0822 20:04:20.448393 13823 solver.cpp:239] Iteration 132900 (9.75823 iter/s, 10.2478s/100 iters), loss = 0.0341055
I0822 20:04:20.448448 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.034105 (* 1 = 0.034105 loss)
I0822 20:04:20.448460 13823 sgd_solver.cpp:112] Iteration 132900, lr = 1e-05
I0822 20:04:30.388970 13823 solver.cpp:239] Iteration 133000 (10.0598 iter/s, 9.94059s/100 iters), loss = 0.0275699
I0822 20:04:30.389029 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0275694 (* 1 = 0.0275694 loss)
I0822 20:04:30.389040 13823 sgd_solver.cpp:112] Iteration 133000, lr = 1e-05
I0822 20:04:40.394165 13823 solver.cpp:239] Iteration 133100 (9.9948 iter/s, 10.0052s/100 iters), loss = 0.0277469
I0822 20:04:40.394215 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0277464 (* 1 = 0.0277464 loss)
I0822 20:04:40.394225 13823 sgd_solver.cpp:112] Iteration 133100, lr = 1e-05
I0822 20:04:50.523835 13823 solver.cpp:239] Iteration 133200 (9.87198 iter/s, 10.1297s/100 iters), loss = 0.026534
I0822 20:04:50.523898 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0265335 (* 1 = 0.0265335 loss)
I0822 20:04:50.523910 13823 sgd_solver.cpp:112] Iteration 133200, lr = 1e-05
I0822 20:05:00.519881 13823 solver.cpp:239] Iteration 133300 (10.004 iter/s, 9.99605s/100 iters), loss = 0.0311067
I0822 20:05:00.519937 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0311062 (* 1 = 0.0311062 loss)
I0822 20:05:00.519948 13823 sgd_solver.cpp:112] Iteration 133300, lr = 1e-05
I0822 20:05:10.447110 13823 solver.cpp:239] Iteration 133400 (10.0733 iter/s, 9.92723s/100 iters), loss = 0.0294204
I0822 20:05:10.447167 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0294199 (* 1 = 0.0294199 loss)
I0822 20:05:10.447177 13823 sgd_solver.cpp:112] Iteration 133400, lr = 1e-05
I0822 20:05:20.747602 13823 solver.cpp:239] Iteration 133500 (9.70827 iter/s, 10.3005s/100 iters), loss = 0.031704
I0822 20:05:20.747654 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0317035 (* 1 = 0.0317035 loss)
I0822 20:05:20.747663 13823 sgd_solver.cpp:112] Iteration 133500, lr = 1e-05
I0822 20:05:30.799947 13823 solver.cpp:239] Iteration 133600 (9.94792 iter/s, 10.0524s/100 iters), loss = 0.0245224
I0822 20:05:30.799995 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0245218 (* 1 = 0.0245218 loss)
I0822 20:05:30.800004 13823 sgd_solver.cpp:112] Iteration 133600, lr = 1e-05
I0822 20:05:40.979598 13823 solver.cpp:239] Iteration 133700 (9.82351 iter/s, 10.1797s/100 iters), loss = 0.0252289
I0822 20:05:40.979660 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0252283 (* 1 = 0.0252283 loss)
I0822 20:05:40.979672 13823 sgd_solver.cpp:112] Iteration 133700, lr = 1e-05
I0822 20:05:51.083083 13823 solver.cpp:239] Iteration 133800 (9.89757 iter/s, 10.1035s/100 iters), loss = 0.0319493
I0822 20:05:51.083135 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0319488 (* 1 = 0.0319488 loss)
I0822 20:05:51.083145 13823 sgd_solver.cpp:112] Iteration 133800, lr = 1e-05
I0822 20:06:01.013556 13823 solver.cpp:239] Iteration 133900 (10.07 iter/s, 9.93048s/100 iters), loss = 0.0355813
I0822 20:06:01.013607 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0355808 (* 1 = 0.0355808 loss)
I0822 20:06:01.013615 13823 sgd_solver.cpp:112] Iteration 133900, lr = 1e-05
I0822 20:06:10.861816 13823 solver.cpp:239] Iteration 134000 (10.1541 iter/s, 9.84827s/100 iters), loss = 0.0424005
I0822 20:06:10.861865 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0424 (* 1 = 0.0424 loss)
I0822 20:06:10.861874 13823 sgd_solver.cpp:112] Iteration 134000, lr = 1e-05
I0822 20:06:20.770484 13823 solver.cpp:239] Iteration 134100 (10.0922 iter/s, 9.90868s/100 iters), loss = 0.0364488
I0822 20:06:20.770535 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0364483 (* 1 = 0.0364483 loss)
I0822 20:06:20.770545 13823 sgd_solver.cpp:112] Iteration 134100, lr = 1e-05
I0822 20:06:31.042801 13823 solver.cpp:239] Iteration 134200 (9.73489 iter/s, 10.2723s/100 iters), loss = 0.02613
I0822 20:06:31.042855 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0261295 (* 1 = 0.0261295 loss)
I0822 20:06:31.042865 13823 sgd_solver.cpp:112] Iteration 134200, lr = 1e-05
I0822 20:06:41.215298 13823 solver.cpp:239] Iteration 134300 (9.83043 iter/s, 10.1725s/100 iters), loss = 0.0421293
I0822 20:06:41.215349 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0421288 (* 1 = 0.0421288 loss)
I0822 20:06:41.215359 13823 sgd_solver.cpp:112] Iteration 134300, lr = 1e-05
I0822 20:06:51.311245 13823 solver.cpp:239] Iteration 134400 (9.90496 iter/s, 10.096s/100 iters), loss = 0.0292442
I0822 20:06:51.311293 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0292436 (* 1 = 0.0292436 loss)
I0822 20:06:51.311302 13823 sgd_solver.cpp:112] Iteration 134400, lr = 1e-05
I0822 20:07:01.233287 13823 solver.cpp:239] Iteration 134500 (10.0786 iter/s, 9.92205s/100 iters), loss = 0.0257189
I0822 20:07:01.233340 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0257184 (* 1 = 0.0257184 loss)
I0822 20:07:01.233348 13823 sgd_solver.cpp:112] Iteration 134500, lr = 1e-05
I0822 20:07:11.456441 13823 solver.cpp:239] Iteration 134600 (9.78171 iter/s, 10.2232s/100 iters), loss = 0.0314743
I0822 20:07:11.456501 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0314738 (* 1 = 0.0314738 loss)
I0822 20:07:11.456512 13823 sgd_solver.cpp:112] Iteration 134600, lr = 1e-05
I0822 20:07:21.521354 13823 solver.cpp:239] Iteration 134700 (9.93551 iter/s, 10.0649s/100 iters), loss = 0.0261234
I0822 20:07:21.521404 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0261229 (* 1 = 0.0261229 loss)
I0822 20:07:21.521412 13823 sgd_solver.cpp:112] Iteration 134700, lr = 1e-05
I0822 20:07:31.692864 13823 solver.cpp:239] Iteration 134800 (9.83138 iter/s, 10.1715s/100 iters), loss = 0.0275344
I0822 20:07:31.692924 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0275338 (* 1 = 0.0275338 loss)
I0822 20:07:31.692934 13823 sgd_solver.cpp:112] Iteration 134800, lr = 1e-05
I0822 20:07:42.036070 13823 solver.cpp:239] Iteration 134900 (9.66818 iter/s, 10.3432s/100 iters), loss = 0.0300598
I0822 20:07:42.036120 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0300592 (* 1 = 0.0300592 loss)
I0822 20:07:42.036134 13823 sgd_solver.cpp:112] Iteration 134900, lr = 1e-05
I0822 20:07:52.110633 13823 solver.cpp:239] Iteration 135000 (9.92599 iter/s, 10.0746s/100 iters), loss = 0.0273011
I0822 20:07:52.110682 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0273006 (* 1 = 0.0273006 loss)
I0822 20:07:52.110692 13823 sgd_solver.cpp:112] Iteration 135000, lr = 1e-05
I0822 20:08:01.943563 13823 solver.cpp:239] Iteration 135100 (10.1699 iter/s, 9.83294s/100 iters), loss = 0.0431668
I0822 20:08:01.943604 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0431662 (* 1 = 0.0431662 loss)
I0822 20:08:01.943611 13823 sgd_solver.cpp:112] Iteration 135100, lr = 1e-05
I0822 20:08:12.189689 13823 solver.cpp:239] Iteration 135200 (9.75978 iter/s, 10.2461s/100 iters), loss = 0.0255323
I0822 20:08:12.189739 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0255317 (* 1 = 0.0255317 loss)
I0822 20:08:12.189749 13823 sgd_solver.cpp:112] Iteration 135200, lr = 1e-05
I0822 20:08:22.302009 13823 solver.cpp:239] Iteration 135300 (9.88893 iter/s, 10.1123s/100 iters), loss = 0.0296645
I0822 20:08:22.302058 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.029664 (* 1 = 0.029664 loss)
I0822 20:08:22.302067 13823 sgd_solver.cpp:112] Iteration 135300, lr = 1e-05
I0822 20:08:32.170481 13823 solver.cpp:239] Iteration 135400 (10.1333 iter/s, 9.86847s/100 iters), loss = 0.0246138
I0822 20:08:32.170531 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0246133 (* 1 = 0.0246133 loss)
I0822 20:08:32.170541 13823 sgd_solver.cpp:112] Iteration 135400, lr = 1e-05
I0822 20:08:42.042310 13823 solver.cpp:239] Iteration 135500 (10.1298 iter/s, 9.87183s/100 iters), loss = 0.0291027
I0822 20:08:42.042357 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0291021 (* 1 = 0.0291021 loss)
I0822 20:08:42.042366 13823 sgd_solver.cpp:112] Iteration 135500, lr = 1e-05
I0822 20:08:52.099953 13823 solver.cpp:239] Iteration 135600 (9.94268 iter/s, 10.0576s/100 iters), loss = 0.0245237
I0822 20:08:52.100004 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0245231 (* 1 = 0.0245231 loss)
I0822 20:08:52.100013 13823 sgd_solver.cpp:112] Iteration 135600, lr = 1e-05
I0822 20:09:02.505319 13823 solver.cpp:239] Iteration 135700 (9.61043 iter/s, 10.4054s/100 iters), loss = 0.0249062
I0822 20:09:02.505369 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0249057 (* 1 = 0.0249057 loss)
I0822 20:09:02.505378 13823 sgd_solver.cpp:112] Iteration 135700, lr = 1e-05
I0822 20:09:12.784560 13823 solver.cpp:239] Iteration 135800 (9.72834 iter/s, 10.2792s/100 iters), loss = 0.0242651
I0822 20:09:12.784610 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0242646 (* 1 = 0.0242646 loss)
I0822 20:09:12.784620 13823 sgd_solver.cpp:112] Iteration 135800, lr = 1e-05
I0822 20:09:23.109742 13823 solver.cpp:239] Iteration 135900 (9.68506 iter/s, 10.3252s/100 iters), loss = 0.0869082
I0822 20:09:23.109800 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0869077 (* 1 = 0.0869077 loss)
I0822 20:09:23.109812 13823 sgd_solver.cpp:112] Iteration 135900, lr = 1e-05
I0822 20:09:33.480104 13823 solver.cpp:239] Iteration 136000 (9.64287 iter/s, 10.3704s/100 iters), loss = 0.0262607
I0822 20:09:33.480167 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0262601 (* 1 = 0.0262601 loss)
I0822 20:09:33.480178 13823 sgd_solver.cpp:112] Iteration 136000, lr = 1e-05
I0822 20:09:43.851886 13823 solver.cpp:239] Iteration 136100 (9.64156 iter/s, 10.3718s/100 iters), loss = 0.0337323
I0822 20:09:43.851938 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0337317 (* 1 = 0.0337317 loss)
I0822 20:09:43.851948 13823 sgd_solver.cpp:112] Iteration 136100, lr = 1e-05
I0822 20:09:54.009351 13823 solver.cpp:239] Iteration 136200 (9.84498 iter/s, 10.1575s/100 iters), loss = 0.0274441
I0822 20:09:54.009402 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0274436 (* 1 = 0.0274436 loss)
I0822 20:09:54.009410 13823 sgd_solver.cpp:112] Iteration 136200, lr = 1e-05
I0822 20:10:04.490738 13823 solver.cpp:239] Iteration 136300 (9.54072 iter/s, 10.4814s/100 iters), loss = 0.0248392
I0822 20:10:04.490789 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0248387 (* 1 = 0.0248387 loss)
I0822 20:10:04.490798 13823 sgd_solver.cpp:112] Iteration 136300, lr = 1e-05
I0822 20:10:14.894784 13823 solver.cpp:239] Iteration 136400 (9.61165 iter/s, 10.404s/100 iters), loss = 0.0231558
I0822 20:10:14.894837 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0231553 (* 1 = 0.0231553 loss)
I0822 20:10:14.894846 13823 sgd_solver.cpp:112] Iteration 136400, lr = 1e-05
I0822 20:10:25.031615 13823 solver.cpp:239] Iteration 136500 (9.86502 iter/s, 10.1368s/100 iters), loss = 0.02337
I0822 20:10:25.031664 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0233695 (* 1 = 0.0233695 loss)
I0822 20:10:25.031673 13823 sgd_solver.cpp:112] Iteration 136500, lr = 1e-05
I0822 20:10:35.296952 13823 solver.cpp:239] Iteration 136600 (9.74152 iter/s, 10.2653s/100 iters), loss = 0.0394995
I0822 20:10:35.297001 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.039499 (* 1 = 0.039499 loss)
I0822 20:10:35.297010 13823 sgd_solver.cpp:112] Iteration 136600, lr = 1e-05
I0822 20:10:45.284359 13823 solver.cpp:239] Iteration 136700 (10.0126 iter/s, 9.9874s/100 iters), loss = 0.0257576
I0822 20:10:45.284411 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0257571 (* 1 = 0.0257571 loss)
I0822 20:10:45.284420 13823 sgd_solver.cpp:112] Iteration 136700, lr = 1e-05
I0822 20:10:55.221244 13823 solver.cpp:239] Iteration 136800 (10.0635 iter/s, 9.93688s/100 iters), loss = 0.0270326
I0822 20:10:55.221297 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0270321 (* 1 = 0.0270321 loss)
I0822 20:10:55.221305 13823 sgd_solver.cpp:112] Iteration 136800, lr = 1e-05
I0822 20:11:05.270697 13823 solver.cpp:239] Iteration 136900 (9.9508 iter/s, 10.0494s/100 iters), loss = 0.0442171
I0822 20:11:05.270747 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0442166 (* 1 = 0.0442166 loss)
I0822 20:11:05.270756 13823 sgd_solver.cpp:112] Iteration 136900, lr = 1e-05
I0822 20:11:15.623062 13823 solver.cpp:239] Iteration 137000 (9.65963 iter/s, 10.3524s/100 iters), loss = 0.0265119
I0822 20:11:15.623114 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0265114 (* 1 = 0.0265114 loss)
I0822 20:11:15.623124 13823 sgd_solver.cpp:112] Iteration 137000, lr = 1e-05
I0822 20:11:26.186834 13823 solver.cpp:239] Iteration 137100 (9.46632 iter/s, 10.5638s/100 iters), loss = 0.0287772
I0822 20:11:26.186885 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0287767 (* 1 = 0.0287767 loss)
I0822 20:11:26.186895 13823 sgd_solver.cpp:112] Iteration 137100, lr = 1e-05
I0822 20:11:36.327414 13823 solver.cpp:239] Iteration 137200 (9.86138 iter/s, 10.1406s/100 iters), loss = 0.0250201
I0822 20:11:36.327466 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0250196 (* 1 = 0.0250196 loss)
I0822 20:11:36.327474 13823 sgd_solver.cpp:112] Iteration 137200, lr = 1e-05
I0822 20:11:46.701131 13823 solver.cpp:239] Iteration 137300 (9.63975 iter/s, 10.3737s/100 iters), loss = 0.091134
I0822 20:11:46.701182 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0911335 (* 1 = 0.0911335 loss)
I0822 20:11:46.701191 13823 sgd_solver.cpp:112] Iteration 137300, lr = 1e-05
I0822 20:11:56.879184 13823 solver.cpp:239] Iteration 137400 (9.82506 iter/s, 10.1781s/100 iters), loss = 0.0266378
I0822 20:11:56.879225 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0266373 (* 1 = 0.0266373 loss)
I0822 20:11:56.879232 13823 sgd_solver.cpp:112] Iteration 137400, lr = 1e-05
I0822 20:12:07.227238 13823 solver.cpp:239] Iteration 137500 (9.66365 iter/s, 10.3481s/100 iters), loss = 0.0300695
I0822 20:12:07.227294 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0300689 (* 1 = 0.0300689 loss)
I0822 20:12:07.227305 13823 sgd_solver.cpp:112] Iteration 137500, lr = 1e-05
I0822 20:12:17.615995 13823 solver.cpp:239] Iteration 137600 (9.6258 iter/s, 10.3887s/100 iters), loss = 0.0371632
I0822 20:12:17.616046 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0371627 (* 1 = 0.0371627 loss)
I0822 20:12:17.616055 13823 sgd_solver.cpp:112] Iteration 137600, lr = 1e-05
I0822 20:12:28.343868 13823 solver.cpp:239] Iteration 137700 (9.32152 iter/s, 10.7279s/100 iters), loss = 0.032552
I0822 20:12:28.343919 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0325514 (* 1 = 0.0325514 loss)
I0822 20:12:28.343928 13823 sgd_solver.cpp:112] Iteration 137700, lr = 1e-05
I0822 20:12:39.144899 13823 solver.cpp:239] Iteration 137800 (9.25838 iter/s, 10.801s/100 iters), loss = 0.0256435
I0822 20:12:39.144958 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0256429 (* 1 = 0.0256429 loss)
I0822 20:12:39.144968 13823 sgd_solver.cpp:112] Iteration 137800, lr = 1e-05
I0822 20:12:49.498080 13823 solver.cpp:239] Iteration 137900 (9.65888 iter/s, 10.3532s/100 iters), loss = 0.0245005
I0822 20:12:49.498143 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0244999 (* 1 = 0.0244999 loss)
I0822 20:12:49.498155 13823 sgd_solver.cpp:112] Iteration 137900, lr = 1e-05
I0822 20:12:59.959638 13823 solver.cpp:239] Iteration 138000 (9.55882 iter/s, 10.4615s/100 iters), loss = 0.0309315
I0822 20:12:59.959687 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0309309 (* 1 = 0.0309309 loss)
I0822 20:12:59.959697 13823 sgd_solver.cpp:112] Iteration 138000, lr = 1e-05
I0822 20:13:10.432673 13823 solver.cpp:239] Iteration 138100 (9.54834 iter/s, 10.473s/100 iters), loss = 0.0294252
I0822 20:13:10.432725 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0294247 (* 1 = 0.0294247 loss)
I0822 20:13:10.432735 13823 sgd_solver.cpp:112] Iteration 138100, lr = 1e-05
I0822 20:13:21.098655 13823 solver.cpp:239] Iteration 138200 (9.37561 iter/s, 10.666s/100 iters), loss = 0.0279929
I0822 20:13:21.098717 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0279923 (* 1 = 0.0279923 loss)
I0822 20:13:21.098729 13823 sgd_solver.cpp:112] Iteration 138200, lr = 1e-05
I0822 20:13:32.023741 13823 solver.cpp:239] Iteration 138300 (9.15326 iter/s, 10.9251s/100 iters), loss = 0.0277168
I0822 20:13:32.023804 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0277163 (* 1 = 0.0277163 loss)
I0822 20:13:32.023816 13823 sgd_solver.cpp:112] Iteration 138300, lr = 1e-05
I0822 20:13:42.885629 13823 solver.cpp:239] Iteration 138400 (9.20652 iter/s, 10.8619s/100 iters), loss = 0.0280244
I0822 20:13:42.885684 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0280238 (* 1 = 0.0280238 loss)
I0822 20:13:42.885694 13823 sgd_solver.cpp:112] Iteration 138400, lr = 1e-05
I0822 20:13:53.383806 13823 solver.cpp:239] Iteration 138500 (9.52547 iter/s, 10.4982s/100 iters), loss = 0.0273088
I0822 20:13:53.383857 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0273083 (* 1 = 0.0273083 loss)
I0822 20:13:53.383867 13823 sgd_solver.cpp:112] Iteration 138500, lr = 1e-05
I0822 20:14:04.030318 13823 solver.cpp:239] Iteration 138600 (9.39276 iter/s, 10.6465s/100 iters), loss = 0.0277127
I0822 20:14:04.030370 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0277122 (* 1 = 0.0277122 loss)
I0822 20:14:04.030380 13823 sgd_solver.cpp:112] Iteration 138600, lr = 1e-05
I0822 20:14:15.104555 13823 solver.cpp:239] Iteration 138700 (9.02997 iter/s, 11.0742s/100 iters), loss = 0.0293755
I0822 20:14:15.104606 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.029375 (* 1 = 0.029375 loss)
I0822 20:14:15.104615 13823 sgd_solver.cpp:112] Iteration 138700, lr = 1e-05
I0822 20:14:26.070150 13823 solver.cpp:239] Iteration 138800 (9.11944 iter/s, 10.9656s/100 iters), loss = 0.0379363
I0822 20:14:26.070211 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0379357 (* 1 = 0.0379357 loss)
I0822 20:14:26.070222 13823 sgd_solver.cpp:112] Iteration 138800, lr = 1e-05
I0822 20:14:36.745558 13823 solver.cpp:239] Iteration 138900 (9.36734 iter/s, 10.6754s/100 iters), loss = 0.0237937
I0822 20:14:36.745616 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0237932 (* 1 = 0.0237932 loss)
I0822 20:14:36.745630 13823 sgd_solver.cpp:112] Iteration 138900, lr = 1e-05
I0822 20:14:47.770951 13823 solver.cpp:239] Iteration 139000 (9.06998 iter/s, 11.0254s/100 iters), loss = 0.0262984
I0822 20:14:47.771015 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0262978 (* 1 = 0.0262978 loss)
I0822 20:14:47.771028 13823 sgd_solver.cpp:112] Iteration 139000, lr = 1e-05
I0822 20:14:58.521894 13823 solver.cpp:239] Iteration 139100 (9.30153 iter/s, 10.7509s/100 iters), loss = 0.0320528
I0822 20:14:58.521955 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0320523 (* 1 = 0.0320523 loss)
I0822 20:14:58.521966 13823 sgd_solver.cpp:112] Iteration 139100, lr = 1e-05
I0822 20:15:09.300763 13823 solver.cpp:239] Iteration 139200 (9.27743 iter/s, 10.7788s/100 iters), loss = 0.0301589
I0822 20:15:09.300822 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0301583 (* 1 = 0.0301583 loss)
I0822 20:15:09.300832 13823 sgd_solver.cpp:112] Iteration 139200, lr = 1e-05
I0822 20:15:19.871088 13823 solver.cpp:239] Iteration 139300 (9.46046 iter/s, 10.5703s/100 iters), loss = 0.0283554
I0822 20:15:19.871140 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0283549 (* 1 = 0.0283549 loss)
I0822 20:15:19.871150 13823 sgd_solver.cpp:112] Iteration 139300, lr = 1e-05
I0822 20:15:30.904189 13823 solver.cpp:239] Iteration 139400 (9.06364 iter/s, 11.0331s/100 iters), loss = 0.027644
I0822 20:15:30.904251 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0276434 (* 1 = 0.0276434 loss)
I0822 20:15:30.904263 13823 sgd_solver.cpp:112] Iteration 139400, lr = 1e-05
I0822 20:15:41.887833 13823 solver.cpp:239] Iteration 139500 (9.10446 iter/s, 10.9836s/100 iters), loss = 0.0277414
I0822 20:15:41.887886 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0277408 (* 1 = 0.0277408 loss)
I0822 20:15:41.887894 13823 sgd_solver.cpp:112] Iteration 139500, lr = 1e-05
I0822 20:15:52.696537 13823 solver.cpp:239] Iteration 139600 (9.25182 iter/s, 10.8087s/100 iters), loss = 0.0286575
I0822 20:15:52.696595 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.028657 (* 1 = 0.028657 loss)
I0822 20:15:52.696606 13823 sgd_solver.cpp:112] Iteration 139600, lr = 1e-05
I0822 20:16:03.676295 13823 solver.cpp:239] Iteration 139700 (9.10768 iter/s, 10.9797s/100 iters), loss = 0.036911
I0822 20:16:03.676347 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0369105 (* 1 = 0.0369105 loss)
I0822 20:16:03.676357 13823 sgd_solver.cpp:112] Iteration 139700, lr = 1e-05
I0822 20:16:14.492267 13823 solver.cpp:239] Iteration 139800 (9.2456 iter/s, 10.816s/100 iters), loss = 0.0252658
I0822 20:16:14.492316 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0252652 (* 1 = 0.0252652 loss)
I0822 20:16:14.492326 13823 sgd_solver.cpp:112] Iteration 139800, lr = 1e-05
I0822 20:16:25.066872 13823 solver.cpp:239] Iteration 139900 (9.45663 iter/s, 10.5746s/100 iters), loss = 0.0297285
I0822 20:16:25.066921 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.029728 (* 1 = 0.029728 loss)
I0822 20:16:25.066931 13823 sgd_solver.cpp:112] Iteration 139900, lr = 1e-05
I0822 20:16:35.429431 13823 solver.cpp:464] Snapshotting to binary proto file ./model_112/cascade_mobilenet_112_iter_140000.caffemodel
I0822 20:16:35.471989 13823 sgd_solver.cpp:284] Snapshotting solver state to binary proto file ./model_112/cascade_mobilenet_112_iter_140000.solverstate
I0822 20:16:35.551692 13823 solver.cpp:347] Iteration 140000, Testing net (#0)
I0822 20:17:36.324765 13823 solver.cpp:414]     Test net output #0: landmark_loss = 0.0221181 (* 1 = 0.0221181 loss)
I0822 20:17:36.411674 13823 solver.cpp:239] Iteration 140000 (1.40164 iter/s, 71.3451s/100 iters), loss = 0.033607
I0822 20:17:36.411712 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0336064 (* 1 = 0.0336064 loss)
I0822 20:17:36.411722 13823 sgd_solver.cpp:112] Iteration 140000, lr = 1e-05
I0822 20:17:46.963362 13823 solver.cpp:239] Iteration 140100 (9.47715 iter/s, 10.5517s/100 iters), loss = 0.0275134
I0822 20:17:46.963412 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0275128 (* 1 = 0.0275128 loss)
I0822 20:17:46.963420 13823 sgd_solver.cpp:112] Iteration 140100, lr = 1e-05
I0822 20:17:57.785815 13823 solver.cpp:239] Iteration 140200 (9.24006 iter/s, 10.8224s/100 iters), loss = 0.0289695
I0822 20:17:57.785863 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.028969 (* 1 = 0.028969 loss)
I0822 20:17:57.785872 13823 sgd_solver.cpp:112] Iteration 140200, lr = 1e-05
I0822 20:18:08.569303 13823 solver.cpp:239] Iteration 140300 (9.27344 iter/s, 10.7835s/100 iters), loss = 0.0364973
I0822 20:18:08.569355 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0364968 (* 1 = 0.0364968 loss)
I0822 20:18:08.569363 13823 sgd_solver.cpp:112] Iteration 140300, lr = 1e-05
I0822 20:18:19.443730 13823 solver.cpp:239] Iteration 140400 (9.19589 iter/s, 10.8744s/100 iters), loss = 0.0255375
I0822 20:18:19.443780 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.025537 (* 1 = 0.025537 loss)
I0822 20:18:19.443789 13823 sgd_solver.cpp:112] Iteration 140400, lr = 1e-05
I0822 20:18:30.418716 13823 solver.cpp:239] Iteration 140500 (9.11163 iter/s, 10.975s/100 iters), loss = 0.0344558
I0822 20:18:30.418764 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0344553 (* 1 = 0.0344553 loss)
I0822 20:18:30.418773 13823 sgd_solver.cpp:112] Iteration 140500, lr = 1e-05
I0822 20:18:41.054996 13823 solver.cpp:239] Iteration 140600 (9.40179 iter/s, 10.6363s/100 iters), loss = 0.0294534
I0822 20:18:41.055044 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0294529 (* 1 = 0.0294529 loss)
I0822 20:18:41.055053 13823 sgd_solver.cpp:112] Iteration 140600, lr = 1e-05
I0822 20:18:51.948124 13823 solver.cpp:239] Iteration 140700 (9.18011 iter/s, 10.8931s/100 iters), loss = 0.0392066
I0822 20:18:51.948179 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0392061 (* 1 = 0.0392061 loss)
I0822 20:18:51.948187 13823 sgd_solver.cpp:112] Iteration 140700, lr = 1e-05
I0822 20:19:02.917865 13823 solver.cpp:239] Iteration 140800 (9.116 iter/s, 10.9697s/100 iters), loss = 0.0242405
I0822 20:19:02.917915 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.02424 (* 1 = 0.02424 loss)
I0822 20:19:02.917924 13823 sgd_solver.cpp:112] Iteration 140800, lr = 1e-05
I0822 20:19:13.720227 13823 solver.cpp:239] Iteration 140900 (9.25724 iter/s, 10.8024s/100 iters), loss = 0.0265143
I0822 20:19:13.720278 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0265138 (* 1 = 0.0265138 loss)
I0822 20:19:13.720288 13823 sgd_solver.cpp:112] Iteration 140900, lr = 1e-05
I0822 20:19:25.015225 13823 solver.cpp:239] Iteration 141000 (8.85348 iter/s, 11.295s/100 iters), loss = 0.0321781
I0822 20:19:25.015278 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0321776 (* 1 = 0.0321776 loss)
I0822 20:19:25.015288 13823 sgd_solver.cpp:112] Iteration 141000, lr = 1e-05
I0822 20:19:36.230531 13823 solver.cpp:239] Iteration 141100 (8.9164 iter/s, 11.2153s/100 iters), loss = 0.0287371
I0822 20:19:36.230590 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0287366 (* 1 = 0.0287366 loss)
I0822 20:19:36.230602 13823 sgd_solver.cpp:112] Iteration 141100, lr = 1e-05
I0822 20:19:47.429947 13823 solver.cpp:239] Iteration 141200 (8.92905 iter/s, 11.1994s/100 iters), loss = 0.0280485
I0822 20:19:47.429998 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.028048 (* 1 = 0.028048 loss)
I0822 20:19:47.430007 13823 sgd_solver.cpp:112] Iteration 141200, lr = 1e-05
I0822 20:19:58.793108 13823 solver.cpp:239] Iteration 141300 (8.80037 iter/s, 11.3632s/100 iters), loss = 0.0255725
I0822 20:19:58.793167 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.025572 (* 1 = 0.025572 loss)
I0822 20:19:58.793179 13823 sgd_solver.cpp:112] Iteration 141300, lr = 1e-05
I0822 20:20:10.241154 13823 solver.cpp:239] Iteration 141400 (8.73513 iter/s, 11.448s/100 iters), loss = 0.0260431
I0822 20:20:10.241210 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0260426 (* 1 = 0.0260426 loss)
I0822 20:20:10.241220 13823 sgd_solver.cpp:112] Iteration 141400, lr = 1e-05
I0822 20:20:21.421644 13823 solver.cpp:239] Iteration 141500 (8.94416 iter/s, 11.1805s/100 iters), loss = 0.0270411
I0822 20:20:21.421702 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0270407 (* 1 = 0.0270407 loss)
I0822 20:20:21.421713 13823 sgd_solver.cpp:112] Iteration 141500, lr = 1e-05
I0822 20:20:32.299516 13823 solver.cpp:239] Iteration 141600 (9.19299 iter/s, 10.8779s/100 iters), loss = 0.0317841
I0822 20:20:32.299566 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0317836 (* 1 = 0.0317836 loss)
I0822 20:20:32.299576 13823 sgd_solver.cpp:112] Iteration 141600, lr = 1e-05
I0822 20:20:43.468165 13823 solver.cpp:239] Iteration 141700 (8.95364 iter/s, 11.1686s/100 iters), loss = 0.0256608
I0822 20:20:43.468214 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0256603 (* 1 = 0.0256603 loss)
I0822 20:20:43.468223 13823 sgd_solver.cpp:112] Iteration 141700, lr = 1e-05
I0822 20:20:54.954603 13823 solver.cpp:239] Iteration 141800 (8.70593 iter/s, 11.4864s/100 iters), loss = 0.0314157
I0822 20:20:54.954664 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0314152 (* 1 = 0.0314152 loss)
I0822 20:20:54.954675 13823 sgd_solver.cpp:112] Iteration 141800, lr = 1e-05
I0822 20:21:06.274996 13823 solver.cpp:239] Iteration 141900 (8.83363 iter/s, 11.3204s/100 iters), loss = 0.0289065
I0822 20:21:06.275048 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.028906 (* 1 = 0.028906 loss)
I0822 20:21:06.275058 13823 sgd_solver.cpp:112] Iteration 141900, lr = 1e-05
I0822 20:21:17.490756 13823 solver.cpp:239] Iteration 142000 (8.91603 iter/s, 11.2157s/100 iters), loss = 0.0276892
I0822 20:21:17.490808 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0276887 (* 1 = 0.0276887 loss)
I0822 20:21:17.490816 13823 sgd_solver.cpp:112] Iteration 142000, lr = 1e-05
I0822 20:21:28.842432 13823 solver.cpp:239] Iteration 142100 (8.80928 iter/s, 11.3517s/100 iters), loss = 0.0280008
I0822 20:21:28.842490 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0280003 (* 1 = 0.0280003 loss)
I0822 20:21:28.842501 13823 sgd_solver.cpp:112] Iteration 142100, lr = 1e-05
I0822 20:21:40.315306 13823 solver.cpp:239] Iteration 142200 (8.71623 iter/s, 11.4729s/100 iters), loss = 0.0249079
I0822 20:21:40.315368 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0249074 (* 1 = 0.0249074 loss)
I0822 20:21:40.315380 13823 sgd_solver.cpp:112] Iteration 142200, lr = 1e-05
I0822 20:21:51.765000 13823 solver.cpp:239] Iteration 142300 (8.73387 iter/s, 11.4497s/100 iters), loss = 0.0279301
I0822 20:21:51.765056 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0279296 (* 1 = 0.0279296 loss)
I0822 20:21:51.765066 13823 sgd_solver.cpp:112] Iteration 142300, lr = 1e-05
I0822 20:22:02.810539 13823 solver.cpp:239] Iteration 142400 (9.05344 iter/s, 11.0455s/100 iters), loss = 0.0325871
I0822 20:22:02.810590 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0325866 (* 1 = 0.0325866 loss)
I0822 20:22:02.810600 13823 sgd_solver.cpp:112] Iteration 142400, lr = 1e-05
I0822 20:22:14.077706 13823 solver.cpp:239] Iteration 142500 (8.87535 iter/s, 11.2672s/100 iters), loss = 0.0271198
I0822 20:22:14.077756 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0271193 (* 1 = 0.0271193 loss)
I0822 20:22:14.077765 13823 sgd_solver.cpp:112] Iteration 142500, lr = 1e-05
I0822 20:22:25.407508 13823 solver.cpp:239] Iteration 142600 (8.82629 iter/s, 11.3298s/100 iters), loss = 0.0296031
I0822 20:22:25.407562 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0296026 (* 1 = 0.0296026 loss)
I0822 20:22:25.407572 13823 sgd_solver.cpp:112] Iteration 142600, lr = 1e-05
I0822 20:22:36.812003 13823 solver.cpp:239] Iteration 142700 (8.76848 iter/s, 11.4045s/100 iters), loss = 0.0244999
I0822 20:22:36.812059 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0244994 (* 1 = 0.0244994 loss)
I0822 20:22:36.812070 13823 sgd_solver.cpp:112] Iteration 142700, lr = 1e-05
I0822 20:22:48.425024 13823 solver.cpp:239] Iteration 142800 (8.61104 iter/s, 11.613s/100 iters), loss = 0.0325165
I0822 20:22:48.425076 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0325161 (* 1 = 0.0325161 loss)
I0822 20:22:48.425086 13823 sgd_solver.cpp:112] Iteration 142800, lr = 1e-05
I0822 20:22:59.645761 13823 solver.cpp:239] Iteration 142900 (8.91208 iter/s, 11.2207s/100 iters), loss = 0.0325201
I0822 20:22:59.645824 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0325196 (* 1 = 0.0325196 loss)
I0822 20:22:59.645838 13823 sgd_solver.cpp:112] Iteration 142900, lr = 1e-05
I0822 20:23:10.845438 13823 solver.cpp:239] Iteration 143000 (8.92885 iter/s, 11.1997s/100 iters), loss = 0.0266023
I0822 20:23:10.845492 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0266019 (* 1 = 0.0266019 loss)
I0822 20:23:10.845502 13823 sgd_solver.cpp:112] Iteration 143000, lr = 1e-05
I0822 20:23:22.051004 13823 solver.cpp:239] Iteration 143100 (8.92415 iter/s, 11.2056s/100 iters), loss = 0.0255999
I0822 20:23:22.051069 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0255995 (* 1 = 0.0255995 loss)
I0822 20:23:22.051084 13823 sgd_solver.cpp:112] Iteration 143100, lr = 1e-05
I0822 20:23:33.259327 13823 solver.cpp:239] Iteration 143200 (8.92196 iter/s, 11.2083s/100 iters), loss = 0.0271528
I0822 20:23:33.259382 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0271523 (* 1 = 0.0271523 loss)
I0822 20:23:33.259392 13823 sgd_solver.cpp:112] Iteration 143200, lr = 1e-05
I0822 20:23:44.576519 13823 solver.cpp:239] Iteration 143300 (8.83613 iter/s, 11.3172s/100 iters), loss = 0.0273159
I0822 20:23:44.576577 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0273154 (* 1 = 0.0273154 loss)
I0822 20:23:44.576591 13823 sgd_solver.cpp:112] Iteration 143300, lr = 1e-05
I0822 20:23:55.859753 13823 solver.cpp:239] Iteration 143400 (8.86272 iter/s, 11.2832s/100 iters), loss = 0.0298065
I0822 20:23:55.859810 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.029806 (* 1 = 0.029806 loss)
I0822 20:23:55.859820 13823 sgd_solver.cpp:112] Iteration 143400, lr = 1e-05
I0822 20:24:07.480231 13823 solver.cpp:239] Iteration 143500 (8.60551 iter/s, 11.6205s/100 iters), loss = 0.0276276
I0822 20:24:07.480293 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0276271 (* 1 = 0.0276271 loss)
I0822 20:24:07.480305 13823 sgd_solver.cpp:112] Iteration 143500, lr = 1e-05
I0822 20:24:18.900872 13823 solver.cpp:239] Iteration 143600 (8.75609 iter/s, 11.4206s/100 iters), loss = 0.0322503
I0822 20:24:18.900921 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0322498 (* 1 = 0.0322498 loss)
I0822 20:24:18.900930 13823 sgd_solver.cpp:112] Iteration 143600, lr = 1e-05
I0822 20:24:30.282158 13823 solver.cpp:239] Iteration 143700 (8.78636 iter/s, 11.3813s/100 iters), loss = 0.0382924
I0822 20:24:30.282219 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0382919 (* 1 = 0.0382919 loss)
I0822 20:24:30.282230 13823 sgd_solver.cpp:112] Iteration 143700, lr = 1e-05
I0822 20:24:41.751669 13823 solver.cpp:239] Iteration 143800 (8.71878 iter/s, 11.4695s/100 iters), loss = 0.0248144
I0822 20:24:41.751720 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0248139 (* 1 = 0.0248139 loss)
I0822 20:24:41.751729 13823 sgd_solver.cpp:112] Iteration 143800, lr = 1e-05
I0822 20:24:53.020640 13823 solver.cpp:239] Iteration 143900 (8.87393 iter/s, 11.269s/100 iters), loss = 0.0431698
I0822 20:24:53.020690 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0431693 (* 1 = 0.0431693 loss)
I0822 20:24:53.020699 13823 sgd_solver.cpp:112] Iteration 143900, lr = 1e-05
I0822 20:25:04.281195 13823 solver.cpp:239] Iteration 144000 (8.88057 iter/s, 11.2605s/100 iters), loss = 0.0275464
I0822 20:25:04.281252 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.027546 (* 1 = 0.027546 loss)
I0822 20:25:04.281263 13823 sgd_solver.cpp:112] Iteration 144000, lr = 1e-05
I0822 20:25:15.818295 13823 solver.cpp:239] Iteration 144100 (8.6677 iter/s, 11.5371s/100 iters), loss = 0.0237704
I0822 20:25:15.818364 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0237699 (* 1 = 0.0237699 loss)
I0822 20:25:15.818382 13823 sgd_solver.cpp:112] Iteration 144100, lr = 1e-05
I0822 20:25:27.404060 13823 solver.cpp:239] Iteration 144200 (8.6313 iter/s, 11.5857s/100 iters), loss = 0.0264587
I0822 20:25:27.404109 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0264582 (* 1 = 0.0264582 loss)
I0822 20:25:27.404121 13823 sgd_solver.cpp:112] Iteration 144200, lr = 1e-05
I0822 20:25:38.189432 13823 solver.cpp:239] Iteration 144300 (9.27183 iter/s, 10.7854s/100 iters), loss = 0.0265339
I0822 20:25:38.189491 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0265334 (* 1 = 0.0265334 loss)
I0822 20:25:38.189501 13823 sgd_solver.cpp:112] Iteration 144300, lr = 1e-05
I0822 20:25:49.447104 13823 solver.cpp:239] Iteration 144400 (8.88285 iter/s, 11.2577s/100 iters), loss = 0.0255587
I0822 20:25:49.447156 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0255582 (* 1 = 0.0255582 loss)
I0822 20:25:49.447166 13823 sgd_solver.cpp:112] Iteration 144400, lr = 1e-05
I0822 20:26:00.492135 13823 solver.cpp:239] Iteration 144500 (9.05386 iter/s, 11.045s/100 iters), loss = 0.0252817
I0822 20:26:00.492177 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0252812 (* 1 = 0.0252812 loss)
I0822 20:26:00.492183 13823 sgd_solver.cpp:112] Iteration 144500, lr = 1e-05
I0822 20:26:11.423264 13823 solver.cpp:239] Iteration 144600 (9.14819 iter/s, 10.9311s/100 iters), loss = 0.0255726
I0822 20:26:11.423305 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0255721 (* 1 = 0.0255721 loss)
I0822 20:26:11.423312 13823 sgd_solver.cpp:112] Iteration 144600, lr = 1e-05
I0822 20:26:22.880465 13823 solver.cpp:239] Iteration 144700 (8.72814 iter/s, 11.4572s/100 iters), loss = 0.0274219
I0822 20:26:22.880522 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0274214 (* 1 = 0.0274214 loss)
I0822 20:26:22.880535 13823 sgd_solver.cpp:112] Iteration 144700, lr = 1e-05
I0822 20:26:34.228829 13823 solver.cpp:239] Iteration 144800 (8.81185 iter/s, 11.3483s/100 iters), loss = 0.0253728
I0822 20:26:34.228888 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0253723 (* 1 = 0.0253723 loss)
I0822 20:26:34.228900 13823 sgd_solver.cpp:112] Iteration 144800, lr = 1e-05
I0822 20:26:45.708043 13823 solver.cpp:239] Iteration 144900 (8.71141 iter/s, 11.4792s/100 iters), loss = 0.0244533
I0822 20:26:45.708108 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0244529 (* 1 = 0.0244529 loss)
I0822 20:26:45.708123 13823 sgd_solver.cpp:112] Iteration 144900, lr = 1e-05
I0822 20:26:57.181506 13823 solver.cpp:239] Iteration 145000 (8.71578 iter/s, 11.4734s/100 iters), loss = 0.0331893
I0822 20:26:57.181567 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0331888 (* 1 = 0.0331888 loss)
I0822 20:26:57.181581 13823 sgd_solver.cpp:112] Iteration 145000, lr = 1e-05
I0822 20:27:08.822294 13823 solver.cpp:239] Iteration 145100 (8.5905 iter/s, 11.6408s/100 iters), loss = 0.0326209
I0822 20:27:08.822352 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0326204 (* 1 = 0.0326204 loss)
I0822 20:27:08.822365 13823 sgd_solver.cpp:112] Iteration 145100, lr = 1e-05
I0822 20:27:20.529863 13823 solver.cpp:239] Iteration 145200 (8.5415 iter/s, 11.7076s/100 iters), loss = 0.0448425
I0822 20:27:20.529927 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0448421 (* 1 = 0.0448421 loss)
I0822 20:27:20.529938 13823 sgd_solver.cpp:112] Iteration 145200, lr = 1e-05
I0822 20:27:32.045466 13823 solver.cpp:239] Iteration 145300 (8.68389 iter/s, 11.5156s/100 iters), loss = 0.0228994
I0822 20:27:32.045526 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0228989 (* 1 = 0.0228989 loss)
I0822 20:27:32.045538 13823 sgd_solver.cpp:112] Iteration 145300, lr = 1e-05
I0822 20:27:43.608363 13823 solver.cpp:239] Iteration 145400 (8.64837 iter/s, 11.5629s/100 iters), loss = 0.0344025
I0822 20:27:43.608428 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0344021 (* 1 = 0.0344021 loss)
I0822 20:27:43.608438 13823 sgd_solver.cpp:112] Iteration 145400, lr = 1e-05
I0822 20:27:54.911554 13823 solver.cpp:239] Iteration 145500 (8.84708 iter/s, 11.3032s/100 iters), loss = 0.027494
I0822 20:27:54.911603 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0274936 (* 1 = 0.0274936 loss)
I0822 20:27:54.911613 13823 sgd_solver.cpp:112] Iteration 145500, lr = 1e-05
I0822 20:28:06.325747 13823 solver.cpp:239] Iteration 145600 (8.76104 iter/s, 11.4142s/100 iters), loss = 0.0271774
I0822 20:28:06.325816 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.027177 (* 1 = 0.027177 loss)
I0822 20:28:06.325829 13823 sgd_solver.cpp:112] Iteration 145600, lr = 1e-05
I0822 20:28:17.726584 13823 solver.cpp:239] Iteration 145700 (8.77131 iter/s, 11.4008s/100 iters), loss = 0.0293828
I0822 20:28:17.726639 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0293823 (* 1 = 0.0293823 loss)
I0822 20:28:17.726649 13823 sgd_solver.cpp:112] Iteration 145700, lr = 1e-05
I0822 20:28:29.082427 13823 solver.cpp:239] Iteration 145800 (8.80605 iter/s, 11.3558s/100 iters), loss = 0.025239
I0822 20:28:29.082484 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0252386 (* 1 = 0.0252386 loss)
I0822 20:28:29.082494 13823 sgd_solver.cpp:112] Iteration 145800, lr = 1e-05
I0822 20:28:40.634049 13823 solver.cpp:239] Iteration 145900 (8.65681 iter/s, 11.5516s/100 iters), loss = 0.027377
I0822 20:28:40.634104 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0273766 (* 1 = 0.0273766 loss)
I0822 20:28:40.634115 13823 sgd_solver.cpp:112] Iteration 145900, lr = 1e-05
I0822 20:28:52.423576 13823 solver.cpp:239] Iteration 146000 (8.48212 iter/s, 11.7895s/100 iters), loss = 0.0281956
I0822 20:28:52.423635 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0281952 (* 1 = 0.0281952 loss)
I0822 20:28:52.423646 13823 sgd_solver.cpp:112] Iteration 146000, lr = 1e-05
I0822 20:29:03.518810 13823 solver.cpp:239] Iteration 146100 (9.0129 iter/s, 11.0952s/100 iters), loss = 0.026553
I0822 20:29:03.518858 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0265526 (* 1 = 0.0265526 loss)
I0822 20:29:03.518867 13823 sgd_solver.cpp:112] Iteration 146100, lr = 1e-05
I0822 20:29:13.087100 13823 solver.cpp:239] Iteration 146200 (10.4512 iter/s, 9.56827s/100 iters), loss = 0.0267104
I0822 20:29:13.087148 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0267099 (* 1 = 0.0267099 loss)
I0822 20:29:13.087157 13823 sgd_solver.cpp:112] Iteration 146200, lr = 1e-05
I0822 20:29:22.874100 13823 solver.cpp:239] Iteration 146300 (10.2177 iter/s, 9.78698s/100 iters), loss = 0.0253721
I0822 20:29:22.874150 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0253716 (* 1 = 0.0253716 loss)
I0822 20:29:22.874161 13823 sgd_solver.cpp:112] Iteration 146300, lr = 1e-05
I0822 20:29:32.357969 13823 solver.cpp:239] Iteration 146400 (10.5442 iter/s, 9.48385s/100 iters), loss = 0.0311246
I0822 20:29:32.358026 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0311242 (* 1 = 0.0311242 loss)
I0822 20:29:32.358036 13823 sgd_solver.cpp:112] Iteration 146400, lr = 1e-05
I0822 20:29:42.044679 13823 solver.cpp:239] Iteration 146500 (10.3234 iter/s, 9.68668s/100 iters), loss = 0.0246833
I0822 20:29:42.044729 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0246828 (* 1 = 0.0246828 loss)
I0822 20:29:42.044739 13823 sgd_solver.cpp:112] Iteration 146500, lr = 1e-05
I0822 20:29:51.726630 13823 solver.cpp:239] Iteration 146600 (10.3285 iter/s, 9.68193s/100 iters), loss = 0.0331691
I0822 20:29:51.726691 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0331687 (* 1 = 0.0331687 loss)
I0822 20:29:51.726703 13823 sgd_solver.cpp:112] Iteration 146600, lr = 1e-05
I0822 20:30:01.892258 13823 solver.cpp:239] Iteration 146700 (9.8371 iter/s, 10.1656s/100 iters), loss = 0.0282802
I0822 20:30:01.892311 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0282798 (* 1 = 0.0282798 loss)
I0822 20:30:01.892321 13823 sgd_solver.cpp:112] Iteration 146700, lr = 1e-05
I0822 20:30:11.580992 13823 solver.cpp:239] Iteration 146800 (10.3213 iter/s, 9.68871s/100 iters), loss = 0.0277769
I0822 20:30:11.581045 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0277765 (* 1 = 0.0277765 loss)
I0822 20:30:11.581055 13823 sgd_solver.cpp:112] Iteration 146800, lr = 1e-05
I0822 20:30:21.225064 13823 solver.cpp:239] Iteration 146900 (10.3691 iter/s, 9.64405s/100 iters), loss = 0.0258635
I0822 20:30:21.225119 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.025863 (* 1 = 0.025863 loss)
I0822 20:30:21.225131 13823 sgd_solver.cpp:112] Iteration 146900, lr = 1e-05
I0822 20:30:30.886309 13823 solver.cpp:239] Iteration 147000 (10.3507 iter/s, 9.66122s/100 iters), loss = 0.024872
I0822 20:30:30.886358 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0248716 (* 1 = 0.0248716 loss)
I0822 20:30:30.886368 13823 sgd_solver.cpp:112] Iteration 147000, lr = 1e-05
I0822 20:30:40.513101 13823 solver.cpp:239] Iteration 147100 (10.3877 iter/s, 9.62677s/100 iters), loss = 0.0232078
I0822 20:30:40.513160 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0232074 (* 1 = 0.0232074 loss)
I0822 20:30:40.513173 13823 sgd_solver.cpp:112] Iteration 147100, lr = 1e-05
I0822 20:30:50.476259 13823 solver.cpp:239] Iteration 147200 (10.037 iter/s, 9.96313s/100 iters), loss = 0.0273431
I0822 20:30:50.476316 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0273426 (* 1 = 0.0273426 loss)
I0822 20:30:50.476330 13823 sgd_solver.cpp:112] Iteration 147200, lr = 1e-05
I0822 20:30:59.981252 13823 solver.cpp:239] Iteration 147300 (10.5208 iter/s, 9.50497s/100 iters), loss = 0.0241628
I0822 20:30:59.981302 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0241624 (* 1 = 0.0241624 loss)
I0822 20:30:59.981310 13823 sgd_solver.cpp:112] Iteration 147300, lr = 1e-05
I0822 20:31:09.501402 13823 solver.cpp:239] Iteration 147400 (10.5041 iter/s, 9.52013s/100 iters), loss = 0.0534818
I0822 20:31:09.501446 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0534814 (* 1 = 0.0534814 loss)
I0822 20:31:09.501453 13823 sgd_solver.cpp:112] Iteration 147400, lr = 1e-05
I0822 20:31:19.181959 13823 solver.cpp:239] Iteration 147500 (10.33 iter/s, 9.68054s/100 iters), loss = 0.0303084
I0822 20:31:19.182015 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.030308 (* 1 = 0.030308 loss)
I0822 20:31:19.182022 13823 sgd_solver.cpp:112] Iteration 147500, lr = 1e-05
I0822 20:31:28.745591 13823 solver.cpp:239] Iteration 147600 (10.4563 iter/s, 9.56361s/100 iters), loss = 0.0269594
I0822 20:31:28.745633 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.026959 (* 1 = 0.026959 loss)
I0822 20:31:28.745640 13823 sgd_solver.cpp:112] Iteration 147600, lr = 1e-05
I0822 20:31:38.305614 13823 solver.cpp:239] Iteration 147700 (10.4602 iter/s, 9.56001s/100 iters), loss = 0.0275615
I0822 20:31:38.305660 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0275611 (* 1 = 0.0275611 loss)
I0822 20:31:38.305667 13823 sgd_solver.cpp:112] Iteration 147700, lr = 1e-05
I0822 20:31:47.738694 13823 solver.cpp:239] Iteration 147800 (10.601 iter/s, 9.43306s/100 iters), loss = 0.0260335
I0822 20:31:47.738739 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0260331 (* 1 = 0.0260331 loss)
I0822 20:31:47.738745 13823 sgd_solver.cpp:112] Iteration 147800, lr = 1e-05
I0822 20:31:57.262115 13823 solver.cpp:239] Iteration 147900 (10.5004 iter/s, 9.52341s/100 iters), loss = 0.0286987
I0822 20:31:57.262156 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0286982 (* 1 = 0.0286982 loss)
I0822 20:31:57.262163 13823 sgd_solver.cpp:112] Iteration 147900, lr = 1e-05
I0822 20:32:06.715582 13823 solver.cpp:239] Iteration 148000 (10.5781 iter/s, 9.45345s/100 iters), loss = 0.025182
I0822 20:32:06.715634 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0251815 (* 1 = 0.0251815 loss)
I0822 20:32:06.715643 13823 sgd_solver.cpp:112] Iteration 148000, lr = 1e-05
I0822 20:32:16.250957 13823 solver.cpp:239] Iteration 148100 (10.4873 iter/s, 9.53535s/100 iters), loss = 0.0281669
I0822 20:32:16.250996 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0281664 (* 1 = 0.0281664 loss)
I0822 20:32:16.251003 13823 sgd_solver.cpp:112] Iteration 148100, lr = 1e-05
I0822 20:32:25.899467 13823 solver.cpp:239] Iteration 148200 (10.3643 iter/s, 9.6485s/100 iters), loss = 0.0316223
I0822 20:32:25.899523 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0316218 (* 1 = 0.0316218 loss)
I0822 20:32:25.899531 13823 sgd_solver.cpp:112] Iteration 148200, lr = 1e-05
I0822 20:32:35.349912 13823 solver.cpp:239] Iteration 148300 (10.5815 iter/s, 9.45041s/100 iters), loss = 0.026172
I0822 20:32:35.349982 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0261716 (* 1 = 0.0261716 loss)
I0822 20:32:35.349998 13823 sgd_solver.cpp:112] Iteration 148300, lr = 1e-05
I0822 20:32:45.225795 13823 solver.cpp:239] Iteration 148400 (10.1257 iter/s, 9.87585s/100 iters), loss = 0.0258978
I0822 20:32:45.225852 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0258974 (* 1 = 0.0258974 loss)
I0822 20:32:45.225865 13823 sgd_solver.cpp:112] Iteration 148400, lr = 1e-05
I0822 20:32:55.146111 13823 solver.cpp:239] Iteration 148500 (10.0804 iter/s, 9.92029s/100 iters), loss = 0.0294987
I0822 20:32:55.146160 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0294983 (* 1 = 0.0294983 loss)
I0822 20:32:55.146169 13823 sgd_solver.cpp:112] Iteration 148500, lr = 1e-05
I0822 20:33:04.741617 13823 solver.cpp:239] Iteration 148600 (10.4216 iter/s, 9.59548s/100 iters), loss = 0.0306581
I0822 20:33:04.741670 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0306577 (* 1 = 0.0306577 loss)
I0822 20:33:04.741679 13823 sgd_solver.cpp:112] Iteration 148600, lr = 1e-05
I0822 20:33:14.253455 13823 solver.cpp:239] Iteration 148700 (10.5132 iter/s, 9.51181s/100 iters), loss = 0.0387415
I0822 20:33:14.253513 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0387411 (* 1 = 0.0387411 loss)
I0822 20:33:14.253525 13823 sgd_solver.cpp:112] Iteration 148700, lr = 1e-05
I0822 20:33:24.219476 13823 solver.cpp:239] Iteration 148800 (10.0341 iter/s, 9.96599s/100 iters), loss = 0.0271189
I0822 20:33:24.219534 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0271184 (* 1 = 0.0271184 loss)
I0822 20:33:24.219544 13823 sgd_solver.cpp:112] Iteration 148800, lr = 1e-05
I0822 20:33:34.366847 13823 solver.cpp:239] Iteration 148900 (9.8548 iter/s, 10.1473s/100 iters), loss = 0.0277158
I0822 20:33:34.366904 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0277153 (* 1 = 0.0277153 loss)
I0822 20:33:34.366914 13823 sgd_solver.cpp:112] Iteration 148900, lr = 1e-05
I0822 20:33:44.527549 13823 solver.cpp:239] Iteration 149000 (9.84187 iter/s, 10.1607s/100 iters), loss = 0.0291315
I0822 20:33:44.527608 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.029131 (* 1 = 0.029131 loss)
I0822 20:33:44.527621 13823 sgd_solver.cpp:112] Iteration 149000, lr = 1e-05
I0822 20:33:54.310194 13823 solver.cpp:239] Iteration 149100 (10.2222 iter/s, 9.78262s/100 iters), loss = 0.0359701
I0822 20:33:54.310250 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0359697 (* 1 = 0.0359697 loss)
I0822 20:33:54.310263 13823 sgd_solver.cpp:112] Iteration 149100, lr = 1e-05
I0822 20:34:04.300436 13823 solver.cpp:239] Iteration 149200 (10.0098 iter/s, 9.99021s/100 iters), loss = 0.0257905
I0822 20:34:04.300498 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.02579 (* 1 = 0.02579 loss)
I0822 20:34:04.300508 13823 sgd_solver.cpp:112] Iteration 149200, lr = 1e-05
I0822 20:34:13.821174 13823 solver.cpp:239] Iteration 149300 (10.5034 iter/s, 9.52071s/100 iters), loss = 0.0249533
I0822 20:34:13.821226 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0249529 (* 1 = 0.0249529 loss)
I0822 20:34:13.821236 13823 sgd_solver.cpp:112] Iteration 149300, lr = 1e-05
I0822 20:34:23.417080 13823 solver.cpp:239] Iteration 149400 (10.4211 iter/s, 9.59588s/100 iters), loss = 0.0292059
I0822 20:34:23.417130 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0292054 (* 1 = 0.0292054 loss)
I0822 20:34:23.417140 13823 sgd_solver.cpp:112] Iteration 149400, lr = 1e-05
I0822 20:34:33.269822 13823 solver.cpp:239] Iteration 149500 (10.1495 iter/s, 9.85272s/100 iters), loss = 0.0273743
I0822 20:34:33.269881 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0273738 (* 1 = 0.0273738 loss)
I0822 20:34:33.269896 13823 sgd_solver.cpp:112] Iteration 149500, lr = 1e-05
I0822 20:34:42.985992 13823 solver.cpp:239] Iteration 149600 (10.2922 iter/s, 9.71614s/100 iters), loss = 0.0268574
I0822 20:34:42.986042 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0268569 (* 1 = 0.0268569 loss)
I0822 20:34:42.986052 13823 sgd_solver.cpp:112] Iteration 149600, lr = 1e-05
I0822 20:34:52.647217 13823 solver.cpp:239] Iteration 149700 (10.3507 iter/s, 9.6612s/100 iters), loss = 0.0222972
I0822 20:34:52.647269 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0222967 (* 1 = 0.0222967 loss)
I0822 20:34:52.647279 13823 sgd_solver.cpp:112] Iteration 149700, lr = 1e-05
I0822 20:35:02.253099 13823 solver.cpp:239] Iteration 149800 (10.4103 iter/s, 9.60585s/100 iters), loss = 0.0261688
I0822 20:35:02.253163 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0261683 (* 1 = 0.0261683 loss)
I0822 20:35:02.253176 13823 sgd_solver.cpp:112] Iteration 149800, lr = 1e-05
I0822 20:35:11.911109 13823 solver.cpp:239] Iteration 149900 (10.3541 iter/s, 9.65797s/100 iters), loss = 0.0249231
I0822 20:35:11.911161 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0249226 (* 1 = 0.0249226 loss)
I0822 20:35:11.911170 13823 sgd_solver.cpp:112] Iteration 149900, lr = 1e-05
I0822 20:35:21.577170 13823 solver.cpp:239] Iteration 150000 (10.3455 iter/s, 9.66603s/100 iters), loss = 0.0274066
I0822 20:35:21.577225 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0274061 (* 1 = 0.0274061 loss)
I0822 20:35:21.577239 13823 sgd_solver.cpp:112] Iteration 150000, lr = 1e-05
I0822 20:35:31.391222 13823 solver.cpp:239] Iteration 150100 (10.1895 iter/s, 9.81403s/100 iters), loss = 0.02703
I0822 20:35:31.391275 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0270295 (* 1 = 0.0270295 loss)
I0822 20:35:31.391284 13823 sgd_solver.cpp:112] Iteration 150100, lr = 1e-05
I0822 20:35:41.291280 13823 solver.cpp:239] Iteration 150200 (10.101 iter/s, 9.90003s/100 iters), loss = 0.0367158
I0822 20:35:41.291330 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0367153 (* 1 = 0.0367153 loss)
I0822 20:35:41.291340 13823 sgd_solver.cpp:112] Iteration 150200, lr = 1e-05
I0822 20:35:51.343545 13823 solver.cpp:239] Iteration 150300 (9.94802 iter/s, 10.0522s/100 iters), loss = 0.0273273
I0822 20:35:51.343586 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0273268 (* 1 = 0.0273268 loss)
I0822 20:35:51.343593 13823 sgd_solver.cpp:112] Iteration 150300, lr = 1e-05
I0822 20:36:01.004161 13823 solver.cpp:239] Iteration 150400 (10.3513 iter/s, 9.66061s/100 iters), loss = 0.0275626
I0822 20:36:01.004206 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0275621 (* 1 = 0.0275621 loss)
I0822 20:36:01.004215 13823 sgd_solver.cpp:112] Iteration 150400, lr = 1e-05
I0822 20:36:10.764214 13823 solver.cpp:239] Iteration 150500 (10.2458 iter/s, 9.76013s/100 iters), loss = 0.0269675
I0822 20:36:10.764256 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.026967 (* 1 = 0.026967 loss)
I0822 20:36:10.764262 13823 sgd_solver.cpp:112] Iteration 150500, lr = 1e-05
I0822 20:36:20.400523 13823 solver.cpp:239] Iteration 150600 (10.3773 iter/s, 9.63638s/100 iters), loss = 0.0266673
I0822 20:36:20.400579 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0266668 (* 1 = 0.0266668 loss)
I0822 20:36:20.400593 13823 sgd_solver.cpp:112] Iteration 150600, lr = 1e-05
I0822 20:36:30.268940 13823 solver.cpp:239] Iteration 150700 (10.1333 iter/s, 9.86848s/100 iters), loss = 0.0332624
I0822 20:36:30.268993 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0332619 (* 1 = 0.0332619 loss)
I0822 20:36:30.269002 13823 sgd_solver.cpp:112] Iteration 150700, lr = 1e-05
I0822 20:36:40.194582 13823 solver.cpp:239] Iteration 150800 (10.0749 iter/s, 9.92571s/100 iters), loss = 0.0232307
I0822 20:36:40.194639 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0232302 (* 1 = 0.0232302 loss)
I0822 20:36:40.194649 13823 sgd_solver.cpp:112] Iteration 150800, lr = 1e-05
I0822 20:36:50.055361 13823 solver.cpp:239] Iteration 150900 (10.1411 iter/s, 9.86084s/100 iters), loss = 0.024615
I0822 20:36:50.055411 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0246145 (* 1 = 0.0246145 loss)
I0822 20:36:50.055420 13823 sgd_solver.cpp:112] Iteration 150900, lr = 1e-05
I0822 20:37:00.233803 13823 solver.cpp:239] Iteration 151000 (9.82462 iter/s, 10.1785s/100 iters), loss = 0.0297776
I0822 20:37:00.233853 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0297771 (* 1 = 0.0297771 loss)
I0822 20:37:00.233862 13823 sgd_solver.cpp:112] Iteration 151000, lr = 1e-05
I0822 20:37:10.262344 13823 solver.cpp:239] Iteration 151100 (9.97148 iter/s, 10.0286s/100 iters), loss = 0.0268743
I0822 20:37:10.262394 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0268738 (* 1 = 0.0268738 loss)
I0822 20:37:10.262404 13823 sgd_solver.cpp:112] Iteration 151100, lr = 1e-05
I0822 20:37:20.000394 13823 solver.cpp:239] Iteration 151200 (10.2689 iter/s, 9.73811s/100 iters), loss = 0.0328228
I0822 20:37:20.000458 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0328223 (* 1 = 0.0328223 loss)
I0822 20:37:20.000470 13823 sgd_solver.cpp:112] Iteration 151200, lr = 1e-05
I0822 20:37:30.113265 13823 solver.cpp:239] Iteration 151300 (9.88834 iter/s, 10.1129s/100 iters), loss = 0.0315738
I0822 20:37:30.113317 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0315733 (* 1 = 0.0315733 loss)
I0822 20:37:30.113325 13823 sgd_solver.cpp:112] Iteration 151300, lr = 1e-05
I0822 20:37:40.014010 13823 solver.cpp:239] Iteration 151400 (10.1002 iter/s, 9.9008s/100 iters), loss = 0.024058
I0822 20:37:40.014061 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0240575 (* 1 = 0.0240575 loss)
I0822 20:37:40.014071 13823 sgd_solver.cpp:112] Iteration 151400, lr = 1e-05
I0822 20:37:50.176640 13823 solver.cpp:239] Iteration 151500 (9.83992 iter/s, 10.1627s/100 iters), loss = 0.0278245
I0822 20:37:50.176689 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.027824 (* 1 = 0.027824 loss)
I0822 20:37:50.176698 13823 sgd_solver.cpp:112] Iteration 151500, lr = 1e-05
I0822 20:37:59.927146 13823 solver.cpp:239] Iteration 151600 (10.2558 iter/s, 9.75056s/100 iters), loss = 0.0251689
I0822 20:37:59.927211 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0251684 (* 1 = 0.0251684 loss)
I0822 20:37:59.927222 13823 sgd_solver.cpp:112] Iteration 151600, lr = 1e-05
I0822 20:38:09.830353 13823 solver.cpp:239] Iteration 151700 (10.0977 iter/s, 9.90325s/100 iters), loss = 0.0288086
I0822 20:38:09.830407 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0288081 (* 1 = 0.0288081 loss)
I0822 20:38:09.830417 13823 sgd_solver.cpp:112] Iteration 151700, lr = 1e-05
I0822 20:38:19.999768 13823 solver.cpp:239] Iteration 151800 (9.83336 iter/s, 10.1695s/100 iters), loss = 0.0319075
I0822 20:38:19.999827 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.031907 (* 1 = 0.031907 loss)
I0822 20:38:19.999840 13823 sgd_solver.cpp:112] Iteration 151800, lr = 1e-05
I0822 20:38:30.027489 13823 solver.cpp:239] Iteration 151900 (9.97231 iter/s, 10.0278s/100 iters), loss = 0.0274435
I0822 20:38:30.027542 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.027443 (* 1 = 0.027443 loss)
I0822 20:38:30.027552 13823 sgd_solver.cpp:112] Iteration 151900, lr = 1e-05
I0822 20:38:40.149755 13823 solver.cpp:239] Iteration 152000 (9.87916 iter/s, 10.1223s/100 iters), loss = 0.0280886
I0822 20:38:40.149807 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0280881 (* 1 = 0.0280881 loss)
I0822 20:38:40.149817 13823 sgd_solver.cpp:112] Iteration 152000, lr = 1e-05
I0822 20:38:49.723497 13823 solver.cpp:239] Iteration 152100 (10.4452 iter/s, 9.57379s/100 iters), loss = 0.0301503
I0822 20:38:49.723539 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0301499 (* 1 = 0.0301499 loss)
I0822 20:38:49.723546 13823 sgd_solver.cpp:112] Iteration 152100, lr = 1e-05
I0822 20:38:59.563975 13823 solver.cpp:239] Iteration 152200 (10.1621 iter/s, 9.84053s/100 iters), loss = 0.0334934
I0822 20:38:59.564026 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0334929 (* 1 = 0.0334929 loss)
I0822 20:38:59.564035 13823 sgd_solver.cpp:112] Iteration 152200, lr = 1e-05
I0822 20:39:09.415566 13823 solver.cpp:239] Iteration 152300 (10.1506 iter/s, 9.85164s/100 iters), loss = 0.0259696
I0822 20:39:09.415632 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0259691 (* 1 = 0.0259691 loss)
I0822 20:39:09.415645 13823 sgd_solver.cpp:112] Iteration 152300, lr = 1e-05
I0822 20:39:19.409059 13823 solver.cpp:239] Iteration 152400 (10.0065 iter/s, 9.99353s/100 iters), loss = 0.0266336
I0822 20:39:19.409123 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0266331 (* 1 = 0.0266331 loss)
I0822 20:39:19.409138 13823 sgd_solver.cpp:112] Iteration 152400, lr = 1e-05
I0822 20:39:29.428748 13823 solver.cpp:239] Iteration 152500 (9.98031 iter/s, 10.0197s/100 iters), loss = 0.0369276
I0822 20:39:29.428804 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0369271 (* 1 = 0.0369271 loss)
I0822 20:39:29.428817 13823 sgd_solver.cpp:112] Iteration 152500, lr = 1e-05
I0822 20:39:39.521512 13823 solver.cpp:239] Iteration 152600 (9.90805 iter/s, 10.0928s/100 iters), loss = 0.0248265
I0822 20:39:39.521564 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.024826 (* 1 = 0.024826 loss)
I0822 20:39:39.521574 13823 sgd_solver.cpp:112] Iteration 152600, lr = 1e-05
I0822 20:39:49.526926 13823 solver.cpp:239] Iteration 152700 (9.99455 iter/s, 10.0055s/100 iters), loss = 0.0239023
I0822 20:39:49.526981 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0239018 (* 1 = 0.0239018 loss)
I0822 20:39:49.526993 13823 sgd_solver.cpp:112] Iteration 152700, lr = 1e-05
I0822 20:39:59.505540 13823 solver.cpp:239] Iteration 152800 (10.0214 iter/s, 9.97865s/100 iters), loss = 0.0299363
I0822 20:39:59.505592 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0299358 (* 1 = 0.0299358 loss)
I0822 20:39:59.505601 13823 sgd_solver.cpp:112] Iteration 152800, lr = 1e-05
I0822 20:40:09.731823 13823 solver.cpp:239] Iteration 152900 (9.77868 iter/s, 10.2263s/100 iters), loss = 0.0279601
I0822 20:40:09.731879 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0279596 (* 1 = 0.0279596 loss)
I0822 20:40:09.731890 13823 sgd_solver.cpp:112] Iteration 152900, lr = 1e-05
I0822 20:40:19.707089 13823 solver.cpp:239] Iteration 153000 (10.0248 iter/s, 9.9753s/100 iters), loss = 0.031059
I0822 20:40:19.707155 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0310585 (* 1 = 0.0310585 loss)
I0822 20:40:19.707171 13823 sgd_solver.cpp:112] Iteration 153000, lr = 1e-05
I0822 20:40:29.971751 13823 solver.cpp:239] Iteration 153100 (9.74213 iter/s, 10.2647s/100 iters), loss = 0.0235363
I0822 20:40:29.971809 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0235358 (* 1 = 0.0235358 loss)
I0822 20:40:29.971822 13823 sgd_solver.cpp:112] Iteration 153100, lr = 1e-05
I0822 20:40:40.441901 13823 solver.cpp:239] Iteration 153200 (9.55093 iter/s, 10.4702s/100 iters), loss = 0.0240467
I0822 20:40:40.441954 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0240462 (* 1 = 0.0240462 loss)
I0822 20:40:40.441964 13823 sgd_solver.cpp:112] Iteration 153200, lr = 1e-05
I0822 20:40:50.861986 13823 solver.cpp:239] Iteration 153300 (9.59681 iter/s, 10.4201s/100 iters), loss = 0.0265955
I0822 20:40:50.862051 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.026595 (* 1 = 0.026595 loss)
I0822 20:40:50.862066 13823 sgd_solver.cpp:112] Iteration 153300, lr = 1e-05
I0822 20:41:00.904247 13823 solver.cpp:239] Iteration 153400 (9.95789 iter/s, 10.0423s/100 iters), loss = 0.0286844
I0822 20:41:00.904300 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0286839 (* 1 = 0.0286839 loss)
I0822 20:41:00.904310 13823 sgd_solver.cpp:112] Iteration 153400, lr = 1e-05
I0822 20:41:11.440129 13823 solver.cpp:239] Iteration 153500 (9.49134 iter/s, 10.5359s/100 iters), loss = 0.0262912
I0822 20:41:11.440183 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0262907 (* 1 = 0.0262907 loss)
I0822 20:41:11.440193 13823 sgd_solver.cpp:112] Iteration 153500, lr = 1e-05
I0822 20:41:21.772312 13823 solver.cpp:239] Iteration 153600 (9.67846 iter/s, 10.3322s/100 iters), loss = 0.0245793
I0822 20:41:21.772367 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0245788 (* 1 = 0.0245788 loss)
I0822 20:41:21.772377 13823 sgd_solver.cpp:112] Iteration 153600, lr = 1e-05
I0822 20:41:31.577404 13823 solver.cpp:239] Iteration 153700 (10.1988 iter/s, 9.80512s/100 iters), loss = 0.0288034
I0822 20:41:31.577456 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0288029 (* 1 = 0.0288029 loss)
I0822 20:41:31.577466 13823 sgd_solver.cpp:112] Iteration 153700, lr = 1e-05
I0822 20:41:41.884158 13823 solver.cpp:239] Iteration 153800 (9.70234 iter/s, 10.3068s/100 iters), loss = 0.0256079
I0822 20:41:41.884212 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0256074 (* 1 = 0.0256074 loss)
I0822 20:41:41.884222 13823 sgd_solver.cpp:112] Iteration 153800, lr = 1e-05
I0822 20:41:52.141131 13823 solver.cpp:239] Iteration 153900 (9.74943 iter/s, 10.257s/100 iters), loss = 0.0256988
I0822 20:41:52.141181 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0256983 (* 1 = 0.0256983 loss)
I0822 20:41:52.141191 13823 sgd_solver.cpp:112] Iteration 153900, lr = 1e-05
I0822 20:42:02.222667 13823 solver.cpp:239] Iteration 154000 (9.91909 iter/s, 10.0816s/100 iters), loss = 0.0228281
I0822 20:42:02.222725 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0228276 (* 1 = 0.0228276 loss)
I0822 20:42:02.222736 13823 sgd_solver.cpp:112] Iteration 154000, lr = 1e-05
I0822 20:42:12.494814 13823 solver.cpp:239] Iteration 154100 (9.73504 iter/s, 10.2722s/100 iters), loss = 0.0255677
I0822 20:42:12.494863 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0255672 (* 1 = 0.0255672 loss)
I0822 20:42:12.494873 13823 sgd_solver.cpp:112] Iteration 154100, lr = 1e-05
I0822 20:42:22.616279 13823 solver.cpp:239] Iteration 154200 (9.87996 iter/s, 10.1215s/100 iters), loss = 0.0270315
I0822 20:42:22.616331 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.027031 (* 1 = 0.027031 loss)
I0822 20:42:22.616341 13823 sgd_solver.cpp:112] Iteration 154200, lr = 1e-05
I0822 20:42:32.699882 13823 solver.cpp:239] Iteration 154300 (9.91706 iter/s, 10.0836s/100 iters), loss = 0.0239608
I0822 20:42:32.699924 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0239603 (* 1 = 0.0239603 loss)
I0822 20:42:32.699932 13823 sgd_solver.cpp:112] Iteration 154300, lr = 1e-05
I0822 20:42:42.805236 13823 solver.cpp:239] Iteration 154400 (9.89571 iter/s, 10.1054s/100 iters), loss = 0.0273205
I0822 20:42:42.805292 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.02732 (* 1 = 0.02732 loss)
I0822 20:42:42.805302 13823 sgd_solver.cpp:112] Iteration 154400, lr = 1e-05
I0822 20:42:53.582340 13823 solver.cpp:239] Iteration 154500 (9.27891 iter/s, 10.7771s/100 iters), loss = 0.0258623
I0822 20:42:53.582406 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0258618 (* 1 = 0.0258618 loss)
I0822 20:42:53.582417 13823 sgd_solver.cpp:112] Iteration 154500, lr = 1e-05
I0822 20:43:03.760987 13823 solver.cpp:239] Iteration 154600 (9.82447 iter/s, 10.1787s/100 iters), loss = 0.0312582
I0822 20:43:03.761039 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0312577 (* 1 = 0.0312577 loss)
I0822 20:43:03.761049 13823 sgd_solver.cpp:112] Iteration 154600, lr = 1e-05
I0822 20:43:13.861420 13823 solver.cpp:239] Iteration 154700 (9.90054 iter/s, 10.1005s/100 iters), loss = 0.0319129
I0822 20:43:13.861471 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0319124 (* 1 = 0.0319124 loss)
I0822 20:43:13.861481 13823 sgd_solver.cpp:112] Iteration 154700, lr = 1e-05
I0822 20:43:24.114181 13823 solver.cpp:239] Iteration 154800 (9.75345 iter/s, 10.2528s/100 iters), loss = 0.0283799
I0822 20:43:24.114244 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0283794 (* 1 = 0.0283794 loss)
I0822 20:43:24.114256 13823 sgd_solver.cpp:112] Iteration 154800, lr = 1e-05
I0822 20:43:34.433313 13823 solver.cpp:239] Iteration 154900 (9.69072 iter/s, 10.3191s/100 iters), loss = 0.0262861
I0822 20:43:34.433365 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0262856 (* 1 = 0.0262856 loss)
I0822 20:43:34.433374 13823 sgd_solver.cpp:112] Iteration 154900, lr = 1e-05
I0822 20:43:44.750689 13823 solver.cpp:239] Iteration 155000 (9.69236 iter/s, 10.3174s/100 iters), loss = 0.0284007
I0822 20:43:44.750742 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0284002 (* 1 = 0.0284002 loss)
I0822 20:43:44.750751 13823 sgd_solver.cpp:112] Iteration 155000, lr = 1e-05
I0822 20:43:55.280711 13823 solver.cpp:239] Iteration 155100 (9.49663 iter/s, 10.53s/100 iters), loss = 0.0278627
I0822 20:43:55.280768 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0278622 (* 1 = 0.0278622 loss)
I0822 20:43:55.280781 13823 sgd_solver.cpp:112] Iteration 155100, lr = 1e-05
I0822 20:44:05.576357 13823 solver.cpp:239] Iteration 155200 (9.71283 iter/s, 10.2957s/100 iters), loss = 0.035084
I0822 20:44:05.576424 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0350835 (* 1 = 0.0350835 loss)
I0822 20:44:05.576442 13823 sgd_solver.cpp:112] Iteration 155200, lr = 1e-05
I0822 20:44:16.009177 13823 solver.cpp:239] Iteration 155300 (9.58512 iter/s, 10.4328s/100 iters), loss = 0.0256695
I0822 20:44:16.009230 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.025669 (* 1 = 0.025669 loss)
I0822 20:44:16.009239 13823 sgd_solver.cpp:112] Iteration 155300, lr = 1e-05
I0822 20:44:26.548861 13823 solver.cpp:239] Iteration 155400 (9.48793 iter/s, 10.5397s/100 iters), loss = 0.0287423
I0822 20:44:26.548910 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0287418 (* 1 = 0.0287418 loss)
I0822 20:44:26.548920 13823 sgd_solver.cpp:112] Iteration 155400, lr = 1e-05
I0822 20:44:36.911036 13823 solver.cpp:239] Iteration 155500 (9.65046 iter/s, 10.3622s/100 iters), loss = 0.0269771
I0822 20:44:36.911090 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0269766 (* 1 = 0.0269766 loss)
I0822 20:44:36.911101 13823 sgd_solver.cpp:112] Iteration 155500, lr = 1e-05
I0822 20:44:47.736194 13823 solver.cpp:239] Iteration 155600 (9.23772 iter/s, 10.8252s/100 iters), loss = 0.031771
I0822 20:44:47.736255 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0317705 (* 1 = 0.0317705 loss)
I0822 20:44:47.736266 13823 sgd_solver.cpp:112] Iteration 155600, lr = 1e-05
I0822 20:44:58.095399 13823 solver.cpp:239] Iteration 155700 (9.65324 iter/s, 10.3592s/100 iters), loss = 0.026012
I0822 20:44:58.095453 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0260115 (* 1 = 0.0260115 loss)
I0822 20:44:58.095461 13823 sgd_solver.cpp:112] Iteration 155700, lr = 1e-05
I0822 20:45:08.535584 13823 solver.cpp:239] Iteration 155800 (9.57835 iter/s, 10.4402s/100 iters), loss = 0.0344251
I0822 20:45:08.535635 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0344246 (* 1 = 0.0344246 loss)
I0822 20:45:08.535645 13823 sgd_solver.cpp:112] Iteration 155800, lr = 1e-05
I0822 20:45:19.223325 13823 solver.cpp:239] Iteration 155900 (9.35649 iter/s, 10.6878s/100 iters), loss = 0.0298398
I0822 20:45:19.223376 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0298393 (* 1 = 0.0298393 loss)
I0822 20:45:19.223387 13823 sgd_solver.cpp:112] Iteration 155900, lr = 1e-05
I0822 20:45:29.690500 13823 solver.cpp:239] Iteration 156000 (9.55366 iter/s, 10.4672s/100 iters), loss = 0.0301717
I0822 20:45:29.690562 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0301712 (* 1 = 0.0301712 loss)
I0822 20:45:29.690572 13823 sgd_solver.cpp:112] Iteration 156000, lr = 1e-05
I0822 20:45:40.298637 13823 solver.cpp:239] Iteration 156100 (9.42671 iter/s, 10.6082s/100 iters), loss = 0.0281955
I0822 20:45:40.298689 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.028195 (* 1 = 0.028195 loss)
I0822 20:45:40.298698 13823 sgd_solver.cpp:112] Iteration 156100, lr = 1e-05
I0822 20:45:51.168998 13823 solver.cpp:239] Iteration 156200 (9.19931 iter/s, 10.8704s/100 iters), loss = 0.0274076
I0822 20:45:51.169056 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0274071 (* 1 = 0.0274071 loss)
I0822 20:45:51.169067 13823 sgd_solver.cpp:112] Iteration 156200, lr = 1e-05
I0822 20:46:01.846961 13823 solver.cpp:239] Iteration 156300 (9.36507 iter/s, 10.678s/100 iters), loss = 0.0302212
I0822 20:46:01.847012 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0302207 (* 1 = 0.0302207 loss)
I0822 20:46:01.847020 13823 sgd_solver.cpp:112] Iteration 156300, lr = 1e-05
I0822 20:46:12.396806 13823 solver.cpp:239] Iteration 156400 (9.4788 iter/s, 10.5499s/100 iters), loss = 0.0268258
I0822 20:46:12.396853 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0268253 (* 1 = 0.0268253 loss)
I0822 20:46:12.396862 13823 sgd_solver.cpp:112] Iteration 156400, lr = 1e-05
I0822 20:46:23.211038 13823 solver.cpp:239] Iteration 156500 (9.24705 iter/s, 10.8143s/100 iters), loss = 0.0254548
I0822 20:46:23.211089 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0254543 (* 1 = 0.0254543 loss)
I0822 20:46:23.211099 13823 sgd_solver.cpp:112] Iteration 156500, lr = 1e-05
I0822 20:46:34.070683 13823 solver.cpp:239] Iteration 156600 (9.20839 iter/s, 10.8597s/100 iters), loss = 0.0281843
I0822 20:46:34.070732 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0281838 (* 1 = 0.0281838 loss)
I0822 20:46:34.070741 13823 sgd_solver.cpp:112] Iteration 156600, lr = 1e-05
I0822 20:46:44.761061 13823 solver.cpp:239] Iteration 156700 (9.35419 iter/s, 10.6904s/100 iters), loss = 0.0282293
I0822 20:46:44.761111 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0282288 (* 1 = 0.0282288 loss)
I0822 20:46:44.761121 13823 sgd_solver.cpp:112] Iteration 156700, lr = 1e-05
I0822 20:46:55.354646 13823 solver.cpp:239] Iteration 156800 (9.43966 iter/s, 10.5936s/100 iters), loss = 0.0275333
I0822 20:46:55.354698 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0275328 (* 1 = 0.0275328 loss)
I0822 20:46:55.354707 13823 sgd_solver.cpp:112] Iteration 156800, lr = 1e-05
I0822 20:47:05.999420 13823 solver.cpp:239] Iteration 156900 (9.39427 iter/s, 10.6448s/100 iters), loss = 0.0282015
I0822 20:47:05.999472 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.028201 (* 1 = 0.028201 loss)
I0822 20:47:05.999481 13823 sgd_solver.cpp:112] Iteration 156900, lr = 1e-05
I0822 20:47:16.451462 13823 solver.cpp:239] Iteration 157000 (9.5675 iter/s, 10.4521s/100 iters), loss = 0.025508
I0822 20:47:16.451520 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0255075 (* 1 = 0.0255075 loss)
I0822 20:47:16.451532 13823 sgd_solver.cpp:112] Iteration 157000, lr = 1e-05
I0822 20:47:27.279479 13823 solver.cpp:239] Iteration 157100 (9.23529 iter/s, 10.828s/100 iters), loss = 0.0250839
I0822 20:47:27.279537 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0250834 (* 1 = 0.0250834 loss)
I0822 20:47:27.279548 13823 sgd_solver.cpp:112] Iteration 157100, lr = 1e-05
I0822 20:47:38.146498 13823 solver.cpp:239] Iteration 157200 (9.20215 iter/s, 10.867s/100 iters), loss = 0.0352847
I0822 20:47:38.146554 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0352842 (* 1 = 0.0352842 loss)
I0822 20:47:38.146565 13823 sgd_solver.cpp:112] Iteration 157200, lr = 1e-05
I0822 20:47:48.962900 13823 solver.cpp:239] Iteration 157300 (9.24521 iter/s, 10.8164s/100 iters), loss = 0.0230017
I0822 20:47:48.962951 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0230012 (* 1 = 0.0230012 loss)
I0822 20:47:48.962960 13823 sgd_solver.cpp:112] Iteration 157300, lr = 1e-05
I0822 20:47:59.363936 13823 solver.cpp:239] Iteration 157400 (9.61442 iter/s, 10.401s/100 iters), loss = 0.0234015
I0822 20:47:59.363986 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.023401 (* 1 = 0.023401 loss)
I0822 20:47:59.363996 13823 sgd_solver.cpp:112] Iteration 157400, lr = 1e-05
I0822 20:48:09.970305 13823 solver.cpp:239] Iteration 157500 (9.42829 iter/s, 10.6064s/100 iters), loss = 0.0249351
I0822 20:48:09.970363 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0249346 (* 1 = 0.0249346 loss)
I0822 20:48:09.970374 13823 sgd_solver.cpp:112] Iteration 157500, lr = 1e-05
I0822 20:48:20.682122 13823 solver.cpp:239] Iteration 157600 (9.33548 iter/s, 10.7118s/100 iters), loss = 0.0278772
I0822 20:48:20.682189 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0278767 (* 1 = 0.0278767 loss)
I0822 20:48:20.682202 13823 sgd_solver.cpp:112] Iteration 157600, lr = 1e-05
I0822 20:48:31.495775 13823 solver.cpp:239] Iteration 157700 (9.24757 iter/s, 10.8137s/100 iters), loss = 0.0242746
I0822 20:48:31.495826 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0242741 (* 1 = 0.0242741 loss)
I0822 20:48:31.495834 13823 sgd_solver.cpp:112] Iteration 157700, lr = 1e-05
I0822 20:48:42.052757 13823 solver.cpp:239] Iteration 157800 (9.4724 iter/s, 10.557s/100 iters), loss = 0.0256653
I0822 20:48:42.052809 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0256648 (* 1 = 0.0256648 loss)
I0822 20:48:42.052819 13823 sgd_solver.cpp:112] Iteration 157800, lr = 1e-05
I0822 20:48:52.682325 13823 solver.cpp:239] Iteration 157900 (9.40771 iter/s, 10.6296s/100 iters), loss = 0.0274589
I0822 20:48:52.682377 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0274584 (* 1 = 0.0274584 loss)
I0822 20:48:52.682387 13823 sgd_solver.cpp:112] Iteration 157900, lr = 1e-05
I0822 20:49:03.368667 13823 solver.cpp:239] Iteration 158000 (9.35773 iter/s, 10.6864s/100 iters), loss = 0.0255266
I0822 20:49:03.368718 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0255261 (* 1 = 0.0255261 loss)
I0822 20:49:03.368727 13823 sgd_solver.cpp:112] Iteration 158000, lr = 1e-05
I0822 20:49:14.223755 13823 solver.cpp:239] Iteration 158100 (9.21226 iter/s, 10.8551s/100 iters), loss = 0.0259078
I0822 20:49:14.223806 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0259073 (* 1 = 0.0259073 loss)
I0822 20:49:14.223815 13823 sgd_solver.cpp:112] Iteration 158100, lr = 1e-05
I0822 20:49:24.888963 13823 solver.cpp:239] Iteration 158200 (9.37627 iter/s, 10.6652s/100 iters), loss = 0.0245069
I0822 20:49:24.889012 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0245064 (* 1 = 0.0245064 loss)
I0822 20:49:24.889021 13823 sgd_solver.cpp:112] Iteration 158200, lr = 1e-05
I0822 20:49:35.577790 13823 solver.cpp:239] Iteration 158300 (9.35555 iter/s, 10.6888s/100 iters), loss = 0.0278329
I0822 20:49:35.577841 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0278324 (* 1 = 0.0278324 loss)
I0822 20:49:35.577852 13823 sgd_solver.cpp:112] Iteration 158300, lr = 1e-05
I0822 20:49:46.657337 13823 solver.cpp:239] Iteration 158400 (9.02563 iter/s, 11.0796s/100 iters), loss = 0.0292988
I0822 20:49:46.657402 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0292983 (* 1 = 0.0292983 loss)
I0822 20:49:46.657413 13823 sgd_solver.cpp:112] Iteration 158400, lr = 1e-05
I0822 20:49:57.658967 13823 solver.cpp:239] Iteration 158500 (9.08956 iter/s, 11.0016s/100 iters), loss = 0.026317
I0822 20:49:57.659021 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0263164 (* 1 = 0.0263164 loss)
I0822 20:49:57.659031 13823 sgd_solver.cpp:112] Iteration 158500, lr = 1e-05
I0822 20:50:08.604307 13823 solver.cpp:239] Iteration 158600 (9.1363 iter/s, 10.9453s/100 iters), loss = 0.0280463
I0822 20:50:08.604363 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0280457 (* 1 = 0.0280457 loss)
I0822 20:50:08.604374 13823 sgd_solver.cpp:112] Iteration 158600, lr = 1e-05
I0822 20:50:19.484261 13823 solver.cpp:239] Iteration 158700 (9.19121 iter/s, 10.88s/100 iters), loss = 0.0302274
I0822 20:50:19.484310 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0302269 (* 1 = 0.0302269 loss)
I0822 20:50:19.484319 13823 sgd_solver.cpp:112] Iteration 158700, lr = 1e-05
I0822 20:50:30.230018 13823 solver.cpp:239] Iteration 158800 (9.30599 iter/s, 10.7458s/100 iters), loss = 0.0285074
I0822 20:50:30.230068 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0285069 (* 1 = 0.0285069 loss)
I0822 20:50:30.230077 13823 sgd_solver.cpp:112] Iteration 158800, lr = 1e-05
I0822 20:50:40.970772 13823 solver.cpp:239] Iteration 158900 (9.31032 iter/s, 10.7408s/100 iters), loss = 0.027432
I0822 20:50:40.970821 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0274315 (* 1 = 0.0274315 loss)
I0822 20:50:40.970830 13823 sgd_solver.cpp:112] Iteration 158900, lr = 1e-05
I0822 20:50:51.549610 13823 solver.cpp:239] Iteration 159000 (9.45282 iter/s, 10.5788s/100 iters), loss = 0.0281869
I0822 20:50:51.549659 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0281864 (* 1 = 0.0281864 loss)
I0822 20:50:51.549669 13823 sgd_solver.cpp:112] Iteration 159000, lr = 1e-05
I0822 20:51:02.560124 13823 solver.cpp:239] Iteration 159100 (9.08222 iter/s, 11.0105s/100 iters), loss = 0.025018
I0822 20:51:02.560187 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0250175 (* 1 = 0.0250175 loss)
I0822 20:51:02.560199 13823 sgd_solver.cpp:112] Iteration 159100, lr = 1e-05
I0822 20:51:13.590785 13823 solver.cpp:239] Iteration 159200 (9.06564 iter/s, 11.0307s/100 iters), loss = 0.0258143
I0822 20:51:13.590840 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0258138 (* 1 = 0.0258138 loss)
I0822 20:51:13.590850 13823 sgd_solver.cpp:112] Iteration 159200, lr = 1e-05
I0822 20:51:24.386914 13823 solver.cpp:239] Iteration 159300 (9.26258 iter/s, 10.7961s/100 iters), loss = 0.0273637
I0822 20:51:24.386965 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0273632 (* 1 = 0.0273632 loss)
I0822 20:51:24.386973 13823 sgd_solver.cpp:112] Iteration 159300, lr = 1e-05
I0822 20:51:35.087715 13823 solver.cpp:239] Iteration 159400 (9.34509 iter/s, 10.7008s/100 iters), loss = 0.0318797
I0822 20:51:35.087764 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0318792 (* 1 = 0.0318792 loss)
I0822 20:51:35.087772 13823 sgd_solver.cpp:112] Iteration 159400, lr = 1e-05
I0822 20:51:45.786165 13823 solver.cpp:239] Iteration 159500 (9.34714 iter/s, 10.6985s/100 iters), loss = 0.0326719
I0822 20:51:45.786216 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0326714 (* 1 = 0.0326714 loss)
I0822 20:51:45.786224 13823 sgd_solver.cpp:112] Iteration 159500, lr = 1e-05
I0822 20:51:56.752766 13823 solver.cpp:239] Iteration 159600 (9.11859 iter/s, 10.9666s/100 iters), loss = 0.0310646
I0822 20:51:56.752817 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0310641 (* 1 = 0.0310641 loss)
I0822 20:51:56.752827 13823 sgd_solver.cpp:112] Iteration 159600, lr = 1e-05
I0822 20:52:07.634548 13823 solver.cpp:239] Iteration 159700 (9.18967 iter/s, 10.8818s/100 iters), loss = 0.0246051
I0822 20:52:07.634608 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0246046 (* 1 = 0.0246046 loss)
I0822 20:52:07.634620 13823 sgd_solver.cpp:112] Iteration 159700, lr = 1e-05
I0822 20:52:18.702150 13823 solver.cpp:239] Iteration 159800 (9.03538 iter/s, 11.0676s/100 iters), loss = 0.0275315
I0822 20:52:18.702203 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0275309 (* 1 = 0.0275309 loss)
I0822 20:52:18.702212 13823 sgd_solver.cpp:112] Iteration 159800, lr = 1e-05
I0822 20:52:30.178946 13823 solver.cpp:239] Iteration 159900 (8.71323 iter/s, 11.4768s/100 iters), loss = 0.0230394
I0822 20:52:30.179003 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0230389 (* 1 = 0.0230389 loss)
I0822 20:52:30.179014 13823 sgd_solver.cpp:112] Iteration 159900, lr = 1e-05
I0822 20:52:41.489490 13823 solver.cpp:464] Snapshotting to binary proto file ./model_112/cascade_mobilenet_112_iter_160000.caffemodel
I0822 20:52:41.534209 13823 sgd_solver.cpp:284] Snapshotting solver state to binary proto file ./model_112/cascade_mobilenet_112_iter_160000.solverstate
I0822 20:52:41.564698 13823 solver.cpp:347] Iteration 160000, Testing net (#0)
I0822 20:53:41.096544 13823 solver.cpp:414]     Test net output #0: landmark_loss = 0.0221716 (* 1 = 0.0221716 loss)
I0822 20:53:41.213495 13823 solver.cpp:239] Iteration 160000 (1.40776 iter/s, 71.0349s/100 iters), loss = 0.0240441
I0822 20:53:41.213538 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0240436 (* 1 = 0.0240436 loss)
I0822 20:53:41.213548 13823 sgd_solver.cpp:50] MultiStep Status: Iteration 160000, step = 3
I0822 20:53:41.219532 13823 sgd_solver.cpp:112] Iteration 160000, lr = 1e-06
I0822 20:53:52.474478 13823 solver.cpp:239] Iteration 160100 (8.8802 iter/s, 11.261s/100 iters), loss = 0.0265107
I0822 20:53:52.474529 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0265102 (* 1 = 0.0265102 loss)
I0822 20:53:52.474539 13823 sgd_solver.cpp:112] Iteration 160100, lr = 1e-06
I0822 20:54:03.744575 13823 solver.cpp:239] Iteration 160200 (8.87303 iter/s, 11.2701s/100 iters), loss = 0.242501
I0822 20:54:03.744626 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.2425 (* 1 = 0.2425 loss)
I0822 20:54:03.744634 13823 sgd_solver.cpp:112] Iteration 160200, lr = 1e-06
I0822 20:54:14.527806 13823 solver.cpp:239] Iteration 160300 (9.27365 iter/s, 10.7832s/100 iters), loss = 0.0289508
I0822 20:54:14.527850 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0289502 (* 1 = 0.0289502 loss)
I0822 20:54:14.527858 13823 sgd_solver.cpp:112] Iteration 160300, lr = 1e-06
I0822 20:54:25.812348 13823 solver.cpp:239] Iteration 160400 (8.86167 iter/s, 11.2846s/100 iters), loss = 0.0243666
I0822 20:54:25.812407 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.024366 (* 1 = 0.024366 loss)
I0822 20:54:25.812417 13823 sgd_solver.cpp:112] Iteration 160400, lr = 1e-06
I0822 20:54:37.146545 13823 solver.cpp:239] Iteration 160500 (8.82285 iter/s, 11.3342s/100 iters), loss = 0.0275349
I0822 20:54:37.146606 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0275344 (* 1 = 0.0275344 loss)
I0822 20:54:37.146620 13823 sgd_solver.cpp:112] Iteration 160500, lr = 1e-06
I0822 20:54:47.981137 13823 solver.cpp:239] Iteration 160600 (9.22969 iter/s, 10.8346s/100 iters), loss = 0.0284684
I0822 20:54:47.981178 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0284678 (* 1 = 0.0284678 loss)
I0822 20:54:47.981185 13823 sgd_solver.cpp:112] Iteration 160600, lr = 1e-06
I0822 20:54:59.039110 13823 solver.cpp:239] Iteration 160700 (9.04323 iter/s, 11.058s/100 iters), loss = 0.0253398
I0822 20:54:59.039165 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0253393 (* 1 = 0.0253393 loss)
I0822 20:54:59.039176 13823 sgd_solver.cpp:112] Iteration 160700, lr = 1e-06
I0822 20:55:10.389883 13823 solver.cpp:239] Iteration 160800 (8.80996 iter/s, 11.3508s/100 iters), loss = 0.0248748
I0822 20:55:10.389941 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0248743 (* 1 = 0.0248743 loss)
I0822 20:55:10.389955 13823 sgd_solver.cpp:112] Iteration 160800, lr = 1e-06
I0822 20:55:21.741454 13823 solver.cpp:239] Iteration 160900 (8.80935 iter/s, 11.3516s/100 iters), loss = 0.0221648
I0822 20:55:21.741513 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0221642 (* 1 = 0.0221642 loss)
I0822 20:55:21.741525 13823 sgd_solver.cpp:112] Iteration 160900, lr = 1e-06
I0822 20:55:33.115061 13823 solver.cpp:239] Iteration 161000 (8.79228 iter/s, 11.3736s/100 iters), loss = 0.0255663
I0822 20:55:33.115115 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0255657 (* 1 = 0.0255657 loss)
I0822 20:55:33.115126 13823 sgd_solver.cpp:112] Iteration 161000, lr = 1e-06
I0822 20:55:44.371417 13823 solver.cpp:239] Iteration 161100 (8.88386 iter/s, 11.2564s/100 iters), loss = 0.0300831
I0822 20:55:44.371469 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0300825 (* 1 = 0.0300825 loss)
I0822 20:55:44.371477 13823 sgd_solver.cpp:112] Iteration 161100, lr = 1e-06
I0822 20:55:55.489051 13823 solver.cpp:239] Iteration 161200 (8.99471 iter/s, 11.1176s/100 iters), loss = 0.0311595
I0822 20:55:55.489102 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0311589 (* 1 = 0.0311589 loss)
I0822 20:55:55.489112 13823 sgd_solver.cpp:112] Iteration 161200, lr = 1e-06
I0822 20:56:06.773450 13823 solver.cpp:239] Iteration 161300 (8.86179 iter/s, 11.2844s/100 iters), loss = 0.0222924
I0822 20:56:06.773507 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0222919 (* 1 = 0.0222919 loss)
I0822 20:56:06.773519 13823 sgd_solver.cpp:112] Iteration 161300, lr = 1e-06
I0822 20:56:17.983633 13823 solver.cpp:239] Iteration 161400 (8.92046 iter/s, 11.2102s/100 iters), loss = 0.0305008
I0822 20:56:17.983690 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0305002 (* 1 = 0.0305002 loss)
I0822 20:56:17.983702 13823 sgd_solver.cpp:112] Iteration 161400, lr = 1e-06
I0822 20:56:29.421447 13823 solver.cpp:239] Iteration 161500 (8.74292 iter/s, 11.4378s/100 iters), loss = 0.0362361
I0822 20:56:29.421501 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0362356 (* 1 = 0.0362356 loss)
I0822 20:56:29.421512 13823 sgd_solver.cpp:112] Iteration 161500, lr = 1e-06
I0822 20:56:41.020195 13823 solver.cpp:239] Iteration 161600 (8.62162 iter/s, 11.5988s/100 iters), loss = 0.0265834
I0822 20:56:41.020251 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0265829 (* 1 = 0.0265829 loss)
I0822 20:56:41.020260 13823 sgd_solver.cpp:112] Iteration 161600, lr = 1e-06
I0822 20:56:52.463012 13823 solver.cpp:239] Iteration 161700 (8.7391 iter/s, 11.4428s/100 iters), loss = 0.0244032
I0822 20:56:52.463068 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0244026 (* 1 = 0.0244026 loss)
I0822 20:56:52.463083 13823 sgd_solver.cpp:112] Iteration 161700, lr = 1e-06
I0822 20:57:03.899464 13823 solver.cpp:239] Iteration 161800 (8.74397 iter/s, 11.4365s/100 iters), loss = 0.0294909
I0822 20:57:03.899523 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0294904 (* 1 = 0.0294904 loss)
I0822 20:57:03.899533 13823 sgd_solver.cpp:112] Iteration 161800, lr = 1e-06
I0822 20:57:14.859606 13823 solver.cpp:239] Iteration 161900 (9.12396 iter/s, 10.9601s/100 iters), loss = 0.0317014
I0822 20:57:14.859647 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0317009 (* 1 = 0.0317009 loss)
I0822 20:57:14.859654 13823 sgd_solver.cpp:112] Iteration 161900, lr = 1e-06
I0822 20:57:25.815937 13823 solver.cpp:239] Iteration 162000 (9.12713 iter/s, 10.9563s/100 iters), loss = 0.0450156
I0822 20:57:25.815989 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0450151 (* 1 = 0.0450151 loss)
I0822 20:57:25.815999 13823 sgd_solver.cpp:112] Iteration 162000, lr = 1e-06
I0822 20:57:36.946880 13823 solver.cpp:239] Iteration 162100 (8.98396 iter/s, 11.1309s/100 iters), loss = 0.038187
I0822 20:57:36.946943 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0381864 (* 1 = 0.0381864 loss)
I0822 20:57:36.946955 13823 sgd_solver.cpp:112] Iteration 162100, lr = 1e-06
I0822 20:57:48.288075 13823 solver.cpp:239] Iteration 162200 (8.81741 iter/s, 11.3412s/100 iters), loss = 0.026235
I0822 20:57:48.288125 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0262345 (* 1 = 0.0262345 loss)
I0822 20:57:48.288141 13823 sgd_solver.cpp:112] Iteration 162200, lr = 1e-06
I0822 20:57:59.964515 13823 solver.cpp:239] Iteration 162300 (8.56425 iter/s, 11.6765s/100 iters), loss = 0.0357996
I0822 20:57:59.964573 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0357991 (* 1 = 0.0357991 loss)
I0822 20:57:59.964586 13823 sgd_solver.cpp:112] Iteration 162300, lr = 1e-06
I0822 20:58:11.337843 13823 solver.cpp:239] Iteration 162400 (8.7925 iter/s, 11.3733s/100 iters), loss = 0.0233379
I0822 20:58:11.337905 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0233374 (* 1 = 0.0233374 loss)
I0822 20:58:11.337919 13823 sgd_solver.cpp:112] Iteration 162400, lr = 1e-06
I0822 20:58:22.692451 13823 solver.cpp:239] Iteration 162500 (8.807 iter/s, 11.3546s/100 iters), loss = 0.0292101
I0822 20:58:22.692517 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0292096 (* 1 = 0.0292096 loss)
I0822 20:58:22.692533 13823 sgd_solver.cpp:112] Iteration 162500, lr = 1e-06
I0822 20:58:34.220171 13823 solver.cpp:239] Iteration 162600 (8.67474 iter/s, 11.5277s/100 iters), loss = 0.0263158
I0822 20:58:34.220229 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0263152 (* 1 = 0.0263152 loss)
I0822 20:58:34.220240 13823 sgd_solver.cpp:112] Iteration 162600, lr = 1e-06
I0822 20:58:45.969807 13823 solver.cpp:239] Iteration 162700 (8.5109 iter/s, 11.7496s/100 iters), loss = 0.0262585
I0822 20:58:45.969866 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.026258 (* 1 = 0.026258 loss)
I0822 20:58:45.969877 13823 sgd_solver.cpp:112] Iteration 162700, lr = 1e-06
I0822 20:58:57.570178 13823 solver.cpp:239] Iteration 162800 (8.62041 iter/s, 11.6004s/100 iters), loss = 0.0264139
I0822 20:58:57.570238 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0264133 (* 1 = 0.0264133 loss)
I0822 20:58:57.570250 13823 sgd_solver.cpp:112] Iteration 162800, lr = 1e-06
I0822 20:59:09.212467 13823 solver.cpp:239] Iteration 162900 (8.58938 iter/s, 11.6423s/100 iters), loss = 0.0260908
I0822 20:59:09.212528 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0260902 (* 1 = 0.0260902 loss)
I0822 20:59:09.212539 13823 sgd_solver.cpp:112] Iteration 162900, lr = 1e-06
I0822 20:59:21.017735 13823 solver.cpp:239] Iteration 163000 (8.47079 iter/s, 11.8053s/100 iters), loss = 0.0308268
I0822 20:59:21.017793 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0308262 (* 1 = 0.0308262 loss)
I0822 20:59:21.017804 13823 sgd_solver.cpp:112] Iteration 163000, lr = 1e-06
I0822 20:59:32.421988 13823 solver.cpp:239] Iteration 163100 (8.76866 iter/s, 11.4043s/100 iters), loss = 0.0243838
I0822 20:59:32.422045 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0243833 (* 1 = 0.0243833 loss)
I0822 20:59:32.422056 13823 sgd_solver.cpp:112] Iteration 163100, lr = 1e-06
I0822 20:59:43.974359 13823 solver.cpp:239] Iteration 163200 (8.65623 iter/s, 11.5524s/100 iters), loss = 0.0412213
I0822 20:59:43.974417 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0412208 (* 1 = 0.0412208 loss)
I0822 20:59:43.974428 13823 sgd_solver.cpp:112] Iteration 163200, lr = 1e-06
I0822 20:59:55.456523 13823 solver.cpp:239] Iteration 163300 (8.70916 iter/s, 11.4822s/100 iters), loss = 0.0274738
I0822 20:59:55.456574 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0274733 (* 1 = 0.0274733 loss)
I0822 20:59:55.456584 13823 sgd_solver.cpp:112] Iteration 163300, lr = 1e-06
I0822 21:00:07.028949 13823 solver.cpp:239] Iteration 163400 (8.64122 iter/s, 11.5724s/100 iters), loss = 0.0344964
I0822 21:00:07.029011 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0344958 (* 1 = 0.0344958 loss)
I0822 21:00:07.029023 13823 sgd_solver.cpp:112] Iteration 163400, lr = 1e-06
I0822 21:00:18.585244 13823 solver.cpp:239] Iteration 163500 (8.65329 iter/s, 11.5563s/100 iters), loss = 0.0341094
I0822 21:00:18.585295 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0341089 (* 1 = 0.0341089 loss)
I0822 21:00:18.585305 13823 sgd_solver.cpp:112] Iteration 163500, lr = 1e-06
I0822 21:00:30.167217 13823 solver.cpp:239] Iteration 163600 (8.6341 iter/s, 11.582s/100 iters), loss = 0.0253263
I0822 21:00:30.167266 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0253258 (* 1 = 0.0253258 loss)
I0822 21:00:30.167275 13823 sgd_solver.cpp:112] Iteration 163600, lr = 1e-06
I0822 21:00:41.865969 13823 solver.cpp:239] Iteration 163700 (8.54791 iter/s, 11.6988s/100 iters), loss = 0.0252036
I0822 21:00:41.866025 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.025203 (* 1 = 0.025203 loss)
I0822 21:00:41.866036 13823 sgd_solver.cpp:112] Iteration 163700, lr = 1e-06
I0822 21:00:53.490289 13823 solver.cpp:239] Iteration 163800 (8.60265 iter/s, 11.6243s/100 iters), loss = 0.0282946
I0822 21:00:53.490350 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0282941 (* 1 = 0.0282941 loss)
I0822 21:00:53.490361 13823 sgd_solver.cpp:112] Iteration 163800, lr = 1e-06
I0822 21:01:05.119508 13823 solver.cpp:239] Iteration 163900 (8.59903 iter/s, 11.6292s/100 iters), loss = 0.031767
I0822 21:01:05.119570 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0317665 (* 1 = 0.0317665 loss)
I0822 21:01:05.119581 13823 sgd_solver.cpp:112] Iteration 163900, lr = 1e-06
I0822 21:01:16.877449 13823 solver.cpp:239] Iteration 164000 (8.50489 iter/s, 11.7579s/100 iters), loss = 0.0385082
I0822 21:01:16.877511 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0385077 (* 1 = 0.0385077 loss)
I0822 21:01:16.877521 13823 sgd_solver.cpp:112] Iteration 164000, lr = 1e-06
I0822 21:01:28.643890 13823 solver.cpp:239] Iteration 164100 (8.49875 iter/s, 11.7664s/100 iters), loss = 0.0310833
I0822 21:01:28.643940 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0310828 (* 1 = 0.0310828 loss)
I0822 21:01:28.643949 13823 sgd_solver.cpp:112] Iteration 164100, lr = 1e-06
I0822 21:01:40.348608 13823 solver.cpp:239] Iteration 164200 (8.54356 iter/s, 11.7047s/100 iters), loss = 0.0256476
I0822 21:01:40.348671 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0256471 (* 1 = 0.0256471 loss)
I0822 21:01:40.348685 13823 sgd_solver.cpp:112] Iteration 164200, lr = 1e-06
I0822 21:01:51.964080 13823 solver.cpp:239] Iteration 164300 (8.60921 iter/s, 11.6155s/100 iters), loss = 0.0260201
I0822 21:01:51.964135 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0260196 (* 1 = 0.0260196 loss)
I0822 21:01:51.964145 13823 sgd_solver.cpp:112] Iteration 164300, lr = 1e-06
I0822 21:02:02.387964 13823 solver.cpp:239] Iteration 164400 (9.59335 iter/s, 10.4239s/100 iters), loss = 0.0264848
I0822 21:02:02.388015 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0264843 (* 1 = 0.0264843 loss)
I0822 21:02:02.388023 13823 sgd_solver.cpp:112] Iteration 164400, lr = 1e-06
I0822 21:02:12.145529 13823 solver.cpp:239] Iteration 164500 (10.2485 iter/s, 9.75756s/100 iters), loss = 0.0306893
I0822 21:02:12.145571 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0306887 (* 1 = 0.0306887 loss)
I0822 21:02:12.145579 13823 sgd_solver.cpp:112] Iteration 164500, lr = 1e-06
I0822 21:02:21.910861 13823 solver.cpp:239] Iteration 164600 (10.2403 iter/s, 9.76534s/100 iters), loss = 0.0271751
I0822 21:02:21.910914 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0271746 (* 1 = 0.0271746 loss)
I0822 21:02:21.910924 13823 sgd_solver.cpp:112] Iteration 164600, lr = 1e-06
I0822 21:02:31.912780 13823 solver.cpp:239] Iteration 164700 (9.99809 iter/s, 10.0019s/100 iters), loss = 0.0215148
I0822 21:02:31.912830 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0215142 (* 1 = 0.0215142 loss)
I0822 21:02:31.912839 13823 sgd_solver.cpp:112] Iteration 164700, lr = 1e-06
I0822 21:02:41.674885 13823 solver.cpp:239] Iteration 164800 (10.2437 iter/s, 9.7621s/100 iters), loss = 0.0270337
I0822 21:02:41.674937 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0270332 (* 1 = 0.0270332 loss)
I0822 21:02:41.674947 13823 sgd_solver.cpp:112] Iteration 164800, lr = 1e-06
I0822 21:02:51.246661 13823 solver.cpp:239] Iteration 164900 (10.4474 iter/s, 9.57177s/100 iters), loss = 0.0264603
I0822 21:02:51.246713 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0264598 (* 1 = 0.0264598 loss)
I0822 21:02:51.246722 13823 sgd_solver.cpp:112] Iteration 164900, lr = 1e-06
I0822 21:03:00.701450 13823 solver.cpp:239] Iteration 165000 (10.5767 iter/s, 9.45478s/100 iters), loss = 0.0305227
I0822 21:03:00.701503 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0305222 (* 1 = 0.0305222 loss)
I0822 21:03:00.701511 13823 sgd_solver.cpp:112] Iteration 165000, lr = 1e-06
I0822 21:03:10.336411 13823 solver.cpp:239] Iteration 165100 (10.3789 iter/s, 9.63496s/100 iters), loss = 0.0376393
I0822 21:03:10.336464 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0376388 (* 1 = 0.0376388 loss)
I0822 21:03:10.336473 13823 sgd_solver.cpp:112] Iteration 165100, lr = 1e-06
I0822 21:03:19.966681 13823 solver.cpp:239] Iteration 165200 (10.3839 iter/s, 9.63026s/100 iters), loss = 0.0309721
I0822 21:03:19.966732 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0309716 (* 1 = 0.0309716 loss)
I0822 21:03:19.966740 13823 sgd_solver.cpp:112] Iteration 165200, lr = 1e-06
I0822 21:03:29.721776 13823 solver.cpp:239] Iteration 165300 (10.2511 iter/s, 9.75509s/100 iters), loss = 0.0400459
I0822 21:03:29.721832 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0400454 (* 1 = 0.0400454 loss)
I0822 21:03:29.721841 13823 sgd_solver.cpp:112] Iteration 165300, lr = 1e-06
I0822 21:03:39.472949 13823 solver.cpp:239] Iteration 165400 (10.2552 iter/s, 9.75117s/100 iters), loss = 0.026773
I0822 21:03:39.472995 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0267724 (* 1 = 0.0267724 loss)
I0822 21:03:39.473003 13823 sgd_solver.cpp:112] Iteration 165400, lr = 1e-06
I0822 21:03:49.598400 13823 solver.cpp:239] Iteration 165500 (9.8761 iter/s, 10.1255s/100 iters), loss = 0.0240793
I0822 21:03:49.598459 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0240788 (* 1 = 0.0240788 loss)
I0822 21:03:49.598471 13823 sgd_solver.cpp:112] Iteration 165500, lr = 1e-06
I0822 21:03:59.437937 13823 solver.cpp:239] Iteration 165600 (10.1631 iter/s, 9.83952s/100 iters), loss = 0.0290208
I0822 21:03:59.437986 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0290203 (* 1 = 0.0290203 loss)
I0822 21:03:59.437996 13823 sgd_solver.cpp:112] Iteration 165600, lr = 1e-06
I0822 21:04:08.997211 13823 solver.cpp:239] Iteration 165700 (10.4611 iter/s, 9.55927s/100 iters), loss = 0.024293
I0822 21:04:08.997262 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0242925 (* 1 = 0.0242925 loss)
I0822 21:04:08.997272 13823 sgd_solver.cpp:112] Iteration 165700, lr = 1e-06
I0822 21:04:18.601899 13823 solver.cpp:239] Iteration 165800 (10.4116 iter/s, 9.60468s/100 iters), loss = 0.0277399
I0822 21:04:18.601941 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0277393 (* 1 = 0.0277393 loss)
I0822 21:04:18.601948 13823 sgd_solver.cpp:112] Iteration 165800, lr = 1e-06
I0822 21:04:28.408418 13823 solver.cpp:239] Iteration 165900 (10.1973 iter/s, 9.80652s/100 iters), loss = 0.0256571
I0822 21:04:28.408473 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0256565 (* 1 = 0.0256565 loss)
I0822 21:04:28.408484 13823 sgd_solver.cpp:112] Iteration 165900, lr = 1e-06
I0822 21:04:38.312865 13823 solver.cpp:239] Iteration 166000 (10.0965 iter/s, 9.90444s/100 iters), loss = 0.0282239
I0822 21:04:38.312914 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0282234 (* 1 = 0.0282234 loss)
I0822 21:04:38.312923 13823 sgd_solver.cpp:112] Iteration 166000, lr = 1e-06
I0822 21:04:48.079278 13823 solver.cpp:239] Iteration 166100 (10.2392 iter/s, 9.76641s/100 iters), loss = 0.0268887
I0822 21:04:48.079329 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0268882 (* 1 = 0.0268882 loss)
I0822 21:04:48.079339 13823 sgd_solver.cpp:112] Iteration 166100, lr = 1e-06
I0822 21:04:57.878545 13823 solver.cpp:239] Iteration 166200 (10.2049 iter/s, 9.79926s/100 iters), loss = 0.0263924
I0822 21:04:57.878597 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0263919 (* 1 = 0.0263919 loss)
I0822 21:04:57.878605 13823 sgd_solver.cpp:112] Iteration 166200, lr = 1e-06
I0822 21:05:07.841771 13823 solver.cpp:239] Iteration 166300 (10.0369 iter/s, 9.96322s/100 iters), loss = 0.0289965
I0822 21:05:07.841832 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0289959 (* 1 = 0.0289959 loss)
I0822 21:05:07.841843 13823 sgd_solver.cpp:112] Iteration 166300, lr = 1e-06
I0822 21:05:17.773680 13823 solver.cpp:239] Iteration 166400 (10.0686 iter/s, 9.93189s/100 iters), loss = 0.0243224
I0822 21:05:17.773735 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0243219 (* 1 = 0.0243219 loss)
I0822 21:05:17.773744 13823 sgd_solver.cpp:112] Iteration 166400, lr = 1e-06
I0822 21:05:27.443742 13823 solver.cpp:239] Iteration 166500 (10.3412 iter/s, 9.67005s/100 iters), loss = 0.0251427
I0822 21:05:27.443792 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0251422 (* 1 = 0.0251422 loss)
I0822 21:05:27.443801 13823 sgd_solver.cpp:112] Iteration 166500, lr = 1e-06
I0822 21:05:37.206508 13823 solver.cpp:239] Iteration 166600 (10.243 iter/s, 9.76276s/100 iters), loss = 0.0270367
I0822 21:05:37.206568 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0270363 (* 1 = 0.0270363 loss)
I0822 21:05:37.206579 13823 sgd_solver.cpp:112] Iteration 166600, lr = 1e-06
I0822 21:05:47.116214 13823 solver.cpp:239] Iteration 166700 (10.0911 iter/s, 9.90969s/100 iters), loss = 0.0291853
I0822 21:05:47.116264 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0291848 (* 1 = 0.0291848 loss)
I0822 21:05:47.116273 13823 sgd_solver.cpp:112] Iteration 166700, lr = 1e-06
I0822 21:05:56.922046 13823 solver.cpp:239] Iteration 166800 (10.198 iter/s, 9.80582s/100 iters), loss = 0.0287685
I0822 21:05:56.922098 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.028768 (* 1 = 0.028768 loss)
I0822 21:05:56.922107 13823 sgd_solver.cpp:112] Iteration 166800, lr = 1e-06
I0822 21:06:06.759328 13823 solver.cpp:239] Iteration 166900 (10.1654 iter/s, 9.83727s/100 iters), loss = 0.0298975
I0822 21:06:06.759378 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.029897 (* 1 = 0.029897 loss)
I0822 21:06:06.759387 13823 sgd_solver.cpp:112] Iteration 166900, lr = 1e-06
I0822 21:06:16.517448 13823 solver.cpp:239] Iteration 167000 (10.2479 iter/s, 9.75811s/100 iters), loss = 0.0246209
I0822 21:06:16.517504 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0246204 (* 1 = 0.0246204 loss)
I0822 21:06:16.517515 13823 sgd_solver.cpp:112] Iteration 167000, lr = 1e-06
I0822 21:06:26.634361 13823 solver.cpp:239] Iteration 167100 (9.88445 iter/s, 10.1169s/100 iters), loss = 0.0279041
I0822 21:06:26.634408 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0279036 (* 1 = 0.0279036 loss)
I0822 21:06:26.634418 13823 sgd_solver.cpp:112] Iteration 167100, lr = 1e-06
I0822 21:06:36.266064 13823 solver.cpp:239] Iteration 167200 (10.3824 iter/s, 9.6317s/100 iters), loss = 0.0306336
I0822 21:06:36.266106 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0306331 (* 1 = 0.0306331 loss)
I0822 21:06:36.266114 13823 sgd_solver.cpp:112] Iteration 167200, lr = 1e-06
I0822 21:06:46.151141 13823 solver.cpp:239] Iteration 167300 (10.1163 iter/s, 9.88508s/100 iters), loss = 0.0256689
I0822 21:06:46.151192 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0256685 (* 1 = 0.0256685 loss)
I0822 21:06:46.151201 13823 sgd_solver.cpp:112] Iteration 167300, lr = 1e-06
I0822 21:06:55.984833 13823 solver.cpp:239] Iteration 167400 (10.1691 iter/s, 9.83368s/100 iters), loss = 0.023953
I0822 21:06:55.984891 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0239525 (* 1 = 0.0239525 loss)
I0822 21:06:55.984903 13823 sgd_solver.cpp:112] Iteration 167400, lr = 1e-06
I0822 21:07:05.963835 13823 solver.cpp:239] Iteration 167500 (10.0211 iter/s, 9.97899s/100 iters), loss = 0.0248708
I0822 21:07:05.963896 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0248703 (* 1 = 0.0248703 loss)
I0822 21:07:05.963907 13823 sgd_solver.cpp:112] Iteration 167500, lr = 1e-06
I0822 21:07:15.651029 13823 solver.cpp:239] Iteration 167600 (10.3229 iter/s, 9.68718s/100 iters), loss = 0.0308437
I0822 21:07:15.651080 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0308432 (* 1 = 0.0308432 loss)
I0822 21:07:15.651090 13823 sgd_solver.cpp:112] Iteration 167600, lr = 1e-06
I0822 21:07:25.324474 13823 solver.cpp:239] Iteration 167700 (10.3376 iter/s, 9.67344s/100 iters), loss = 0.0293093
I0822 21:07:25.324525 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0293088 (* 1 = 0.0293088 loss)
I0822 21:07:25.324534 13823 sgd_solver.cpp:112] Iteration 167700, lr = 1e-06
I0822 21:07:35.349931 13823 solver.cpp:239] Iteration 167800 (9.97461 iter/s, 10.0255s/100 iters), loss = 0.0233009
I0822 21:07:35.349982 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0233005 (* 1 = 0.0233005 loss)
I0822 21:07:35.349990 13823 sgd_solver.cpp:112] Iteration 167800, lr = 1e-06
I0822 21:07:44.960175 13823 solver.cpp:239] Iteration 167900 (10.4056 iter/s, 9.61023s/100 iters), loss = 0.0263597
I0822 21:07:44.960225 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0263592 (* 1 = 0.0263592 loss)
I0822 21:07:44.960235 13823 sgd_solver.cpp:112] Iteration 167900, lr = 1e-06
I0822 21:07:54.864070 13823 solver.cpp:239] Iteration 168000 (10.097 iter/s, 9.90389s/100 iters), loss = 0.0211717
I0822 21:07:54.864121 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0211713 (* 1 = 0.0211713 loss)
I0822 21:07:54.864136 13823 sgd_solver.cpp:112] Iteration 168000, lr = 1e-06
I0822 21:08:04.821363 13823 solver.cpp:239] Iteration 168100 (10.0429 iter/s, 9.95728s/100 iters), loss = 0.026741
I0822 21:08:04.821413 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0267405 (* 1 = 0.0267405 loss)
I0822 21:08:04.821422 13823 sgd_solver.cpp:112] Iteration 168100, lr = 1e-06
I0822 21:08:14.386952 13823 solver.cpp:239] Iteration 168200 (10.4541 iter/s, 9.56559s/100 iters), loss = 0.0254519
I0822 21:08:14.386992 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0254514 (* 1 = 0.0254514 loss)
I0822 21:08:14.387001 13823 sgd_solver.cpp:112] Iteration 168200, lr = 1e-06
I0822 21:08:23.795783 13823 solver.cpp:239] Iteration 168300 (10.6283 iter/s, 9.40883s/100 iters), loss = 0.0232229
I0822 21:08:23.795823 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0232224 (* 1 = 0.0232224 loss)
I0822 21:08:23.795831 13823 sgd_solver.cpp:112] Iteration 168300, lr = 1e-06
I0822 21:08:33.465153 13823 solver.cpp:239] Iteration 168400 (10.3419 iter/s, 9.66937s/100 iters), loss = 0.0277821
I0822 21:08:33.465203 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0277816 (* 1 = 0.0277816 loss)
I0822 21:08:33.465212 13823 sgd_solver.cpp:112] Iteration 168400, lr = 1e-06
I0822 21:08:43.135108 13823 solver.cpp:239] Iteration 168500 (10.3413 iter/s, 9.66995s/100 iters), loss = 0.0286722
I0822 21:08:43.135164 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0286717 (* 1 = 0.0286717 loss)
I0822 21:08:43.135174 13823 sgd_solver.cpp:112] Iteration 168500, lr = 1e-06
I0822 21:08:52.615360 13823 solver.cpp:239] Iteration 168600 (10.5483 iter/s, 9.48024s/100 iters), loss = 0.0281858
I0822 21:08:52.615408 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0281853 (* 1 = 0.0281853 loss)
I0822 21:08:52.615417 13823 sgd_solver.cpp:112] Iteration 168600, lr = 1e-06
I0822 21:09:02.686780 13823 solver.cpp:239] Iteration 168700 (9.92909 iter/s, 10.0714s/100 iters), loss = 0.0262078
I0822 21:09:02.686838 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0262073 (* 1 = 0.0262073 loss)
I0822 21:09:02.686848 13823 sgd_solver.cpp:112] Iteration 168700, lr = 1e-06
I0822 21:09:12.632122 13823 solver.cpp:239] Iteration 168800 (10.055 iter/s, 9.94533s/100 iters), loss = 0.027706
I0822 21:09:12.632175 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0277055 (* 1 = 0.0277055 loss)
I0822 21:09:12.632184 13823 sgd_solver.cpp:112] Iteration 168800, lr = 1e-06
I0822 21:09:22.623504 13823 solver.cpp:239] Iteration 168900 (10.0086 iter/s, 9.99137s/100 iters), loss = 0.0265203
I0822 21:09:22.623554 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0265198 (* 1 = 0.0265198 loss)
I0822 21:09:22.623564 13823 sgd_solver.cpp:112] Iteration 168900, lr = 1e-06
I0822 21:09:32.883754 13823 solver.cpp:239] Iteration 169000 (9.74636 iter/s, 10.2602s/100 iters), loss = 0.0478
I0822 21:09:32.883802 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0477995 (* 1 = 0.0477995 loss)
I0822 21:09:32.883811 13823 sgd_solver.cpp:112] Iteration 169000, lr = 1e-06
I0822 21:09:42.839138 13823 solver.cpp:239] Iteration 169100 (10.0448 iter/s, 9.95538s/100 iters), loss = 0.0271707
I0822 21:09:42.839188 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0271702 (* 1 = 0.0271702 loss)
I0822 21:09:42.839198 13823 sgd_solver.cpp:112] Iteration 169100, lr = 1e-06
I0822 21:09:52.454169 13823 solver.cpp:239] Iteration 169200 (10.4004 iter/s, 9.61502s/100 iters), loss = 0.0250099
I0822 21:09:52.454218 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0250094 (* 1 = 0.0250094 loss)
I0822 21:09:52.454228 13823 sgd_solver.cpp:112] Iteration 169200, lr = 1e-06
I0822 21:10:02.544698 13823 solver.cpp:239] Iteration 169300 (9.91029 iter/s, 10.0905s/100 iters), loss = 0.0245603
I0822 21:10:02.544747 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0245598 (* 1 = 0.0245598 loss)
I0822 21:10:02.544756 13823 sgd_solver.cpp:112] Iteration 169300, lr = 1e-06
I0822 21:10:12.536959 13823 solver.cpp:239] Iteration 169400 (10.0078 iter/s, 9.99217s/100 iters), loss = 0.025204
I0822 21:10:12.537010 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0252035 (* 1 = 0.0252035 loss)
I0822 21:10:12.537020 13823 sgd_solver.cpp:112] Iteration 169400, lr = 1e-06
I0822 21:10:22.320341 13823 solver.cpp:239] Iteration 169500 (10.2216 iter/s, 9.78319s/100 iters), loss = 0.0249638
I0822 21:10:22.320394 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0249633 (* 1 = 0.0249633 loss)
I0822 21:10:22.320402 13823 sgd_solver.cpp:112] Iteration 169500, lr = 1e-06
I0822 21:10:32.451632 13823 solver.cpp:239] Iteration 169600 (9.8706 iter/s, 10.1311s/100 iters), loss = 0.0265472
I0822 21:10:32.451683 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0265467 (* 1 = 0.0265467 loss)
I0822 21:10:32.451691 13823 sgd_solver.cpp:112] Iteration 169600, lr = 1e-06
I0822 21:10:42.335669 13823 solver.cpp:239] Iteration 169700 (10.1175 iter/s, 9.88384s/100 iters), loss = 0.0284478
I0822 21:10:42.335733 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0284473 (* 1 = 0.0284473 loss)
I0822 21:10:42.335744 13823 sgd_solver.cpp:112] Iteration 169700, lr = 1e-06
I0822 21:10:53.100726 13823 solver.cpp:239] Iteration 169800 (9.2895 iter/s, 10.7648s/100 iters), loss = 0.0260594
I0822 21:10:53.100780 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0260589 (* 1 = 0.0260589 loss)
I0822 21:10:53.100788 13823 sgd_solver.cpp:112] Iteration 169800, lr = 1e-06
I0822 21:11:03.096668 13823 solver.cpp:239] Iteration 169900 (10.0042 iter/s, 9.99575s/100 iters), loss = 0.0249763
I0822 21:11:03.096719 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0249758 (* 1 = 0.0249758 loss)
I0822 21:11:03.096729 13823 sgd_solver.cpp:112] Iteration 169900, lr = 1e-06
I0822 21:11:12.884397 13823 solver.cpp:239] Iteration 170000 (10.2171 iter/s, 9.78755s/100 iters), loss = 0.0260564
I0822 21:11:12.884445 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0260559 (* 1 = 0.0260559 loss)
I0822 21:11:12.884455 13823 sgd_solver.cpp:112] Iteration 170000, lr = 1e-06
I0822 21:11:22.783885 13823 solver.cpp:239] Iteration 170100 (10.1017 iter/s, 9.89931s/100 iters), loss = 0.027439
I0822 21:11:22.783932 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0274385 (* 1 = 0.0274385 loss)
I0822 21:11:22.783942 13823 sgd_solver.cpp:112] Iteration 170100, lr = 1e-06
I0822 21:11:32.772958 13823 solver.cpp:239] Iteration 170200 (10.0111 iter/s, 9.9889s/100 iters), loss = 0.0251166
I0822 21:11:32.773010 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0251161 (* 1 = 0.0251161 loss)
I0822 21:11:32.773018 13823 sgd_solver.cpp:112] Iteration 170200, lr = 1e-06
I0822 21:11:43.045949 13823 solver.cpp:239] Iteration 170300 (9.73443 iter/s, 10.2728s/100 iters), loss = 0.0239993
I0822 21:11:43.046000 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0239987 (* 1 = 0.0239987 loss)
I0822 21:11:43.046010 13823 sgd_solver.cpp:112] Iteration 170300, lr = 1e-06
I0822 21:11:52.865375 13823 solver.cpp:239] Iteration 170400 (10.1841 iter/s, 9.81926s/100 iters), loss = 0.0273026
I0822 21:11:52.865424 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0273021 (* 1 = 0.0273021 loss)
I0822 21:11:52.865433 13823 sgd_solver.cpp:112] Iteration 170400, lr = 1e-06
I0822 21:12:02.819010 13823 solver.cpp:239] Iteration 170500 (10.0467 iter/s, 9.95347s/100 iters), loss = 0.0274243
I0822 21:12:02.819061 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0274238 (* 1 = 0.0274238 loss)
I0822 21:12:02.819069 13823 sgd_solver.cpp:112] Iteration 170500, lr = 1e-06
I0822 21:12:12.927202 13823 solver.cpp:239] Iteration 170600 (9.89313 iter/s, 10.108s/100 iters), loss = 0.0331643
I0822 21:12:12.927253 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0331638 (* 1 = 0.0331638 loss)
I0822 21:12:12.927263 13823 sgd_solver.cpp:112] Iteration 170600, lr = 1e-06
I0822 21:12:23.096129 13823 solver.cpp:239] Iteration 170700 (9.83404 iter/s, 10.1688s/100 iters), loss = 0.026287
I0822 21:12:23.096184 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0262865 (* 1 = 0.0262865 loss)
I0822 21:12:23.096194 13823 sgd_solver.cpp:112] Iteration 170700, lr = 1e-06
I0822 21:12:33.147716 13823 solver.cpp:239] Iteration 170800 (9.94884 iter/s, 10.0514s/100 iters), loss = 0.0271464
I0822 21:12:33.147765 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0271458 (* 1 = 0.0271458 loss)
I0822 21:12:33.147774 13823 sgd_solver.cpp:112] Iteration 170800, lr = 1e-06
I0822 21:12:43.185494 13823 solver.cpp:239] Iteration 170900 (9.96252 iter/s, 10.0376s/100 iters), loss = 0.05426
I0822 21:12:43.185545 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0542595 (* 1 = 0.0542595 loss)
I0822 21:12:43.185554 13823 sgd_solver.cpp:112] Iteration 170900, lr = 1e-06
I0822 21:12:53.273787 13823 solver.cpp:239] Iteration 171000 (9.91263 iter/s, 10.0881s/100 iters), loss = 0.025504
I0822 21:12:53.273838 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0255035 (* 1 = 0.0255035 loss)
I0822 21:12:53.273849 13823 sgd_solver.cpp:112] Iteration 171000, lr = 1e-06
I0822 21:13:03.327669 13823 solver.cpp:239] Iteration 171100 (9.94656 iter/s, 10.0537s/100 iters), loss = 0.0327821
I0822 21:13:03.327720 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0327816 (* 1 = 0.0327816 loss)
I0822 21:13:03.327729 13823 sgd_solver.cpp:112] Iteration 171100, lr = 1e-06
I0822 21:13:13.488215 13823 solver.cpp:239] Iteration 171200 (9.84214 iter/s, 10.1604s/100 iters), loss = 0.0295537
I0822 21:13:13.488272 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0295532 (* 1 = 0.0295532 loss)
I0822 21:13:13.488283 13823 sgd_solver.cpp:112] Iteration 171200, lr = 1e-06
I0822 21:13:23.611984 13823 solver.cpp:239] Iteration 171300 (9.8779 iter/s, 10.1236s/100 iters), loss = 0.0340242
I0822 21:13:23.612037 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0340237 (* 1 = 0.0340237 loss)
I0822 21:13:23.612047 13823 sgd_solver.cpp:112] Iteration 171300, lr = 1e-06
I0822 21:13:33.735527 13823 solver.cpp:239] Iteration 171400 (9.87811 iter/s, 10.1234s/100 iters), loss = 0.0270562
I0822 21:13:33.735576 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0270557 (* 1 = 0.0270557 loss)
I0822 21:13:33.735586 13823 sgd_solver.cpp:112] Iteration 171400, lr = 1e-06
I0822 21:13:43.908316 13823 solver.cpp:239] Iteration 171500 (9.83028 iter/s, 10.1726s/100 iters), loss = 0.0283846
I0822 21:13:43.908370 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0283841 (* 1 = 0.0283841 loss)
I0822 21:13:43.908380 13823 sgd_solver.cpp:112] Iteration 171500, lr = 1e-06
I0822 21:13:53.916777 13823 solver.cpp:239] Iteration 171600 (9.99169 iter/s, 10.0083s/100 iters), loss = 0.0264177
I0822 21:13:53.916826 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0264172 (* 1 = 0.0264172 loss)
I0822 21:13:53.916836 13823 sgd_solver.cpp:112] Iteration 171600, lr = 1e-06
I0822 21:14:04.010982 13823 solver.cpp:239] Iteration 171700 (9.90681 iter/s, 10.0941s/100 iters), loss = 0.0253771
I0822 21:14:04.011046 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0253766 (* 1 = 0.0253766 loss)
I0822 21:14:04.011059 13823 sgd_solver.cpp:112] Iteration 171700, lr = 1e-06
I0822 21:14:14.066879 13823 solver.cpp:239] Iteration 171800 (9.94456 iter/s, 10.0557s/100 iters), loss = 0.0304723
I0822 21:14:14.066931 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0304717 (* 1 = 0.0304717 loss)
I0822 21:14:14.066939 13823 sgd_solver.cpp:112] Iteration 171800, lr = 1e-06
I0822 21:14:24.596807 13823 solver.cpp:239] Iteration 171900 (9.49687 iter/s, 10.5298s/100 iters), loss = 0.0275251
I0822 21:14:24.596865 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0275246 (* 1 = 0.0275246 loss)
I0822 21:14:24.596876 13823 sgd_solver.cpp:112] Iteration 171900, lr = 1e-06
I0822 21:14:34.994881 13823 solver.cpp:239] Iteration 172000 (9.6173 iter/s, 10.3979s/100 iters), loss = 0.0259974
I0822 21:14:34.994933 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0259969 (* 1 = 0.0259969 loss)
I0822 21:14:34.994942 13823 sgd_solver.cpp:112] Iteration 172000, lr = 1e-06
I0822 21:14:45.246898 13823 solver.cpp:239] Iteration 172100 (9.75431 iter/s, 10.2519s/100 iters), loss = 0.0242117
I0822 21:14:45.246953 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0242111 (* 1 = 0.0242111 loss)
I0822 21:14:45.246963 13823 sgd_solver.cpp:112] Iteration 172100, lr = 1e-06
I0822 21:14:55.581077 13823 solver.cpp:239] Iteration 172200 (9.67675 iter/s, 10.334s/100 iters), loss = 0.0280565
I0822 21:14:55.581138 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0280559 (* 1 = 0.0280559 loss)
I0822 21:14:55.581149 13823 sgd_solver.cpp:112] Iteration 172200, lr = 1e-06
I0822 21:15:05.975816 13823 solver.cpp:239] Iteration 172300 (9.62038 iter/s, 10.3946s/100 iters), loss = 0.031765
I0822 21:15:05.975865 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0317645 (* 1 = 0.0317645 loss)
I0822 21:15:05.975875 13823 sgd_solver.cpp:112] Iteration 172300, lr = 1e-06
I0822 21:15:16.324550 13823 solver.cpp:239] Iteration 172400 (9.66313 iter/s, 10.3486s/100 iters), loss = 0.0265758
I0822 21:15:16.324602 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0265753 (* 1 = 0.0265753 loss)
I0822 21:15:16.324612 13823 sgd_solver.cpp:112] Iteration 172400, lr = 1e-06
I0822 21:15:26.654899 13823 solver.cpp:239] Iteration 172500 (9.68033 iter/s, 10.3302s/100 iters), loss = 0.026095
I0822 21:15:26.654950 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0260945 (* 1 = 0.0260945 loss)
I0822 21:15:26.654959 13823 sgd_solver.cpp:112] Iteration 172500, lr = 1e-06
I0822 21:15:36.706511 13823 solver.cpp:239] Iteration 172600 (9.94877 iter/s, 10.0515s/100 iters), loss = 0.0262786
I0822 21:15:36.706552 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.026278 (* 1 = 0.026278 loss)
I0822 21:15:36.706560 13823 sgd_solver.cpp:112] Iteration 172600, lr = 1e-06
I0822 21:15:46.981333 13823 solver.cpp:239] Iteration 172700 (9.73264 iter/s, 10.2747s/100 iters), loss = 0.0277877
I0822 21:15:46.981382 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0277872 (* 1 = 0.0277872 loss)
I0822 21:15:46.981391 13823 sgd_solver.cpp:112] Iteration 172700, lr = 1e-06
I0822 21:15:57.264317 13823 solver.cpp:239] Iteration 172800 (9.72492 iter/s, 10.2829s/100 iters), loss = 0.0276908
I0822 21:15:57.264374 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0276902 (* 1 = 0.0276902 loss)
I0822 21:15:57.264384 13823 sgd_solver.cpp:112] Iteration 172800, lr = 1e-06
I0822 21:16:07.791395 13823 solver.cpp:239] Iteration 172900 (9.49942 iter/s, 10.527s/100 iters), loss = 0.0490678
I0822 21:16:07.791446 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0490673 (* 1 = 0.0490673 loss)
I0822 21:16:07.791456 13823 sgd_solver.cpp:112] Iteration 172900, lr = 1e-06
I0822 21:16:17.929198 13823 solver.cpp:239] Iteration 173000 (9.86418 iter/s, 10.1377s/100 iters), loss = 0.0374747
I0822 21:16:17.929250 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0374741 (* 1 = 0.0374741 loss)
I0822 21:16:17.929258 13823 sgd_solver.cpp:112] Iteration 173000, lr = 1e-06
I0822 21:16:28.350499 13823 solver.cpp:239] Iteration 173100 (9.59584 iter/s, 10.4212s/100 iters), loss = 0.0280938
I0822 21:16:28.350558 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0280933 (* 1 = 0.0280933 loss)
I0822 21:16:28.350569 13823 sgd_solver.cpp:112] Iteration 173100, lr = 1e-06
I0822 21:16:38.451736 13823 solver.cpp:239] Iteration 173200 (9.89989 iter/s, 10.1011s/100 iters), loss = 0.0271645
I0822 21:16:38.451797 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0271639 (* 1 = 0.0271639 loss)
I0822 21:16:38.451807 13823 sgd_solver.cpp:112] Iteration 173200, lr = 1e-06
I0822 21:16:48.499043 13823 solver.cpp:239] Iteration 173300 (9.95303 iter/s, 10.0472s/100 iters), loss = 0.0417135
I0822 21:16:48.499094 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.041713 (* 1 = 0.041713 loss)
I0822 21:16:48.499102 13823 sgd_solver.cpp:112] Iteration 173300, lr = 1e-06
I0822 21:16:58.941431 13823 solver.cpp:239] Iteration 173400 (9.57645 iter/s, 10.4423s/100 iters), loss = 0.0294141
I0822 21:16:58.941481 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0294136 (* 1 = 0.0294136 loss)
I0822 21:16:58.941491 13823 sgd_solver.cpp:112] Iteration 173400, lr = 1e-06
I0822 21:17:09.484143 13823 solver.cpp:239] Iteration 173500 (9.48533 iter/s, 10.5426s/100 iters), loss = 0.0395103
I0822 21:17:09.484192 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0395098 (* 1 = 0.0395098 loss)
I0822 21:17:09.484201 13823 sgd_solver.cpp:112] Iteration 173500, lr = 1e-06
I0822 21:17:20.132050 13823 solver.cpp:239] Iteration 173600 (9.39161 iter/s, 10.6478s/100 iters), loss = 0.0319024
I0822 21:17:20.132099 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0319019 (* 1 = 0.0319019 loss)
I0822 21:17:20.132108 13823 sgd_solver.cpp:112] Iteration 173600, lr = 1e-06
I0822 21:17:30.674329 13823 solver.cpp:239] Iteration 173700 (9.48571 iter/s, 10.5422s/100 iters), loss = 0.0260701
I0822 21:17:30.674381 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0260696 (* 1 = 0.0260696 loss)
I0822 21:17:30.674389 13823 sgd_solver.cpp:112] Iteration 173700, lr = 1e-06
I0822 21:17:40.990113 13823 solver.cpp:239] Iteration 173800 (9.69398 iter/s, 10.3157s/100 iters), loss = 0.0310529
I0822 21:17:40.990166 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0310524 (* 1 = 0.0310524 loss)
I0822 21:17:40.990177 13823 sgd_solver.cpp:112] Iteration 173800, lr = 1e-06
I0822 21:17:51.353927 13823 solver.cpp:239] Iteration 173900 (9.64905 iter/s, 10.3637s/100 iters), loss = 0.0263134
I0822 21:17:51.353979 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0263129 (* 1 = 0.0263129 loss)
I0822 21:17:51.353989 13823 sgd_solver.cpp:112] Iteration 173900, lr = 1e-06
I0822 21:18:01.842733 13823 solver.cpp:239] Iteration 174000 (9.53407 iter/s, 10.4887s/100 iters), loss = 0.0259675
I0822 21:18:01.842780 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0259669 (* 1 = 0.0259669 loss)
I0822 21:18:01.842790 13823 sgd_solver.cpp:112] Iteration 174000, lr = 1e-06
I0822 21:18:12.079777 13823 solver.cpp:239] Iteration 174100 (9.76854 iter/s, 10.2369s/100 iters), loss = 0.028694
I0822 21:18:12.079826 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0286935 (* 1 = 0.0286935 loss)
I0822 21:18:12.079836 13823 sgd_solver.cpp:112] Iteration 174100, lr = 1e-06
I0822 21:18:22.710402 13823 solver.cpp:239] Iteration 174200 (9.40687 iter/s, 10.6305s/100 iters), loss = 0.0245829
I0822 21:18:22.710451 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0245824 (* 1 = 0.0245824 loss)
I0822 21:18:22.710460 13823 sgd_solver.cpp:112] Iteration 174200, lr = 1e-06
I0822 21:18:33.498390 13823 solver.cpp:239] Iteration 174300 (9.26965 iter/s, 10.7879s/100 iters), loss = 0.0248681
I0822 21:18:33.498441 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0248676 (* 1 = 0.0248676 loss)
I0822 21:18:33.498451 13823 sgd_solver.cpp:112] Iteration 174300, lr = 1e-06
I0822 21:18:44.010622 13823 solver.cpp:239] Iteration 174400 (9.51282 iter/s, 10.5121s/100 iters), loss = 0.0311265
I0822 21:18:44.010675 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.031126 (* 1 = 0.031126 loss)
I0822 21:18:44.010685 13823 sgd_solver.cpp:112] Iteration 174400, lr = 1e-06
I0822 21:18:54.834111 13823 solver.cpp:239] Iteration 174500 (9.23925 iter/s, 10.8234s/100 iters), loss = 0.0239441
I0822 21:18:54.834161 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0239436 (* 1 = 0.0239436 loss)
I0822 21:18:54.834170 13823 sgd_solver.cpp:112] Iteration 174500, lr = 1e-06
I0822 21:19:05.218386 13823 solver.cpp:239] Iteration 174600 (9.63003 iter/s, 10.3842s/100 iters), loss = 0.0277449
I0822 21:19:05.218438 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0277444 (* 1 = 0.0277444 loss)
I0822 21:19:05.218447 13823 sgd_solver.cpp:112] Iteration 174600, lr = 1e-06
I0822 21:19:15.737689 13823 solver.cpp:239] Iteration 174700 (9.50642 iter/s, 10.5192s/100 iters), loss = 0.0256083
I0822 21:19:15.737738 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0256078 (* 1 = 0.0256078 loss)
I0822 21:19:15.737748 13823 sgd_solver.cpp:112] Iteration 174700, lr = 1e-06
I0822 21:19:26.315299 13823 solver.cpp:239] Iteration 174800 (9.45401 iter/s, 10.5775s/100 iters), loss = 0.026484
I0822 21:19:26.315369 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0264835 (* 1 = 0.0264835 loss)
I0822 21:19:26.315380 13823 sgd_solver.cpp:112] Iteration 174800, lr = 1e-06
I0822 21:19:36.859289 13823 solver.cpp:239] Iteration 174900 (9.48417 iter/s, 10.5439s/100 iters), loss = 0.0247388
I0822 21:19:36.859338 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0247384 (* 1 = 0.0247384 loss)
I0822 21:19:36.859347 13823 sgd_solver.cpp:112] Iteration 174900, lr = 1e-06
I0822 21:19:47.514684 13823 solver.cpp:239] Iteration 175000 (9.38499 iter/s, 10.6553s/100 iters), loss = 0.031766
I0822 21:19:47.514734 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0317655 (* 1 = 0.0317655 loss)
I0822 21:19:47.514744 13823 sgd_solver.cpp:112] Iteration 175000, lr = 1e-06
I0822 21:19:57.974149 13823 solver.cpp:239] Iteration 175100 (9.5608 iter/s, 10.4594s/100 iters), loss = 0.0258123
I0822 21:19:57.974200 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0258118 (* 1 = 0.0258118 loss)
I0822 21:19:57.974210 13823 sgd_solver.cpp:112] Iteration 175100, lr = 1e-06
I0822 21:20:08.299053 13823 solver.cpp:239] Iteration 175200 (9.6854 iter/s, 10.3248s/100 iters), loss = 0.027995
I0822 21:20:08.299103 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0279945 (* 1 = 0.0279945 loss)
I0822 21:20:08.299113 13823 sgd_solver.cpp:112] Iteration 175200, lr = 1e-06
I0822 21:20:19.013411 13823 solver.cpp:239] Iteration 175300 (9.33334 iter/s, 10.7143s/100 iters), loss = 0.0238159
I0822 21:20:19.013459 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0238154 (* 1 = 0.0238154 loss)
I0822 21:20:19.013468 13823 sgd_solver.cpp:112] Iteration 175300, lr = 1e-06
I0822 21:20:29.814333 13823 solver.cpp:239] Iteration 175400 (9.25855 iter/s, 10.8008s/100 iters), loss = 0.0273895
I0822 21:20:29.814414 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.027389 (* 1 = 0.027389 loss)
I0822 21:20:29.814425 13823 sgd_solver.cpp:112] Iteration 175400, lr = 1e-06
I0822 21:20:40.061327 13823 solver.cpp:239] Iteration 175500 (9.75906 iter/s, 10.2469s/100 iters), loss = 0.0258771
I0822 21:20:40.061378 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0258766 (* 1 = 0.0258766 loss)
I0822 21:20:40.061386 13823 sgd_solver.cpp:112] Iteration 175500, lr = 1e-06
I0822 21:20:50.746709 13823 solver.cpp:239] Iteration 175600 (9.35865 iter/s, 10.6853s/100 iters), loss = 0.0255681
I0822 21:20:50.746762 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0255676 (* 1 = 0.0255676 loss)
I0822 21:20:50.746773 13823 sgd_solver.cpp:112] Iteration 175600, lr = 1e-06
I0822 21:21:01.258805 13823 solver.cpp:239] Iteration 175700 (9.51292 iter/s, 10.512s/100 iters), loss = 0.0247681
I0822 21:21:01.258854 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0247677 (* 1 = 0.0247677 loss)
I0822 21:21:01.258863 13823 sgd_solver.cpp:112] Iteration 175700, lr = 1e-06
I0822 21:21:11.925240 13823 solver.cpp:239] Iteration 175800 (9.37527 iter/s, 10.6664s/100 iters), loss = 0.0302461
I0822 21:21:11.925292 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0302456 (* 1 = 0.0302456 loss)
I0822 21:21:11.925300 13823 sgd_solver.cpp:112] Iteration 175800, lr = 1e-06
I0822 21:21:22.528360 13823 solver.cpp:239] Iteration 175900 (9.43126 iter/s, 10.603s/100 iters), loss = 0.0235846
I0822 21:21:22.528414 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0235841 (* 1 = 0.0235841 loss)
I0822 21:21:22.528424 13823 sgd_solver.cpp:112] Iteration 175900, lr = 1e-06
I0822 21:21:33.396214 13823 solver.cpp:239] Iteration 176000 (9.20152 iter/s, 10.8678s/100 iters), loss = 0.0281389
I0822 21:21:33.396267 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0281384 (* 1 = 0.0281384 loss)
I0822 21:21:33.396277 13823 sgd_solver.cpp:112] Iteration 176000, lr = 1e-06
I0822 21:21:44.166515 13823 solver.cpp:239] Iteration 176100 (9.28486 iter/s, 10.7702s/100 iters), loss = 0.0309867
I0822 21:21:44.166571 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0309862 (* 1 = 0.0309862 loss)
I0822 21:21:44.166584 13823 sgd_solver.cpp:112] Iteration 176100, lr = 1e-06
I0822 21:21:55.337919 13823 solver.cpp:239] Iteration 176200 (8.95149 iter/s, 11.1713s/100 iters), loss = 0.0270358
I0822 21:21:55.337977 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0270353 (* 1 = 0.0270353 loss)
I0822 21:21:55.337990 13823 sgd_solver.cpp:112] Iteration 176200, lr = 1e-06
I0822 21:22:06.202957 13823 solver.cpp:239] Iteration 176300 (9.20391 iter/s, 10.865s/100 iters), loss = 0.0336306
I0822 21:22:06.203019 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0336302 (* 1 = 0.0336302 loss)
I0822 21:22:06.203030 13823 sgd_solver.cpp:112] Iteration 176300, lr = 1e-06
I0822 21:22:17.275451 13823 solver.cpp:239] Iteration 176400 (9.03146 iter/s, 11.0724s/100 iters), loss = 0.0270128
I0822 21:22:17.275502 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0270124 (* 1 = 0.0270124 loss)
I0822 21:22:17.275511 13823 sgd_solver.cpp:112] Iteration 176400, lr = 1e-06
I0822 21:22:28.229051 13823 solver.cpp:239] Iteration 176500 (9.12948 iter/s, 10.9535s/100 iters), loss = 0.0268025
I0822 21:22:28.229101 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0268021 (* 1 = 0.0268021 loss)
I0822 21:22:28.229111 13823 sgd_solver.cpp:112] Iteration 176500, lr = 1e-06
I0822 21:22:39.472548 13823 solver.cpp:239] Iteration 176600 (8.89409 iter/s, 11.2434s/100 iters), loss = 0.0219441
I0822 21:22:39.472600 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0219436 (* 1 = 0.0219436 loss)
I0822 21:22:39.472610 13823 sgd_solver.cpp:112] Iteration 176600, lr = 1e-06
I0822 21:22:50.558152 13823 solver.cpp:239] Iteration 176700 (9.02077 iter/s, 11.0855s/100 iters), loss = 0.0313172
I0822 21:22:50.558203 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0313167 (* 1 = 0.0313167 loss)
I0822 21:22:50.558212 13823 sgd_solver.cpp:112] Iteration 176700, lr = 1e-06
I0822 21:23:01.356689 13823 solver.cpp:239] Iteration 176800 (9.26057 iter/s, 10.7985s/100 iters), loss = 0.0252855
I0822 21:23:01.356741 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.025285 (* 1 = 0.025285 loss)
I0822 21:23:01.356751 13823 sgd_solver.cpp:112] Iteration 176800, lr = 1e-06
I0822 21:23:12.412958 13823 solver.cpp:239] Iteration 176900 (9.0447 iter/s, 11.0562s/100 iters), loss = 0.02632
I0822 21:23:12.413012 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0263195 (* 1 = 0.0263195 loss)
I0822 21:23:12.413022 13823 sgd_solver.cpp:112] Iteration 176900, lr = 1e-06
I0822 21:23:23.417248 13823 solver.cpp:239] Iteration 177000 (9.08743 iter/s, 11.0042s/100 iters), loss = 0.0268231
I0822 21:23:23.417307 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0268226 (* 1 = 0.0268226 loss)
I0822 21:23:23.417320 13823 sgd_solver.cpp:112] Iteration 177000, lr = 1e-06
I0822 21:23:34.651011 13823 solver.cpp:239] Iteration 177100 (8.9018 iter/s, 11.2337s/100 iters), loss = 0.0281806
I0822 21:23:34.651070 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0281801 (* 1 = 0.0281801 loss)
I0822 21:23:34.651083 13823 sgd_solver.cpp:112] Iteration 177100, lr = 1e-06
I0822 21:23:45.737417 13823 solver.cpp:239] Iteration 177200 (9.02012 iter/s, 11.0863s/100 iters), loss = 0.0310977
I0822 21:23:45.737466 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0310972 (* 1 = 0.0310972 loss)
I0822 21:23:45.737475 13823 sgd_solver.cpp:112] Iteration 177200, lr = 1e-06
I0822 21:23:56.814832 13823 solver.cpp:239] Iteration 177300 (9.02743 iter/s, 11.0774s/100 iters), loss = 0.0303084
I0822 21:23:56.814885 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0303079 (* 1 = 0.0303079 loss)
I0822 21:23:56.814895 13823 sgd_solver.cpp:112] Iteration 177300, lr = 1e-06
I0822 21:24:07.817426 13823 solver.cpp:239] Iteration 177400 (9.08882 iter/s, 11.0025s/100 iters), loss = 0.0283604
I0822 21:24:07.817477 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.02836 (* 1 = 0.02836 loss)
I0822 21:24:07.817487 13823 sgd_solver.cpp:112] Iteration 177400, lr = 1e-06
I0822 21:24:19.018004 13823 solver.cpp:239] Iteration 177500 (8.92816 iter/s, 11.2005s/100 iters), loss = 0.0354127
I0822 21:24:19.018059 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0354123 (* 1 = 0.0354123 loss)
I0822 21:24:19.018069 13823 sgd_solver.cpp:112] Iteration 177500, lr = 1e-06
I0822 21:24:30.018394 13823 solver.cpp:239] Iteration 177600 (9.09064 iter/s, 11.0003s/100 iters), loss = 0.0246551
I0822 21:24:30.018455 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0246546 (* 1 = 0.0246546 loss)
I0822 21:24:30.018468 13823 sgd_solver.cpp:112] Iteration 177600, lr = 1e-06
I0822 21:24:41.313127 13823 solver.cpp:239] Iteration 177700 (8.85374 iter/s, 11.2947s/100 iters), loss = 0.0271995
I0822 21:24:41.313177 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0271991 (* 1 = 0.0271991 loss)
I0822 21:24:41.313186 13823 sgd_solver.cpp:112] Iteration 177700, lr = 1e-06
I0822 21:24:52.387143 13823 solver.cpp:239] Iteration 177800 (9.0302 iter/s, 11.074s/100 iters), loss = 0.0261644
I0822 21:24:52.387195 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.026164 (* 1 = 0.026164 loss)
I0822 21:24:52.387205 13823 sgd_solver.cpp:112] Iteration 177800, lr = 1e-06
I0822 21:25:03.429504 13823 solver.cpp:239] Iteration 177900 (9.05608 iter/s, 11.0423s/100 iters), loss = 0.0259221
I0822 21:25:03.429559 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0259217 (* 1 = 0.0259217 loss)
I0822 21:25:03.429569 13823 sgd_solver.cpp:112] Iteration 177900, lr = 1e-06
I0822 21:25:14.690325 13823 solver.cpp:239] Iteration 178000 (8.8804 iter/s, 11.2608s/100 iters), loss = 0.0253671
I0822 21:25:14.690384 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0253666 (* 1 = 0.0253666 loss)
I0822 21:25:14.690397 13823 sgd_solver.cpp:112] Iteration 178000, lr = 1e-06
I0822 21:25:25.829480 13823 solver.cpp:239] Iteration 178100 (8.9774 iter/s, 11.1391s/100 iters), loss = 0.0235223
I0822 21:25:25.829541 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0235218 (* 1 = 0.0235218 loss)
I0822 21:25:25.829553 13823 sgd_solver.cpp:112] Iteration 178100, lr = 1e-06
I0822 21:25:36.634070 13823 solver.cpp:239] Iteration 178200 (9.25538 iter/s, 10.8045s/100 iters), loss = 0.0318107
I0822 21:25:36.634127 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0318103 (* 1 = 0.0318103 loss)
I0822 21:25:36.634137 13823 sgd_solver.cpp:112] Iteration 178200, lr = 1e-06
I0822 21:25:47.623119 13823 solver.cpp:239] Iteration 178300 (9.10002 iter/s, 10.989s/100 iters), loss = 0.0264618
I0822 21:25:47.623168 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0264613 (* 1 = 0.0264613 loss)
I0822 21:25:47.623178 13823 sgd_solver.cpp:112] Iteration 178300, lr = 1e-06
I0822 21:25:58.773466 13823 solver.cpp:239] Iteration 178400 (8.96838 iter/s, 11.1503s/100 iters), loss = 0.0242778
I0822 21:25:58.773519 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0242774 (* 1 = 0.0242774 loss)
I0822 21:25:58.773528 13823 sgd_solver.cpp:112] Iteration 178400, lr = 1e-06
I0822 21:26:09.872370 13823 solver.cpp:239] Iteration 178500 (9.00995 iter/s, 11.0988s/100 iters), loss = 0.0280502
I0822 21:26:09.872421 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0280498 (* 1 = 0.0280498 loss)
I0822 21:26:09.872431 13823 sgd_solver.cpp:112] Iteration 178500, lr = 1e-06
I0822 21:26:20.997644 13823 solver.cpp:239] Iteration 178600 (8.98859 iter/s, 11.1252s/100 iters), loss = 0.0367412
I0822 21:26:20.997695 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0367408 (* 1 = 0.0367408 loss)
I0822 21:26:20.997705 13823 sgd_solver.cpp:112] Iteration 178600, lr = 1e-06
I0822 21:26:32.289036 13823 solver.cpp:239] Iteration 178700 (8.85635 iter/s, 11.2913s/100 iters), loss = 0.0282465
I0822 21:26:32.289089 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.028246 (* 1 = 0.028246 loss)
I0822 21:26:32.289099 13823 sgd_solver.cpp:112] Iteration 178700, lr = 1e-06
I0822 21:26:43.702581 13823 solver.cpp:239] Iteration 178800 (8.76156 iter/s, 11.4135s/100 iters), loss = 0.0878341
I0822 21:26:43.702642 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0878337 (* 1 = 0.0878337 loss)
I0822 21:26:43.702654 13823 sgd_solver.cpp:112] Iteration 178800, lr = 1e-06
I0822 21:26:54.966162 13823 solver.cpp:239] Iteration 178900 (8.87822 iter/s, 11.2635s/100 iters), loss = 0.0256957
I0822 21:26:54.966222 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0256953 (* 1 = 0.0256953 loss)
I0822 21:26:54.966233 13823 sgd_solver.cpp:112] Iteration 178900, lr = 1e-06
I0822 21:27:06.279929 13823 solver.cpp:239] Iteration 179000 (8.83884 iter/s, 11.3137s/100 iters), loss = 0.0305745
I0822 21:27:06.279979 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0305741 (* 1 = 0.0305741 loss)
I0822 21:27:06.279989 13823 sgd_solver.cpp:112] Iteration 179000, lr = 1e-06
I0822 21:27:17.406800 13823 solver.cpp:239] Iteration 179100 (8.9873 iter/s, 11.1268s/100 iters), loss = 0.0247371
I0822 21:27:17.406848 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0247367 (* 1 = 0.0247367 loss)
I0822 21:27:17.406857 13823 sgd_solver.cpp:112] Iteration 179100, lr = 1e-06
I0822 21:27:28.394243 13823 solver.cpp:239] Iteration 179200 (9.10134 iter/s, 10.9874s/100 iters), loss = 0.027026
I0822 21:27:28.394294 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0270256 (* 1 = 0.0270256 loss)
I0822 21:27:28.394304 13823 sgd_solver.cpp:112] Iteration 179200, lr = 1e-06
I0822 21:27:39.295469 13823 solver.cpp:239] Iteration 179300 (9.17332 iter/s, 10.9012s/100 iters), loss = 0.0269841
I0822 21:27:39.295519 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0269836 (* 1 = 0.0269836 loss)
I0822 21:27:39.295528 13823 sgd_solver.cpp:112] Iteration 179300, lr = 1e-06
I0822 21:27:50.371433 13823 solver.cpp:239] Iteration 179400 (9.0286 iter/s, 11.0759s/100 iters), loss = 0.0278086
I0822 21:27:50.371484 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0278081 (* 1 = 0.0278081 loss)
I0822 21:27:50.371492 13823 sgd_solver.cpp:112] Iteration 179400, lr = 1e-06
I0822 21:28:01.453531 13823 solver.cpp:239] Iteration 179500 (9.0236 iter/s, 11.082s/100 iters), loss = 0.0396784
I0822 21:28:01.453593 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.039678 (* 1 = 0.039678 loss)
I0822 21:28:01.453605 13823 sgd_solver.cpp:112] Iteration 179500, lr = 1e-06
I0822 21:28:12.593472 13823 solver.cpp:239] Iteration 179600 (8.97676 iter/s, 11.1399s/100 iters), loss = 0.0257575
I0822 21:28:12.593525 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0257571 (* 1 = 0.0257571 loss)
I0822 21:28:12.593535 13823 sgd_solver.cpp:112] Iteration 179600, lr = 1e-06
I0822 21:28:23.520941 13823 solver.cpp:239] Iteration 179700 (9.1513 iter/s, 10.9274s/100 iters), loss = 0.0289666
I0822 21:28:23.520997 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0289661 (* 1 = 0.0289661 loss)
I0822 21:28:23.521006 13823 sgd_solver.cpp:112] Iteration 179700, lr = 1e-06
I0822 21:28:34.483988 13823 solver.cpp:239] Iteration 179800 (9.1216 iter/s, 10.963s/100 iters), loss = 0.0316476
I0822 21:28:34.484047 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0316472 (* 1 = 0.0316472 loss)
I0822 21:28:34.484059 13823 sgd_solver.cpp:112] Iteration 179800, lr = 1e-06
I0822 21:28:45.698547 13823 solver.cpp:239] Iteration 179900 (8.91703 iter/s, 11.2145s/100 iters), loss = 0.0280453
I0822 21:28:45.698612 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0280449 (* 1 = 0.0280449 loss)
I0822 21:28:45.698626 13823 sgd_solver.cpp:112] Iteration 179900, lr = 1e-06
I0822 21:28:56.652880 13823 solver.cpp:464] Snapshotting to binary proto file ./model_112/cascade_mobilenet_112_iter_180000.caffemodel
I0822 21:28:56.749177 13823 sgd_solver.cpp:284] Snapshotting solver state to binary proto file ./model_112/cascade_mobilenet_112_iter_180000.solverstate
I0822 21:28:56.791697 13823 solver.cpp:347] Iteration 180000, Testing net (#0)
I0822 21:29:57.043062 13823 solver.cpp:414]     Test net output #0: landmark_loss = 0.0219777 (* 1 = 0.0219777 loss)
I0822 21:29:57.161108 13823 solver.cpp:239] Iteration 180000 (1.39933 iter/s, 71.4626s/100 iters), loss = 0.0227649
I0822 21:29:57.161159 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0227645 (* 1 = 0.0227645 loss)
I0822 21:29:57.161171 13823 sgd_solver.cpp:112] Iteration 180000, lr = 1e-06
I0822 21:30:08.561000 13823 solver.cpp:239] Iteration 180100 (8.77204 iter/s, 11.3999s/100 iters), loss = 0.0280431
I0822 21:30:08.561055 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0280427 (* 1 = 0.0280427 loss)
I0822 21:30:08.561065 13823 sgd_solver.cpp:112] Iteration 180100, lr = 1e-06
I0822 21:30:19.883918 13823 solver.cpp:239] Iteration 180200 (8.83168 iter/s, 11.3229s/100 iters), loss = 0.0293412
I0822 21:30:19.883970 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0293408 (* 1 = 0.0293408 loss)
I0822 21:30:19.883980 13823 sgd_solver.cpp:112] Iteration 180200, lr = 1e-06
I0822 21:30:31.468180 13823 solver.cpp:239] Iteration 180300 (8.63243 iter/s, 11.5842s/100 iters), loss = 0.0253736
I0822 21:30:31.468241 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0253732 (* 1 = 0.0253732 loss)
I0822 21:30:31.468253 13823 sgd_solver.cpp:112] Iteration 180300, lr = 1e-06
I0822 21:30:43.049371 13823 solver.cpp:239] Iteration 180400 (8.63473 iter/s, 11.5811s/100 iters), loss = 0.0272813
I0822 21:30:43.049433 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0272808 (* 1 = 0.0272808 loss)
I0822 21:30:43.049445 13823 sgd_solver.cpp:112] Iteration 180400, lr = 1e-06
I0822 21:30:54.286132 13823 solver.cpp:239] Iteration 180500 (8.8994 iter/s, 11.2367s/100 iters), loss = 0.0259427
I0822 21:30:54.286190 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0259422 (* 1 = 0.0259422 loss)
I0822 21:30:54.286201 13823 sgd_solver.cpp:112] Iteration 180500, lr = 1e-06
I0822 21:31:05.843880 13823 solver.cpp:239] Iteration 180600 (8.65224 iter/s, 11.5577s/100 iters), loss = 0.0246136
I0822 21:31:05.843938 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0246131 (* 1 = 0.0246131 loss)
I0822 21:31:05.843948 13823 sgd_solver.cpp:112] Iteration 180600, lr = 1e-06
I0822 21:31:17.275048 13823 solver.cpp:239] Iteration 180700 (8.74805 iter/s, 11.4311s/100 iters), loss = 0.0292486
I0822 21:31:17.275107 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0292482 (* 1 = 0.0292482 loss)
I0822 21:31:17.275118 13823 sgd_solver.cpp:112] Iteration 180700, lr = 1e-06
I0822 21:31:28.791940 13823 solver.cpp:239] Iteration 180800 (8.68293 iter/s, 11.5168s/100 iters), loss = 0.0374638
I0822 21:31:28.791990 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0374633 (* 1 = 0.0374633 loss)
I0822 21:31:28.791999 13823 sgd_solver.cpp:112] Iteration 180800, lr = 1e-06
I0822 21:31:40.023769 13823 solver.cpp:239] Iteration 180900 (8.9033 iter/s, 11.2318s/100 iters), loss = 0.0283791
I0822 21:31:40.023824 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0283786 (* 1 = 0.0283786 loss)
I0822 21:31:40.023833 13823 sgd_solver.cpp:112] Iteration 180900, lr = 1e-06
I0822 21:31:51.645566 13823 solver.cpp:239] Iteration 181000 (8.60455 iter/s, 11.6218s/100 iters), loss = 0.0259829
I0822 21:31:51.645639 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0259825 (* 1 = 0.0259825 loss)
I0822 21:31:51.645656 13823 sgd_solver.cpp:112] Iteration 181000, lr = 1e-06
I0822 21:32:03.035142 13823 solver.cpp:239] Iteration 181100 (8.78 iter/s, 11.3895s/100 iters), loss = 0.0263077
I0822 21:32:03.035194 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0263073 (* 1 = 0.0263073 loss)
I0822 21:32:03.035204 13823 sgd_solver.cpp:112] Iteration 181100, lr = 1e-06
I0822 21:32:14.559902 13823 solver.cpp:239] Iteration 181200 (8.677 iter/s, 11.5247s/100 iters), loss = 0.0253443
I0822 21:32:14.559957 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0253439 (* 1 = 0.0253439 loss)
I0822 21:32:14.559969 13823 sgd_solver.cpp:112] Iteration 181200, lr = 1e-06
I0822 21:32:26.073732 13823 solver.cpp:239] Iteration 181300 (8.68524 iter/s, 11.5138s/100 iters), loss = 0.0287452
I0822 21:32:26.073804 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0287447 (* 1 = 0.0287447 loss)
I0822 21:32:26.073822 13823 sgd_solver.cpp:112] Iteration 181300, lr = 1e-06
I0822 21:32:37.757180 13823 solver.cpp:239] Iteration 181400 (8.55915 iter/s, 11.6834s/100 iters), loss = 0.0271083
I0822 21:32:37.757241 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0271079 (* 1 = 0.0271079 loss)
I0822 21:32:37.757254 13823 sgd_solver.cpp:112] Iteration 181400, lr = 1e-06
I0822 21:32:49.292840 13823 solver.cpp:239] Iteration 181500 (8.6688 iter/s, 11.5356s/100 iters), loss = 0.0290655
I0822 21:32:49.292894 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0290651 (* 1 = 0.0290651 loss)
I0822 21:32:49.292906 13823 sgd_solver.cpp:112] Iteration 181500, lr = 1e-06
I0822 21:33:00.982398 13823 solver.cpp:239] Iteration 181600 (8.55467 iter/s, 11.6895s/100 iters), loss = 0.0266699
I0822 21:33:00.982451 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0266695 (* 1 = 0.0266695 loss)
I0822 21:33:00.982461 13823 sgd_solver.cpp:112] Iteration 181600, lr = 1e-06
I0822 21:33:12.504911 13823 solver.cpp:239] Iteration 181700 (8.67869 iter/s, 11.5225s/100 iters), loss = 0.0257321
I0822 21:33:12.504969 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0257317 (* 1 = 0.0257317 loss)
I0822 21:33:12.504983 13823 sgd_solver.cpp:112] Iteration 181700, lr = 1e-06
I0822 21:33:24.061868 13823 solver.cpp:239] Iteration 181800 (8.65283 iter/s, 11.5569s/100 iters), loss = 0.0244977
I0822 21:33:24.061930 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0244972 (* 1 = 0.0244972 loss)
I0822 21:33:24.061941 13823 sgd_solver.cpp:112] Iteration 181800, lr = 1e-06
I0822 21:33:35.813899 13823 solver.cpp:239] Iteration 181900 (8.5092 iter/s, 11.752s/100 iters), loss = 0.0252214
I0822 21:33:35.813958 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0252209 (* 1 = 0.0252209 loss)
I0822 21:33:35.813971 13823 sgd_solver.cpp:112] Iteration 181900, lr = 1e-06
I0822 21:33:47.454221 13823 solver.cpp:239] Iteration 182000 (8.59086 iter/s, 11.6403s/100 iters), loss = 0.0355801
I0822 21:33:47.454272 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0355796 (* 1 = 0.0355796 loss)
I0822 21:33:47.454282 13823 sgd_solver.cpp:112] Iteration 182000, lr = 1e-06
I0822 21:33:59.109740 13823 solver.cpp:239] Iteration 182100 (8.57965 iter/s, 11.6555s/100 iters), loss = 0.0298396
I0822 21:33:59.109797 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0298392 (* 1 = 0.0298392 loss)
I0822 21:33:59.109807 13823 sgd_solver.cpp:112] Iteration 182100, lr = 1e-06
I0822 21:34:10.828286 13823 solver.cpp:239] Iteration 182200 (8.53351 iter/s, 11.7185s/100 iters), loss = 0.0213379
I0822 21:34:10.828343 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0213374 (* 1 = 0.0213374 loss)
I0822 21:34:10.828356 13823 sgd_solver.cpp:112] Iteration 182200, lr = 1e-06
I0822 21:34:22.556290 13823 solver.cpp:239] Iteration 182300 (8.52663 iter/s, 11.728s/100 iters), loss = 0.0272646
I0822 21:34:22.556352 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0272641 (* 1 = 0.0272641 loss)
I0822 21:34:22.556365 13823 sgd_solver.cpp:112] Iteration 182300, lr = 1e-06
I0822 21:34:34.384704 13823 solver.cpp:239] Iteration 182400 (8.45425 iter/s, 11.8284s/100 iters), loss = 0.0272205
I0822 21:34:34.384757 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.02722 (* 1 = 0.02722 loss)
I0822 21:34:34.384766 13823 sgd_solver.cpp:112] Iteration 182400, lr = 1e-06
I0822 21:34:46.372269 13823 solver.cpp:239] Iteration 182500 (8.342 iter/s, 11.9875s/100 iters), loss = 0.0292853
I0822 21:34:46.372323 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0292849 (* 1 = 0.0292849 loss)
I0822 21:34:46.372334 13823 sgd_solver.cpp:112] Iteration 182500, lr = 1e-06
I0822 21:34:58.328382 13823 solver.cpp:239] Iteration 182600 (8.36395 iter/s, 11.9561s/100 iters), loss = 0.0244483
I0822 21:34:58.328438 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0244478 (* 1 = 0.0244478 loss)
I0822 21:34:58.328447 13823 sgd_solver.cpp:112] Iteration 182600, lr = 1e-06
I0822 21:35:08.068307 13823 solver.cpp:239] Iteration 182700 (10.2671 iter/s, 9.73988s/100 iters), loss = 0.0262446
I0822 21:35:08.068357 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0262442 (* 1 = 0.0262442 loss)
I0822 21:35:08.068367 13823 sgd_solver.cpp:112] Iteration 182700, lr = 1e-06
I0822 21:35:17.572576 13823 solver.cpp:239] Iteration 182800 (10.5216 iter/s, 9.50423s/100 iters), loss = 0.0263602
I0822 21:35:17.572628 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0263597 (* 1 = 0.0263597 loss)
I0822 21:35:17.572638 13823 sgd_solver.cpp:112] Iteration 182800, lr = 1e-06
I0822 21:35:27.542662 13823 solver.cpp:239] Iteration 182900 (10.03 iter/s, 9.97005s/100 iters), loss = 0.027405
I0822 21:35:27.542718 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0274045 (* 1 = 0.0274045 loss)
I0822 21:35:27.542729 13823 sgd_solver.cpp:112] Iteration 182900, lr = 1e-06
I0822 21:35:37.478710 13823 solver.cpp:239] Iteration 183000 (10.0644 iter/s, 9.93601s/100 iters), loss = 0.0278546
I0822 21:35:37.478763 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0278541 (* 1 = 0.0278541 loss)
I0822 21:35:37.478772 13823 sgd_solver.cpp:112] Iteration 183000, lr = 1e-06
I0822 21:35:47.226676 13823 solver.cpp:239] Iteration 183100 (10.2586 iter/s, 9.74793s/100 iters), loss = 0.0233989
I0822 21:35:47.226725 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0233984 (* 1 = 0.0233984 loss)
I0822 21:35:47.226734 13823 sgd_solver.cpp:112] Iteration 183100, lr = 1e-06
I0822 21:35:56.972331 13823 solver.cpp:239] Iteration 183200 (10.261 iter/s, 9.74562s/100 iters), loss = 0.0447055
I0822 21:35:56.972383 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.044705 (* 1 = 0.044705 loss)
I0822 21:35:56.972391 13823 sgd_solver.cpp:112] Iteration 183200, lr = 1e-06
I0822 21:36:06.859831 13823 solver.cpp:239] Iteration 183300 (10.1138 iter/s, 9.88746s/100 iters), loss = 0.0287993
I0822 21:36:06.859882 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0287988 (* 1 = 0.0287988 loss)
I0822 21:36:06.859891 13823 sgd_solver.cpp:112] Iteration 183300, lr = 1e-06
I0822 21:36:16.507593 13823 solver.cpp:239] Iteration 183400 (10.3651 iter/s, 9.64772s/100 iters), loss = 0.025802
I0822 21:36:16.507644 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0258015 (* 1 = 0.0258015 loss)
I0822 21:36:16.507653 13823 sgd_solver.cpp:112] Iteration 183400, lr = 1e-06
I0822 21:36:26.374202 13823 solver.cpp:239] Iteration 183500 (10.1352 iter/s, 9.86657s/100 iters), loss = 0.0265046
I0822 21:36:26.374255 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0265041 (* 1 = 0.0265041 loss)
I0822 21:36:26.374266 13823 sgd_solver.cpp:112] Iteration 183500, lr = 1e-06
I0822 21:36:36.090380 13823 solver.cpp:239] Iteration 183600 (10.2922 iter/s, 9.71614s/100 iters), loss = 0.023057
I0822 21:36:36.090432 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0230565 (* 1 = 0.0230565 loss)
I0822 21:36:36.090441 13823 sgd_solver.cpp:112] Iteration 183600, lr = 1e-06
I0822 21:36:45.693504 13823 solver.cpp:239] Iteration 183700 (10.4133 iter/s, 9.60309s/100 iters), loss = 0.0261693
I0822 21:36:45.693549 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0261688 (* 1 = 0.0261688 loss)
I0822 21:36:45.693578 13823 sgd_solver.cpp:112] Iteration 183700, lr = 1e-06
I0822 21:36:55.283396 13823 solver.cpp:239] Iteration 183800 (10.4277 iter/s, 9.58986s/100 iters), loss = 0.024649
I0822 21:36:55.283448 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0246486 (* 1 = 0.0246486 loss)
I0822 21:36:55.283455 13823 sgd_solver.cpp:112] Iteration 183800, lr = 1e-06
I0822 21:37:05.229401 13823 solver.cpp:239] Iteration 183900 (10.0543 iter/s, 9.94596s/100 iters), loss = 0.03028
I0822 21:37:05.229465 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0302795 (* 1 = 0.0302795 loss)
I0822 21:37:05.229478 13823 sgd_solver.cpp:112] Iteration 183900, lr = 1e-06
I0822 21:37:14.857388 13823 solver.cpp:239] Iteration 184000 (10.3864 iter/s, 9.62794s/100 iters), loss = 0.027298
I0822 21:37:14.857439 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0272975 (* 1 = 0.0272975 loss)
I0822 21:37:14.857448 13823 sgd_solver.cpp:112] Iteration 184000, lr = 1e-06
I0822 21:37:24.934679 13823 solver.cpp:239] Iteration 184100 (9.92334 iter/s, 10.0773s/100 iters), loss = 0.0300353
I0822 21:37:24.934728 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0300348 (* 1 = 0.0300348 loss)
I0822 21:37:24.934738 13823 sgd_solver.cpp:112] Iteration 184100, lr = 1e-06
I0822 21:37:34.817668 13823 solver.cpp:239] Iteration 184200 (10.1184 iter/s, 9.88295s/100 iters), loss = 0.0264677
I0822 21:37:34.817728 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0264672 (* 1 = 0.0264672 loss)
I0822 21:37:34.817739 13823 sgd_solver.cpp:112] Iteration 184200, lr = 1e-06
I0822 21:37:44.518448 13823 solver.cpp:239] Iteration 184300 (10.3085 iter/s, 9.70074s/100 iters), loss = 0.0294356
I0822 21:37:44.518502 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0294351 (* 1 = 0.0294351 loss)
I0822 21:37:44.518512 13823 sgd_solver.cpp:112] Iteration 184300, lr = 1e-06
I0822 21:37:54.132622 13823 solver.cpp:239] Iteration 184400 (10.4014 iter/s, 9.61413s/100 iters), loss = 0.0258568
I0822 21:37:54.132671 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0258563 (* 1 = 0.0258563 loss)
I0822 21:37:54.132681 13823 sgd_solver.cpp:112] Iteration 184400, lr = 1e-06
I0822 21:38:03.888522 13823 solver.cpp:239] Iteration 184500 (10.2502 iter/s, 9.75586s/100 iters), loss = 0.03059
I0822 21:38:03.888573 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0305895 (* 1 = 0.0305895 loss)
I0822 21:38:03.888582 13823 sgd_solver.cpp:112] Iteration 184500, lr = 1e-06
I0822 21:38:13.568018 13823 solver.cpp:239] Iteration 184600 (10.3312 iter/s, 9.67946s/100 iters), loss = 0.0252946
I0822 21:38:13.568066 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0252941 (* 1 = 0.0252941 loss)
I0822 21:38:13.568075 13823 sgd_solver.cpp:112] Iteration 184600, lr = 1e-06
I0822 21:38:23.427755 13823 solver.cpp:239] Iteration 184700 (10.1423 iter/s, 9.8597s/100 iters), loss = 0.0299175
I0822 21:38:23.427808 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.029917 (* 1 = 0.029917 loss)
I0822 21:38:23.427816 13823 sgd_solver.cpp:112] Iteration 184700, lr = 1e-06
I0822 21:38:33.164525 13823 solver.cpp:239] Iteration 184800 (10.2704 iter/s, 9.73673s/100 iters), loss = 0.0258923
I0822 21:38:33.164587 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0258918 (* 1 = 0.0258918 loss)
I0822 21:38:33.164598 13823 sgd_solver.cpp:112] Iteration 184800, lr = 1e-06
I0822 21:38:42.763645 13823 solver.cpp:239] Iteration 184900 (10.4177 iter/s, 9.59907s/100 iters), loss = 0.0274664
I0822 21:38:42.763695 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0274659 (* 1 = 0.0274659 loss)
I0822 21:38:42.763705 13823 sgd_solver.cpp:112] Iteration 184900, lr = 1e-06
I0822 21:38:52.471491 13823 solver.cpp:239] Iteration 185000 (10.301 iter/s, 9.70781s/100 iters), loss = 0.0279196
I0822 21:38:52.471541 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.027919 (* 1 = 0.027919 loss)
I0822 21:38:52.471550 13823 sgd_solver.cpp:112] Iteration 185000, lr = 1e-06
I0822 21:39:02.179579 13823 solver.cpp:239] Iteration 185100 (10.3007 iter/s, 9.70805s/100 iters), loss = 0.0236782
I0822 21:39:02.179630 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0236777 (* 1 = 0.0236777 loss)
I0822 21:39:02.179639 13823 sgd_solver.cpp:112] Iteration 185100, lr = 1e-06
I0822 21:39:12.120108 13823 solver.cpp:239] Iteration 185200 (10.0599 iter/s, 9.94049s/100 iters), loss = 0.0267388
I0822 21:39:12.120174 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0267382 (* 1 = 0.0267382 loss)
I0822 21:39:12.120187 13823 sgd_solver.cpp:112] Iteration 185200, lr = 1e-06
I0822 21:39:22.119036 13823 solver.cpp:239] Iteration 185300 (10.0011 iter/s, 9.99888s/100 iters), loss = 0.037238
I0822 21:39:22.119086 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0372374 (* 1 = 0.0372374 loss)
I0822 21:39:22.119096 13823 sgd_solver.cpp:112] Iteration 185300, lr = 1e-06
I0822 21:39:32.151664 13823 solver.cpp:239] Iteration 185400 (9.96751 iter/s, 10.0326s/100 iters), loss = 0.0262524
I0822 21:39:32.151715 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0262519 (* 1 = 0.0262519 loss)
I0822 21:39:32.151723 13823 sgd_solver.cpp:112] Iteration 185400, lr = 1e-06
I0822 21:39:41.731791 13823 solver.cpp:239] Iteration 185500 (10.4383 iter/s, 9.58009s/100 iters), loss = 0.0240068
I0822 21:39:41.731842 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0240063 (* 1 = 0.0240063 loss)
I0822 21:39:41.731851 13823 sgd_solver.cpp:112] Iteration 185500, lr = 1e-06
I0822 21:39:51.686132 13823 solver.cpp:239] Iteration 185600 (10.0459 iter/s, 9.9543s/100 iters), loss = 0.0299864
I0822 21:39:51.686197 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0299859 (* 1 = 0.0299859 loss)
I0822 21:39:51.686208 13823 sgd_solver.cpp:112] Iteration 185600, lr = 1e-06
I0822 21:40:01.511358 13823 solver.cpp:239] Iteration 185700 (10.1779 iter/s, 9.82518s/100 iters), loss = 0.0257872
I0822 21:40:01.511407 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0257867 (* 1 = 0.0257867 loss)
I0822 21:40:01.511416 13823 sgd_solver.cpp:112] Iteration 185700, lr = 1e-06
I0822 21:40:11.256323 13823 solver.cpp:239] Iteration 185800 (10.2617 iter/s, 9.74493s/100 iters), loss = 0.0283846
I0822 21:40:11.256377 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0283841 (* 1 = 0.0283841 loss)
I0822 21:40:11.256387 13823 sgd_solver.cpp:112] Iteration 185800, lr = 1e-06
I0822 21:40:21.110785 13823 solver.cpp:239] Iteration 185900 (10.1477 iter/s, 9.85442s/100 iters), loss = 0.0251413
I0822 21:40:21.110836 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0251408 (* 1 = 0.0251408 loss)
I0822 21:40:21.110846 13823 sgd_solver.cpp:112] Iteration 185900, lr = 1e-06
I0822 21:40:31.069067 13823 solver.cpp:239] Iteration 186000 (10.0419 iter/s, 9.95825s/100 iters), loss = 0.0236965
I0822 21:40:31.069115 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.023696 (* 1 = 0.023696 loss)
I0822 21:40:31.069125 13823 sgd_solver.cpp:112] Iteration 186000, lr = 1e-06
I0822 21:40:40.613658 13823 solver.cpp:239] Iteration 186100 (10.4772 iter/s, 9.54455s/100 iters), loss = 0.0303191
I0822 21:40:40.613714 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0303186 (* 1 = 0.0303186 loss)
I0822 21:40:40.613725 13823 sgd_solver.cpp:112] Iteration 186100, lr = 1e-06
I0822 21:40:50.699450 13823 solver.cpp:239] Iteration 186200 (9.91498 iter/s, 10.0858s/100 iters), loss = 0.0248258
I0822 21:40:50.699502 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0248253 (* 1 = 0.0248253 loss)
I0822 21:40:50.699512 13823 sgd_solver.cpp:112] Iteration 186200, lr = 1e-06
I0822 21:41:00.357789 13823 solver.cpp:239] Iteration 186300 (10.3538 iter/s, 9.6583s/100 iters), loss = 0.0386401
I0822 21:41:00.357841 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0386396 (* 1 = 0.0386396 loss)
I0822 21:41:00.357851 13823 sgd_solver.cpp:112] Iteration 186300, lr = 1e-06
I0822 21:41:10.134091 13823 solver.cpp:239] Iteration 186400 (10.2289 iter/s, 9.77627s/100 iters), loss = 0.0267589
I0822 21:41:10.134142 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0267584 (* 1 = 0.0267584 loss)
I0822 21:41:10.134151 13823 sgd_solver.cpp:112] Iteration 186400, lr = 1e-06
I0822 21:41:20.002446 13823 solver.cpp:239] Iteration 186500 (10.1334 iter/s, 9.86832s/100 iters), loss = 0.0283131
I0822 21:41:20.002501 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0283126 (* 1 = 0.0283126 loss)
I0822 21:41:20.002512 13823 sgd_solver.cpp:112] Iteration 186500, lr = 1e-06
I0822 21:41:30.119560 13823 solver.cpp:239] Iteration 186600 (9.88428 iter/s, 10.1171s/100 iters), loss = 0.0258669
I0822 21:41:30.119612 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0258664 (* 1 = 0.0258664 loss)
I0822 21:41:30.119621 13823 sgd_solver.cpp:112] Iteration 186600, lr = 1e-06
I0822 21:41:40.387333 13823 solver.cpp:239] Iteration 186700 (9.73924 iter/s, 10.2677s/100 iters), loss = 0.0248014
I0822 21:41:40.387390 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0248009 (* 1 = 0.0248009 loss)
I0822 21:41:40.387401 13823 sgd_solver.cpp:112] Iteration 186700, lr = 1e-06
I0822 21:41:50.079324 13823 solver.cpp:239] Iteration 186800 (10.3178 iter/s, 9.69195s/100 iters), loss = 0.0319263
I0822 21:41:50.079385 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0319258 (* 1 = 0.0319258 loss)
I0822 21:41:50.079397 13823 sgd_solver.cpp:112] Iteration 186800, lr = 1e-06
I0822 21:42:00.144165 13823 solver.cpp:239] Iteration 186900 (9.93562 iter/s, 10.0648s/100 iters), loss = 0.0360777
I0822 21:42:00.144217 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0360772 (* 1 = 0.0360772 loss)
I0822 21:42:00.144227 13823 sgd_solver.cpp:112] Iteration 186900, lr = 1e-06
I0822 21:42:10.245508 13823 solver.cpp:239] Iteration 187000 (9.89971 iter/s, 10.1013s/100 iters), loss = 0.0265167
I0822 21:42:10.245559 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0265162 (* 1 = 0.0265162 loss)
I0822 21:42:10.245569 13823 sgd_solver.cpp:112] Iteration 187000, lr = 1e-06
I0822 21:42:19.859902 13823 solver.cpp:239] Iteration 187100 (10.4011 iter/s, 9.61436s/100 iters), loss = 0.0240557
I0822 21:42:19.859964 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0240552 (* 1 = 0.0240552 loss)
I0822 21:42:19.859977 13823 sgd_solver.cpp:112] Iteration 187100, lr = 1e-06
I0822 21:42:29.958434 13823 solver.cpp:239] Iteration 187200 (9.90247 iter/s, 10.0985s/100 iters), loss = 0.0232375
I0822 21:42:29.958485 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.023237 (* 1 = 0.023237 loss)
I0822 21:42:29.958494 13823 sgd_solver.cpp:112] Iteration 187200, lr = 1e-06
I0822 21:42:39.852038 13823 solver.cpp:239] Iteration 187300 (10.1076 iter/s, 9.89357s/100 iters), loss = 0.0256211
I0822 21:42:39.852088 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0256205 (* 1 = 0.0256205 loss)
I0822 21:42:39.852098 13823 sgd_solver.cpp:112] Iteration 187300, lr = 1e-06
I0822 21:42:49.556727 13823 solver.cpp:239] Iteration 187400 (10.3043 iter/s, 9.70466s/100 iters), loss = 0.0313932
I0822 21:42:49.556778 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0313927 (* 1 = 0.0313927 loss)
I0822 21:42:49.556787 13823 sgd_solver.cpp:112] Iteration 187400, lr = 1e-06
I0822 21:42:59.308594 13823 solver.cpp:239] Iteration 187500 (10.2545 iter/s, 9.75183s/100 iters), loss = 0.0275913
I0822 21:42:59.308642 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0275909 (* 1 = 0.0275909 loss)
I0822 21:42:59.308651 13823 sgd_solver.cpp:112] Iteration 187500, lr = 1e-06
I0822 21:43:08.936337 13823 solver.cpp:239] Iteration 187600 (10.3867 iter/s, 9.62771s/100 iters), loss = 0.025971
I0822 21:43:08.936394 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0259706 (* 1 = 0.0259706 loss)
I0822 21:43:08.936405 13823 sgd_solver.cpp:112] Iteration 187600, lr = 1e-06
I0822 21:43:18.595216 13823 solver.cpp:239] Iteration 187700 (10.3532 iter/s, 9.65884s/100 iters), loss = 0.0236005
I0822 21:43:18.595268 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0236 (* 1 = 0.0236 loss)
I0822 21:43:18.595278 13823 sgd_solver.cpp:112] Iteration 187700, lr = 1e-06
I0822 21:43:28.550915 13823 solver.cpp:239] Iteration 187800 (10.0445 iter/s, 9.95566s/100 iters), loss = 0.0317234
I0822 21:43:28.550964 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0317229 (* 1 = 0.0317229 loss)
I0822 21:43:28.550973 13823 sgd_solver.cpp:112] Iteration 187800, lr = 1e-06
I0822 21:43:38.423017 13823 solver.cpp:239] Iteration 187900 (10.1296 iter/s, 9.87207s/100 iters), loss = 0.029003
I0822 21:43:38.423066 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0290025 (* 1 = 0.0290025 loss)
I0822 21:43:38.423075 13823 sgd_solver.cpp:112] Iteration 187900, lr = 1e-06
I0822 21:43:48.217435 13823 solver.cpp:239] Iteration 188000 (10.2099 iter/s, 9.79439s/100 iters), loss = 0.0264835
I0822 21:43:48.217478 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.026483 (* 1 = 0.026483 loss)
I0822 21:43:48.217484 13823 sgd_solver.cpp:112] Iteration 188000, lr = 1e-06
I0822 21:43:58.094660 13823 solver.cpp:239] Iteration 188100 (10.1243 iter/s, 9.8772s/100 iters), loss = 0.0245199
I0822 21:43:58.094710 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0245194 (* 1 = 0.0245194 loss)
I0822 21:43:58.094720 13823 sgd_solver.cpp:112] Iteration 188100, lr = 1e-06
I0822 21:44:08.219605 13823 solver.cpp:239] Iteration 188200 (9.87663 iter/s, 10.1249s/100 iters), loss = 0.0282544
I0822 21:44:08.219655 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0282539 (* 1 = 0.0282539 loss)
I0822 21:44:08.219664 13823 sgd_solver.cpp:112] Iteration 188200, lr = 1e-06
I0822 21:44:18.122601 13823 solver.cpp:239] Iteration 188300 (10.098 iter/s, 9.90297s/100 iters), loss = 0.0249262
I0822 21:44:18.122644 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0249258 (* 1 = 0.0249258 loss)
I0822 21:44:18.122653 13823 sgd_solver.cpp:112] Iteration 188300, lr = 1e-06
I0822 21:44:28.044426 13823 solver.cpp:239] Iteration 188400 (10.0788 iter/s, 9.9218s/100 iters), loss = 0.0245433
I0822 21:44:28.044478 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0245428 (* 1 = 0.0245428 loss)
I0822 21:44:28.044487 13823 sgd_solver.cpp:112] Iteration 188400, lr = 1e-06
I0822 21:44:38.090836 13823 solver.cpp:239] Iteration 188500 (9.95384 iter/s, 10.0464s/100 iters), loss = 0.0254878
I0822 21:44:38.090891 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0254873 (* 1 = 0.0254873 loss)
I0822 21:44:38.090903 13823 sgd_solver.cpp:112] Iteration 188500, lr = 1e-06
I0822 21:44:48.038218 13823 solver.cpp:239] Iteration 188600 (10.0529 iter/s, 9.94735s/100 iters), loss = 0.0293819
I0822 21:44:48.038259 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0293814 (* 1 = 0.0293814 loss)
I0822 21:44:48.038266 13823 sgd_solver.cpp:112] Iteration 188600, lr = 1e-06
I0822 21:44:57.959316 13823 solver.cpp:239] Iteration 188700 (10.0796 iter/s, 9.92107s/100 iters), loss = 0.0242154
I0822 21:44:57.959364 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0242149 (* 1 = 0.0242149 loss)
I0822 21:44:57.959374 13823 sgd_solver.cpp:112] Iteration 188700, lr = 1e-06
I0822 21:45:07.996459 13823 solver.cpp:239] Iteration 188800 (9.96303 iter/s, 10.0371s/100 iters), loss = 0.0332433
I0822 21:45:07.996511 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0332428 (* 1 = 0.0332428 loss)
I0822 21:45:07.996532 13823 sgd_solver.cpp:112] Iteration 188800, lr = 1e-06
I0822 21:45:18.005336 13823 solver.cpp:239] Iteration 188900 (9.99117 iter/s, 10.0088s/100 iters), loss = 0.0272607
I0822 21:45:18.005385 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0272603 (* 1 = 0.0272603 loss)
I0822 21:45:18.005394 13823 sgd_solver.cpp:112] Iteration 188900, lr = 1e-06
I0822 21:45:28.230602 13823 solver.cpp:239] Iteration 189000 (9.77973 iter/s, 10.2252s/100 iters), loss = 0.0320352
I0822 21:45:28.230651 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0320348 (* 1 = 0.0320348 loss)
I0822 21:45:28.230660 13823 sgd_solver.cpp:112] Iteration 189000, lr = 1e-06
I0822 21:45:38.172325 13823 solver.cpp:239] Iteration 189100 (10.0587 iter/s, 9.94169s/100 iters), loss = 0.0252121
I0822 21:45:38.172374 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0252116 (* 1 = 0.0252116 loss)
I0822 21:45:38.172382 13823 sgd_solver.cpp:112] Iteration 189100, lr = 1e-06
I0822 21:45:48.096745 13823 solver.cpp:239] Iteration 189200 (10.0762 iter/s, 9.92439s/100 iters), loss = 0.0293085
I0822 21:45:48.096799 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.029308 (* 1 = 0.029308 loss)
I0822 21:45:48.096809 13823 sgd_solver.cpp:112] Iteration 189200, lr = 1e-06
I0822 21:45:58.055287 13823 solver.cpp:239] Iteration 189300 (10.0417 iter/s, 9.9585s/100 iters), loss = 0.0315059
I0822 21:45:58.055343 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0315054 (* 1 = 0.0315054 loss)
I0822 21:45:58.055353 13823 sgd_solver.cpp:112] Iteration 189300, lr = 1e-06
I0822 21:46:07.958529 13823 solver.cpp:239] Iteration 189400 (10.0977 iter/s, 9.90321s/100 iters), loss = 0.0258787
I0822 21:46:07.958580 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0258782 (* 1 = 0.0258782 loss)
I0822 21:46:07.958588 13823 sgd_solver.cpp:112] Iteration 189400, lr = 1e-06
I0822 21:46:18.015465 13823 solver.cpp:239] Iteration 189500 (9.94342 iter/s, 10.0569s/100 iters), loss = 0.028877
I0822 21:46:18.015516 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0288765 (* 1 = 0.0288765 loss)
I0822 21:46:18.015527 13823 sgd_solver.cpp:112] Iteration 189500, lr = 1e-06
I0822 21:46:28.173135 13823 solver.cpp:239] Iteration 189600 (9.84481 iter/s, 10.1576s/100 iters), loss = 0.0242274
I0822 21:46:28.173187 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0242269 (* 1 = 0.0242269 loss)
I0822 21:46:28.173197 13823 sgd_solver.cpp:112] Iteration 189600, lr = 1e-06
I0822 21:46:38.405905 13823 solver.cpp:239] Iteration 189700 (9.77256 iter/s, 10.2327s/100 iters), loss = 0.0242096
I0822 21:46:38.405954 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0242091 (* 1 = 0.0242091 loss)
I0822 21:46:38.405964 13823 sgd_solver.cpp:112] Iteration 189700, lr = 1e-06
I0822 21:46:48.707357 13823 solver.cpp:239] Iteration 189800 (9.7074 iter/s, 10.3014s/100 iters), loss = 0.0285961
I0822 21:46:48.707407 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0285956 (* 1 = 0.0285956 loss)
I0822 21:46:48.707417 13823 sgd_solver.cpp:112] Iteration 189800, lr = 1e-06
I0822 21:46:58.828706 13823 solver.cpp:239] Iteration 189900 (9.88014 iter/s, 10.1213s/100 iters), loss = 0.0295994
I0822 21:46:58.828758 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.029599 (* 1 = 0.029599 loss)
I0822 21:46:58.828766 13823 sgd_solver.cpp:112] Iteration 189900, lr = 1e-06
I0822 21:47:09.118893 13823 solver.cpp:239] Iteration 190000 (9.71803 iter/s, 10.2902s/100 iters), loss = 0.0206418
I0822 21:47:09.118942 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0206413 (* 1 = 0.0206413 loss)
I0822 21:47:09.118952 13823 sgd_solver.cpp:112] Iteration 190000, lr = 1e-06
I0822 21:47:18.994935 13823 solver.cpp:239] Iteration 190100 (10.1255 iter/s, 9.87601s/100 iters), loss = 0.0263642
I0822 21:47:18.994985 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0263637 (* 1 = 0.0263637 loss)
I0822 21:47:18.994995 13823 sgd_solver.cpp:112] Iteration 190100, lr = 1e-06
I0822 21:47:29.215077 13823 solver.cpp:239] Iteration 190200 (9.78463 iter/s, 10.2201s/100 iters), loss = 0.0283202
I0822 21:47:29.215127 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0283197 (* 1 = 0.0283197 loss)
I0822 21:47:29.215137 13823 sgd_solver.cpp:112] Iteration 190200, lr = 1e-06
I0822 21:47:39.399880 13823 solver.cpp:239] Iteration 190300 (9.81858 iter/s, 10.1848s/100 iters), loss = 0.0251119
I0822 21:47:39.399930 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0251115 (* 1 = 0.0251115 loss)
I0822 21:47:39.399940 13823 sgd_solver.cpp:112] Iteration 190300, lr = 1e-06
I0822 21:47:49.677215 13823 solver.cpp:239] Iteration 190400 (9.73018 iter/s, 10.2773s/100 iters), loss = 0.0283212
I0822 21:47:49.677264 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0283207 (* 1 = 0.0283207 loss)
I0822 21:47:49.677273 13823 sgd_solver.cpp:112] Iteration 190400, lr = 1e-06
I0822 21:47:59.971750 13823 solver.cpp:239] Iteration 190500 (9.71392 iter/s, 10.2945s/100 iters), loss = 0.0342294
I0822 21:47:59.971802 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0342289 (* 1 = 0.0342289 loss)
I0822 21:47:59.971812 13823 sgd_solver.cpp:112] Iteration 190500, lr = 1e-06
I0822 21:48:10.455876 13823 solver.cpp:239] Iteration 190600 (9.53826 iter/s, 10.4841s/100 iters), loss = 0.0298832
I0822 21:48:10.455925 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0298827 (* 1 = 0.0298827 loss)
I0822 21:48:10.455935 13823 sgd_solver.cpp:112] Iteration 190600, lr = 1e-06
I0822 21:48:20.819356 13823 solver.cpp:239] Iteration 190700 (9.6493 iter/s, 10.3634s/100 iters), loss = 0.0340029
I0822 21:48:20.819412 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0340025 (* 1 = 0.0340025 loss)
I0822 21:48:20.819422 13823 sgd_solver.cpp:112] Iteration 190700, lr = 1e-06
I0822 21:48:31.348004 13823 solver.cpp:239] Iteration 190800 (9.49793 iter/s, 10.5286s/100 iters), loss = 0.0274921
I0822 21:48:31.348062 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0274916 (* 1 = 0.0274916 loss)
I0822 21:48:31.348073 13823 sgd_solver.cpp:112] Iteration 190800, lr = 1e-06
I0822 21:48:41.458936 13823 solver.cpp:239] Iteration 190900 (9.89032 iter/s, 10.1109s/100 iters), loss = 0.0302633
I0822 21:48:41.458992 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0302628 (* 1 = 0.0302628 loss)
I0822 21:48:41.459002 13823 sgd_solver.cpp:112] Iteration 190900, lr = 1e-06
I0822 21:48:51.777734 13823 solver.cpp:239] Iteration 191000 (9.69108 iter/s, 10.3188s/100 iters), loss = 0.0261985
I0822 21:48:51.777786 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.026198 (* 1 = 0.026198 loss)
I0822 21:48:51.777796 13823 sgd_solver.cpp:112] Iteration 191000, lr = 1e-06
I0822 21:49:02.396167 13823 solver.cpp:239] Iteration 191100 (9.41762 iter/s, 10.6184s/100 iters), loss = 0.024322
I0822 21:49:02.396242 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0243215 (* 1 = 0.0243215 loss)
I0822 21:49:02.396255 13823 sgd_solver.cpp:112] Iteration 191100, lr = 1e-06
I0822 21:49:12.670709 13823 solver.cpp:239] Iteration 191200 (9.73284 iter/s, 10.2745s/100 iters), loss = 0.0299098
I0822 21:49:12.670760 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0299093 (* 1 = 0.0299093 loss)
I0822 21:49:12.670769 13823 sgd_solver.cpp:112] Iteration 191200, lr = 1e-06
I0822 21:49:22.943089 13823 solver.cpp:239] Iteration 191300 (9.73487 iter/s, 10.2723s/100 iters), loss = 0.0306012
I0822 21:49:22.943138 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0306007 (* 1 = 0.0306007 loss)
I0822 21:49:22.943148 13823 sgd_solver.cpp:112] Iteration 191300, lr = 1e-06
I0822 21:49:33.255501 13823 solver.cpp:239] Iteration 191400 (9.69708 iter/s, 10.3124s/100 iters), loss = 0.0263112
I0822 21:49:33.255558 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0263108 (* 1 = 0.0263108 loss)
I0822 21:49:33.255569 13823 sgd_solver.cpp:112] Iteration 191400, lr = 1e-06
I0822 21:49:43.840675 13823 solver.cpp:239] Iteration 191500 (9.44721 iter/s, 10.5851s/100 iters), loss = 0.0325203
I0822 21:49:43.840734 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0325198 (* 1 = 0.0325198 loss)
I0822 21:49:43.840744 13823 sgd_solver.cpp:112] Iteration 191500, lr = 1e-06
I0822 21:49:54.487217 13823 solver.cpp:239] Iteration 191600 (9.39275 iter/s, 10.6465s/100 iters), loss = 0.0268955
I0822 21:49:54.487267 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.026895 (* 1 = 0.026895 loss)
I0822 21:49:54.487277 13823 sgd_solver.cpp:112] Iteration 191600, lr = 1e-06
I0822 21:50:05.259230 13823 solver.cpp:239] Iteration 191700 (9.28334 iter/s, 10.772s/100 iters), loss = 0.0264532
I0822 21:50:05.259280 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0264528 (* 1 = 0.0264528 loss)
I0822 21:50:05.259289 13823 sgd_solver.cpp:112] Iteration 191700, lr = 1e-06
I0822 21:50:15.879535 13823 solver.cpp:239] Iteration 191800 (9.41595 iter/s, 10.6203s/100 iters), loss = 0.0285065
I0822 21:50:15.879588 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.028506 (* 1 = 0.028506 loss)
I0822 21:50:15.879598 13823 sgd_solver.cpp:112] Iteration 191800, lr = 1e-06
I0822 21:50:26.545305 13823 solver.cpp:239] Iteration 191900 (9.37582 iter/s, 10.6657s/100 iters), loss = 0.0242953
I0822 21:50:26.545357 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0242948 (* 1 = 0.0242948 loss)
I0822 21:50:26.545367 13823 sgd_solver.cpp:112] Iteration 191900, lr = 1e-06
I0822 21:50:37.239107 13823 solver.cpp:239] Iteration 192000 (9.35124 iter/s, 10.6938s/100 iters), loss = 0.0277553
I0822 21:50:37.239158 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0277549 (* 1 = 0.0277549 loss)
I0822 21:50:37.239168 13823 sgd_solver.cpp:112] Iteration 192000, lr = 1e-06
I0822 21:50:47.665391 13823 solver.cpp:239] Iteration 192100 (9.59117 iter/s, 10.4263s/100 iters), loss = 0.0251546
I0822 21:50:47.665439 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0251541 (* 1 = 0.0251541 loss)
I0822 21:50:47.665448 13823 sgd_solver.cpp:112] Iteration 192100, lr = 1e-06
I0822 21:50:57.975975 13823 solver.cpp:239] Iteration 192200 (9.6988 iter/s, 10.3106s/100 iters), loss = 0.0247877
I0822 21:50:57.976037 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0247872 (* 1 = 0.0247872 loss)
I0822 21:50:57.976049 13823 sgd_solver.cpp:112] Iteration 192200, lr = 1e-06
I0822 21:51:08.350718 13823 solver.cpp:239] Iteration 192300 (9.63883 iter/s, 10.3747s/100 iters), loss = 0.0294614
I0822 21:51:08.350769 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0294609 (* 1 = 0.0294609 loss)
I0822 21:51:08.350780 13823 sgd_solver.cpp:112] Iteration 192300, lr = 1e-06
I0822 21:51:18.573444 13823 solver.cpp:239] Iteration 192400 (9.78216 iter/s, 10.2227s/100 iters), loss = 0.0244085
I0822 21:51:18.573496 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0244081 (* 1 = 0.0244081 loss)
I0822 21:51:18.573506 13823 sgd_solver.cpp:112] Iteration 192400, lr = 1e-06
I0822 21:51:29.178192 13823 solver.cpp:239] Iteration 192500 (9.42977 iter/s, 10.6047s/100 iters), loss = 0.0395722
I0822 21:51:29.178246 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0395717 (* 1 = 0.0395717 loss)
I0822 21:51:29.178256 13823 sgd_solver.cpp:112] Iteration 192500, lr = 1e-06
I0822 21:51:39.721825 13823 solver.cpp:239] Iteration 192600 (9.48443 iter/s, 10.5436s/100 iters), loss = 0.0370396
I0822 21:51:39.721877 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0370391 (* 1 = 0.0370391 loss)
I0822 21:51:39.721886 13823 sgd_solver.cpp:112] Iteration 192600, lr = 1e-06
I0822 21:51:50.298100 13823 solver.cpp:239] Iteration 192700 (9.45515 iter/s, 10.5762s/100 iters), loss = 0.0265482
I0822 21:51:50.298151 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0265478 (* 1 = 0.0265478 loss)
I0822 21:51:50.298159 13823 sgd_solver.cpp:112] Iteration 192700, lr = 1e-06
I0822 21:52:00.907413 13823 solver.cpp:239] Iteration 192800 (9.42571 iter/s, 10.6093s/100 iters), loss = 0.0335354
I0822 21:52:00.907464 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0335349 (* 1 = 0.0335349 loss)
I0822 21:52:00.907472 13823 sgd_solver.cpp:112] Iteration 192800, lr = 1e-06
I0822 21:52:11.659719 13823 solver.cpp:239] Iteration 192900 (9.30036 iter/s, 10.7523s/100 iters), loss = 0.0249615
I0822 21:52:11.659772 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0249611 (* 1 = 0.0249611 loss)
I0822 21:52:11.659781 13823 sgd_solver.cpp:112] Iteration 192900, lr = 1e-06
I0822 21:52:22.196856 13823 solver.cpp:239] Iteration 193000 (9.49028 iter/s, 10.5371s/100 iters), loss = 0.0255181
I0822 21:52:22.196919 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0255176 (* 1 = 0.0255176 loss)
I0822 21:52:22.196931 13823 sgd_solver.cpp:112] Iteration 193000, lr = 1e-06
I0822 21:52:32.967419 13823 solver.cpp:239] Iteration 193100 (9.2846 iter/s, 10.7705s/100 iters), loss = 0.0269742
I0822 21:52:32.967474 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0269737 (* 1 = 0.0269737 loss)
I0822 21:52:32.967485 13823 sgd_solver.cpp:112] Iteration 193100, lr = 1e-06
I0822 21:52:43.555950 13823 solver.cpp:239] Iteration 193200 (9.44421 iter/s, 10.5885s/100 iters), loss = 0.0393051
I0822 21:52:43.555999 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0393047 (* 1 = 0.0393047 loss)
I0822 21:52:43.556008 13823 sgd_solver.cpp:112] Iteration 193200, lr = 1e-06
I0822 21:52:54.252044 13823 solver.cpp:239] Iteration 193300 (9.34924 iter/s, 10.6961s/100 iters), loss = 0.0299329
I0822 21:52:54.252104 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0299325 (* 1 = 0.0299325 loss)
I0822 21:52:54.252115 13823 sgd_solver.cpp:112] Iteration 193300, lr = 1e-06
I0822 21:53:04.814105 13823 solver.cpp:239] Iteration 193400 (9.46789 iter/s, 10.562s/100 iters), loss = 0.0371771
I0822 21:53:04.814162 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0371767 (* 1 = 0.0371767 loss)
I0822 21:53:04.814172 13823 sgd_solver.cpp:112] Iteration 193400, lr = 1e-06
I0822 21:53:15.215579 13823 solver.cpp:239] Iteration 193500 (9.61405 iter/s, 10.4014s/100 iters), loss = 0.0264863
I0822 21:53:15.215629 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0264859 (* 1 = 0.0264859 loss)
I0822 21:53:15.215638 13823 sgd_solver.cpp:112] Iteration 193500, lr = 1e-06
I0822 21:53:25.887138 13823 solver.cpp:239] Iteration 193600 (9.37073 iter/s, 10.6715s/100 iters), loss = 0.0245304
I0822 21:53:25.887189 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0245299 (* 1 = 0.0245299 loss)
I0822 21:53:25.887198 13823 sgd_solver.cpp:112] Iteration 193600, lr = 1e-06
I0822 21:53:36.559367 13823 solver.cpp:239] Iteration 193700 (9.37014 iter/s, 10.6722s/100 iters), loss = 0.0343191
I0822 21:53:36.559417 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0343187 (* 1 = 0.0343187 loss)
I0822 21:53:36.559427 13823 sgd_solver.cpp:112] Iteration 193700, lr = 1e-06
I0822 21:53:47.136183 13823 solver.cpp:239] Iteration 193800 (9.45467 iter/s, 10.5768s/100 iters), loss = 0.0253438
I0822 21:53:47.136235 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0253433 (* 1 = 0.0253433 loss)
I0822 21:53:47.136245 13823 sgd_solver.cpp:112] Iteration 193800, lr = 1e-06
I0822 21:53:57.918013 13823 solver.cpp:239] Iteration 193900 (9.27489 iter/s, 10.7818s/100 iters), loss = 0.0274889
I0822 21:53:57.918071 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0274885 (* 1 = 0.0274885 loss)
I0822 21:53:57.918081 13823 sgd_solver.cpp:112] Iteration 193900, lr = 1e-06
I0822 21:54:08.679250 13823 solver.cpp:239] Iteration 194000 (9.29264 iter/s, 10.7612s/100 iters), loss = 0.0279676
I0822 21:54:08.679311 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0279671 (* 1 = 0.0279671 loss)
I0822 21:54:08.679322 13823 sgd_solver.cpp:112] Iteration 194000, lr = 1e-06
I0822 21:54:19.670480 13823 solver.cpp:239] Iteration 194100 (9.09819 iter/s, 10.9912s/100 iters), loss = 0.0249457
I0822 21:54:19.670529 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0249453 (* 1 = 0.0249453 loss)
I0822 21:54:19.670538 13823 sgd_solver.cpp:112] Iteration 194100, lr = 1e-06
I0822 21:54:30.377465 13823 solver.cpp:239] Iteration 194200 (9.33972 iter/s, 10.707s/100 iters), loss = 0.0284194
I0822 21:54:30.377516 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.028419 (* 1 = 0.028419 loss)
I0822 21:54:30.377526 13823 sgd_solver.cpp:112] Iteration 194200, lr = 1e-06
I0822 21:54:41.254360 13823 solver.cpp:239] Iteration 194300 (9.19382 iter/s, 10.8769s/100 iters), loss = 0.0290442
I0822 21:54:41.254411 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0290438 (* 1 = 0.0290438 loss)
I0822 21:54:41.254421 13823 sgd_solver.cpp:112] Iteration 194300, lr = 1e-06
I0822 21:54:52.066078 13823 solver.cpp:239] Iteration 194400 (9.24925 iter/s, 10.8117s/100 iters), loss = 0.0272585
I0822 21:54:52.066128 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0272581 (* 1 = 0.0272581 loss)
I0822 21:54:52.066138 13823 sgd_solver.cpp:112] Iteration 194400, lr = 1e-06
I0822 21:55:02.321411 13823 solver.cpp:239] Iteration 194500 (9.75105 iter/s, 10.2553s/100 iters), loss = 0.0258802
I0822 21:55:02.321461 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0258798 (* 1 = 0.0258798 loss)
I0822 21:55:02.321471 13823 sgd_solver.cpp:112] Iteration 194500, lr = 1e-06
I0822 21:55:12.906983 13823 solver.cpp:239] Iteration 194600 (9.44685 iter/s, 10.5855s/100 iters), loss = 0.0270949
I0822 21:55:12.907038 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0270944 (* 1 = 0.0270944 loss)
I0822 21:55:12.907049 13823 sgd_solver.cpp:112] Iteration 194600, lr = 1e-06
I0822 21:55:23.535874 13823 solver.cpp:239] Iteration 194700 (9.40835 iter/s, 10.6289s/100 iters), loss = 0.0252774
I0822 21:55:23.535923 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.025277 (* 1 = 0.025277 loss)
I0822 21:55:23.535933 13823 sgd_solver.cpp:112] Iteration 194700, lr = 1e-06
I0822 21:55:34.687872 13823 solver.cpp:239] Iteration 194800 (8.96703 iter/s, 11.152s/100 iters), loss = 0.0294588
I0822 21:55:34.687933 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0294584 (* 1 = 0.0294584 loss)
I0822 21:55:34.687945 13823 sgd_solver.cpp:112] Iteration 194800, lr = 1e-06
I0822 21:55:45.628870 13823 solver.cpp:239] Iteration 194900 (9.13997 iter/s, 10.941s/100 iters), loss = 0.027528
I0822 21:55:45.628927 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0275275 (* 1 = 0.0275275 loss)
I0822 21:55:45.628938 13823 sgd_solver.cpp:112] Iteration 194900, lr = 1e-06
I0822 21:55:56.664727 13823 solver.cpp:239] Iteration 195000 (9.0614 iter/s, 11.0358s/100 iters), loss = 0.0226005
I0822 21:55:56.664777 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0226001 (* 1 = 0.0226001 loss)
I0822 21:55:56.664786 13823 sgd_solver.cpp:112] Iteration 195000, lr = 1e-06
I0822 21:56:07.892422 13823 solver.cpp:239] Iteration 195100 (8.90657 iter/s, 11.2277s/100 iters), loss = 0.0275235
I0822 21:56:07.892472 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0275231 (* 1 = 0.0275231 loss)
I0822 21:56:07.892480 13823 sgd_solver.cpp:112] Iteration 195100, lr = 1e-06
I0822 21:56:18.681006 13823 solver.cpp:239] Iteration 195200 (9.26908 iter/s, 10.7886s/100 iters), loss = 0.0265058
I0822 21:56:18.681058 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0265054 (* 1 = 0.0265054 loss)
I0822 21:56:18.681068 13823 sgd_solver.cpp:112] Iteration 195200, lr = 1e-06
I0822 21:56:29.594846 13823 solver.cpp:239] Iteration 195300 (9.16271 iter/s, 10.9138s/100 iters), loss = 0.023175
I0822 21:56:29.594907 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0231746 (* 1 = 0.0231746 loss)
I0822 21:56:29.594919 13823 sgd_solver.cpp:112] Iteration 195300, lr = 1e-06
I0822 21:56:40.500432 13823 solver.cpp:239] Iteration 195400 (9.16965 iter/s, 10.9055s/100 iters), loss = 0.0258699
I0822 21:56:40.500490 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0258695 (* 1 = 0.0258695 loss)
I0822 21:56:40.500501 13823 sgd_solver.cpp:112] Iteration 195400, lr = 1e-06
I0822 21:56:51.335085 13823 solver.cpp:239] Iteration 195500 (9.22967 iter/s, 10.8346s/100 iters), loss = 0.0300619
I0822 21:56:51.335136 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0300614 (* 1 = 0.0300614 loss)
I0822 21:56:51.335146 13823 sgd_solver.cpp:112] Iteration 195500, lr = 1e-06
I0822 21:57:02.346935 13823 solver.cpp:239] Iteration 195600 (9.08115 iter/s, 11.0118s/100 iters), loss = 0.0259255
I0822 21:57:02.346982 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0259251 (* 1 = 0.0259251 loss)
I0822 21:57:02.346992 13823 sgd_solver.cpp:112] Iteration 195600, lr = 1e-06
I0822 21:57:13.022079 13823 solver.cpp:239] Iteration 195700 (9.36758 iter/s, 10.6751s/100 iters), loss = 0.0298306
I0822 21:57:13.022140 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0298302 (* 1 = 0.0298302 loss)
I0822 21:57:13.022151 13823 sgd_solver.cpp:112] Iteration 195700, lr = 1e-06
I0822 21:57:24.057698 13823 solver.cpp:239] Iteration 195800 (9.0616 iter/s, 11.0356s/100 iters), loss = 0.0272323
I0822 21:57:24.057750 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0272319 (* 1 = 0.0272319 loss)
I0822 21:57:24.057760 13823 sgd_solver.cpp:112] Iteration 195800, lr = 1e-06
I0822 21:57:34.890964 13823 solver.cpp:239] Iteration 195900 (9.23085 iter/s, 10.8332s/100 iters), loss = 0.0270835
I0822 21:57:34.891014 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0270831 (* 1 = 0.0270831 loss)
I0822 21:57:34.891023 13823 sgd_solver.cpp:112] Iteration 195900, lr = 1e-06
I0822 21:57:45.739069 13823 solver.cpp:239] Iteration 196000 (9.21822 iter/s, 10.8481s/100 iters), loss = 0.0219182
I0822 21:57:45.739122 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0219178 (* 1 = 0.0219178 loss)
I0822 21:57:45.739131 13823 sgd_solver.cpp:112] Iteration 196000, lr = 1e-06
I0822 21:57:57.020931 13823 solver.cpp:239] Iteration 196100 (8.86381 iter/s, 11.2818s/100 iters), loss = 0.0286125
I0822 21:57:57.020987 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0286121 (* 1 = 0.0286121 loss)
I0822 21:57:57.020999 13823 sgd_solver.cpp:112] Iteration 196100, lr = 1e-06
I0822 21:58:08.130275 13823 solver.cpp:239] Iteration 196200 (9.00146 iter/s, 11.1093s/100 iters), loss = 0.020887
I0822 21:58:08.130327 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0208866 (* 1 = 0.0208866 loss)
I0822 21:58:08.130336 13823 sgd_solver.cpp:112] Iteration 196200, lr = 1e-06
I0822 21:58:18.946074 13823 solver.cpp:239] Iteration 196300 (9.24576 iter/s, 10.8158s/100 iters), loss = 0.0297687
I0822 21:58:18.946125 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0297682 (* 1 = 0.0297682 loss)
I0822 21:58:18.946135 13823 sgd_solver.cpp:112] Iteration 196300, lr = 1e-06
I0822 21:58:30.053880 13823 solver.cpp:239] Iteration 196400 (9.0027 iter/s, 11.1078s/100 iters), loss = 0.0284189
I0822 21:58:30.053931 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0284185 (* 1 = 0.0284185 loss)
I0822 21:58:30.053941 13823 sgd_solver.cpp:112] Iteration 196400, lr = 1e-06
I0822 21:58:41.117467 13823 solver.cpp:239] Iteration 196500 (9.03868 iter/s, 11.0636s/100 iters), loss = 0.0371249
I0822 21:58:41.117524 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0371245 (* 1 = 0.0371245 loss)
I0822 21:58:41.117537 13823 sgd_solver.cpp:112] Iteration 196500, lr = 1e-06
I0822 21:58:52.200372 13823 solver.cpp:239] Iteration 196600 (9.02293 iter/s, 11.0829s/100 iters), loss = 0.0338223
I0822 21:58:52.200423 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0338219 (* 1 = 0.0338219 loss)
I0822 21:58:52.200433 13823 sgd_solver.cpp:112] Iteration 196600, lr = 1e-06
I0822 21:59:03.279723 13823 solver.cpp:239] Iteration 196700 (9.02582 iter/s, 11.0793s/100 iters), loss = 0.0242896
I0822 21:59:03.279772 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0242892 (* 1 = 0.0242892 loss)
I0822 21:59:03.279783 13823 sgd_solver.cpp:112] Iteration 196700, lr = 1e-06
I0822 21:59:13.978950 13823 solver.cpp:239] Iteration 196800 (9.34649 iter/s, 10.6992s/100 iters), loss = 0.0300699
I0822 21:59:13.978999 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0300695 (* 1 = 0.0300695 loss)
I0822 21:59:13.979008 13823 sgd_solver.cpp:112] Iteration 196800, lr = 1e-06
I0822 21:59:25.014514 13823 solver.cpp:239] Iteration 196900 (9.06163 iter/s, 11.0355s/100 iters), loss = 0.0369333
I0822 21:59:25.014569 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0369329 (* 1 = 0.0369329 loss)
I0822 21:59:25.014578 13823 sgd_solver.cpp:112] Iteration 196900, lr = 1e-06
I0822 21:59:35.709385 13823 solver.cpp:239] Iteration 197000 (9.3503 iter/s, 10.6948s/100 iters), loss = 0.0251881
I0822 21:59:35.709429 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0251877 (* 1 = 0.0251877 loss)
I0822 21:59:35.709437 13823 sgd_solver.cpp:112] Iteration 197000, lr = 1e-06
I0822 21:59:46.392179 13823 solver.cpp:239] Iteration 197100 (9.36087 iter/s, 10.6828s/100 iters), loss = 0.0276067
I0822 21:59:46.392230 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0276063 (* 1 = 0.0276063 loss)
I0822 21:59:46.392240 13823 sgd_solver.cpp:112] Iteration 197100, lr = 1e-06
I0822 21:59:57.433920 13823 solver.cpp:239] Iteration 197200 (9.05657 iter/s, 11.0417s/100 iters), loss = 0.0256244
I0822 21:59:57.433971 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.025624 (* 1 = 0.025624 loss)
I0822 21:59:57.433981 13823 sgd_solver.cpp:112] Iteration 197200, lr = 1e-06
I0822 22:00:08.732898 13823 solver.cpp:239] Iteration 197300 (8.85038 iter/s, 11.2989s/100 iters), loss = 0.0353225
I0822 22:00:08.732951 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0353221 (* 1 = 0.0353221 loss)
I0822 22:00:08.732961 13823 sgd_solver.cpp:112] Iteration 197300, lr = 1e-06
I0822 22:00:19.768471 13823 solver.cpp:239] Iteration 197400 (9.06163 iter/s, 11.0355s/100 iters), loss = 0.0286473
I0822 22:00:19.768523 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0286469 (* 1 = 0.0286469 loss)
I0822 22:00:19.768532 13823 sgd_solver.cpp:112] Iteration 197400, lr = 1e-06
I0822 22:00:31.002055 13823 solver.cpp:239] Iteration 197500 (8.9019 iter/s, 11.2336s/100 iters), loss = 0.0302895
I0822 22:00:31.002106 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0302891 (* 1 = 0.0302891 loss)
I0822 22:00:31.002116 13823 sgd_solver.cpp:112] Iteration 197500, lr = 1e-06
I0822 22:00:42.309962 13823 solver.cpp:239] Iteration 197600 (8.84339 iter/s, 11.3079s/100 iters), loss = 0.0279539
I0822 22:00:42.310019 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0279535 (* 1 = 0.0279535 loss)
I0822 22:00:42.310030 13823 sgd_solver.cpp:112] Iteration 197600, lr = 1e-06
I0822 22:00:53.514216 13823 solver.cpp:239] Iteration 197700 (8.92521 iter/s, 11.2042s/100 iters), loss = 0.028929
I0822 22:00:53.514276 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0289286 (* 1 = 0.0289286 loss)
I0822 22:00:53.514286 13823 sgd_solver.cpp:112] Iteration 197700, lr = 1e-06
I0822 22:01:04.693912 13823 solver.cpp:239] Iteration 197800 (8.94482 iter/s, 11.1797s/100 iters), loss = 0.0276897
I0822 22:01:04.693977 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0276893 (* 1 = 0.0276893 loss)
I0822 22:01:04.693991 13823 sgd_solver.cpp:112] Iteration 197800, lr = 1e-06
I0822 22:01:16.123296 13823 solver.cpp:239] Iteration 197900 (8.74941 iter/s, 11.4293s/100 iters), loss = 0.023677
I0822 22:01:16.123358 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0236765 (* 1 = 0.0236765 loss)
I0822 22:01:16.123370 13823 sgd_solver.cpp:112] Iteration 197900, lr = 1e-06
I0822 22:01:27.426512 13823 solver.cpp:239] Iteration 198000 (8.84707 iter/s, 11.3032s/100 iters), loss = 0.0273722
I0822 22:01:27.426569 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0273718 (* 1 = 0.0273718 loss)
I0822 22:01:27.426580 13823 sgd_solver.cpp:112] Iteration 198000, lr = 1e-06
I0822 22:01:38.757714 13823 solver.cpp:239] Iteration 198100 (8.82521 iter/s, 11.3312s/100 iters), loss = 0.0332606
I0822 22:01:38.757763 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0332602 (* 1 = 0.0332602 loss)
I0822 22:01:38.757772 13823 sgd_solver.cpp:112] Iteration 198100, lr = 1e-06
I0822 22:01:50.201252 13823 solver.cpp:239] Iteration 198200 (8.73858 iter/s, 11.4435s/100 iters), loss = 0.0268169
I0822 22:01:50.201310 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0268165 (* 1 = 0.0268165 loss)
I0822 22:01:50.201321 13823 sgd_solver.cpp:112] Iteration 198200, lr = 1e-06
I0822 22:02:01.503408 13823 solver.cpp:239] Iteration 198300 (8.8479 iter/s, 11.3021s/100 iters), loss = 0.023373
I0822 22:02:01.503468 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0233725 (* 1 = 0.0233725 loss)
I0822 22:02:01.503479 13823 sgd_solver.cpp:112] Iteration 198300, lr = 1e-06
I0822 22:02:12.905565 13823 solver.cpp:239] Iteration 198400 (8.7703 iter/s, 11.4021s/100 iters), loss = 0.025379
I0822 22:02:12.905627 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0253786 (* 1 = 0.0253786 loss)
I0822 22:02:12.905640 13823 sgd_solver.cpp:112] Iteration 198400, lr = 1e-06
I0822 22:02:24.516829 13823 solver.cpp:239] Iteration 198500 (8.61235 iter/s, 11.6112s/100 iters), loss = 0.031243
I0822 22:02:24.516880 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0312426 (* 1 = 0.0312426 loss)
I0822 22:02:24.516891 13823 sgd_solver.cpp:112] Iteration 198500, lr = 1e-06
I0822 22:02:35.875861 13823 solver.cpp:239] Iteration 198600 (8.80359 iter/s, 11.359s/100 iters), loss = 0.0232303
I0822 22:02:35.875918 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0232299 (* 1 = 0.0232299 loss)
I0822 22:02:35.875929 13823 sgd_solver.cpp:112] Iteration 198600, lr = 1e-06
I0822 22:02:47.250553 13823 solver.cpp:239] Iteration 198700 (8.79147 iter/s, 11.3747s/100 iters), loss = 0.028067
I0822 22:02:47.250612 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0280666 (* 1 = 0.0280666 loss)
I0822 22:02:47.250623 13823 sgd_solver.cpp:112] Iteration 198700, lr = 1e-06
I0822 22:02:58.642544 13823 solver.cpp:239] Iteration 198800 (8.77812 iter/s, 11.392s/100 iters), loss = 0.0264507
I0822 22:02:58.642602 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0264503 (* 1 = 0.0264503 loss)
I0822 22:02:58.642613 13823 sgd_solver.cpp:112] Iteration 198800, lr = 1e-06
I0822 22:03:09.985604 13823 solver.cpp:239] Iteration 198900 (8.81599 iter/s, 11.343s/100 iters), loss = 0.0444611
I0822 22:03:09.985668 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0444607 (* 1 = 0.0444607 loss)
I0822 22:03:09.985682 13823 sgd_solver.cpp:112] Iteration 198900, lr = 1e-06
I0822 22:03:21.715770 13823 solver.cpp:239] Iteration 199000 (8.52506 iter/s, 11.7301s/100 iters), loss = 0.0313943
I0822 22:03:21.715831 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0313938 (* 1 = 0.0313938 loss)
I0822 22:03:21.715842 13823 sgd_solver.cpp:112] Iteration 199000, lr = 1e-06
I0822 22:03:33.035076 13823 solver.cpp:239] Iteration 199100 (8.83449 iter/s, 11.3193s/100 iters), loss = 0.0287625
I0822 22:03:33.035127 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0287621 (* 1 = 0.0287621 loss)
I0822 22:03:33.035136 13823 sgd_solver.cpp:112] Iteration 199100, lr = 1e-06
I0822 22:03:44.707288 13823 solver.cpp:239] Iteration 199200 (8.56738 iter/s, 11.6722s/100 iters), loss = 0.0257664
I0822 22:03:44.707347 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.025766 (* 1 = 0.025766 loss)
I0822 22:03:44.707358 13823 sgd_solver.cpp:112] Iteration 199200, lr = 1e-06
I0822 22:03:56.303159 13823 solver.cpp:239] Iteration 199300 (8.62378 iter/s, 11.5958s/100 iters), loss = 0.0278871
I0822 22:03:56.303221 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0278867 (* 1 = 0.0278867 loss)
I0822 22:03:56.303233 13823 sgd_solver.cpp:112] Iteration 199300, lr = 1e-06
I0822 22:04:07.776057 13823 solver.cpp:239] Iteration 199400 (8.71622 iter/s, 11.4729s/100 iters), loss = 0.0267253
I0822 22:04:07.776108 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0267249 (* 1 = 0.0267249 loss)
I0822 22:04:07.776118 13823 sgd_solver.cpp:112] Iteration 199400, lr = 1e-06
I0822 22:04:19.183929 13823 solver.cpp:239] Iteration 199500 (8.7659 iter/s, 11.4078s/100 iters), loss = 0.024688
I0822 22:04:19.183976 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0246876 (* 1 = 0.0246876 loss)
I0822 22:04:19.183986 13823 sgd_solver.cpp:112] Iteration 199500, lr = 1e-06
I0822 22:04:30.701362 13823 solver.cpp:239] Iteration 199600 (8.68251 iter/s, 11.5174s/100 iters), loss = 0.0274956
I0822 22:04:30.701414 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0274952 (* 1 = 0.0274952 loss)
I0822 22:04:30.701423 13823 sgd_solver.cpp:112] Iteration 199600, lr = 1e-06
I0822 22:04:42.136148 13823 solver.cpp:239] Iteration 199700 (8.74526 iter/s, 11.4348s/100 iters), loss = 0.0318075
I0822 22:04:42.136199 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0318071 (* 1 = 0.0318071 loss)
I0822 22:04:42.136209 13823 sgd_solver.cpp:112] Iteration 199700, lr = 1e-06
I0822 22:04:53.402606 13823 solver.cpp:239] Iteration 199800 (8.87593 iter/s, 11.2664s/100 iters), loss = 0.0270558
I0822 22:04:53.402660 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0270554 (* 1 = 0.0270554 loss)
I0822 22:04:53.402670 13823 sgd_solver.cpp:112] Iteration 199800, lr = 1e-06
I0822 22:05:04.820387 13823 solver.cpp:239] Iteration 199900 (8.75829 iter/s, 11.4178s/100 iters), loss = 0.0273431
I0822 22:05:04.820438 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0273427 (* 1 = 0.0273427 loss)
I0822 22:05:04.820448 13823 sgd_solver.cpp:112] Iteration 199900, lr = 1e-06
I0822 22:05:16.302358 13823 solver.cpp:464] Snapshotting to binary proto file ./model_112/cascade_mobilenet_112_iter_200000.caffemodel
I0822 22:05:16.351336 13823 sgd_solver.cpp:284] Snapshotting solver state to binary proto file ./model_112/cascade_mobilenet_112_iter_200000.solverstate
I0822 22:05:16.382810 13823 solver.cpp:347] Iteration 200000, Testing net (#0)
I0822 22:06:16.739711 13823 solver.cpp:414]     Test net output #0: landmark_loss = 0.0219465 (* 1 = 0.0219465 loss)
I0822 22:06:16.861990 13823 solver.cpp:239] Iteration 200000 (1.38808 iter/s, 72.0418s/100 iters), loss = 0.0273528
I0822 22:06:16.862043 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0273523 (* 1 = 0.0273523 loss)
I0822 22:06:16.862056 13823 sgd_solver.cpp:112] Iteration 200000, lr = 1e-06
I0822 22:06:28.531494 13823 solver.cpp:239] Iteration 200100 (8.56936 iter/s, 11.6695s/100 iters), loss = 0.0255462
I0822 22:06:28.531555 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0255458 (* 1 = 0.0255458 loss)
I0822 22:06:28.531566 13823 sgd_solver.cpp:112] Iteration 200100, lr = 1e-06
I0822 22:06:40.139619 13823 solver.cpp:239] Iteration 200200 (8.61468 iter/s, 11.6081s/100 iters), loss = 0.0413679
I0822 22:06:40.139678 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0413675 (* 1 = 0.0413675 loss)
I0822 22:06:40.139688 13823 sgd_solver.cpp:112] Iteration 200200, lr = 1e-06
I0822 22:06:51.968585 13823 solver.cpp:239] Iteration 200300 (8.45384 iter/s, 11.8289s/100 iters), loss = 0.0261339
I0822 22:06:51.968642 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0261335 (* 1 = 0.0261335 loss)
I0822 22:06:51.968652 13823 sgd_solver.cpp:112] Iteration 200300, lr = 1e-06
I0822 22:07:03.499743 13823 solver.cpp:239] Iteration 200400 (8.67218 iter/s, 11.5311s/100 iters), loss = 0.0242797
I0822 22:07:03.499804 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0242793 (* 1 = 0.0242793 loss)
I0822 22:07:03.499815 13823 sgd_solver.cpp:112] Iteration 200400, lr = 1e-06
I0822 22:07:15.308806 13823 solver.cpp:239] Iteration 200500 (8.46809 iter/s, 11.809s/100 iters), loss = 0.0280027
I0822 22:07:15.308866 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0280022 (* 1 = 0.0280022 loss)
I0822 22:07:15.308877 13823 sgd_solver.cpp:112] Iteration 200500, lr = 1e-06
I0822 22:07:26.945349 13823 solver.cpp:239] Iteration 200600 (8.59364 iter/s, 11.6365s/100 iters), loss = 0.0297427
I0822 22:07:26.945402 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0297423 (* 1 = 0.0297423 loss)
I0822 22:07:26.945412 13823 sgd_solver.cpp:112] Iteration 200600, lr = 1e-06
I0822 22:07:38.753360 13823 solver.cpp:239] Iteration 200700 (8.46884 iter/s, 11.808s/100 iters), loss = 0.0312327
I0822 22:07:38.753417 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0312323 (* 1 = 0.0312323 loss)
I0822 22:07:38.753427 13823 sgd_solver.cpp:112] Iteration 200700, lr = 1e-06
I0822 22:07:50.380681 13823 solver.cpp:239] Iteration 200800 (8.60045 iter/s, 11.6273s/100 iters), loss = 0.0290961
I0822 22:07:50.380730 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0290956 (* 1 = 0.0290956 loss)
I0822 22:07:50.380739 13823 sgd_solver.cpp:112] Iteration 200800, lr = 1e-06
I0822 22:08:01.388643 13823 solver.cpp:239] Iteration 200900 (9.08435 iter/s, 11.0079s/100 iters), loss = 0.0278701
I0822 22:08:01.388695 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0278697 (* 1 = 0.0278697 loss)
I0822 22:08:01.388703 13823 sgd_solver.cpp:112] Iteration 200900, lr = 1e-06
I0822 22:08:11.135102 13823 solver.cpp:239] Iteration 201000 (10.2602 iter/s, 9.74643s/100 iters), loss = 0.0251491
I0822 22:08:11.135154 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0251487 (* 1 = 0.0251487 loss)
I0822 22:08:11.135162 13823 sgd_solver.cpp:112] Iteration 201000, lr = 1e-06
I0822 22:08:20.930373 13823 solver.cpp:239] Iteration 201100 (10.209 iter/s, 9.79524s/100 iters), loss = 0.0287852
I0822 22:08:20.930425 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0287847 (* 1 = 0.0287847 loss)
I0822 22:08:20.930434 13823 sgd_solver.cpp:112] Iteration 201100, lr = 1e-06
I0822 22:08:30.839848 13823 solver.cpp:239] Iteration 201200 (10.0914 iter/s, 9.90945s/100 iters), loss = 0.0279805
I0822 22:08:30.839898 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.02798 (* 1 = 0.02798 loss)
I0822 22:08:30.839908 13823 sgd_solver.cpp:112] Iteration 201200, lr = 1e-06
I0822 22:08:40.391748 13823 solver.cpp:239] Iteration 201300 (10.4692 iter/s, 9.55187s/100 iters), loss = 0.0388135
I0822 22:08:40.391796 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0388131 (* 1 = 0.0388131 loss)
I0822 22:08:40.391805 13823 sgd_solver.cpp:112] Iteration 201300, lr = 1e-06
I0822 22:08:50.075517 13823 solver.cpp:239] Iteration 201400 (10.3266 iter/s, 9.68374s/100 iters), loss = 0.0277163
I0822 22:08:50.075567 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0277159 (* 1 = 0.0277159 loss)
I0822 22:08:50.075577 13823 sgd_solver.cpp:112] Iteration 201400, lr = 1e-06
I0822 22:08:59.670647 13823 solver.cpp:239] Iteration 201500 (10.422 iter/s, 9.59511s/100 iters), loss = 0.0341572
I0822 22:08:59.670688 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0341568 (* 1 = 0.0341568 loss)
I0822 22:08:59.670696 13823 sgd_solver.cpp:112] Iteration 201500, lr = 1e-06
I0822 22:09:09.399144 13823 solver.cpp:239] Iteration 201600 (10.2791 iter/s, 9.72848s/100 iters), loss = 0.0291716
I0822 22:09:09.399195 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0291712 (* 1 = 0.0291712 loss)
I0822 22:09:09.399204 13823 sgd_solver.cpp:112] Iteration 201600, lr = 1e-06
I0822 22:09:19.216115 13823 solver.cpp:239] Iteration 201700 (10.1865 iter/s, 9.81694s/100 iters), loss = 0.0349473
I0822 22:09:19.216167 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0349469 (* 1 = 0.0349469 loss)
I0822 22:09:19.216176 13823 sgd_solver.cpp:112] Iteration 201700, lr = 1e-06
I0822 22:09:29.020102 13823 solver.cpp:239] Iteration 201800 (10.2 iter/s, 9.80395s/100 iters), loss = 0.0257444
I0822 22:09:29.020155 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0257439 (* 1 = 0.0257439 loss)
I0822 22:09:29.020165 13823 sgd_solver.cpp:112] Iteration 201800, lr = 1e-06
I0822 22:09:38.841578 13823 solver.cpp:239] Iteration 201900 (10.1818 iter/s, 9.82145s/100 iters), loss = 0.0276146
I0822 22:09:38.841629 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0276142 (* 1 = 0.0276142 loss)
I0822 22:09:38.841639 13823 sgd_solver.cpp:112] Iteration 201900, lr = 1e-06
I0822 22:09:48.717238 13823 solver.cpp:239] Iteration 202000 (10.1259 iter/s, 9.87563s/100 iters), loss = 0.0275172
I0822 22:09:48.717306 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0275168 (* 1 = 0.0275168 loss)
I0822 22:09:48.717319 13823 sgd_solver.cpp:112] Iteration 202000, lr = 1e-06
I0822 22:09:58.575835 13823 solver.cpp:239] Iteration 202100 (10.1435 iter/s, 9.85855s/100 iters), loss = 0.025073
I0822 22:09:58.575883 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0250725 (* 1 = 0.0250725 loss)
I0822 22:09:58.575892 13823 sgd_solver.cpp:112] Iteration 202100, lr = 1e-06
I0822 22:10:08.439616 13823 solver.cpp:239] Iteration 202200 (10.1381 iter/s, 9.86376s/100 iters), loss = 0.0300239
I0822 22:10:08.439659 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0300235 (* 1 = 0.0300235 loss)
I0822 22:10:08.439666 13823 sgd_solver.cpp:112] Iteration 202200, lr = 1e-06
I0822 22:10:18.232398 13823 solver.cpp:239] Iteration 202300 (10.2116 iter/s, 9.79276s/100 iters), loss = 0.0247887
I0822 22:10:18.232450 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0247882 (* 1 = 0.0247882 loss)
I0822 22:10:18.232458 13823 sgd_solver.cpp:112] Iteration 202300, lr = 1e-06
I0822 22:10:27.661317 13823 solver.cpp:239] Iteration 202400 (10.6057 iter/s, 9.42889s/100 iters), loss = 0.0263619
I0822 22:10:27.661358 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0263614 (* 1 = 0.0263614 loss)
I0822 22:10:27.661365 13823 sgd_solver.cpp:112] Iteration 202400, lr = 1e-06
I0822 22:10:37.376092 13823 solver.cpp:239] Iteration 202500 (10.2936 iter/s, 9.71475s/100 iters), loss = 0.0256646
I0822 22:10:37.376147 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0256642 (* 1 = 0.0256642 loss)
I0822 22:10:37.376157 13823 sgd_solver.cpp:112] Iteration 202500, lr = 1e-06
I0822 22:10:46.878427 13823 solver.cpp:239] Iteration 202600 (10.5238 iter/s, 9.50231s/100 iters), loss = 0.0371481
I0822 22:10:46.878468 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0371477 (* 1 = 0.0371477 loss)
I0822 22:10:46.878476 13823 sgd_solver.cpp:112] Iteration 202600, lr = 1e-06
I0822 22:10:56.703446 13823 solver.cpp:239] Iteration 202700 (10.1781 iter/s, 9.825s/100 iters), loss = 0.0336376
I0822 22:10:56.703496 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0336372 (* 1 = 0.0336372 loss)
I0822 22:10:56.703505 13823 sgd_solver.cpp:112] Iteration 202700, lr = 1e-06
I0822 22:11:06.203811 13823 solver.cpp:239] Iteration 202800 (10.5259 iter/s, 9.50034s/100 iters), loss = 0.0248048
I0822 22:11:06.203860 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0248044 (* 1 = 0.0248044 loss)
I0822 22:11:06.203869 13823 sgd_solver.cpp:112] Iteration 202800, lr = 1e-06
I0822 22:11:16.131741 13823 solver.cpp:239] Iteration 202900 (10.0726 iter/s, 9.9279s/100 iters), loss = 0.0253022
I0822 22:11:16.131793 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0253018 (* 1 = 0.0253018 loss)
I0822 22:11:16.131801 13823 sgd_solver.cpp:112] Iteration 202900, lr = 1e-06
I0822 22:11:25.852375 13823 solver.cpp:239] Iteration 203000 (10.2874 iter/s, 9.7206s/100 iters), loss = 0.0257948
I0822 22:11:25.852425 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0257944 (* 1 = 0.0257944 loss)
I0822 22:11:25.852434 13823 sgd_solver.cpp:112] Iteration 203000, lr = 1e-06
I0822 22:11:35.407490 13823 solver.cpp:239] Iteration 203100 (10.4656 iter/s, 9.55509s/100 iters), loss = 0.0295609
I0822 22:11:35.407543 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0295605 (* 1 = 0.0295605 loss)
I0822 22:11:35.407552 13823 sgd_solver.cpp:112] Iteration 203100, lr = 1e-06
I0822 22:11:45.165422 13823 solver.cpp:239] Iteration 203200 (10.2481 iter/s, 9.7579s/100 iters), loss = 0.0277788
I0822 22:11:45.165472 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0277784 (* 1 = 0.0277784 loss)
I0822 22:11:45.165480 13823 sgd_solver.cpp:112] Iteration 203200, lr = 1e-06
I0822 22:11:54.854815 13823 solver.cpp:239] Iteration 203300 (10.3206 iter/s, 9.68936s/100 iters), loss = 0.0295601
I0822 22:11:54.854866 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0295596 (* 1 = 0.0295596 loss)
I0822 22:11:54.854876 13823 sgd_solver.cpp:112] Iteration 203300, lr = 1e-06
I0822 22:12:04.849686 13823 solver.cpp:239] Iteration 203400 (10.0052 iter/s, 9.99484s/100 iters), loss = 0.0260361
I0822 22:12:04.849740 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0260356 (* 1 = 0.0260356 loss)
I0822 22:12:04.849750 13823 sgd_solver.cpp:112] Iteration 203400, lr = 1e-06
I0822 22:12:14.367238 13823 solver.cpp:239] Iteration 203500 (10.5069 iter/s, 9.51752s/100 iters), loss = 0.0285307
I0822 22:12:14.367280 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0285302 (* 1 = 0.0285302 loss)
I0822 22:12:14.367286 13823 sgd_solver.cpp:112] Iteration 203500, lr = 1e-06
I0822 22:12:24.003109 13823 solver.cpp:239] Iteration 203600 (10.3779 iter/s, 9.63585s/100 iters), loss = 0.0266064
I0822 22:12:24.003159 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.026606 (* 1 = 0.026606 loss)
I0822 22:12:24.003167 13823 sgd_solver.cpp:112] Iteration 203600, lr = 1e-06
I0822 22:12:33.433804 13823 solver.cpp:239] Iteration 203700 (10.6037 iter/s, 9.43067s/100 iters), loss = 0.0277371
I0822 22:12:33.433854 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0277366 (* 1 = 0.0277366 loss)
I0822 22:12:33.433863 13823 sgd_solver.cpp:112] Iteration 203700, lr = 1e-06
I0822 22:12:43.053072 13823 solver.cpp:239] Iteration 203800 (10.3958 iter/s, 9.61924s/100 iters), loss = 0.0252059
I0822 22:12:43.053125 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0252054 (* 1 = 0.0252054 loss)
I0822 22:12:43.053133 13823 sgd_solver.cpp:112] Iteration 203800, lr = 1e-06
I0822 22:12:53.004673 13823 solver.cpp:239] Iteration 203900 (10.0487 iter/s, 9.95157s/100 iters), loss = 0.0286707
I0822 22:12:53.004722 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0286703 (* 1 = 0.0286703 loss)
I0822 22:12:53.004731 13823 sgd_solver.cpp:112] Iteration 203900, lr = 1e-06
I0822 22:13:02.797991 13823 solver.cpp:239] Iteration 204000 (10.2111 iter/s, 9.79329s/100 iters), loss = 0.0327199
I0822 22:13:02.798043 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0327194 (* 1 = 0.0327194 loss)
I0822 22:13:02.798053 13823 sgd_solver.cpp:112] Iteration 204000, lr = 1e-06
I0822 22:13:12.655690 13823 solver.cpp:239] Iteration 204100 (10.1444 iter/s, 9.85767s/100 iters), loss = 0.0243864
I0822 22:13:12.655747 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0243859 (* 1 = 0.0243859 loss)
I0822 22:13:12.655758 13823 sgd_solver.cpp:112] Iteration 204100, lr = 1e-06
I0822 22:13:22.599334 13823 solver.cpp:239] Iteration 204200 (10.0567 iter/s, 9.94361s/100 iters), loss = 0.0250202
I0822 22:13:22.599388 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0250197 (* 1 = 0.0250197 loss)
I0822 22:13:22.599398 13823 sgd_solver.cpp:112] Iteration 204200, lr = 1e-06
I0822 22:13:32.456269 13823 solver.cpp:239] Iteration 204300 (10.1452 iter/s, 9.8569s/100 iters), loss = 0.0245639
I0822 22:13:32.456317 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0245634 (* 1 = 0.0245634 loss)
I0822 22:13:32.456326 13823 sgd_solver.cpp:112] Iteration 204300, lr = 1e-06
I0822 22:13:42.306030 13823 solver.cpp:239] Iteration 204400 (10.1526 iter/s, 9.84973s/100 iters), loss = 0.0252252
I0822 22:13:42.306082 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0252247 (* 1 = 0.0252247 loss)
I0822 22:13:42.306090 13823 sgd_solver.cpp:112] Iteration 204400, lr = 1e-06
I0822 22:13:52.156261 13823 solver.cpp:239] Iteration 204500 (10.1521 iter/s, 9.8502s/100 iters), loss = 0.02632
I0822 22:13:52.156312 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0263195 (* 1 = 0.0263195 loss)
I0822 22:13:52.156322 13823 sgd_solver.cpp:112] Iteration 204500, lr = 1e-06
I0822 22:14:01.846771 13823 solver.cpp:239] Iteration 204600 (10.3194 iter/s, 9.69048s/100 iters), loss = 0.0308493
I0822 22:14:01.846823 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0308488 (* 1 = 0.0308488 loss)
I0822 22:14:01.846833 13823 sgd_solver.cpp:112] Iteration 204600, lr = 1e-06
I0822 22:14:11.680789 13823 solver.cpp:239] Iteration 204700 (10.1688 iter/s, 9.83399s/100 iters), loss = 0.0284978
I0822 22:14:11.680847 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0284974 (* 1 = 0.0284974 loss)
I0822 22:14:11.680860 13823 sgd_solver.cpp:112] Iteration 204700, lr = 1e-06
I0822 22:14:21.548583 13823 solver.cpp:239] Iteration 204800 (10.134 iter/s, 9.86776s/100 iters), loss = 0.0230826
I0822 22:14:21.548635 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0230821 (* 1 = 0.0230821 loss)
I0822 22:14:21.548645 13823 sgd_solver.cpp:112] Iteration 204800, lr = 1e-06
I0822 22:14:31.418432 13823 solver.cpp:239] Iteration 204900 (10.1319 iter/s, 9.86982s/100 iters), loss = 0.023515
I0822 22:14:31.418483 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0235146 (* 1 = 0.0235146 loss)
I0822 22:14:31.418491 13823 sgd_solver.cpp:112] Iteration 204900, lr = 1e-06
I0822 22:14:41.373440 13823 solver.cpp:239] Iteration 205000 (10.0452 iter/s, 9.95498s/100 iters), loss = 0.0251209
I0822 22:14:41.373490 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0251204 (* 1 = 0.0251204 loss)
I0822 22:14:41.373499 13823 sgd_solver.cpp:112] Iteration 205000, lr = 1e-06
I0822 22:14:51.322891 13823 solver.cpp:239] Iteration 205100 (10.0508 iter/s, 9.94942s/100 iters), loss = 0.0256641
I0822 22:14:51.322948 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0256637 (* 1 = 0.0256637 loss)
I0822 22:14:51.322958 13823 sgd_solver.cpp:112] Iteration 205100, lr = 1e-06
I0822 22:15:01.490341 13823 solver.cpp:239] Iteration 205200 (9.83534 iter/s, 10.1674s/100 iters), loss = 0.0303097
I0822 22:15:01.490406 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0303093 (* 1 = 0.0303093 loss)
I0822 22:15:01.490418 13823 sgd_solver.cpp:112] Iteration 205200, lr = 1e-06
I0822 22:15:11.371419 13823 solver.cpp:239] Iteration 205300 (10.1204 iter/s, 9.88103s/100 iters), loss = 0.0259675
I0822 22:15:11.371469 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0259671 (* 1 = 0.0259671 loss)
I0822 22:15:11.371479 13823 sgd_solver.cpp:112] Iteration 205300, lr = 1e-06
I0822 22:15:21.301718 13823 solver.cpp:239] Iteration 205400 (10.0702 iter/s, 9.93027s/100 iters), loss = 0.0286116
I0822 22:15:21.301769 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0286111 (* 1 = 0.0286111 loss)
I0822 22:15:21.301777 13823 sgd_solver.cpp:112] Iteration 205400, lr = 1e-06
I0822 22:15:30.981307 13823 solver.cpp:239] Iteration 205500 (10.331 iter/s, 9.67956s/100 iters), loss = 0.0238807
I0822 22:15:30.981359 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0238802 (* 1 = 0.0238802 loss)
I0822 22:15:30.981369 13823 sgd_solver.cpp:112] Iteration 205500, lr = 1e-06
I0822 22:15:41.139719 13823 solver.cpp:239] Iteration 205600 (9.84409 iter/s, 10.1584s/100 iters), loss = 0.0250309
I0822 22:15:41.139770 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0250304 (* 1 = 0.0250304 loss)
I0822 22:15:41.139780 13823 sgd_solver.cpp:112] Iteration 205600, lr = 1e-06
I0822 22:15:51.002540 13823 solver.cpp:239] Iteration 205700 (10.1391 iter/s, 9.86279s/100 iters), loss = 0.0237254
I0822 22:15:51.002591 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.023725 (* 1 = 0.023725 loss)
I0822 22:15:51.002600 13823 sgd_solver.cpp:112] Iteration 205700, lr = 1e-06
I0822 22:16:01.093092 13823 solver.cpp:239] Iteration 205800 (9.91029 iter/s, 10.0905s/100 iters), loss = 0.0334463
I0822 22:16:01.093145 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0334458 (* 1 = 0.0334458 loss)
I0822 22:16:01.093155 13823 sgd_solver.cpp:112] Iteration 205800, lr = 1e-06
I0822 22:16:10.958662 13823 solver.cpp:239] Iteration 205900 (10.1363 iter/s, 9.86554s/100 iters), loss = 0.0289021
I0822 22:16:10.958714 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0289016 (* 1 = 0.0289016 loss)
I0822 22:16:10.958724 13823 sgd_solver.cpp:112] Iteration 205900, lr = 1e-06
I0822 22:16:21.061836 13823 solver.cpp:239] Iteration 206000 (9.89791 iter/s, 10.1031s/100 iters), loss = 0.0232161
I0822 22:16:21.061887 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0232157 (* 1 = 0.0232157 loss)
I0822 22:16:21.061895 13823 sgd_solver.cpp:112] Iteration 206000, lr = 1e-06
I0822 22:16:30.781996 13823 solver.cpp:239] Iteration 206100 (10.2879 iter/s, 9.72013s/100 iters), loss = 0.0241784
I0822 22:16:30.782047 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0241779 (* 1 = 0.0241779 loss)
I0822 22:16:30.782058 13823 sgd_solver.cpp:112] Iteration 206100, lr = 1e-06
I0822 22:16:40.398793 13823 solver.cpp:239] Iteration 206200 (10.3985 iter/s, 9.61677s/100 iters), loss = 0.0238622
I0822 22:16:40.398833 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0238618 (* 1 = 0.0238618 loss)
I0822 22:16:40.398841 13823 sgd_solver.cpp:112] Iteration 206200, lr = 1e-06
I0822 22:16:50.207578 13823 solver.cpp:239] Iteration 206300 (10.195 iter/s, 9.80876s/100 iters), loss = 0.024881
I0822 22:16:50.207628 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0248806 (* 1 = 0.0248806 loss)
I0822 22:16:50.207638 13823 sgd_solver.cpp:112] Iteration 206300, lr = 1e-06
I0822 22:17:00.451120 13823 solver.cpp:239] Iteration 206400 (9.76228 iter/s, 10.2435s/100 iters), loss = 0.0258633
I0822 22:17:00.451174 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0258628 (* 1 = 0.0258628 loss)
I0822 22:17:00.451184 13823 sgd_solver.cpp:112] Iteration 206400, lr = 1e-06
I0822 22:17:10.401000 13823 solver.cpp:239] Iteration 206500 (10.0504 iter/s, 9.94985s/100 iters), loss = 0.0223133
I0822 22:17:10.401049 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0223129 (* 1 = 0.0223129 loss)
I0822 22:17:10.401059 13823 sgd_solver.cpp:112] Iteration 206500, lr = 1e-06
I0822 22:17:20.499819 13823 solver.cpp:239] Iteration 206600 (9.90218 iter/s, 10.0988s/100 iters), loss = 0.0278162
I0822 22:17:20.499869 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0278157 (* 1 = 0.0278157 loss)
I0822 22:17:20.499878 13823 sgd_solver.cpp:112] Iteration 206600, lr = 1e-06
I0822 22:17:30.673907 13823 solver.cpp:239] Iteration 206700 (9.82892 iter/s, 10.1741s/100 iters), loss = 0.0261795
I0822 22:17:30.673960 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0261791 (* 1 = 0.0261791 loss)
I0822 22:17:30.673970 13823 sgd_solver.cpp:112] Iteration 206700, lr = 1e-06
I0822 22:17:40.876240 13823 solver.cpp:239] Iteration 206800 (9.80171 iter/s, 10.2023s/100 iters), loss = 0.0247861
I0822 22:17:40.876291 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0247857 (* 1 = 0.0247857 loss)
I0822 22:17:40.876302 13823 sgd_solver.cpp:112] Iteration 206800, lr = 1e-06
I0822 22:17:51.063926 13823 solver.cpp:239] Iteration 206900 (9.8158 iter/s, 10.1877s/100 iters), loss = 0.0232494
I0822 22:17:51.063977 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0232489 (* 1 = 0.0232489 loss)
I0822 22:17:51.063985 13823 sgd_solver.cpp:112] Iteration 206900, lr = 1e-06
I0822 22:18:01.148195 13823 solver.cpp:239] Iteration 207000 (9.91646 iter/s, 10.0842s/100 iters), loss = 0.0324087
I0822 22:18:01.148247 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0324083 (* 1 = 0.0324083 loss)
I0822 22:18:01.148255 13823 sgd_solver.cpp:112] Iteration 207000, lr = 1e-06
I0822 22:18:11.222332 13823 solver.cpp:239] Iteration 207100 (9.92644 iter/s, 10.0741s/100 iters), loss = 0.0240943
I0822 22:18:11.222383 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0240938 (* 1 = 0.0240938 loss)
I0822 22:18:11.222393 13823 sgd_solver.cpp:112] Iteration 207100, lr = 1e-06
I0822 22:18:21.279685 13823 solver.cpp:239] Iteration 207200 (9.94301 iter/s, 10.0573s/100 iters), loss = 0.027369
I0822 22:18:21.279734 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0273686 (* 1 = 0.0273686 loss)
I0822 22:18:21.279744 13823 sgd_solver.cpp:112] Iteration 207200, lr = 1e-06
I0822 22:18:31.190742 13823 solver.cpp:239] Iteration 207300 (10.0895 iter/s, 9.91129s/100 iters), loss = 0.025284
I0822 22:18:31.190783 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0252836 (* 1 = 0.0252836 loss)
I0822 22:18:31.190791 13823 sgd_solver.cpp:112] Iteration 207300, lr = 1e-06
I0822 22:18:41.286952 13823 solver.cpp:239] Iteration 207400 (9.90432 iter/s, 10.0966s/100 iters), loss = 0.027023
I0822 22:18:41.287001 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0270226 (* 1 = 0.0270226 loss)
I0822 22:18:41.287009 13823 sgd_solver.cpp:112] Iteration 207400, lr = 1e-06
I0822 22:18:51.188884 13823 solver.cpp:239] Iteration 207500 (10.0987 iter/s, 9.90231s/100 iters), loss = 0.0267454
I0822 22:18:51.188935 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.026745 (* 1 = 0.026745 loss)
I0822 22:18:51.188943 13823 sgd_solver.cpp:112] Iteration 207500, lr = 1e-06
I0822 22:19:01.130578 13823 solver.cpp:239] Iteration 207600 (10.0583 iter/s, 9.94207s/100 iters), loss = 0.0284609
I0822 22:19:01.130620 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0284604 (* 1 = 0.0284604 loss)
I0822 22:19:01.130627 13823 sgd_solver.cpp:112] Iteration 207600, lr = 1e-06
I0822 22:19:11.252039 13823 solver.cpp:239] Iteration 207700 (9.87962 iter/s, 10.1218s/100 iters), loss = 0.023373
I0822 22:19:11.252081 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0233725 (* 1 = 0.0233725 loss)
I0822 22:19:11.252089 13823 sgd_solver.cpp:112] Iteration 207700, lr = 1e-06
I0822 22:19:21.244280 13823 solver.cpp:239] Iteration 207800 (10.0074 iter/s, 9.99261s/100 iters), loss = 0.0285975
I0822 22:19:21.244331 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.028597 (* 1 = 0.028597 loss)
I0822 22:19:21.244340 13823 sgd_solver.cpp:112] Iteration 207800, lr = 1e-06
I0822 22:19:31.287474 13823 solver.cpp:239] Iteration 207900 (9.95665 iter/s, 10.0435s/100 iters), loss = 0.0264472
I0822 22:19:31.287528 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0264467 (* 1 = 0.0264467 loss)
I0822 22:19:31.287536 13823 sgd_solver.cpp:112] Iteration 207900, lr = 1e-06
I0822 22:19:41.234344 13823 solver.cpp:239] Iteration 208000 (10.0531 iter/s, 9.94721s/100 iters), loss = 0.0283167
I0822 22:19:41.234385 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0283163 (* 1 = 0.0283163 loss)
I0822 22:19:41.234392 13823 sgd_solver.cpp:112] Iteration 208000, lr = 1e-06
I0822 22:19:51.121219 13823 solver.cpp:239] Iteration 208100 (10.1141 iter/s, 9.88722s/100 iters), loss = 0.023465
I0822 22:19:51.121268 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0234646 (* 1 = 0.0234646 loss)
I0822 22:19:51.121276 13823 sgd_solver.cpp:112] Iteration 208100, lr = 1e-06
I0822 22:20:01.157068 13823 solver.cpp:239] Iteration 208200 (9.96395 iter/s, 10.0362s/100 iters), loss = 0.0250415
I0822 22:20:01.157132 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.025041 (* 1 = 0.025041 loss)
I0822 22:20:01.157145 13823 sgd_solver.cpp:112] Iteration 208200, lr = 1e-06
I0822 22:20:11.191604 13823 solver.cpp:239] Iteration 208300 (9.96527 iter/s, 10.0349s/100 iters), loss = 0.023683
I0822 22:20:11.191654 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0236825 (* 1 = 0.0236825 loss)
I0822 22:20:11.191664 13823 sgd_solver.cpp:112] Iteration 208300, lr = 1e-06
I0822 22:20:21.169448 13823 solver.cpp:239] Iteration 208400 (10.0219 iter/s, 9.97816s/100 iters), loss = 0.0329164
I0822 22:20:21.169497 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.032916 (* 1 = 0.032916 loss)
I0822 22:20:21.169507 13823 sgd_solver.cpp:112] Iteration 208400, lr = 1e-06
I0822 22:20:31.394834 13823 solver.cpp:239] Iteration 208500 (9.77927 iter/s, 10.2257s/100 iters), loss = 0.0255109
I0822 22:20:31.394884 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0255104 (* 1 = 0.0255104 loss)
I0822 22:20:31.394893 13823 sgd_solver.cpp:112] Iteration 208500, lr = 1e-06
I0822 22:20:41.682683 13823 solver.cpp:239] Iteration 208600 (9.7199 iter/s, 10.2882s/100 iters), loss = 0.0302119
I0822 22:20:41.682734 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0302114 (* 1 = 0.0302114 loss)
I0822 22:20:41.682744 13823 sgd_solver.cpp:112] Iteration 208600, lr = 1e-06
I0822 22:20:51.862021 13823 solver.cpp:239] Iteration 208700 (9.82352 iter/s, 10.1796s/100 iters), loss = 0.024912
I0822 22:20:51.862071 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0249115 (* 1 = 0.0249115 loss)
I0822 22:20:51.862082 13823 sgd_solver.cpp:112] Iteration 208700, lr = 1e-06
I0822 22:21:01.992753 13823 solver.cpp:239] Iteration 208800 (9.87066 iter/s, 10.131s/100 iters), loss = 0.0264932
I0822 22:21:01.992803 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0264927 (* 1 = 0.0264927 loss)
I0822 22:21:01.992813 13823 sgd_solver.cpp:112] Iteration 208800, lr = 1e-06
I0822 22:21:12.251392 13823 solver.cpp:239] Iteration 208900 (9.74759 iter/s, 10.2589s/100 iters), loss = 0.0257619
I0822 22:21:12.251447 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0257614 (* 1 = 0.0257614 loss)
I0822 22:21:12.251458 13823 sgd_solver.cpp:112] Iteration 208900, lr = 1e-06
I0822 22:21:22.608809 13823 solver.cpp:239] Iteration 209000 (9.65464 iter/s, 10.3577s/100 iters), loss = 0.0225178
I0822 22:21:22.608860 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0225173 (* 1 = 0.0225173 loss)
I0822 22:21:22.608870 13823 sgd_solver.cpp:112] Iteration 209000, lr = 1e-06
I0822 22:21:33.151660 13823 solver.cpp:239] Iteration 209100 (9.48483 iter/s, 10.5432s/100 iters), loss = 0.0255027
I0822 22:21:33.151710 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0255023 (* 1 = 0.0255023 loss)
I0822 22:21:33.151720 13823 sgd_solver.cpp:112] Iteration 209100, lr = 1e-06
I0822 22:21:43.628811 13823 solver.cpp:239] Iteration 209200 (9.54431 iter/s, 10.4774s/100 iters), loss = 0.0350971
I0822 22:21:43.628862 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0350966 (* 1 = 0.0350966 loss)
I0822 22:21:43.628872 13823 sgd_solver.cpp:112] Iteration 209200, lr = 1e-06
I0822 22:21:54.040402 13823 solver.cpp:239] Iteration 209300 (9.60442 iter/s, 10.4119s/100 iters), loss = 0.026605
I0822 22:21:54.040453 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0266046 (* 1 = 0.0266046 loss)
I0822 22:21:54.040463 13823 sgd_solver.cpp:112] Iteration 209300, lr = 1e-06
I0822 22:22:04.374924 13823 solver.cpp:239] Iteration 209400 (9.67605 iter/s, 10.3348s/100 iters), loss = 0.0277672
I0822 22:22:04.374975 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0277668 (* 1 = 0.0277668 loss)
I0822 22:22:04.374984 13823 sgd_solver.cpp:112] Iteration 209400, lr = 1e-06
I0822 22:22:14.646699 13823 solver.cpp:239] Iteration 209500 (9.73516 iter/s, 10.272s/100 iters), loss = 0.0282178
I0822 22:22:14.646749 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0282174 (* 1 = 0.0282174 loss)
I0822 22:22:14.646757 13823 sgd_solver.cpp:112] Iteration 209500, lr = 1e-06
I0822 22:22:24.792661 13823 solver.cpp:239] Iteration 209600 (9.85588 iter/s, 10.1462s/100 iters), loss = 0.0256165
I0822 22:22:24.792711 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.025616 (* 1 = 0.025616 loss)
I0822 22:22:24.792721 13823 sgd_solver.cpp:112] Iteration 209600, lr = 1e-06
I0822 22:22:34.858952 13823 solver.cpp:239] Iteration 209700 (9.93389 iter/s, 10.0665s/100 iters), loss = 0.0285042
I0822 22:22:34.859002 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0285038 (* 1 = 0.0285038 loss)
I0822 22:22:34.859012 13823 sgd_solver.cpp:112] Iteration 209700, lr = 1e-06
I0822 22:22:45.123876 13823 solver.cpp:239] Iteration 209800 (9.74167 iter/s, 10.2652s/100 iters), loss = 0.0275721
I0822 22:22:45.123926 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0275717 (* 1 = 0.0275717 loss)
I0822 22:22:45.123936 13823 sgd_solver.cpp:112] Iteration 209800, lr = 1e-06
I0822 22:22:55.601698 13823 solver.cpp:239] Iteration 209900 (9.54373 iter/s, 10.4781s/100 iters), loss = 0.0302605
I0822 22:22:55.601754 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.03026 (* 1 = 0.03026 loss)
I0822 22:22:55.601764 13823 sgd_solver.cpp:112] Iteration 209900, lr = 1e-06
I0822 22:23:05.965752 13823 solver.cpp:239] Iteration 210000 (9.64851 iter/s, 10.3643s/100 iters), loss = 0.0253418
I0822 22:23:05.965811 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0253413 (* 1 = 0.0253413 loss)
I0822 22:23:05.965822 13823 sgd_solver.cpp:112] Iteration 210000, lr = 1e-06
I0822 22:23:16.603121 13823 solver.cpp:239] Iteration 210100 (9.4006 iter/s, 10.6376s/100 iters), loss = 0.0252504
I0822 22:23:16.603171 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.02525 (* 1 = 0.02525 loss)
I0822 22:23:16.603183 13823 sgd_solver.cpp:112] Iteration 210100, lr = 1e-06
I0822 22:23:27.051379 13823 solver.cpp:239] Iteration 210200 (9.57075 iter/s, 10.4485s/100 iters), loss = 0.029202
I0822 22:23:27.051430 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0292016 (* 1 = 0.0292016 loss)
I0822 22:23:27.051440 13823 sgd_solver.cpp:112] Iteration 210200, lr = 1e-06
I0822 22:23:37.971302 13823 solver.cpp:239] Iteration 210300 (9.15736 iter/s, 10.9202s/100 iters), loss = 0.0282191
I0822 22:23:37.971351 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0282187 (* 1 = 0.0282187 loss)
I0822 22:23:37.971360 13823 sgd_solver.cpp:112] Iteration 210300, lr = 1e-06
I0822 22:23:48.535908 13823 solver.cpp:239] Iteration 210400 (9.46535 iter/s, 10.5648s/100 iters), loss = 0.0249885
I0822 22:23:48.535967 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.024988 (* 1 = 0.024988 loss)
I0822 22:23:48.535979 13823 sgd_solver.cpp:112] Iteration 210400, lr = 1e-06
I0822 22:23:59.006502 13823 solver.cpp:239] Iteration 210500 (9.55035 iter/s, 10.4708s/100 iters), loss = 0.0277307
I0822 22:23:59.006553 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0277302 (* 1 = 0.0277302 loss)
I0822 22:23:59.006562 13823 sgd_solver.cpp:112] Iteration 210500, lr = 1e-06
I0822 22:24:09.793509 13823 solver.cpp:239] Iteration 210600 (9.27021 iter/s, 10.7872s/100 iters), loss = 0.0258522
I0822 22:24:09.793561 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0258518 (* 1 = 0.0258518 loss)
I0822 22:24:09.793571 13823 sgd_solver.cpp:112] Iteration 210600, lr = 1e-06
I0822 22:24:20.173048 13823 solver.cpp:239] Iteration 210700 (9.63413 iter/s, 10.3798s/100 iters), loss = 0.0262217
I0822 22:24:20.173097 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0262212 (* 1 = 0.0262212 loss)
I0822 22:24:20.173106 13823 sgd_solver.cpp:112] Iteration 210700, lr = 1e-06
I0822 22:24:30.742390 13823 solver.cpp:239] Iteration 210800 (9.46113 iter/s, 10.5696s/100 iters), loss = 0.0277399
I0822 22:24:30.742455 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0277395 (* 1 = 0.0277395 loss)
I0822 22:24:30.742468 13823 sgd_solver.cpp:112] Iteration 210800, lr = 1e-06
I0822 22:24:41.118096 13823 solver.cpp:239] Iteration 210900 (9.63771 iter/s, 10.3759s/100 iters), loss = 0.0247642
I0822 22:24:41.118160 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0247638 (* 1 = 0.0247638 loss)
I0822 22:24:41.118172 13823 sgd_solver.cpp:112] Iteration 210900, lr = 1e-06
I0822 22:24:51.998900 13823 solver.cpp:239] Iteration 211000 (9.19032 iter/s, 10.881s/100 iters), loss = 0.0231309
I0822 22:24:51.998950 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0231304 (* 1 = 0.0231304 loss)
I0822 22:24:51.998958 13823 sgd_solver.cpp:112] Iteration 211000, lr = 1e-06
I0822 22:25:02.758643 13823 solver.cpp:239] Iteration 211100 (9.29371 iter/s, 10.76s/100 iters), loss = 0.0263852
I0822 22:25:02.758692 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0263848 (* 1 = 0.0263848 loss)
I0822 22:25:02.758700 13823 sgd_solver.cpp:112] Iteration 211100, lr = 1e-06
I0822 22:25:13.407871 13823 solver.cpp:239] Iteration 211200 (9.39017 iter/s, 10.6494s/100 iters), loss = 0.0319214
I0822 22:25:13.407922 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0319209 (* 1 = 0.0319209 loss)
I0822 22:25:13.407932 13823 sgd_solver.cpp:112] Iteration 211200, lr = 1e-06
I0822 22:25:23.995188 13823 solver.cpp:239] Iteration 211300 (9.44508 iter/s, 10.5875s/100 iters), loss = 0.0289513
I0822 22:25:23.995246 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0289508 (* 1 = 0.0289508 loss)
I0822 22:25:23.995257 13823 sgd_solver.cpp:112] Iteration 211300, lr = 1e-06
I0822 22:25:34.430984 13823 solver.cpp:239] Iteration 211400 (9.58222 iter/s, 10.436s/100 iters), loss = 0.0237688
I0822 22:25:34.431033 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0237684 (* 1 = 0.0237684 loss)
I0822 22:25:34.431042 13823 sgd_solver.cpp:112] Iteration 211400, lr = 1e-06
I0822 22:25:44.986678 13823 solver.cpp:239] Iteration 211500 (9.47338 iter/s, 10.5559s/100 iters), loss = 0.0313215
I0822 22:25:44.986734 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0313211 (* 1 = 0.0313211 loss)
I0822 22:25:44.986744 13823 sgd_solver.cpp:112] Iteration 211500, lr = 1e-06
I0822 22:25:55.716809 13823 solver.cpp:239] Iteration 211600 (9.31938 iter/s, 10.7303s/100 iters), loss = 0.0291532
I0822 22:25:55.716859 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0291528 (* 1 = 0.0291528 loss)
I0822 22:25:55.716868 13823 sgd_solver.cpp:112] Iteration 211600, lr = 1e-06
I0822 22:26:06.591433 13823 solver.cpp:239] Iteration 211700 (9.19555 iter/s, 10.8748s/100 iters), loss = 0.0456791
I0822 22:26:06.591488 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0456787 (* 1 = 0.0456787 loss)
I0822 22:26:06.591500 13823 sgd_solver.cpp:112] Iteration 211700, lr = 1e-06
I0822 22:26:17.251740 13823 solver.cpp:239] Iteration 211800 (9.38043 iter/s, 10.6605s/100 iters), loss = 0.0271078
I0822 22:26:17.251790 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0271074 (* 1 = 0.0271074 loss)
I0822 22:26:17.251798 13823 sgd_solver.cpp:112] Iteration 211800, lr = 1e-06
I0822 22:26:27.818284 13823 solver.cpp:239] Iteration 211900 (9.46367 iter/s, 10.5667s/100 iters), loss = 0.0255733
I0822 22:26:27.818334 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0255729 (* 1 = 0.0255729 loss)
I0822 22:26:27.818343 13823 sgd_solver.cpp:112] Iteration 211900, lr = 1e-06
I0822 22:26:38.410778 13823 solver.cpp:239] Iteration 212000 (9.44049 iter/s, 10.5927s/100 iters), loss = 0.0234736
I0822 22:26:38.410836 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0234732 (* 1 = 0.0234732 loss)
I0822 22:26:38.410846 13823 sgd_solver.cpp:112] Iteration 212000, lr = 1e-06
I0822 22:26:49.206938 13823 solver.cpp:239] Iteration 212100 (9.2624 iter/s, 10.7963s/100 iters), loss = 0.0283802
I0822 22:26:49.206996 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0283798 (* 1 = 0.0283798 loss)
I0822 22:26:49.207007 13823 sgd_solver.cpp:112] Iteration 212100, lr = 1e-06
I0822 22:27:00.263291 13823 solver.cpp:239] Iteration 212200 (9.04443 iter/s, 11.0565s/100 iters), loss = 0.0255453
I0822 22:27:00.263340 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0255449 (* 1 = 0.0255449 loss)
I0822 22:27:00.263350 13823 sgd_solver.cpp:112] Iteration 212200, lr = 1e-06
I0822 22:27:11.369837 13823 solver.cpp:239] Iteration 212300 (9.00355 iter/s, 11.1067s/100 iters), loss = 0.0272088
I0822 22:27:11.369894 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0272084 (* 1 = 0.0272084 loss)
I0822 22:27:11.369904 13823 sgd_solver.cpp:112] Iteration 212300, lr = 1e-06
I0822 22:27:22.360565 13823 solver.cpp:239] Iteration 212400 (9.09844 iter/s, 10.9909s/100 iters), loss = 0.0259889
I0822 22:27:22.360622 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0259884 (* 1 = 0.0259884 loss)
I0822 22:27:22.360633 13823 sgd_solver.cpp:112] Iteration 212400, lr = 1e-06
I0822 22:27:33.015518 13823 solver.cpp:239] Iteration 212500 (9.38517 iter/s, 10.6551s/100 iters), loss = 0.0319601
I0822 22:27:33.015574 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0319596 (* 1 = 0.0319596 loss)
I0822 22:27:33.015585 13823 sgd_solver.cpp:112] Iteration 212500, lr = 1e-06
I0822 22:27:43.667979 13823 solver.cpp:239] Iteration 212600 (9.38736 iter/s, 10.6526s/100 iters), loss = 0.0417521
I0822 22:27:43.668038 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0417516 (* 1 = 0.0417516 loss)
I0822 22:27:43.668051 13823 sgd_solver.cpp:112] Iteration 212600, lr = 1e-06
I0822 22:27:54.641433 13823 solver.cpp:239] Iteration 212700 (9.11277 iter/s, 10.9736s/100 iters), loss = 0.0236117
I0822 22:27:54.641487 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0236112 (* 1 = 0.0236112 loss)
I0822 22:27:54.641497 13823 sgd_solver.cpp:112] Iteration 212700, lr = 1e-06
I0822 22:28:05.580124 13823 solver.cpp:239] Iteration 212800 (9.14173 iter/s, 10.9389s/100 iters), loss = 0.0248098
I0822 22:28:05.580185 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0248094 (* 1 = 0.0248094 loss)
I0822 22:28:05.580197 13823 sgd_solver.cpp:112] Iteration 212800, lr = 1e-06
I0822 22:28:16.190954 13823 solver.cpp:239] Iteration 212900 (9.4242 iter/s, 10.611s/100 iters), loss = 0.0232637
I0822 22:28:16.191004 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0232633 (* 1 = 0.0232633 loss)
I0822 22:28:16.191013 13823 sgd_solver.cpp:112] Iteration 212900, lr = 1e-06
I0822 22:28:26.961774 13823 solver.cpp:239] Iteration 213000 (9.28421 iter/s, 10.771s/100 iters), loss = 0.0235531
I0822 22:28:26.961825 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0235527 (* 1 = 0.0235527 loss)
I0822 22:28:26.961835 13823 sgd_solver.cpp:112] Iteration 213000, lr = 1e-06
I0822 22:28:37.975345 13823 solver.cpp:239] Iteration 213100 (9.07958 iter/s, 11.0137s/100 iters), loss = 0.0252788
I0822 22:28:37.975414 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0252783 (* 1 = 0.0252783 loss)
I0822 22:28:37.975426 13823 sgd_solver.cpp:112] Iteration 213100, lr = 1e-06
I0822 22:28:49.045440 13823 solver.cpp:239] Iteration 213200 (9.03323 iter/s, 11.0702s/100 iters), loss = 0.0311763
I0822 22:28:49.045506 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0311759 (* 1 = 0.0311759 loss)
I0822 22:28:49.045519 13823 sgd_solver.cpp:112] Iteration 213200, lr = 1e-06
I0822 22:29:00.140836 13823 solver.cpp:239] Iteration 213300 (9.01263 iter/s, 11.0955s/100 iters), loss = 0.0335068
I0822 22:29:00.140890 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0335063 (* 1 = 0.0335063 loss)
I0822 22:29:00.140900 13823 sgd_solver.cpp:112] Iteration 213300, lr = 1e-06
I0822 22:29:11.195700 13823 solver.cpp:239] Iteration 213400 (9.04567 iter/s, 11.055s/100 iters), loss = 0.0243008
I0822 22:29:11.195751 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0243004 (* 1 = 0.0243004 loss)
I0822 22:29:11.195760 13823 sgd_solver.cpp:112] Iteration 213400, lr = 1e-06
I0822 22:29:21.969483 13823 solver.cpp:239] Iteration 213500 (9.28167 iter/s, 10.7739s/100 iters), loss = 0.0241349
I0822 22:29:21.969544 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0241344 (* 1 = 0.0241344 loss)
I0822 22:29:21.969555 13823 sgd_solver.cpp:112] Iteration 213500, lr = 1e-06
I0822 22:29:32.891280 13823 solver.cpp:239] Iteration 213600 (9.15589 iter/s, 10.9219s/100 iters), loss = 0.0308546
I0822 22:29:32.891337 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0308542 (* 1 = 0.0308542 loss)
I0822 22:29:32.891348 13823 sgd_solver.cpp:112] Iteration 213600, lr = 1e-06
I0822 22:29:44.077847 13823 solver.cpp:239] Iteration 213700 (8.93918 iter/s, 11.1867s/100 iters), loss = 0.030694
I0822 22:29:44.077908 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0306936 (* 1 = 0.0306936 loss)
I0822 22:29:44.077920 13823 sgd_solver.cpp:112] Iteration 213700, lr = 1e-06
I0822 22:29:55.180742 13823 solver.cpp:239] Iteration 213800 (9.00655 iter/s, 11.103s/100 iters), loss = 0.0273719
I0822 22:29:55.180791 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0273715 (* 1 = 0.0273715 loss)
I0822 22:29:55.180801 13823 sgd_solver.cpp:112] Iteration 213800, lr = 1e-06
I0822 22:30:05.867569 13823 solver.cpp:239] Iteration 213900 (9.3572 iter/s, 10.687s/100 iters), loss = 0.0296663
I0822 22:30:05.867625 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0296659 (* 1 = 0.0296659 loss)
I0822 22:30:05.867635 13823 sgd_solver.cpp:112] Iteration 213900, lr = 1e-06
I0822 22:30:17.074789 13823 solver.cpp:239] Iteration 214000 (8.92271 iter/s, 11.2074s/100 iters), loss = 0.0266692
I0822 22:30:17.074848 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0266687 (* 1 = 0.0266687 loss)
I0822 22:30:17.074860 13823 sgd_solver.cpp:112] Iteration 214000, lr = 1e-06
I0822 22:30:28.123692 13823 solver.cpp:239] Iteration 214100 (9.05057 iter/s, 11.049s/100 iters), loss = 0.0255562
I0822 22:30:28.123741 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0255558 (* 1 = 0.0255558 loss)
I0822 22:30:28.123750 13823 sgd_solver.cpp:112] Iteration 214100, lr = 1e-06
I0822 22:30:38.970685 13823 solver.cpp:239] Iteration 214200 (9.21904 iter/s, 10.8471s/100 iters), loss = 0.0269036
I0822 22:30:38.970749 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0269031 (* 1 = 0.0269031 loss)
I0822 22:30:38.970762 13823 sgd_solver.cpp:112] Iteration 214200, lr = 1e-06
I0822 22:30:50.072158 13823 solver.cpp:239] Iteration 214300 (9.00772 iter/s, 11.1016s/100 iters), loss = 0.0277248
I0822 22:30:50.072228 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0277243 (* 1 = 0.0277243 loss)
I0822 22:30:50.072240 13823 sgd_solver.cpp:112] Iteration 214300, lr = 1e-06
I0822 22:31:01.422894 13823 solver.cpp:239] Iteration 214400 (8.80991 iter/s, 11.3509s/100 iters), loss = 0.0426917
I0822 22:31:01.422950 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0426913 (* 1 = 0.0426913 loss)
I0822 22:31:01.422962 13823 sgd_solver.cpp:112] Iteration 214400, lr = 1e-06
I0822 22:31:12.615228 13823 solver.cpp:239] Iteration 214500 (8.93459 iter/s, 11.1925s/100 iters), loss = 0.0321654
I0822 22:31:12.615288 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.032165 (* 1 = 0.032165 loss)
I0822 22:31:12.615298 13823 sgd_solver.cpp:112] Iteration 214500, lr = 1e-06
I0822 22:31:23.705608 13823 solver.cpp:239] Iteration 214600 (9.01673 iter/s, 11.0905s/100 iters), loss = 0.0239485
I0822 22:31:23.705673 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.023948 (* 1 = 0.023948 loss)
I0822 22:31:23.705685 13823 sgd_solver.cpp:112] Iteration 214600, lr = 1e-06
I0822 22:31:35.017628 13823 solver.cpp:239] Iteration 214700 (8.84007 iter/s, 11.3121s/100 iters), loss = 0.0247319
I0822 22:31:35.017686 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0247315 (* 1 = 0.0247315 loss)
I0822 22:31:35.017699 13823 sgd_solver.cpp:112] Iteration 214700, lr = 1e-06
I0822 22:31:46.179740 13823 solver.cpp:239] Iteration 214800 (8.95878 iter/s, 11.1622s/100 iters), loss = 0.0248756
I0822 22:31:46.179792 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0248752 (* 1 = 0.0248752 loss)
I0822 22:31:46.179802 13823 sgd_solver.cpp:112] Iteration 214800, lr = 1e-06
I0822 22:31:57.446981 13823 solver.cpp:239] Iteration 214900 (8.87519 iter/s, 11.2674s/100 iters), loss = 0.0280067
I0822 22:31:57.447042 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0280062 (* 1 = 0.0280062 loss)
I0822 22:31:57.447055 13823 sgd_solver.cpp:112] Iteration 214900, lr = 1e-06
I0822 22:32:08.510334 13823 solver.cpp:239] Iteration 215000 (9.03876 iter/s, 11.0635s/100 iters), loss = 0.03195
I0822 22:32:08.510390 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0319496 (* 1 = 0.0319496 loss)
I0822 22:32:08.510401 13823 sgd_solver.cpp:112] Iteration 215000, lr = 1e-06
I0822 22:32:19.516906 13823 solver.cpp:239] Iteration 215100 (9.08539 iter/s, 11.0067s/100 iters), loss = 0.0235865
I0822 22:32:19.516954 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.023586 (* 1 = 0.023586 loss)
I0822 22:32:19.516964 13823 sgd_solver.cpp:112] Iteration 215100, lr = 1e-06
I0822 22:32:30.735314 13823 solver.cpp:239] Iteration 215200 (8.91383 iter/s, 11.2185s/100 iters), loss = 0.0241066
I0822 22:32:30.735378 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0241062 (* 1 = 0.0241062 loss)
I0822 22:32:30.735391 13823 sgd_solver.cpp:112] Iteration 215200, lr = 1e-06
I0822 22:32:42.006317 13823 solver.cpp:239] Iteration 215300 (8.87224 iter/s, 11.2711s/100 iters), loss = 0.0271365
I0822 22:32:42.006367 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0271361 (* 1 = 0.0271361 loss)
I0822 22:32:42.006376 13823 sgd_solver.cpp:112] Iteration 215300, lr = 1e-06
I0822 22:32:53.404158 13823 solver.cpp:239] Iteration 215400 (8.7735 iter/s, 11.398s/100 iters), loss = 0.0259705
I0822 22:32:53.404208 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.02597 (* 1 = 0.02597 loss)
I0822 22:32:53.404219 13823 sgd_solver.cpp:112] Iteration 215400, lr = 1e-06
I0822 22:33:04.494164 13823 solver.cpp:239] Iteration 215500 (9.01704 iter/s, 11.0901s/100 iters), loss = 0.028789
I0822 22:33:04.494216 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0287886 (* 1 = 0.0287886 loss)
I0822 22:33:04.494225 13823 sgd_solver.cpp:112] Iteration 215500, lr = 1e-06
I0822 22:33:15.940307 13823 solver.cpp:239] Iteration 215600 (8.73648 iter/s, 11.4463s/100 iters), loss = 0.0311536
I0822 22:33:15.940357 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0311531 (* 1 = 0.0311531 loss)
I0822 22:33:15.940366 13823 sgd_solver.cpp:112] Iteration 215600, lr = 1e-06
I0822 22:33:27.193924 13823 solver.cpp:239] Iteration 215700 (8.88595 iter/s, 11.2537s/100 iters), loss = 0.023472
I0822 22:33:27.193981 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0234716 (* 1 = 0.0234716 loss)
I0822 22:33:27.193992 13823 sgd_solver.cpp:112] Iteration 215700, lr = 1e-06
I0822 22:33:38.451459 13823 solver.cpp:239] Iteration 215800 (8.88286 iter/s, 11.2576s/100 iters), loss = 0.026995
I0822 22:33:38.451522 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0269945 (* 1 = 0.0269945 loss)
I0822 22:33:38.451534 13823 sgd_solver.cpp:112] Iteration 215800, lr = 1e-06
I0822 22:33:49.718883 13823 solver.cpp:239] Iteration 215900 (8.87507 iter/s, 11.2675s/100 iters), loss = 0.025972
I0822 22:33:49.718933 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0259716 (* 1 = 0.0259716 loss)
I0822 22:33:49.718943 13823 sgd_solver.cpp:112] Iteration 215900, lr = 1e-06
I0822 22:34:00.833412 13823 solver.cpp:239] Iteration 216000 (8.99715 iter/s, 11.1146s/100 iters), loss = 0.0258955
I0822 22:34:00.833463 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.025895 (* 1 = 0.025895 loss)
I0822 22:34:00.833472 13823 sgd_solver.cpp:112] Iteration 216000, lr = 1e-06
I0822 22:34:12.199726 13823 solver.cpp:239] Iteration 216100 (8.79785 iter/s, 11.3664s/100 iters), loss = 0.0259272
I0822 22:34:12.199787 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0259268 (* 1 = 0.0259268 loss)
I0822 22:34:12.199798 13823 sgd_solver.cpp:112] Iteration 216100, lr = 1e-06
I0822 22:34:23.511662 13823 solver.cpp:239] Iteration 216200 (8.84015 iter/s, 11.312s/100 iters), loss = 0.0277734
I0822 22:34:23.511710 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0277729 (* 1 = 0.0277729 loss)
I0822 22:34:23.511720 13823 sgd_solver.cpp:112] Iteration 216200, lr = 1e-06
I0822 22:34:34.725832 13823 solver.cpp:239] Iteration 216300 (8.91721 iter/s, 11.2143s/100 iters), loss = 0.0268623
I0822 22:34:34.725894 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0268619 (* 1 = 0.0268619 loss)
I0822 22:34:34.725908 13823 sgd_solver.cpp:112] Iteration 216300, lr = 1e-06
I0822 22:34:46.050736 13823 solver.cpp:239] Iteration 216400 (8.83003 iter/s, 11.325s/100 iters), loss = 0.0255673
I0822 22:34:46.050802 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0255669 (* 1 = 0.0255669 loss)
I0822 22:34:46.050817 13823 sgd_solver.cpp:112] Iteration 216400, lr = 1e-06
I0822 22:34:57.592541 13823 solver.cpp:239] Iteration 216500 (8.66409 iter/s, 11.5419s/100 iters), loss = 0.0255562
I0822 22:34:57.592602 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0255557 (* 1 = 0.0255557 loss)
I0822 22:34:57.592617 13823 sgd_solver.cpp:112] Iteration 216500, lr = 1e-06
I0822 22:35:08.828336 13823 solver.cpp:239] Iteration 216600 (8.90006 iter/s, 11.2359s/100 iters), loss = 0.0250912
I0822 22:35:08.828405 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0250907 (* 1 = 0.0250907 loss)
I0822 22:35:08.828423 13823 sgd_solver.cpp:112] Iteration 216600, lr = 1e-06
I0822 22:35:20.047559 13823 solver.cpp:239] Iteration 216700 (8.91321 iter/s, 11.2193s/100 iters), loss = 0.0267811
I0822 22:35:20.047617 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0267806 (* 1 = 0.0267806 loss)
I0822 22:35:20.047629 13823 sgd_solver.cpp:112] Iteration 216700, lr = 1e-06
I0822 22:35:31.447537 13823 solver.cpp:239] Iteration 216800 (8.77188 iter/s, 11.4001s/100 iters), loss = 0.0306111
I0822 22:35:31.447595 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0306107 (* 1 = 0.0306107 loss)
I0822 22:35:31.447609 13823 sgd_solver.cpp:112] Iteration 216800, lr = 1e-06
I0822 22:35:42.805109 13823 solver.cpp:239] Iteration 216900 (8.80463 iter/s, 11.3577s/100 iters), loss = 0.030487
I0822 22:35:42.805166 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0304865 (* 1 = 0.0304865 loss)
I0822 22:35:42.805179 13823 sgd_solver.cpp:112] Iteration 216900, lr = 1e-06
I0822 22:35:54.268105 13823 solver.cpp:239] Iteration 217000 (8.72365 iter/s, 11.4631s/100 iters), loss = 0.0297633
I0822 22:35:54.268167 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0297628 (* 1 = 0.0297628 loss)
I0822 22:35:54.268179 13823 sgd_solver.cpp:112] Iteration 217000, lr = 1e-06
I0822 22:36:05.824903 13823 solver.cpp:239] Iteration 217100 (8.65285 iter/s, 11.5569s/100 iters), loss = 0.0240268
I0822 22:36:05.824959 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0240264 (* 1 = 0.0240264 loss)
I0822 22:36:05.824968 13823 sgd_solver.cpp:112] Iteration 217100, lr = 1e-06
I0822 22:36:17.246474 13823 solver.cpp:239] Iteration 217200 (8.7553 iter/s, 11.4217s/100 iters), loss = 0.0377828
I0822 22:36:17.246524 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0377823 (* 1 = 0.0377823 loss)
I0822 22:36:17.246534 13823 sgd_solver.cpp:112] Iteration 217200, lr = 1e-06
I0822 22:36:28.722846 13823 solver.cpp:239] Iteration 217300 (8.71349 iter/s, 11.4765s/100 iters), loss = 0.0266449
I0822 22:36:28.722908 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0266444 (* 1 = 0.0266444 loss)
I0822 22:36:28.722921 13823 sgd_solver.cpp:112] Iteration 217300, lr = 1e-06
I0822 22:36:40.237315 13823 solver.cpp:239] Iteration 217400 (8.68467 iter/s, 11.5145s/100 iters), loss = 0.0220836
I0822 22:36:40.237373 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0220831 (* 1 = 0.0220831 loss)
I0822 22:36:40.237385 13823 sgd_solver.cpp:112] Iteration 217400, lr = 1e-06
I0822 22:36:51.720057 13823 solver.cpp:239] Iteration 217500 (8.70866 iter/s, 11.4828s/100 iters), loss = 0.0264051
I0822 22:36:51.720121 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0264046 (* 1 = 0.0264046 loss)
I0822 22:36:51.720140 13823 sgd_solver.cpp:112] Iteration 217500, lr = 1e-06
I0822 22:37:03.361694 13823 solver.cpp:239] Iteration 217600 (8.5898 iter/s, 11.6417s/100 iters), loss = 0.0334416
I0822 22:37:03.361743 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0334411 (* 1 = 0.0334411 loss)
I0822 22:37:03.361752 13823 sgd_solver.cpp:112] Iteration 217600, lr = 1e-06
I0822 22:37:14.725787 13823 solver.cpp:239] Iteration 217700 (8.79958 iter/s, 11.3642s/100 iters), loss = 0.0406207
I0822 22:37:14.725847 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0406202 (* 1 = 0.0406202 loss)
I0822 22:37:14.725857 13823 sgd_solver.cpp:112] Iteration 217700, lr = 1e-06
I0822 22:37:26.338363 13823 solver.cpp:239] Iteration 217800 (8.61129 iter/s, 11.6127s/100 iters), loss = 0.0295784
I0822 22:37:26.338418 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0295779 (* 1 = 0.0295779 loss)
I0822 22:37:26.338429 13823 sgd_solver.cpp:112] Iteration 217800, lr = 1e-06
I0822 22:37:37.771649 13823 solver.cpp:239] Iteration 217900 (8.74633 iter/s, 11.4334s/100 iters), loss = 0.0276917
I0822 22:37:37.771703 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0276912 (* 1 = 0.0276912 loss)
I0822 22:37:37.771713 13823 sgd_solver.cpp:112] Iteration 217900, lr = 1e-06
I0822 22:37:49.199817 13823 solver.cpp:239] Iteration 218000 (8.75025 iter/s, 11.4282s/100 iters), loss = 0.0257977
I0822 22:37:49.199868 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0257972 (* 1 = 0.0257972 loss)
I0822 22:37:49.199878 13823 sgd_solver.cpp:112] Iteration 218000, lr = 1e-06
I0822 22:38:00.477993 13823 solver.cpp:239] Iteration 218100 (8.86662 iter/s, 11.2783s/100 iters), loss = 0.0349879
I0822 22:38:00.478052 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0349875 (* 1 = 0.0349875 loss)
I0822 22:38:00.478065 13823 sgd_solver.cpp:112] Iteration 218100, lr = 1e-06
I0822 22:38:12.113876 13823 solver.cpp:239] Iteration 218200 (8.59405 iter/s, 11.636s/100 iters), loss = 0.0374999
I0822 22:38:12.113929 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0374994 (* 1 = 0.0374994 loss)
I0822 22:38:12.113941 13823 sgd_solver.cpp:112] Iteration 218200, lr = 1e-06
I0822 22:38:23.740162 13823 solver.cpp:239] Iteration 218300 (8.60114 iter/s, 11.6264s/100 iters), loss = 0.0353101
I0822 22:38:23.740221 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0353096 (* 1 = 0.0353096 loss)
I0822 22:38:23.740232 13823 sgd_solver.cpp:112] Iteration 218300, lr = 1e-06
I0822 22:38:35.217317 13823 solver.cpp:239] Iteration 218400 (8.71291 iter/s, 11.4772s/100 iters), loss = 0.0270862
I0822 22:38:35.217368 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0270857 (* 1 = 0.0270857 loss)
I0822 22:38:35.217378 13823 sgd_solver.cpp:112] Iteration 218400, lr = 1e-06
I0822 22:38:46.690495 13823 solver.cpp:239] Iteration 218500 (8.71592 iter/s, 11.4733s/100 iters), loss = 0.0381186
I0822 22:38:46.690548 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0381181 (* 1 = 0.0381181 loss)
I0822 22:38:46.690558 13823 sgd_solver.cpp:112] Iteration 218500, lr = 1e-06
I0822 22:38:58.492280 13823 solver.cpp:239] Iteration 218600 (8.47323 iter/s, 11.8019s/100 iters), loss = 0.027277
I0822 22:38:58.492338 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0272766 (* 1 = 0.0272766 loss)
I0822 22:38:58.492348 13823 sgd_solver.cpp:112] Iteration 218600, lr = 1e-06
I0822 22:39:10.405623 13823 solver.cpp:239] Iteration 218700 (8.3939 iter/s, 11.9134s/100 iters), loss = 0.0289746
I0822 22:39:10.405685 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0289741 (* 1 = 0.0289741 loss)
I0822 22:39:10.405697 13823 sgd_solver.cpp:112] Iteration 218700, lr = 1e-06
I0822 22:39:22.104570 13823 solver.cpp:239] Iteration 218800 (8.54773 iter/s, 11.699s/100 iters), loss = 0.0230761
I0822 22:39:22.104622 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0230757 (* 1 = 0.0230757 loss)
I0822 22:39:22.104632 13823 sgd_solver.cpp:112] Iteration 218800, lr = 1e-06
I0822 22:39:33.821838 13823 solver.cpp:239] Iteration 218900 (8.53436 iter/s, 11.7173s/100 iters), loss = 0.0237614
I0822 22:39:33.821903 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0237609 (* 1 = 0.0237609 loss)
I0822 22:39:33.821916 13823 sgd_solver.cpp:112] Iteration 218900, lr = 1e-06
I0822 22:39:45.445096 13823 solver.cpp:239] Iteration 219000 (8.60339 iter/s, 11.6233s/100 iters), loss = 0.0342233
I0822 22:39:45.445152 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0342228 (* 1 = 0.0342228 loss)
I0822 22:39:45.445163 13823 sgd_solver.cpp:112] Iteration 219000, lr = 1e-06
I0822 22:39:57.119328 13823 solver.cpp:239] Iteration 219100 (8.56582 iter/s, 11.6743s/100 iters), loss = 0.0243545
I0822 22:39:57.119380 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.024354 (* 1 = 0.024354 loss)
I0822 22:39:57.119390 13823 sgd_solver.cpp:112] Iteration 219100, lr = 1e-06
I0822 22:40:07.068903 13823 solver.cpp:239] Iteration 219200 (10.0506 iter/s, 9.94963s/100 iters), loss = 0.026902
I0822 22:40:07.068959 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0269015 (* 1 = 0.0269015 loss)
I0822 22:40:07.068970 13823 sgd_solver.cpp:112] Iteration 219200, lr = 1e-06
I0822 22:40:16.595396 13823 solver.cpp:239] Iteration 219300 (10.497 iter/s, 9.52654s/100 iters), loss = 0.0254991
I0822 22:40:16.595445 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0254987 (* 1 = 0.0254987 loss)
I0822 22:40:16.595455 13823 sgd_solver.cpp:112] Iteration 219300, lr = 1e-06
I0822 22:40:26.090757 13823 solver.cpp:239] Iteration 219400 (10.5314 iter/s, 9.49541s/100 iters), loss = 0.0288413
I0822 22:40:26.090809 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0288408 (* 1 = 0.0288408 loss)
I0822 22:40:26.090818 13823 sgd_solver.cpp:112] Iteration 219400, lr = 1e-06
I0822 22:40:35.339321 13823 solver.cpp:239] Iteration 219500 (10.8124 iter/s, 9.24862s/100 iters), loss = 0.0322768
I0822 22:40:35.339375 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0322763 (* 1 = 0.0322763 loss)
I0822 22:40:35.339381 13823 sgd_solver.cpp:112] Iteration 219500, lr = 1e-06
I0822 22:40:45.053606 13823 solver.cpp:239] Iteration 219600 (10.2941 iter/s, 9.71433s/100 iters), loss = 0.0243311
I0822 22:40:45.053656 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0243306 (* 1 = 0.0243306 loss)
I0822 22:40:45.053665 13823 sgd_solver.cpp:112] Iteration 219600, lr = 1e-06
I0822 22:40:54.728567 13823 solver.cpp:239] Iteration 219700 (10.3359 iter/s, 9.67501s/100 iters), loss = 0.0250388
I0822 22:40:54.728615 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0250383 (* 1 = 0.0250383 loss)
I0822 22:40:54.728624 13823 sgd_solver.cpp:112] Iteration 219700, lr = 1e-06
I0822 22:41:04.523159 13823 solver.cpp:239] Iteration 219800 (10.2097 iter/s, 9.79464s/100 iters), loss = 0.0268174
I0822 22:41:04.523217 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0268169 (* 1 = 0.0268169 loss)
I0822 22:41:04.523227 13823 sgd_solver.cpp:112] Iteration 219800, lr = 1e-06
I0822 22:41:14.402437 13823 solver.cpp:239] Iteration 219900 (10.1222 iter/s, 9.87932s/100 iters), loss = 0.0262583
I0822 22:41:14.402488 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0262578 (* 1 = 0.0262578 loss)
I0822 22:41:14.402498 13823 sgd_solver.cpp:112] Iteration 219900, lr = 1e-06
I0822 22:41:23.944507 13823 solver.cpp:464] Snapshotting to binary proto file ./model_112/cascade_mobilenet_112_iter_220000.caffemodel
I0822 22:41:23.987255 13823 sgd_solver.cpp:284] Snapshotting solver state to binary proto file ./model_112/cascade_mobilenet_112_iter_220000.solverstate
I0822 22:41:24.077971 13823 solver.cpp:347] Iteration 220000, Testing net (#0)
I0822 22:42:26.380942 13823 solver.cpp:414]     Test net output #0: landmark_loss = 0.0219317 (* 1 = 0.0219317 loss)
I0822 22:42:26.471922 13823 solver.cpp:239] Iteration 220000 (1.38754 iter/s, 72.0702s/100 iters), loss = 0.0273306
I0822 22:42:26.471964 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0273301 (* 1 = 0.0273301 loss)
I0822 22:42:26.471976 13823 sgd_solver.cpp:112] Iteration 220000, lr = 1e-06
I0822 22:42:36.040753 13823 solver.cpp:239] Iteration 220100 (10.4505 iter/s, 9.56889s/100 iters), loss = 0.0298419
I0822 22:42:36.040804 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0298414 (* 1 = 0.0298414 loss)
I0822 22:42:36.040814 13823 sgd_solver.cpp:112] Iteration 220100, lr = 1e-06
I0822 22:42:45.663516 13823 solver.cpp:239] Iteration 220200 (10.392 iter/s, 9.62281s/100 iters), loss = 0.0247227
I0822 22:42:45.663565 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0247222 (* 1 = 0.0247222 loss)
I0822 22:42:45.663575 13823 sgd_solver.cpp:112] Iteration 220200, lr = 1e-06
I0822 22:42:55.503104 13823 solver.cpp:239] Iteration 220300 (10.163 iter/s, 9.83964s/100 iters), loss = 0.0218134
I0822 22:42:55.503155 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0218129 (* 1 = 0.0218129 loss)
I0822 22:42:55.503165 13823 sgd_solver.cpp:112] Iteration 220300, lr = 1e-06
I0822 22:43:05.226373 13823 solver.cpp:239] Iteration 220400 (10.2846 iter/s, 9.72332s/100 iters), loss = 0.0378901
I0822 22:43:05.226424 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0378896 (* 1 = 0.0378896 loss)
I0822 22:43:05.226433 13823 sgd_solver.cpp:112] Iteration 220400, lr = 1e-06
I0822 22:43:15.177323 13823 solver.cpp:239] Iteration 220500 (10.0492 iter/s, 9.951s/100 iters), loss = 0.0264651
I0822 22:43:15.177376 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0264646 (* 1 = 0.0264646 loss)
I0822 22:43:15.177384 13823 sgd_solver.cpp:112] Iteration 220500, lr = 1e-06
I0822 22:43:25.002600 13823 solver.cpp:239] Iteration 220600 (10.1778 iter/s, 9.82532s/100 iters), loss = 0.0260961
I0822 22:43:25.002651 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0260956 (* 1 = 0.0260956 loss)
I0822 22:43:25.002660 13823 sgd_solver.cpp:112] Iteration 220600, lr = 1e-06
I0822 22:43:34.706040 13823 solver.cpp:239] Iteration 220700 (10.3056 iter/s, 9.70349s/100 iters), loss = 0.0282338
I0822 22:43:34.706092 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0282333 (* 1 = 0.0282333 loss)
I0822 22:43:34.706101 13823 sgd_solver.cpp:112] Iteration 220700, lr = 1e-06
I0822 22:43:44.550091 13823 solver.cpp:239] Iteration 220800 (10.1584 iter/s, 9.8441s/100 iters), loss = 0.027201
I0822 22:43:44.550144 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0272005 (* 1 = 0.0272005 loss)
I0822 22:43:44.550153 13823 sgd_solver.cpp:112] Iteration 220800, lr = 1e-06
I0822 22:43:54.506269 13823 solver.cpp:239] Iteration 220900 (10.044 iter/s, 9.95622s/100 iters), loss = 0.026269
I0822 22:43:54.506320 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0262685 (* 1 = 0.0262685 loss)
I0822 22:43:54.506330 13823 sgd_solver.cpp:112] Iteration 220900, lr = 1e-06
I0822 22:44:04.560253 13823 solver.cpp:239] Iteration 221000 (9.94626 iter/s, 10.054s/100 iters), loss = 0.0252954
I0822 22:44:04.560303 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0252949 (* 1 = 0.0252949 loss)
I0822 22:44:04.560312 13823 sgd_solver.cpp:112] Iteration 221000, lr = 1e-06
I0822 22:44:14.390390 13823 solver.cpp:239] Iteration 221100 (10.1727 iter/s, 9.83018s/100 iters), loss = 0.0290072
I0822 22:44:14.390442 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0290067 (* 1 = 0.0290067 loss)
I0822 22:44:14.390452 13823 sgd_solver.cpp:112] Iteration 221100, lr = 1e-06
I0822 22:44:24.456619 13823 solver.cpp:239] Iteration 221200 (9.93416 iter/s, 10.0663s/100 iters), loss = 0.0278796
I0822 22:44:24.456677 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0278791 (* 1 = 0.0278791 loss)
I0822 22:44:24.456688 13823 sgd_solver.cpp:112] Iteration 221200, lr = 1e-06
I0822 22:44:34.425690 13823 solver.cpp:239] Iteration 221300 (10.031 iter/s, 9.96911s/100 iters), loss = 0.0239275
I0822 22:44:34.425745 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.023927 (* 1 = 0.023927 loss)
I0822 22:44:34.425755 13823 sgd_solver.cpp:112] Iteration 221300, lr = 1e-06
I0822 22:44:44.579747 13823 solver.cpp:239] Iteration 221400 (9.84824 iter/s, 10.1541s/100 iters), loss = 0.0277342
I0822 22:44:44.579797 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0277337 (* 1 = 0.0277337 loss)
I0822 22:44:44.579807 13823 sgd_solver.cpp:112] Iteration 221400, lr = 1e-06
I0822 22:44:54.362259 13823 solver.cpp:239] Iteration 221500 (10.2223 iter/s, 9.78256s/100 iters), loss = 0.0271399
I0822 22:44:54.362309 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0271395 (* 1 = 0.0271395 loss)
I0822 22:44:54.362319 13823 sgd_solver.cpp:112] Iteration 221500, lr = 1e-06
I0822 22:45:04.330349 13823 solver.cpp:239] Iteration 221600 (10.032 iter/s, 9.96813s/100 iters), loss = 0.0353657
I0822 22:45:04.330401 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0353652 (* 1 = 0.0353652 loss)
I0822 22:45:04.330410 13823 sgd_solver.cpp:112] Iteration 221600, lr = 1e-06
I0822 22:45:14.266714 13823 solver.cpp:239] Iteration 221700 (10.064 iter/s, 9.93641s/100 iters), loss = 0.0236784
I0822 22:45:14.266763 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0236779 (* 1 = 0.0236779 loss)
I0822 22:45:14.266772 13823 sgd_solver.cpp:112] Iteration 221700, lr = 1e-06
I0822 22:45:23.988624 13823 solver.cpp:239] Iteration 221800 (10.286 iter/s, 9.72195s/100 iters), loss = 0.0304104
I0822 22:45:23.988677 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0304099 (* 1 = 0.0304099 loss)
I0822 22:45:23.988685 13823 sgd_solver.cpp:112] Iteration 221800, lr = 1e-06
I0822 22:45:33.796875 13823 solver.cpp:239] Iteration 221900 (10.1955 iter/s, 9.80829s/100 iters), loss = 0.0216993
I0822 22:45:33.796926 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0216988 (* 1 = 0.0216988 loss)
I0822 22:45:33.796936 13823 sgd_solver.cpp:112] Iteration 221900, lr = 1e-06
I0822 22:45:43.773689 13823 solver.cpp:239] Iteration 222000 (10.0232 iter/s, 9.97686s/100 iters), loss = 0.0299801
I0822 22:45:43.773741 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0299796 (* 1 = 0.0299796 loss)
I0822 22:45:43.773749 13823 sgd_solver.cpp:112] Iteration 222000, lr = 1e-06
I0822 22:45:53.781738 13823 solver.cpp:239] Iteration 222100 (9.99192 iter/s, 10.0081s/100 iters), loss = 0.0242203
I0822 22:45:53.781795 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0242199 (* 1 = 0.0242199 loss)
I0822 22:45:53.781806 13823 sgd_solver.cpp:112] Iteration 222100, lr = 1e-06
I0822 22:46:03.932457 13823 solver.cpp:239] Iteration 222200 (9.85148 iter/s, 10.1508s/100 iters), loss = 0.0383491
I0822 22:46:03.932504 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0383486 (* 1 = 0.0383486 loss)
I0822 22:46:03.932513 13823 sgd_solver.cpp:112] Iteration 222200, lr = 1e-06
I0822 22:46:13.927986 13823 solver.cpp:239] Iteration 222300 (10.0044 iter/s, 9.99557s/100 iters), loss = 0.0269785
I0822 22:46:13.928036 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.026978 (* 1 = 0.026978 loss)
I0822 22:46:13.928046 13823 sgd_solver.cpp:112] Iteration 222300, lr = 1e-06
I0822 22:46:23.922597 13823 solver.cpp:239] Iteration 222400 (10.0053 iter/s, 9.99465s/100 iters), loss = 0.0268104
I0822 22:46:23.922648 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.02681 (* 1 = 0.02681 loss)
I0822 22:46:23.922658 13823 sgd_solver.cpp:112] Iteration 222400, lr = 1e-06
I0822 22:46:34.108698 13823 solver.cpp:239] Iteration 222500 (9.81726 iter/s, 10.1861s/100 iters), loss = 0.0270662
I0822 22:46:34.108748 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0270657 (* 1 = 0.0270657 loss)
I0822 22:46:34.108758 13823 sgd_solver.cpp:112] Iteration 222500, lr = 1e-06
I0822 22:46:44.139904 13823 solver.cpp:239] Iteration 222600 (9.96885 iter/s, 10.0312s/100 iters), loss = 0.0239589
I0822 22:46:44.139967 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0239584 (* 1 = 0.0239584 loss)
I0822 22:46:44.139979 13823 sgd_solver.cpp:112] Iteration 222600, lr = 1e-06
I0822 22:46:54.477785 13823 solver.cpp:239] Iteration 222700 (9.67313 iter/s, 10.3379s/100 iters), loss = 0.0298384
I0822 22:46:54.477849 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0298379 (* 1 = 0.0298379 loss)
I0822 22:46:54.477860 13823 sgd_solver.cpp:112] Iteration 222700, lr = 1e-06
I0822 22:47:04.416527 13823 solver.cpp:239] Iteration 222800 (10.0616 iter/s, 9.93878s/100 iters), loss = 0.024333
I0822 22:47:04.416577 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0243325 (* 1 = 0.0243325 loss)
I0822 22:47:04.416586 13823 sgd_solver.cpp:112] Iteration 222800, lr = 1e-06
I0822 22:47:14.385437 13823 solver.cpp:239] Iteration 222900 (10.0311 iter/s, 9.96895s/100 iters), loss = 0.0236987
I0822 22:47:14.385488 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0236982 (* 1 = 0.0236982 loss)
I0822 22:47:14.385496 13823 sgd_solver.cpp:112] Iteration 222900, lr = 1e-06
I0822 22:47:24.241643 13823 solver.cpp:239] Iteration 223000 (10.1459 iter/s, 9.85625s/100 iters), loss = 0.0302796
I0822 22:47:24.241696 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0302792 (* 1 = 0.0302792 loss)
I0822 22:47:24.241706 13823 sgd_solver.cpp:112] Iteration 223000, lr = 1e-06
I0822 22:47:34.433218 13823 solver.cpp:239] Iteration 223100 (9.81199 iter/s, 10.1916s/100 iters), loss = 0.0299173
I0822 22:47:34.433267 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0299169 (* 1 = 0.0299169 loss)
I0822 22:47:34.433277 13823 sgd_solver.cpp:112] Iteration 223100, lr = 1e-06
I0822 22:47:44.553933 13823 solver.cpp:239] Iteration 223200 (9.88068 iter/s, 10.1208s/100 iters), loss = 0.0259241
I0822 22:47:44.553983 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0259237 (* 1 = 0.0259237 loss)
I0822 22:47:44.553993 13823 sgd_solver.cpp:112] Iteration 223200, lr = 1e-06
I0822 22:47:54.552464 13823 solver.cpp:239] Iteration 223300 (10.0014 iter/s, 9.99857s/100 iters), loss = 0.0266475
I0822 22:47:54.552512 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.026647 (* 1 = 0.026647 loss)
I0822 22:47:54.552521 13823 sgd_solver.cpp:112] Iteration 223300, lr = 1e-06
I0822 22:48:04.476351 13823 solver.cpp:239] Iteration 223400 (10.0767 iter/s, 9.92393s/100 iters), loss = 0.0253032
I0822 22:48:04.476402 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0253028 (* 1 = 0.0253028 loss)
I0822 22:48:04.476413 13823 sgd_solver.cpp:112] Iteration 223400, lr = 1e-06
I0822 22:48:14.388872 13823 solver.cpp:239] Iteration 223500 (10.0882 iter/s, 9.91256s/100 iters), loss = 0.0266967
I0822 22:48:14.388929 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0266962 (* 1 = 0.0266962 loss)
I0822 22:48:14.388940 13823 sgd_solver.cpp:112] Iteration 223500, lr = 1e-06
I0822 22:48:24.665555 13823 solver.cpp:239] Iteration 223600 (9.73073 iter/s, 10.2767s/100 iters), loss = 0.0380844
I0822 22:48:24.665606 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.038084 (* 1 = 0.038084 loss)
I0822 22:48:24.665614 13823 sgd_solver.cpp:112] Iteration 223600, lr = 1e-06
I0822 22:48:34.909885 13823 solver.cpp:239] Iteration 223700 (9.76146 iter/s, 10.2444s/100 iters), loss = 0.0285284
I0822 22:48:34.909935 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.028528 (* 1 = 0.028528 loss)
I0822 22:48:34.909945 13823 sgd_solver.cpp:112] Iteration 223700, lr = 1e-06
I0822 22:48:45.116931 13823 solver.cpp:239] Iteration 223800 (9.79712 iter/s, 10.2071s/100 iters), loss = 0.0366086
I0822 22:48:45.116995 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0366082 (* 1 = 0.0366082 loss)
I0822 22:48:45.117004 13823 sgd_solver.cpp:112] Iteration 223800, lr = 1e-06
I0822 22:48:55.267154 13823 solver.cpp:239] Iteration 223900 (9.85198 iter/s, 10.1502s/100 iters), loss = 0.029474
I0822 22:48:55.267210 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0294735 (* 1 = 0.0294735 loss)
I0822 22:48:55.267220 13823 sgd_solver.cpp:112] Iteration 223900, lr = 1e-06
I0822 22:49:05.432814 13823 solver.cpp:239] Iteration 224000 (9.83701 iter/s, 10.1657s/100 iters), loss = 0.027562
I0822 22:49:05.432873 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0275615 (* 1 = 0.0275615 loss)
I0822 22:49:05.432884 13823 sgd_solver.cpp:112] Iteration 224000, lr = 1e-06
I0822 22:49:15.450968 13823 solver.cpp:239] Iteration 224100 (9.98185 iter/s, 10.0182s/100 iters), loss = 0.0359145
I0822 22:49:15.451020 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.035914 (* 1 = 0.035914 loss)
I0822 22:49:15.451030 13823 sgd_solver.cpp:112] Iteration 224100, lr = 1e-06
I0822 22:49:25.471619 13823 solver.cpp:239] Iteration 224200 (9.97936 iter/s, 10.0207s/100 iters), loss = 0.0296707
I0822 22:49:25.471671 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0296702 (* 1 = 0.0296702 loss)
I0822 22:49:25.471680 13823 sgd_solver.cpp:112] Iteration 224200, lr = 1e-06
I0822 22:49:35.558429 13823 solver.cpp:239] Iteration 224300 (9.9139 iter/s, 10.0868s/100 iters), loss = 0.0254496
I0822 22:49:35.558485 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0254491 (* 1 = 0.0254491 loss)
I0822 22:49:35.558496 13823 sgd_solver.cpp:112] Iteration 224300, lr = 1e-06
I0822 22:49:45.630231 13823 solver.cpp:239] Iteration 224400 (9.92868 iter/s, 10.0718s/100 iters), loss = 0.0274878
I0822 22:49:45.630280 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0274873 (* 1 = 0.0274873 loss)
I0822 22:49:45.630290 13823 sgd_solver.cpp:112] Iteration 224400, lr = 1e-06
I0822 22:49:55.497681 13823 solver.cpp:239] Iteration 224500 (10.1343 iter/s, 9.86749s/100 iters), loss = 0.0271671
I0822 22:49:55.497732 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0271666 (* 1 = 0.0271666 loss)
I0822 22:49:55.497741 13823 sgd_solver.cpp:112] Iteration 224500, lr = 1e-06
I0822 22:50:05.621397 13823 solver.cpp:239] Iteration 224600 (9.87776 iter/s, 10.1238s/100 iters), loss = 0.0305417
I0822 22:50:05.621446 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0305413 (* 1 = 0.0305413 loss)
I0822 22:50:05.621455 13823 sgd_solver.cpp:112] Iteration 224600, lr = 1e-06
I0822 22:50:15.387549 13823 solver.cpp:239] Iteration 224700 (10.2394 iter/s, 9.76619s/100 iters), loss = 0.0287272
I0822 22:50:15.387589 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0287267 (* 1 = 0.0287267 loss)
I0822 22:50:15.387596 13823 sgd_solver.cpp:112] Iteration 224700, lr = 1e-06
I0822 22:50:25.191529 13823 solver.cpp:239] Iteration 224800 (10.1999 iter/s, 9.80402s/100 iters), loss = 0.0279769
I0822 22:50:25.191576 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0279764 (* 1 = 0.0279764 loss)
I0822 22:50:25.191586 13823 sgd_solver.cpp:112] Iteration 224800, lr = 1e-06
I0822 22:50:35.411761 13823 solver.cpp:239] Iteration 224900 (9.78448 iter/s, 10.2203s/100 iters), loss = 0.0262887
I0822 22:50:35.411823 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0262882 (* 1 = 0.0262882 loss)
I0822 22:50:35.411834 13823 sgd_solver.cpp:112] Iteration 224900, lr = 1e-06
I0822 22:50:45.722805 13823 solver.cpp:239] Iteration 225000 (9.69831 iter/s, 10.3111s/100 iters), loss = 0.02751
I0822 22:50:45.722856 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0275095 (* 1 = 0.0275095 loss)
I0822 22:50:45.722865 13823 sgd_solver.cpp:112] Iteration 225000, lr = 1e-06
I0822 22:50:55.960793 13823 solver.cpp:239] Iteration 225100 (9.76751 iter/s, 10.238s/100 iters), loss = 0.0259205
I0822 22:50:55.960842 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.02592 (* 1 = 0.02592 loss)
I0822 22:50:55.960851 13823 sgd_solver.cpp:112] Iteration 225100, lr = 1e-06
I0822 22:51:06.307572 13823 solver.cpp:239] Iteration 225200 (9.66481 iter/s, 10.3468s/100 iters), loss = 0.0371147
I0822 22:51:06.307636 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0371143 (* 1 = 0.0371143 loss)
I0822 22:51:06.307647 13823 sgd_solver.cpp:112] Iteration 225200, lr = 1e-06
I0822 22:51:16.675559 13823 solver.cpp:239] Iteration 225300 (9.64505 iter/s, 10.368s/100 iters), loss = 0.0268936
I0822 22:51:16.675623 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0268932 (* 1 = 0.0268932 loss)
I0822 22:51:16.675637 13823 sgd_solver.cpp:112] Iteration 225300, lr = 1e-06
I0822 22:51:26.926481 13823 solver.cpp:239] Iteration 225400 (9.7552 iter/s, 10.2509s/100 iters), loss = 0.0298387
I0822 22:51:26.926532 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0298383 (* 1 = 0.0298383 loss)
I0822 22:51:26.926542 13823 sgd_solver.cpp:112] Iteration 225400, lr = 1e-06
I0822 22:51:37.361894 13823 solver.cpp:239] Iteration 225500 (9.58272 iter/s, 10.4355s/100 iters), loss = 0.0333377
I0822 22:51:37.361943 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0333372 (* 1 = 0.0333372 loss)
I0822 22:51:37.361953 13823 sgd_solver.cpp:112] Iteration 225500, lr = 1e-06
I0822 22:51:47.892329 13823 solver.cpp:239] Iteration 225600 (9.49625 iter/s, 10.5305s/100 iters), loss = 0.0419976
I0822 22:51:47.892387 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0419972 (* 1 = 0.0419972 loss)
I0822 22:51:47.892398 13823 sgd_solver.cpp:112] Iteration 225600, lr = 1e-06
I0822 22:51:58.021939 13823 solver.cpp:239] Iteration 225700 (9.87202 iter/s, 10.1296s/100 iters), loss = 0.0237915
I0822 22:51:58.021991 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.023791 (* 1 = 0.023791 loss)
I0822 22:51:58.021999 13823 sgd_solver.cpp:112] Iteration 225700, lr = 1e-06
I0822 22:52:08.522217 13823 solver.cpp:239] Iteration 225800 (9.52352 iter/s, 10.5003s/100 iters), loss = 0.0236712
I0822 22:52:08.522272 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0236707 (* 1 = 0.0236707 loss)
I0822 22:52:08.522284 13823 sgd_solver.cpp:112] Iteration 225800, lr = 1e-06
I0822 22:52:18.878412 13823 solver.cpp:239] Iteration 225900 (9.65603 iter/s, 10.3562s/100 iters), loss = 0.024749
I0822 22:52:18.878463 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0247485 (* 1 = 0.0247485 loss)
I0822 22:52:18.878473 13823 sgd_solver.cpp:112] Iteration 225900, lr = 1e-06
I0822 22:52:29.068575 13823 solver.cpp:239] Iteration 226000 (9.81335 iter/s, 10.1902s/100 iters), loss = 0.0338927
I0822 22:52:29.068629 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0338923 (* 1 = 0.0338923 loss)
I0822 22:52:29.068637 13823 sgd_solver.cpp:112] Iteration 226000, lr = 1e-06
I0822 22:52:39.229089 13823 solver.cpp:239] Iteration 226100 (9.84199 iter/s, 10.1605s/100 iters), loss = 0.0241969
I0822 22:52:39.229140 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0241964 (* 1 = 0.0241964 loss)
I0822 22:52:39.229148 13823 sgd_solver.cpp:112] Iteration 226100, lr = 1e-06
I0822 22:52:49.464053 13823 solver.cpp:239] Iteration 226200 (9.7704 iter/s, 10.235s/100 iters), loss = 0.0228243
I0822 22:52:49.464103 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0228238 (* 1 = 0.0228238 loss)
I0822 22:52:49.464113 13823 sgd_solver.cpp:112] Iteration 226200, lr = 1e-06
I0822 22:53:00.070050 13823 solver.cpp:239] Iteration 226300 (9.42859 iter/s, 10.606s/100 iters), loss = 0.0251975
I0822 22:53:00.070103 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.025197 (* 1 = 0.025197 loss)
I0822 22:53:00.070113 13823 sgd_solver.cpp:112] Iteration 226300, lr = 1e-06
I0822 22:53:10.579811 13823 solver.cpp:239] Iteration 226400 (9.51493 iter/s, 10.5098s/100 iters), loss = 0.0346677
I0822 22:53:10.579875 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0346672 (* 1 = 0.0346672 loss)
I0822 22:53:10.579888 13823 sgd_solver.cpp:112] Iteration 226400, lr = 1e-06
I0822 22:53:20.691457 13823 solver.cpp:239] Iteration 226500 (9.88956 iter/s, 10.1117s/100 iters), loss = 0.0244483
I0822 22:53:20.691509 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0244478 (* 1 = 0.0244478 loss)
I0822 22:53:20.691517 13823 sgd_solver.cpp:112] Iteration 226500, lr = 1e-06
I0822 22:53:31.219668 13823 solver.cpp:239] Iteration 226600 (9.49826 iter/s, 10.5282s/100 iters), loss = 0.023409
I0822 22:53:31.219718 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0234085 (* 1 = 0.0234085 loss)
I0822 22:53:31.219728 13823 sgd_solver.cpp:112] Iteration 226600, lr = 1e-06
I0822 22:53:41.602460 13823 solver.cpp:239] Iteration 226700 (9.63129 iter/s, 10.3828s/100 iters), loss = 0.0262007
I0822 22:53:41.602515 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0262003 (* 1 = 0.0262003 loss)
I0822 22:53:41.602526 13823 sgd_solver.cpp:112] Iteration 226700, lr = 1e-06
I0822 22:53:52.034140 13823 solver.cpp:239] Iteration 226800 (9.58615 iter/s, 10.4317s/100 iters), loss = 0.0268383
I0822 22:53:52.034202 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0268378 (* 1 = 0.0268378 loss)
I0822 22:53:52.034214 13823 sgd_solver.cpp:112] Iteration 226800, lr = 1e-06
I0822 22:54:02.505086 13823 solver.cpp:239] Iteration 226900 (9.55021 iter/s, 10.471s/100 iters), loss = 0.0345466
I0822 22:54:02.505142 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0345461 (* 1 = 0.0345461 loss)
I0822 22:54:02.505152 13823 sgd_solver.cpp:112] Iteration 226900, lr = 1e-06
I0822 22:54:13.002115 13823 solver.cpp:239] Iteration 227000 (9.52647 iter/s, 10.4971s/100 iters), loss = 0.0231965
I0822 22:54:13.002167 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0231961 (* 1 = 0.0231961 loss)
I0822 22:54:13.002177 13823 sgd_solver.cpp:112] Iteration 227000, lr = 1e-06
I0822 22:54:23.500334 13823 solver.cpp:239] Iteration 227100 (9.52539 iter/s, 10.4983s/100 iters), loss = 0.0221058
I0822 22:54:23.500386 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0221054 (* 1 = 0.0221054 loss)
I0822 22:54:23.500396 13823 sgd_solver.cpp:112] Iteration 227100, lr = 1e-06
I0822 22:54:33.986948 13823 solver.cpp:239] Iteration 227200 (9.53594 iter/s, 10.4866s/100 iters), loss = 0.0271415
I0822 22:54:33.986999 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0271411 (* 1 = 0.0271411 loss)
I0822 22:54:33.987010 13823 sgd_solver.cpp:112] Iteration 227200, lr = 1e-06
I0822 22:54:44.538187 13823 solver.cpp:239] Iteration 227300 (9.47753 iter/s, 10.5513s/100 iters), loss = 0.0288745
I0822 22:54:44.538239 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0288741 (* 1 = 0.0288741 loss)
I0822 22:54:44.538249 13823 sgd_solver.cpp:112] Iteration 227300, lr = 1e-06
I0822 22:54:54.900413 13823 solver.cpp:239] Iteration 227400 (9.6504 iter/s, 10.3623s/100 iters), loss = 0.0242597
I0822 22:54:54.900463 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0242593 (* 1 = 0.0242593 loss)
I0822 22:54:54.900473 13823 sgd_solver.cpp:112] Iteration 227400, lr = 1e-06
I0822 22:55:05.560436 13823 solver.cpp:239] Iteration 227500 (9.38081 iter/s, 10.6601s/100 iters), loss = 0.0266757
I0822 22:55:05.560504 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0266752 (* 1 = 0.0266752 loss)
I0822 22:55:05.560519 13823 sgd_solver.cpp:112] Iteration 227500, lr = 1e-06
I0822 22:55:16.107348 13823 solver.cpp:239] Iteration 227600 (9.48143 iter/s, 10.5469s/100 iters), loss = 0.0220019
I0822 22:55:16.107398 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0220014 (* 1 = 0.0220014 loss)
I0822 22:55:16.107409 13823 sgd_solver.cpp:112] Iteration 227600, lr = 1e-06
I0822 22:55:26.657318 13823 solver.cpp:239] Iteration 227700 (9.47867 iter/s, 10.55s/100 iters), loss = 0.0307884
I0822 22:55:26.657368 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.030788 (* 1 = 0.030788 loss)
I0822 22:55:26.657378 13823 sgd_solver.cpp:112] Iteration 227700, lr = 1e-06
I0822 22:55:37.410145 13823 solver.cpp:239] Iteration 227800 (9.29985 iter/s, 10.7529s/100 iters), loss = 0.0265599
I0822 22:55:37.410202 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0265595 (* 1 = 0.0265595 loss)
I0822 22:55:37.410213 13823 sgd_solver.cpp:112] Iteration 227800, lr = 1e-06
I0822 22:55:47.845427 13823 solver.cpp:239] Iteration 227900 (9.58285 iter/s, 10.4353s/100 iters), loss = 0.0249184
I0822 22:55:47.845480 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.024918 (* 1 = 0.024918 loss)
I0822 22:55:47.845490 13823 sgd_solver.cpp:112] Iteration 227900, lr = 1e-06
I0822 22:55:57.964960 13823 solver.cpp:239] Iteration 228000 (9.88185 iter/s, 10.1196s/100 iters), loss = 0.0240293
I0822 22:55:57.965020 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0240288 (* 1 = 0.0240288 loss)
I0822 22:55:57.965034 13823 sgd_solver.cpp:112] Iteration 228000, lr = 1e-06
I0822 22:56:08.353118 13823 solver.cpp:239] Iteration 228100 (9.62632 iter/s, 10.3882s/100 iters), loss = 0.026459
I0822 22:56:08.353186 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0264586 (* 1 = 0.0264586 loss)
I0822 22:56:08.353202 13823 sgd_solver.cpp:112] Iteration 228100, lr = 1e-06
I0822 22:56:18.974844 13823 solver.cpp:239] Iteration 228200 (9.41464 iter/s, 10.6218s/100 iters), loss = 0.0393761
I0822 22:56:18.974895 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0393756 (* 1 = 0.0393756 loss)
I0822 22:56:18.974903 13823 sgd_solver.cpp:112] Iteration 228200, lr = 1e-06
I0822 22:56:29.667448 13823 solver.cpp:239] Iteration 228300 (9.35223 iter/s, 10.6926s/100 iters), loss = 0.0283862
I0822 22:56:29.667502 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0283858 (* 1 = 0.0283858 loss)
I0822 22:56:29.667511 13823 sgd_solver.cpp:112] Iteration 228300, lr = 1e-06
I0822 22:56:40.602025 13823 solver.cpp:239] Iteration 228400 (9.14527 iter/s, 10.9346s/100 iters), loss = 0.028731
I0822 22:56:40.602090 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0287305 (* 1 = 0.0287305 loss)
I0822 22:56:40.602103 13823 sgd_solver.cpp:112] Iteration 228400, lr = 1e-06
I0822 22:56:51.377530 13823 solver.cpp:239] Iteration 228500 (9.28028 iter/s, 10.7755s/100 iters), loss = 0.0282606
I0822 22:56:51.377580 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0282602 (* 1 = 0.0282602 loss)
I0822 22:56:51.377590 13823 sgd_solver.cpp:112] Iteration 228500, lr = 1e-06
I0822 22:57:01.808049 13823 solver.cpp:239] Iteration 228600 (9.58722 iter/s, 10.4306s/100 iters), loss = 0.0268366
I0822 22:57:01.808102 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0268362 (* 1 = 0.0268362 loss)
I0822 22:57:01.808112 13823 sgd_solver.cpp:112] Iteration 228600, lr = 1e-06
I0822 22:57:12.646652 13823 solver.cpp:239] Iteration 228700 (9.22625 iter/s, 10.8386s/100 iters), loss = 0.0257165
I0822 22:57:12.646704 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0257161 (* 1 = 0.0257161 loss)
I0822 22:57:12.646714 13823 sgd_solver.cpp:112] Iteration 228700, lr = 1e-06
I0822 22:57:23.207062 13823 solver.cpp:239] Iteration 228800 (9.4693 iter/s, 10.5604s/100 iters), loss = 0.0300832
I0822 22:57:23.207111 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0300828 (* 1 = 0.0300828 loss)
I0822 22:57:23.207120 13823 sgd_solver.cpp:112] Iteration 228800, lr = 1e-06
I0822 22:57:33.720697 13823 solver.cpp:239] Iteration 228900 (9.51143 iter/s, 10.5137s/100 iters), loss = 0.0283541
I0822 22:57:33.720747 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0283536 (* 1 = 0.0283536 loss)
I0822 22:57:33.720757 13823 sgd_solver.cpp:112] Iteration 228900, lr = 1e-06
I0822 22:57:44.584091 13823 solver.cpp:239] Iteration 229000 (9.20519 iter/s, 10.8634s/100 iters), loss = 0.0284703
I0822 22:57:44.584148 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0284698 (* 1 = 0.0284698 loss)
I0822 22:57:44.584159 13823 sgd_solver.cpp:112] Iteration 229000, lr = 1e-06
I0822 22:57:55.313944 13823 solver.cpp:239] Iteration 229100 (9.31977 iter/s, 10.7299s/100 iters), loss = 0.0240463
I0822 22:57:55.314008 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0240459 (* 1 = 0.0240459 loss)
I0822 22:57:55.314023 13823 sgd_solver.cpp:112] Iteration 229100, lr = 1e-06
I0822 22:58:06.166177 13823 solver.cpp:239] Iteration 229200 (9.21467 iter/s, 10.8523s/100 iters), loss = 0.0251104
I0822 22:58:06.166231 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.02511 (* 1 = 0.02511 loss)
I0822 22:58:06.166241 13823 sgd_solver.cpp:112] Iteration 229200, lr = 1e-06
I0822 22:58:16.900298 13823 solver.cpp:239] Iteration 229300 (9.31606 iter/s, 10.7342s/100 iters), loss = 0.0301083
I0822 22:58:16.900362 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0301078 (* 1 = 0.0301078 loss)
I0822 22:58:16.900378 13823 sgd_solver.cpp:112] Iteration 229300, lr = 1e-06
I0822 22:58:27.820353 13823 solver.cpp:239] Iteration 229400 (9.15744 iter/s, 10.9201s/100 iters), loss = 0.0325622
I0822 22:58:27.820412 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0325618 (* 1 = 0.0325618 loss)
I0822 22:58:27.820423 13823 sgd_solver.cpp:112] Iteration 229400, lr = 1e-06
I0822 22:58:38.991626 13823 solver.cpp:239] Iteration 229500 (8.95151 iter/s, 11.1713s/100 iters), loss = 0.0359997
I0822 22:58:38.991685 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0359992 (* 1 = 0.0359992 loss)
I0822 22:58:38.991696 13823 sgd_solver.cpp:112] Iteration 229500, lr = 1e-06
I0822 22:58:49.717439 13823 solver.cpp:239] Iteration 229600 (9.32328 iter/s, 10.7258s/100 iters), loss = 0.026214
I0822 22:58:49.717490 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0262136 (* 1 = 0.0262136 loss)
I0822 22:58:49.717500 13823 sgd_solver.cpp:112] Iteration 229600, lr = 1e-06
I0822 22:59:00.598393 13823 solver.cpp:239] Iteration 229700 (9.19034 iter/s, 10.881s/100 iters), loss = 0.0331085
I0822 22:59:00.598450 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0331081 (* 1 = 0.0331081 loss)
I0822 22:59:00.598461 13823 sgd_solver.cpp:112] Iteration 229700, lr = 1e-06
I0822 22:59:11.303669 13823 solver.cpp:239] Iteration 229800 (9.34116 iter/s, 10.7053s/100 iters), loss = 0.0266383
I0822 22:59:11.303714 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0266378 (* 1 = 0.0266378 loss)
I0822 22:59:11.303721 13823 sgd_solver.cpp:112] Iteration 229800, lr = 1e-06
I0822 22:59:21.814522 13823 solver.cpp:239] Iteration 229900 (9.51394 iter/s, 10.5109s/100 iters), loss = 0.0488531
I0822 22:59:21.814587 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0488526 (* 1 = 0.0488526 loss)
I0822 22:59:21.814604 13823 sgd_solver.cpp:112] Iteration 229900, lr = 1e-06
I0822 22:59:32.373239 13823 solver.cpp:239] Iteration 230000 (9.47082 iter/s, 10.5587s/100 iters), loss = 0.0274481
I0822 22:59:32.373282 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0274477 (* 1 = 0.0274477 loss)
I0822 22:59:32.373291 13823 sgd_solver.cpp:112] Iteration 230000, lr = 1e-06
I0822 22:59:42.848754 13823 solver.cpp:239] Iteration 230100 (9.54603 iter/s, 10.4756s/100 iters), loss = 0.0230238
I0822 22:59:42.848814 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0230234 (* 1 = 0.0230234 loss)
I0822 22:59:42.848827 13823 sgd_solver.cpp:112] Iteration 230100, lr = 1e-06
I0822 22:59:53.668920 13823 solver.cpp:239] Iteration 230200 (9.24197 iter/s, 10.8202s/100 iters), loss = 0.0282814
I0822 22:59:53.668975 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0282809 (* 1 = 0.0282809 loss)
I0822 22:59:53.668987 13823 sgd_solver.cpp:112] Iteration 230200, lr = 1e-06
I0822 23:00:04.636111 13823 solver.cpp:239] Iteration 230300 (9.11807 iter/s, 10.9672s/100 iters), loss = 0.0243031
I0822 23:00:04.636168 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0243027 (* 1 = 0.0243027 loss)
I0822 23:00:04.636179 13823 sgd_solver.cpp:112] Iteration 230300, lr = 1e-06
I0822 23:00:15.504473 13823 solver.cpp:239] Iteration 230400 (9.20099 iter/s, 10.8684s/100 iters), loss = 0.0247357
I0822 23:00:15.504523 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0247353 (* 1 = 0.0247353 loss)
I0822 23:00:15.504532 13823 sgd_solver.cpp:112] Iteration 230400, lr = 1e-06
I0822 23:00:26.036108 13823 solver.cpp:239] Iteration 230500 (9.49517 iter/s, 10.5317s/100 iters), loss = 0.0268896
I0822 23:00:26.036165 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0268891 (* 1 = 0.0268891 loss)
I0822 23:00:26.036175 13823 sgd_solver.cpp:112] Iteration 230500, lr = 1e-06
I0822 23:00:36.974514 13823 solver.cpp:239] Iteration 230600 (9.14207 iter/s, 10.9384s/100 iters), loss = 0.0247164
I0822 23:00:36.974565 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0247159 (* 1 = 0.0247159 loss)
I0822 23:00:36.974575 13823 sgd_solver.cpp:112] Iteration 230600, lr = 1e-06
I0822 23:00:47.674690 13823 solver.cpp:239] Iteration 230700 (9.34561 iter/s, 10.7002s/100 iters), loss = 0.0254561
I0822 23:00:47.674751 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0254556 (* 1 = 0.0254556 loss)
I0822 23:00:47.674762 13823 sgd_solver.cpp:112] Iteration 230700, lr = 1e-06
I0822 23:00:57.977838 13823 solver.cpp:239] Iteration 230800 (9.70574 iter/s, 10.3032s/100 iters), loss = 0.0375234
I0822 23:00:57.977879 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0375229 (* 1 = 0.0375229 loss)
I0822 23:00:57.977885 13823 sgd_solver.cpp:112] Iteration 230800, lr = 1e-06
I0822 23:01:08.808491 13823 solver.cpp:239] Iteration 230900 (9.23302 iter/s, 10.8307s/100 iters), loss = 0.0366171
I0822 23:01:08.808557 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0366166 (* 1 = 0.0366166 loss)
I0822 23:01:08.808569 13823 sgd_solver.cpp:112] Iteration 230900, lr = 1e-06
I0822 23:01:19.734908 13823 solver.cpp:239] Iteration 231000 (9.15211 iter/s, 10.9264s/100 iters), loss = 0.0332926
I0822 23:01:19.734966 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0332922 (* 1 = 0.0332922 loss)
I0822 23:01:19.734977 13823 sgd_solver.cpp:112] Iteration 231000, lr = 1e-06
I0822 23:01:30.656354 13823 solver.cpp:239] Iteration 231100 (9.15627 iter/s, 10.9215s/100 iters), loss = 0.0258477
I0822 23:01:30.656414 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0258472 (* 1 = 0.0258472 loss)
I0822 23:01:30.656424 13823 sgd_solver.cpp:112] Iteration 231100, lr = 1e-06
I0822 23:01:41.777496 13823 solver.cpp:239] Iteration 231200 (8.99186 iter/s, 11.1212s/100 iters), loss = 0.0353054
I0822 23:01:41.777556 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.035305 (* 1 = 0.035305 loss)
I0822 23:01:41.777567 13823 sgd_solver.cpp:112] Iteration 231200, lr = 1e-06
I0822 23:01:52.767558 13823 solver.cpp:239] Iteration 231300 (9.0991 iter/s, 10.9901s/100 iters), loss = 0.0302492
I0822 23:01:52.767609 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0302488 (* 1 = 0.0302488 loss)
I0822 23:01:52.767619 13823 sgd_solver.cpp:112] Iteration 231300, lr = 1e-06
I0822 23:02:03.756558 13823 solver.cpp:239] Iteration 231400 (9.09998 iter/s, 10.989s/100 iters), loss = 0.0234047
I0822 23:02:03.756618 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0234042 (* 1 = 0.0234042 loss)
I0822 23:02:03.756629 13823 sgd_solver.cpp:112] Iteration 231400, lr = 1e-06
I0822 23:02:14.994702 13823 solver.cpp:239] Iteration 231500 (8.89824 iter/s, 11.2382s/100 iters), loss = 0.0283939
I0822 23:02:14.994757 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0283934 (* 1 = 0.0283934 loss)
I0822 23:02:14.994767 13823 sgd_solver.cpp:112] Iteration 231500, lr = 1e-06
I0822 23:02:25.896862 13823 solver.cpp:239] Iteration 231600 (9.17247 iter/s, 10.9022s/100 iters), loss = 0.039967
I0822 23:02:25.896917 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0399665 (* 1 = 0.0399665 loss)
I0822 23:02:25.896929 13823 sgd_solver.cpp:112] Iteration 231600, lr = 1e-06
I0822 23:02:36.918107 13823 solver.cpp:239] Iteration 231700 (9.07336 iter/s, 11.0213s/100 iters), loss = 0.0290923
I0822 23:02:36.918159 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0290918 (* 1 = 0.0290918 loss)
I0822 23:02:36.918169 13823 sgd_solver.cpp:112] Iteration 231700, lr = 1e-06
I0822 23:02:48.072628 13823 solver.cpp:239] Iteration 231800 (8.96494 iter/s, 11.1546s/100 iters), loss = 0.0261929
I0822 23:02:48.072683 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0261924 (* 1 = 0.0261924 loss)
I0822 23:02:48.072695 13823 sgd_solver.cpp:112] Iteration 231800, lr = 1e-06
I0822 23:02:59.247766 13823 solver.cpp:239] Iteration 231900 (8.94841 iter/s, 11.1752s/100 iters), loss = 0.0400651
I0822 23:02:59.247817 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0400646 (* 1 = 0.0400646 loss)
I0822 23:02:59.247826 13823 sgd_solver.cpp:112] Iteration 231900, lr = 1e-06
I0822 23:03:10.249123 13823 solver.cpp:239] Iteration 232000 (9.08976 iter/s, 11.0014s/100 iters), loss = 0.0316595
I0822 23:03:10.249174 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.031659 (* 1 = 0.031659 loss)
I0822 23:03:10.249184 13823 sgd_solver.cpp:112] Iteration 232000, lr = 1e-06
I0822 23:03:21.366128 13823 solver.cpp:239] Iteration 232100 (8.9952 iter/s, 11.117s/100 iters), loss = 0.267801
I0822 23:03:21.366180 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.2678 (* 1 = 0.2678 loss)
I0822 23:03:21.366190 13823 sgd_solver.cpp:112] Iteration 232100, lr = 1e-06
I0822 23:03:32.496829 13823 solver.cpp:239] Iteration 232200 (8.98413 iter/s, 11.1307s/100 iters), loss = 0.0333977
I0822 23:03:32.496886 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0333972 (* 1 = 0.0333972 loss)
I0822 23:03:32.496898 13823 sgd_solver.cpp:112] Iteration 232200, lr = 1e-06
I0822 23:03:43.743888 13823 solver.cpp:239] Iteration 232300 (8.89119 iter/s, 11.2471s/100 iters), loss = 0.0342649
I0822 23:03:43.743945 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0342645 (* 1 = 0.0342645 loss)
I0822 23:03:43.743957 13823 sgd_solver.cpp:112] Iteration 232300, lr = 1e-06
I0822 23:03:54.724822 13823 solver.cpp:239] Iteration 232400 (9.10667 iter/s, 10.981s/100 iters), loss = 0.0258147
I0822 23:03:54.724877 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0258142 (* 1 = 0.0258142 loss)
I0822 23:03:54.724887 13823 sgd_solver.cpp:112] Iteration 232400, lr = 1e-06
I0822 23:04:05.803925 13823 solver.cpp:239] Iteration 232500 (9.02597 iter/s, 11.0791s/100 iters), loss = 0.0259933
I0822 23:04:05.803975 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0259929 (* 1 = 0.0259929 loss)
I0822 23:04:05.803984 13823 sgd_solver.cpp:112] Iteration 232500, lr = 1e-06
I0822 23:04:17.034116 13823 solver.cpp:239] Iteration 232600 (8.90454 iter/s, 11.2302s/100 iters), loss = 0.0249293
I0822 23:04:17.034174 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0249289 (* 1 = 0.0249289 loss)
I0822 23:04:17.034185 13823 sgd_solver.cpp:112] Iteration 232600, lr = 1e-06
I0822 23:04:28.110064 13823 solver.cpp:239] Iteration 232700 (9.02855 iter/s, 11.076s/100 iters), loss = 0.0246437
I0822 23:04:28.110121 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0246432 (* 1 = 0.0246432 loss)
I0822 23:04:28.110131 13823 sgd_solver.cpp:112] Iteration 232700, lr = 1e-06
I0822 23:04:39.047410 13823 solver.cpp:239] Iteration 232800 (9.14296 iter/s, 10.9374s/100 iters), loss = 0.0243545
I0822 23:04:39.047467 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0243541 (* 1 = 0.0243541 loss)
I0822 23:04:39.047479 13823 sgd_solver.cpp:112] Iteration 232800, lr = 1e-06
I0822 23:04:50.308502 13823 solver.cpp:239] Iteration 232900 (8.88011 iter/s, 11.2611s/100 iters), loss = 0.0225434
I0822 23:04:50.308564 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0225429 (* 1 = 0.0225429 loss)
I0822 23:04:50.308576 13823 sgd_solver.cpp:112] Iteration 232900, lr = 1e-06
I0822 23:05:01.401661 13823 solver.cpp:239] Iteration 233000 (9.01454 iter/s, 11.0932s/100 iters), loss = 0.0289189
I0822 23:05:01.401720 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0289184 (* 1 = 0.0289184 loss)
I0822 23:05:01.401731 13823 sgd_solver.cpp:112] Iteration 233000, lr = 1e-06
I0822 23:05:12.605645 13823 solver.cpp:239] Iteration 233100 (8.92537 iter/s, 11.204s/100 iters), loss = 0.0262978
I0822 23:05:12.605696 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0262973 (* 1 = 0.0262973 loss)
I0822 23:05:12.605705 13823 sgd_solver.cpp:112] Iteration 233100, lr = 1e-06
I0822 23:05:23.623926 13823 solver.cpp:239] Iteration 233200 (9.07579 iter/s, 11.0183s/100 iters), loss = 0.032983
I0822 23:05:23.623977 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0329825 (* 1 = 0.0329825 loss)
I0822 23:05:23.623987 13823 sgd_solver.cpp:112] Iteration 233200, lr = 1e-06
I0822 23:05:34.453084 13823 solver.cpp:239] Iteration 233300 (9.2343 iter/s, 10.8292s/100 iters), loss = 0.026971
I0822 23:05:34.453137 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0269706 (* 1 = 0.0269706 loss)
I0822 23:05:34.453147 13823 sgd_solver.cpp:112] Iteration 233300, lr = 1e-06
I0822 23:05:45.389362 13823 solver.cpp:239] Iteration 233400 (9.14385 iter/s, 10.9363s/100 iters), loss = 0.0352779
I0822 23:05:45.389410 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0352774 (* 1 = 0.0352774 loss)
I0822 23:05:45.389420 13823 sgd_solver.cpp:112] Iteration 233400, lr = 1e-06
I0822 23:05:56.628334 13823 solver.cpp:239] Iteration 233500 (8.89758 iter/s, 11.239s/100 iters), loss = 0.0264153
I0822 23:05:56.628386 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0264148 (* 1 = 0.0264148 loss)
I0822 23:05:56.628396 13823 sgd_solver.cpp:112] Iteration 233500, lr = 1e-06
I0822 23:06:07.895247 13823 solver.cpp:239] Iteration 233600 (8.87552 iter/s, 11.267s/100 iters), loss = 0.0277131
I0822 23:06:07.895306 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0277127 (* 1 = 0.0277127 loss)
I0822 23:06:07.895318 13823 sgd_solver.cpp:112] Iteration 233600, lr = 1e-06
I0822 23:06:18.883970 13823 solver.cpp:239] Iteration 233700 (9.10021 iter/s, 10.9888s/100 iters), loss = 0.025924
I0822 23:06:18.884025 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0259235 (* 1 = 0.0259235 loss)
I0822 23:06:18.884037 13823 sgd_solver.cpp:112] Iteration 233700, lr = 1e-06
I0822 23:06:30.103863 13823 solver.cpp:239] Iteration 233800 (8.91271 iter/s, 11.2199s/100 iters), loss = 0.0256512
I0822 23:06:30.103919 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0256508 (* 1 = 0.0256508 loss)
I0822 23:06:30.103930 13823 sgd_solver.cpp:112] Iteration 233800, lr = 1e-06
I0822 23:06:41.134671 13823 solver.cpp:239] Iteration 233900 (9.06549 iter/s, 11.0308s/100 iters), loss = 0.0264581
I0822 23:06:41.134724 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0264577 (* 1 = 0.0264577 loss)
I0822 23:06:41.134734 13823 sgd_solver.cpp:112] Iteration 233900, lr = 1e-06
I0822 23:06:52.013016 13823 solver.cpp:239] Iteration 234000 (9.19255 iter/s, 10.8784s/100 iters), loss = 0.0284213
I0822 23:06:52.013067 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0284208 (* 1 = 0.0284208 loss)
I0822 23:06:52.013077 13823 sgd_solver.cpp:112] Iteration 234000, lr = 1e-06
I0822 23:07:02.751238 13823 solver.cpp:239] Iteration 234100 (9.3125 iter/s, 10.7383s/100 iters), loss = 0.0273326
I0822 23:07:02.751288 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0273322 (* 1 = 0.0273322 loss)
I0822 23:07:02.751298 13823 sgd_solver.cpp:112] Iteration 234100, lr = 1e-06
I0822 23:07:13.847741 13823 solver.cpp:239] Iteration 234200 (9.01182 iter/s, 11.0965s/100 iters), loss = 0.0232945
I0822 23:07:13.847791 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.023294 (* 1 = 0.023294 loss)
I0822 23:07:13.847800 13823 sgd_solver.cpp:112] Iteration 234200, lr = 1e-06
I0822 23:07:25.027320 13823 solver.cpp:239] Iteration 234300 (8.94485 iter/s, 11.1796s/100 iters), loss = 0.0275045
I0822 23:07:25.027375 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0275041 (* 1 = 0.0275041 loss)
I0822 23:07:25.027385 13823 sgd_solver.cpp:112] Iteration 234300, lr = 1e-06
I0822 23:07:36.455837 13823 solver.cpp:239] Iteration 234400 (8.75001 iter/s, 11.4286s/100 iters), loss = 0.0447082
I0822 23:07:36.455888 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0447078 (* 1 = 0.0447078 loss)
I0822 23:07:36.455896 13823 sgd_solver.cpp:112] Iteration 234400, lr = 1e-06
I0822 23:07:47.942888 13823 solver.cpp:239] Iteration 234500 (8.70542 iter/s, 11.4871s/100 iters), loss = 0.0251558
I0822 23:07:47.942945 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0251554 (* 1 = 0.0251554 loss)
I0822 23:07:47.942955 13823 sgd_solver.cpp:112] Iteration 234500, lr = 1e-06
I0822 23:07:59.361323 13823 solver.cpp:239] Iteration 234600 (8.75774 iter/s, 11.4185s/100 iters), loss = 0.027247
I0822 23:07:59.361388 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0272466 (* 1 = 0.0272466 loss)
I0822 23:07:59.361402 13823 sgd_solver.cpp:112] Iteration 234600, lr = 1e-06
I0822 23:08:10.621552 13823 solver.cpp:239] Iteration 234700 (8.88079 iter/s, 11.2603s/100 iters), loss = 0.0292606
I0822 23:08:10.621603 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0292601 (* 1 = 0.0292601 loss)
I0822 23:08:10.621613 13823 sgd_solver.cpp:112] Iteration 234700, lr = 1e-06
I0822 23:08:22.035491 13823 solver.cpp:239] Iteration 234800 (8.76119 iter/s, 11.414s/100 iters), loss = 0.0318493
I0822 23:08:22.035542 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0318488 (* 1 = 0.0318488 loss)
I0822 23:08:22.035550 13823 sgd_solver.cpp:112] Iteration 234800, lr = 1e-06
I0822 23:08:33.216707 13823 solver.cpp:239] Iteration 234900 (8.94354 iter/s, 11.1813s/100 iters), loss = 0.0234344
I0822 23:08:33.216758 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0234339 (* 1 = 0.0234339 loss)
I0822 23:08:33.216766 13823 sgd_solver.cpp:112] Iteration 234900, lr = 1e-06
I0822 23:08:44.354138 13823 solver.cpp:239] Iteration 235000 (8.9787 iter/s, 11.1375s/100 iters), loss = 0.0237247
I0822 23:08:44.354194 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0237242 (* 1 = 0.0237242 loss)
I0822 23:08:44.354204 13823 sgd_solver.cpp:112] Iteration 235000, lr = 1e-06
I0822 23:08:55.611783 13823 solver.cpp:239] Iteration 235100 (8.88282 iter/s, 11.2577s/100 iters), loss = 0.0334746
I0822 23:08:55.611833 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0334741 (* 1 = 0.0334741 loss)
I0822 23:08:55.611843 13823 sgd_solver.cpp:112] Iteration 235100, lr = 1e-06
I0822 23:09:06.665832 13823 solver.cpp:239] Iteration 235200 (9.04643 iter/s, 11.0541s/100 iters), loss = 0.0261216
I0822 23:09:06.665882 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0261211 (* 1 = 0.0261211 loss)
I0822 23:09:06.665892 13823 sgd_solver.cpp:112] Iteration 235200, lr = 1e-06
I0822 23:09:17.899186 13823 solver.cpp:239] Iteration 235300 (8.90203 iter/s, 11.2334s/100 iters), loss = 0.0423634
I0822 23:09:17.899235 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0423629 (* 1 = 0.0423629 loss)
I0822 23:09:17.899245 13823 sgd_solver.cpp:112] Iteration 235300, lr = 1e-06
I0822 23:09:29.154747 13823 solver.cpp:239] Iteration 235400 (8.88447 iter/s, 11.2556s/100 iters), loss = 0.0301948
I0822 23:09:29.154798 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0301943 (* 1 = 0.0301943 loss)
I0822 23:09:29.154808 13823 sgd_solver.cpp:112] Iteration 235400, lr = 1e-06
I0822 23:09:40.443631 13823 solver.cpp:239] Iteration 235500 (8.85824 iter/s, 11.2889s/100 iters), loss = 0.0223383
I0822 23:09:40.443687 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0223378 (* 1 = 0.0223378 loss)
I0822 23:09:40.443697 13823 sgd_solver.cpp:112] Iteration 235500, lr = 1e-06
I0822 23:09:51.621107 13823 solver.cpp:239] Iteration 235600 (8.94654 iter/s, 11.1775s/100 iters), loss = 0.206606
I0822 23:09:51.621160 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.206605 (* 1 = 0.206605 loss)
I0822 23:09:51.621170 13823 sgd_solver.cpp:112] Iteration 235600, lr = 1e-06
I0822 23:10:02.752099 13823 solver.cpp:239] Iteration 235700 (8.98389 iter/s, 11.131s/100 iters), loss = 0.0361979
I0822 23:10:02.752151 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0361974 (* 1 = 0.0361974 loss)
I0822 23:10:02.752159 13823 sgd_solver.cpp:112] Iteration 235700, lr = 1e-06
I0822 23:10:13.943542 13823 solver.cpp:239] Iteration 235800 (8.93537 iter/s, 11.1915s/100 iters), loss = 0.0326737
I0822 23:10:13.943593 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0326732 (* 1 = 0.0326732 loss)
I0822 23:10:13.943603 13823 sgd_solver.cpp:112] Iteration 235800, lr = 1e-06
I0822 23:10:25.208061 13823 solver.cpp:239] Iteration 235900 (8.8774 iter/s, 11.2646s/100 iters), loss = 0.0298679
I0822 23:10:25.208120 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0298674 (* 1 = 0.0298674 loss)
I0822 23:10:25.208137 13823 sgd_solver.cpp:112] Iteration 235900, lr = 1e-06
I0822 23:10:36.694159 13823 solver.cpp:239] Iteration 236000 (8.70615 iter/s, 11.4861s/100 iters), loss = 0.0294349
I0822 23:10:36.694213 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0294344 (* 1 = 0.0294344 loss)
I0822 23:10:36.694223 13823 sgd_solver.cpp:112] Iteration 236000, lr = 1e-06
I0822 23:10:48.011435 13823 solver.cpp:239] Iteration 236100 (8.83602 iter/s, 11.3173s/100 iters), loss = 0.0399052
I0822 23:10:48.011483 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0399048 (* 1 = 0.0399048 loss)
I0822 23:10:48.011492 13823 sgd_solver.cpp:112] Iteration 236100, lr = 1e-06
I0822 23:10:59.382789 13823 solver.cpp:239] Iteration 236200 (8.79399 iter/s, 11.3714s/100 iters), loss = 0.0254418
I0822 23:10:59.382850 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0254414 (* 1 = 0.0254414 loss)
I0822 23:10:59.382863 13823 sgd_solver.cpp:112] Iteration 236200, lr = 1e-06
I0822 23:11:10.944141 13823 solver.cpp:239] Iteration 236300 (8.64948 iter/s, 11.5614s/100 iters), loss = 0.0254359
I0822 23:11:10.944192 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0254355 (* 1 = 0.0254355 loss)
I0822 23:11:10.944201 13823 sgd_solver.cpp:112] Iteration 236300, lr = 1e-06
I0822 23:11:22.460275 13823 solver.cpp:239] Iteration 236400 (8.68344 iter/s, 11.5162s/100 iters), loss = 0.0255695
I0822 23:11:22.460331 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.025569 (* 1 = 0.025569 loss)
I0822 23:11:22.460341 13823 sgd_solver.cpp:112] Iteration 236400, lr = 1e-06
I0822 23:11:34.149027 13823 solver.cpp:239] Iteration 236500 (8.55521 iter/s, 11.6888s/100 iters), loss = 0.02738
I0822 23:11:34.149086 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0273796 (* 1 = 0.0273796 loss)
I0822 23:11:34.149099 13823 sgd_solver.cpp:112] Iteration 236500, lr = 1e-06
I0822 23:11:45.728508 13823 solver.cpp:239] Iteration 236600 (8.63594 iter/s, 11.5795s/100 iters), loss = 0.0284898
I0822 23:11:45.728565 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0284894 (* 1 = 0.0284894 loss)
I0822 23:11:45.728579 13823 sgd_solver.cpp:112] Iteration 236600, lr = 1e-06
I0822 23:11:57.306227 13823 solver.cpp:239] Iteration 236700 (8.63725 iter/s, 11.5778s/100 iters), loss = 0.0262723
I0822 23:11:57.306285 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0262718 (* 1 = 0.0262718 loss)
I0822 23:11:57.306296 13823 sgd_solver.cpp:112] Iteration 236700, lr = 1e-06
I0822 23:12:08.877454 13823 solver.cpp:239] Iteration 236800 (8.6421 iter/s, 11.5713s/100 iters), loss = 0.05312
I0822 23:12:08.877514 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0531195 (* 1 = 0.0531195 loss)
I0822 23:12:08.877527 13823 sgd_solver.cpp:112] Iteration 236800, lr = 1e-06
I0822 23:12:20.391029 13823 solver.cpp:239] Iteration 236900 (8.68538 iter/s, 11.5136s/100 iters), loss = 0.0286021
I0822 23:12:20.391103 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0286016 (* 1 = 0.0286016 loss)
I0822 23:12:20.391121 13823 sgd_solver.cpp:112] Iteration 236900, lr = 1e-06
I0822 23:12:31.781430 13823 solver.cpp:239] Iteration 237000 (8.77931 iter/s, 11.3904s/100 iters), loss = 0.0292723
I0822 23:12:31.781494 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0292718 (* 1 = 0.0292718 loss)
I0822 23:12:31.781507 13823 sgd_solver.cpp:112] Iteration 237000, lr = 1e-06
I0822 23:12:43.270035 13823 solver.cpp:239] Iteration 237100 (8.70426 iter/s, 11.4886s/100 iters), loss = 0.0242491
I0822 23:12:43.270092 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0242486 (* 1 = 0.0242486 loss)
I0822 23:12:43.270104 13823 sgd_solver.cpp:112] Iteration 237100, lr = 1e-06
I0822 23:12:54.724826 13823 solver.cpp:239] Iteration 237200 (8.72994 iter/s, 11.4548s/100 iters), loss = 0.0273592
I0822 23:12:54.724884 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0273587 (* 1 = 0.0273587 loss)
I0822 23:12:54.724896 13823 sgd_solver.cpp:112] Iteration 237200, lr = 1e-06
I0822 23:13:06.198933 13823 solver.cpp:239] Iteration 237300 (8.71525 iter/s, 11.4741s/100 iters), loss = 0.0284971
I0822 23:13:06.198992 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0284966 (* 1 = 0.0284966 loss)
I0822 23:13:06.199004 13823 sgd_solver.cpp:112] Iteration 237300, lr = 1e-06
I0822 23:13:17.426255 13823 solver.cpp:239] Iteration 237400 (8.90682 iter/s, 11.2274s/100 iters), loss = 0.0253335
I0822 23:13:17.426314 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.025333 (* 1 = 0.025333 loss)
I0822 23:13:17.426326 13823 sgd_solver.cpp:112] Iteration 237400, lr = 1e-06
I0822 23:13:27.011126 13823 solver.cpp:239] Iteration 237500 (10.4331 iter/s, 9.58489s/100 iters), loss = 0.0252463
I0822 23:13:27.011178 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0252458 (* 1 = 0.0252458 loss)
I0822 23:13:27.011188 13823 sgd_solver.cpp:112] Iteration 237500, lr = 1e-06
I0822 23:13:36.629596 13823 solver.cpp:239] Iteration 237600 (10.3966 iter/s, 9.61849s/100 iters), loss = 0.0248636
I0822 23:13:36.629647 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0248631 (* 1 = 0.0248631 loss)
I0822 23:13:36.629657 13823 sgd_solver.cpp:112] Iteration 237600, lr = 1e-06
I0822 23:13:46.078148 13823 solver.cpp:239] Iteration 237700 (10.5836 iter/s, 9.44858s/100 iters), loss = 0.0248514
I0822 23:13:46.078191 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0248509 (* 1 = 0.0248509 loss)
I0822 23:13:46.078198 13823 sgd_solver.cpp:112] Iteration 237700, lr = 1e-06
I0822 23:13:55.537098 13823 solver.cpp:239] Iteration 237800 (10.572 iter/s, 9.45898s/100 iters), loss = 0.0263478
I0822 23:13:55.537144 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0263473 (* 1 = 0.0263473 loss)
I0822 23:13:55.537166 13823 sgd_solver.cpp:112] Iteration 237800, lr = 1e-06
I0822 23:14:05.064297 13823 solver.cpp:239] Iteration 237900 (10.4962 iter/s, 9.52723s/100 iters), loss = 0.0278799
I0822 23:14:05.064344 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0278794 (* 1 = 0.0278794 loss)
I0822 23:14:05.064352 13823 sgd_solver.cpp:112] Iteration 237900, lr = 1e-06
I0822 23:14:14.929951 13823 solver.cpp:239] Iteration 238000 (10.1361 iter/s, 9.86568s/100 iters), loss = 0.0232198
I0822 23:14:14.930001 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0232193 (* 1 = 0.0232193 loss)
I0822 23:14:14.930011 13823 sgd_solver.cpp:112] Iteration 238000, lr = 1e-06
I0822 23:14:24.610721 13823 solver.cpp:239] Iteration 238100 (10.3297 iter/s, 9.6808s/100 iters), loss = 0.0266806
I0822 23:14:24.610774 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0266801 (* 1 = 0.0266801 loss)
I0822 23:14:24.610783 13823 sgd_solver.cpp:112] Iteration 238100, lr = 1e-06
I0822 23:14:33.974864 13823 solver.cpp:239] Iteration 238200 (10.679 iter/s, 9.36416s/100 iters), loss = 0.0279487
I0822 23:14:33.974915 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0279482 (* 1 = 0.0279482 loss)
I0822 23:14:33.974925 13823 sgd_solver.cpp:112] Iteration 238200, lr = 1e-06
I0822 23:14:43.626713 13823 solver.cpp:239] Iteration 238300 (10.3607 iter/s, 9.65187s/100 iters), loss = 0.0244734
I0822 23:14:43.626761 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0244729 (* 1 = 0.0244729 loss)
I0822 23:14:43.626770 13823 sgd_solver.cpp:112] Iteration 238300, lr = 1e-06
I0822 23:14:53.199393 13823 solver.cpp:239] Iteration 238400 (10.4464 iter/s, 9.5727s/100 iters), loss = 0.0262381
I0822 23:14:53.199453 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0262376 (* 1 = 0.0262376 loss)
I0822 23:14:53.199465 13823 sgd_solver.cpp:112] Iteration 238400, lr = 1e-06
I0822 23:15:02.983125 13823 solver.cpp:239] Iteration 238500 (10.221 iter/s, 9.78375s/100 iters), loss = 0.0255925
I0822 23:15:02.983176 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.025592 (* 1 = 0.025592 loss)
I0822 23:15:02.983186 13823 sgd_solver.cpp:112] Iteration 238500, lr = 1e-06
I0822 23:15:12.890192 13823 solver.cpp:239] Iteration 238600 (10.0938 iter/s, 9.90709s/100 iters), loss = 0.0292568
I0822 23:15:12.890244 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0292563 (* 1 = 0.0292563 loss)
I0822 23:15:12.890254 13823 sgd_solver.cpp:112] Iteration 238600, lr = 1e-06
I0822 23:15:22.323987 13823 solver.cpp:239] Iteration 238700 (10.6002 iter/s, 9.43382s/100 iters), loss = 0.0390846
I0822 23:15:22.324035 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0390841 (* 1 = 0.0390841 loss)
I0822 23:15:22.324044 13823 sgd_solver.cpp:112] Iteration 238700, lr = 1e-06
I0822 23:15:32.131286 13823 solver.cpp:239] Iteration 238800 (10.1965 iter/s, 9.80733s/100 iters), loss = 0.0292626
I0822 23:15:32.131337 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.029262 (* 1 = 0.029262 loss)
I0822 23:15:32.131346 13823 sgd_solver.cpp:112] Iteration 238800, lr = 1e-06
I0822 23:15:41.713289 13823 solver.cpp:239] Iteration 238900 (10.4362 iter/s, 9.58203s/100 iters), loss = 0.0264982
I0822 23:15:41.713330 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0264977 (* 1 = 0.0264977 loss)
I0822 23:15:41.713338 13823 sgd_solver.cpp:112] Iteration 238900, lr = 1e-06
I0822 23:15:51.289472 13823 solver.cpp:239] Iteration 239000 (10.4425 iter/s, 9.57621s/100 iters), loss = 0.0295107
I0822 23:15:51.289521 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0295102 (* 1 = 0.0295102 loss)
I0822 23:15:51.289530 13823 sgd_solver.cpp:112] Iteration 239000, lr = 1e-06
I0822 23:16:00.689292 13823 solver.cpp:239] Iteration 239100 (10.6385 iter/s, 9.39985s/100 iters), loss = 0.0284191
I0822 23:16:00.689332 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0284186 (* 1 = 0.0284186 loss)
I0822 23:16:00.689338 13823 sgd_solver.cpp:112] Iteration 239100, lr = 1e-06
I0822 23:16:10.203418 13823 solver.cpp:239] Iteration 239200 (10.5107 iter/s, 9.51416s/100 iters), loss = 0.0260624
I0822 23:16:10.203470 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0260619 (* 1 = 0.0260619 loss)
I0822 23:16:10.203480 13823 sgd_solver.cpp:112] Iteration 239200, lr = 1e-06
I0822 23:16:19.832958 13823 solver.cpp:239] Iteration 239300 (10.3847 iter/s, 9.62956s/100 iters), loss = 0.0282816
I0822 23:16:19.833009 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0282811 (* 1 = 0.0282811 loss)
I0822 23:16:19.833019 13823 sgd_solver.cpp:112] Iteration 239300, lr = 1e-06
I0822 23:16:29.279247 13823 solver.cpp:239] Iteration 239400 (10.5861 iter/s, 9.44632s/100 iters), loss = 0.029319
I0822 23:16:29.279287 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0293185 (* 1 = 0.0293185 loss)
I0822 23:16:29.279294 13823 sgd_solver.cpp:112] Iteration 239400, lr = 1e-06
I0822 23:16:38.860100 13823 solver.cpp:239] Iteration 239500 (10.4375 iter/s, 9.58088s/100 iters), loss = 0.0253602
I0822 23:16:38.860153 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0253597 (* 1 = 0.0253597 loss)
I0822 23:16:38.860164 13823 sgd_solver.cpp:112] Iteration 239500, lr = 1e-06
I0822 23:16:48.493372 13823 solver.cpp:239] Iteration 239600 (10.3807 iter/s, 9.63329s/100 iters), loss = 0.0251529
I0822 23:16:48.493435 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0251524 (* 1 = 0.0251524 loss)
I0822 23:16:48.493448 13823 sgd_solver.cpp:112] Iteration 239600, lr = 1e-06
I0822 23:16:58.170083 13823 solver.cpp:239] Iteration 239700 (10.3341 iter/s, 9.67672s/100 iters), loss = 0.0277441
I0822 23:16:58.170145 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0277436 (* 1 = 0.0277436 loss)
I0822 23:16:58.170157 13823 sgd_solver.cpp:112] Iteration 239700, lr = 1e-06
I0822 23:17:08.273146 13823 solver.cpp:239] Iteration 239800 (9.89797 iter/s, 10.1031s/100 iters), loss = 0.0225953
I0822 23:17:08.273208 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0225948 (* 1 = 0.0225948 loss)
I0822 23:17:08.273219 13823 sgd_solver.cpp:112] Iteration 239800, lr = 1e-06
I0822 23:17:17.820858 13823 solver.cpp:239] Iteration 239900 (10.4737 iter/s, 9.54773s/100 iters), loss = 0.031268
I0822 23:17:17.820909 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0312675 (* 1 = 0.0312675 loss)
I0822 23:17:17.820919 13823 sgd_solver.cpp:112] Iteration 239900, lr = 1e-06
I0822 23:17:27.485307 13823 solver.cpp:464] Snapshotting to binary proto file ./model_112/cascade_mobilenet_112_iter_240000.caffemodel
I0822 23:17:27.528152 13823 sgd_solver.cpp:284] Snapshotting solver state to binary proto file ./model_112/cascade_mobilenet_112_iter_240000.solverstate
I0822 23:17:27.559229 13823 solver.cpp:347] Iteration 240000, Testing net (#0)
I0822 23:18:30.868911 13823 solver.cpp:414]     Test net output #0: landmark_loss = 0.0219227 (* 1 = 0.0219227 loss)
I0822 23:18:30.961520 13823 solver.cpp:239] Iteration 240000 (1.36722 iter/s, 73.1412s/100 iters), loss = 0.0256581
I0822 23:18:30.961560 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0256576 (* 1 = 0.0256576 loss)
I0822 23:18:30.961576 13823 sgd_solver.cpp:112] Iteration 240000, lr = 1e-06
I0822 23:18:41.188822 13823 solver.cpp:239] Iteration 240100 (9.77771 iter/s, 10.2273s/100 iters), loss = 0.0265135
I0822 23:18:41.188874 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.026513 (* 1 = 0.026513 loss)
I0822 23:18:41.188884 13823 sgd_solver.cpp:112] Iteration 240100, lr = 1e-06
I0822 23:18:51.210216 13823 solver.cpp:239] Iteration 240200 (9.97862 iter/s, 10.0214s/100 iters), loss = 0.025282
I0822 23:18:51.210270 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0252815 (* 1 = 0.0252815 loss)
I0822 23:18:51.210280 13823 sgd_solver.cpp:112] Iteration 240200, lr = 1e-06
I0822 23:19:01.150856 13823 solver.cpp:239] Iteration 240300 (10.0597 iter/s, 9.94067s/100 iters), loss = 0.0265006
I0822 23:19:01.150897 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0265001 (* 1 = 0.0265001 loss)
I0822 23:19:01.150904 13823 sgd_solver.cpp:112] Iteration 240300, lr = 1e-06
I0822 23:19:11.114488 13823 solver.cpp:239] Iteration 240400 (10.0365 iter/s, 9.96367s/100 iters), loss = 0.0288518
I0822 23:19:11.114537 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0288513 (* 1 = 0.0288513 loss)
I0822 23:19:11.114545 13823 sgd_solver.cpp:112] Iteration 240400, lr = 1e-06
I0822 23:19:20.814378 13823 solver.cpp:239] Iteration 240500 (10.3094 iter/s, 9.69992s/100 iters), loss = 0.0363248
I0822 23:19:20.814429 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0363243 (* 1 = 0.0363243 loss)
I0822 23:19:20.814438 13823 sgd_solver.cpp:112] Iteration 240500, lr = 1e-06
I0822 23:19:30.578536 13823 solver.cpp:239] Iteration 240600 (10.2415 iter/s, 9.76418s/100 iters), loss = 0.0244342
I0822 23:19:30.578600 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0244337 (* 1 = 0.0244337 loss)
I0822 23:19:30.578613 13823 sgd_solver.cpp:112] Iteration 240600, lr = 1e-06
I0822 23:19:40.493261 13823 solver.cpp:239] Iteration 240700 (10.086 iter/s, 9.91474s/100 iters), loss = 0.0229429
I0822 23:19:40.493324 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0229424 (* 1 = 0.0229424 loss)
I0822 23:19:40.493336 13823 sgd_solver.cpp:112] Iteration 240700, lr = 1e-06
I0822 23:19:50.303756 13823 solver.cpp:239] Iteration 240800 (10.1931 iter/s, 9.81051s/100 iters), loss = 0.028949
I0822 23:19:50.303814 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0289485 (* 1 = 0.0289485 loss)
I0822 23:19:50.303827 13823 sgd_solver.cpp:112] Iteration 240800, lr = 1e-06
I0822 23:20:00.217018 13823 solver.cpp:239] Iteration 240900 (10.0875 iter/s, 9.91328s/100 iters), loss = 0.0257505
I0822 23:20:00.217072 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.02575 (* 1 = 0.02575 loss)
I0822 23:20:00.217082 13823 sgd_solver.cpp:112] Iteration 240900, lr = 1e-06
I0822 23:20:10.017428 13823 solver.cpp:239] Iteration 241000 (10.2036 iter/s, 9.80044s/100 iters), loss = 0.0292362
I0822 23:20:10.017480 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0292357 (* 1 = 0.0292357 loss)
I0822 23:20:10.017489 13823 sgd_solver.cpp:112] Iteration 241000, lr = 1e-06
I0822 23:20:19.953083 13823 solver.cpp:239] Iteration 241100 (10.0647 iter/s, 9.93568s/100 iters), loss = 0.0244012
I0822 23:20:19.953136 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0244007 (* 1 = 0.0244007 loss)
I0822 23:20:19.953146 13823 sgd_solver.cpp:112] Iteration 241100, lr = 1e-06
I0822 23:20:29.803802 13823 solver.cpp:239] Iteration 241200 (10.1515 iter/s, 9.85074s/100 iters), loss = 0.025174
I0822 23:20:29.803853 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0251736 (* 1 = 0.0251736 loss)
I0822 23:20:29.803862 13823 sgd_solver.cpp:112] Iteration 241200, lr = 1e-06
I0822 23:20:39.822495 13823 solver.cpp:239] Iteration 241300 (9.98131 iter/s, 10.0187s/100 iters), loss = 0.0279144
I0822 23:20:39.822548 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0279139 (* 1 = 0.0279139 loss)
I0822 23:20:39.822558 13823 sgd_solver.cpp:112] Iteration 241300, lr = 1e-06
I0822 23:20:49.927112 13823 solver.cpp:239] Iteration 241400 (9.89644 iter/s, 10.1046s/100 iters), loss = 0.0269607
I0822 23:20:49.927171 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0269602 (* 1 = 0.0269602 loss)
I0822 23:20:49.927183 13823 sgd_solver.cpp:112] Iteration 241400, lr = 1e-06
I0822 23:20:59.779218 13823 solver.cpp:239] Iteration 241500 (10.1501 iter/s, 9.85213s/100 iters), loss = 0.0273172
I0822 23:20:59.779269 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0273167 (* 1 = 0.0273167 loss)
I0822 23:20:59.779279 13823 sgd_solver.cpp:112] Iteration 241500, lr = 1e-06
I0822 23:21:09.818411 13823 solver.cpp:239] Iteration 241600 (9.96093 iter/s, 10.0392s/100 iters), loss = 0.0231204
I0822 23:21:09.818472 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0231199 (* 1 = 0.0231199 loss)
I0822 23:21:09.818485 13823 sgd_solver.cpp:112] Iteration 241600, lr = 1e-06
I0822 23:21:19.854815 13823 solver.cpp:239] Iteration 241700 (9.96371 iter/s, 10.0364s/100 iters), loss = 0.0288963
I0822 23:21:19.854867 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0288958 (* 1 = 0.0288958 loss)
I0822 23:21:19.854876 13823 sgd_solver.cpp:112] Iteration 241700, lr = 1e-06
I0822 23:21:29.902806 13823 solver.cpp:239] Iteration 241800 (9.95221 iter/s, 10.048s/100 iters), loss = 0.0245359
I0822 23:21:29.902856 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0245354 (* 1 = 0.0245354 loss)
I0822 23:21:29.902866 13823 sgd_solver.cpp:112] Iteration 241800, lr = 1e-06
I0822 23:21:39.791999 13823 solver.cpp:239] Iteration 241900 (10.112 iter/s, 9.88922s/100 iters), loss = 0.0242098
I0822 23:21:39.792049 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0242093 (* 1 = 0.0242093 loss)
I0822 23:21:39.792058 13823 sgd_solver.cpp:112] Iteration 241900, lr = 1e-06
I0822 23:21:49.965216 13823 solver.cpp:239] Iteration 242000 (9.8297 iter/s, 10.1732s/100 iters), loss = 0.0348452
I0822 23:21:49.965268 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0348447 (* 1 = 0.0348447 loss)
I0822 23:21:49.965278 13823 sgd_solver.cpp:112] Iteration 242000, lr = 1e-06
I0822 23:22:00.053259 13823 solver.cpp:239] Iteration 242100 (9.91269 iter/s, 10.0881s/100 iters), loss = 0.0259798
I0822 23:22:00.053300 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0259793 (* 1 = 0.0259793 loss)
I0822 23:22:00.053308 13823 sgd_solver.cpp:112] Iteration 242100, lr = 1e-06
I0822 23:22:09.863915 13823 solver.cpp:239] Iteration 242200 (10.193 iter/s, 9.81069s/100 iters), loss = 0.024977
I0822 23:22:09.863968 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0249765 (* 1 = 0.0249765 loss)
I0822 23:22:09.863978 13823 sgd_solver.cpp:112] Iteration 242200, lr = 1e-06
I0822 23:22:20.085887 13823 solver.cpp:239] Iteration 242300 (9.78282 iter/s, 10.222s/100 iters), loss = 0.0251417
I0822 23:22:20.085937 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0251412 (* 1 = 0.0251412 loss)
I0822 23:22:20.085947 13823 sgd_solver.cpp:112] Iteration 242300, lr = 1e-06
I0822 23:22:30.151330 13823 solver.cpp:239] Iteration 242400 (9.93495 iter/s, 10.0655s/100 iters), loss = 0.0315751
I0822 23:22:30.151382 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0315746 (* 1 = 0.0315746 loss)
I0822 23:22:30.151391 13823 sgd_solver.cpp:112] Iteration 242400, lr = 1e-06
I0822 23:22:40.495106 13823 solver.cpp:239] Iteration 242500 (9.66762 iter/s, 10.3438s/100 iters), loss = 0.0296116
I0822 23:22:40.495157 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0296111 (* 1 = 0.0296111 loss)
I0822 23:22:40.495167 13823 sgd_solver.cpp:112] Iteration 242500, lr = 1e-06
I0822 23:22:50.569471 13823 solver.cpp:239] Iteration 242600 (9.92616 iter/s, 10.0744s/100 iters), loss = 0.0224677
I0822 23:22:50.569533 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0224672 (* 1 = 0.0224672 loss)
I0822 23:22:50.569545 13823 sgd_solver.cpp:112] Iteration 242600, lr = 1e-06
I0822 23:23:00.890043 13823 solver.cpp:239] Iteration 242700 (9.68937 iter/s, 10.3206s/100 iters), loss = 0.0248688
I0822 23:23:00.890098 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0248683 (* 1 = 0.0248683 loss)
I0822 23:23:00.890110 13823 sgd_solver.cpp:112] Iteration 242700, lr = 1e-06
I0822 23:23:10.788899 13823 solver.cpp:239] Iteration 242800 (10.1022 iter/s, 9.89888s/100 iters), loss = 0.030923
I0822 23:23:10.788951 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0309225 (* 1 = 0.0309225 loss)
I0822 23:23:10.788961 13823 sgd_solver.cpp:112] Iteration 242800, lr = 1e-06
I0822 23:23:20.870548 13823 solver.cpp:239] Iteration 242900 (9.91899 iter/s, 10.0817s/100 iters), loss = 0.0298282
I0822 23:23:20.870599 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0298278 (* 1 = 0.0298278 loss)
I0822 23:23:20.870609 13823 sgd_solver.cpp:112] Iteration 242900, lr = 1e-06
I0822 23:23:30.829666 13823 solver.cpp:239] Iteration 243000 (10.041 iter/s, 9.95915s/100 iters), loss = 0.0234166
I0822 23:23:30.829720 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0234161 (* 1 = 0.0234161 loss)
I0822 23:23:30.829727 13823 sgd_solver.cpp:112] Iteration 243000, lr = 1e-06
I0822 23:23:41.166765 13823 solver.cpp:239] Iteration 243100 (9.67387 iter/s, 10.3371s/100 iters), loss = 0.0248186
I0822 23:23:41.166818 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0248181 (* 1 = 0.0248181 loss)
I0822 23:23:41.166828 13823 sgd_solver.cpp:112] Iteration 243100, lr = 1e-06
I0822 23:23:51.485010 13823 solver.cpp:239] Iteration 243200 (9.69155 iter/s, 10.3183s/100 iters), loss = 0.0282239
I0822 23:23:51.485066 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0282234 (* 1 = 0.0282234 loss)
I0822 23:23:51.485077 13823 sgd_solver.cpp:112] Iteration 243200, lr = 1e-06
I0822 23:24:01.693548 13823 solver.cpp:239] Iteration 243300 (9.7957 iter/s, 10.2086s/100 iters), loss = 0.0236969
I0822 23:24:01.693605 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0236964 (* 1 = 0.0236964 loss)
I0822 23:24:01.693616 13823 sgd_solver.cpp:112] Iteration 243300, lr = 1e-06
I0822 23:24:11.785815 13823 solver.cpp:239] Iteration 243400 (9.90855 iter/s, 10.0923s/100 iters), loss = 0.03752
I0822 23:24:11.785864 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0375195 (* 1 = 0.0375195 loss)
I0822 23:24:11.785874 13823 sgd_solver.cpp:112] Iteration 243400, lr = 1e-06
I0822 23:24:22.252521 13823 solver.cpp:239] Iteration 243500 (9.55408 iter/s, 10.4667s/100 iters), loss = 0.0240701
I0822 23:24:22.252581 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0240696 (* 1 = 0.0240696 loss)
I0822 23:24:22.252593 13823 sgd_solver.cpp:112] Iteration 243500, lr = 1e-06
I0822 23:24:32.611397 13823 solver.cpp:239] Iteration 243600 (9.65354 iter/s, 10.3589s/100 iters), loss = 0.0258992
I0822 23:24:32.611449 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0258987 (* 1 = 0.0258987 loss)
I0822 23:24:32.611459 13823 sgd_solver.cpp:112] Iteration 243600, lr = 1e-06
I0822 23:24:42.936663 13823 solver.cpp:239] Iteration 243700 (9.68495 iter/s, 10.3253s/100 iters), loss = 0.037998
I0822 23:24:42.936715 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0379975 (* 1 = 0.0379975 loss)
I0822 23:24:42.936724 13823 sgd_solver.cpp:112] Iteration 243700, lr = 1e-06
I0822 23:24:53.288283 13823 solver.cpp:239] Iteration 243800 (9.6603 iter/s, 10.3516s/100 iters), loss = 0.0301008
I0822 23:24:53.288332 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0301003 (* 1 = 0.0301003 loss)
I0822 23:24:53.288342 13823 sgd_solver.cpp:112] Iteration 243800, lr = 1e-06
I0822 23:25:03.641432 13823 solver.cpp:239] Iteration 243900 (9.65887 iter/s, 10.3532s/100 iters), loss = 0.0243634
I0822 23:25:03.641484 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0243629 (* 1 = 0.0243629 loss)
I0822 23:25:03.641494 13823 sgd_solver.cpp:112] Iteration 243900, lr = 1e-06
I0822 23:25:13.774756 13823 solver.cpp:239] Iteration 244000 (9.8684 iter/s, 10.1334s/100 iters), loss = 0.028547
I0822 23:25:13.774809 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0285465 (* 1 = 0.0285465 loss)
I0822 23:25:13.774819 13823 sgd_solver.cpp:112] Iteration 244000, lr = 1e-06
I0822 23:25:24.157127 13823 solver.cpp:239] Iteration 244100 (9.63169 iter/s, 10.3824s/100 iters), loss = 0.0261676
I0822 23:25:24.157177 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0261671 (* 1 = 0.0261671 loss)
I0822 23:25:24.157187 13823 sgd_solver.cpp:112] Iteration 244100, lr = 1e-06
I0822 23:25:34.463443 13823 solver.cpp:239] Iteration 244200 (9.70276 iter/s, 10.3063s/100 iters), loss = 0.0270273
I0822 23:25:34.463491 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0270268 (* 1 = 0.0270268 loss)
I0822 23:25:34.463500 13823 sgd_solver.cpp:112] Iteration 244200, lr = 1e-06
I0822 23:25:45.028470 13823 solver.cpp:239] Iteration 244300 (9.46516 iter/s, 10.5651s/100 iters), loss = 0.0248515
I0822 23:25:45.028532 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.024851 (* 1 = 0.024851 loss)
I0822 23:25:45.028543 13823 sgd_solver.cpp:112] Iteration 244300, lr = 1e-06
I0822 23:25:55.376835 13823 solver.cpp:239] Iteration 244400 (9.66334 iter/s, 10.3484s/100 iters), loss = 0.0288353
I0822 23:25:55.376885 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0288348 (* 1 = 0.0288348 loss)
I0822 23:25:55.376895 13823 sgd_solver.cpp:112] Iteration 244400, lr = 1e-06
I0822 23:26:05.564898 13823 solver.cpp:239] Iteration 244500 (9.81538 iter/s, 10.1881s/100 iters), loss = 0.0321454
I0822 23:26:05.564949 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0321449 (* 1 = 0.0321449 loss)
I0822 23:26:05.564958 13823 sgd_solver.cpp:112] Iteration 244500, lr = 1e-06
I0822 23:26:15.881346 13823 solver.cpp:239] Iteration 244600 (9.69323 iter/s, 10.3165s/100 iters), loss = 0.0391195
I0822 23:26:15.881412 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.039119 (* 1 = 0.039119 loss)
I0822 23:26:15.881425 13823 sgd_solver.cpp:112] Iteration 244600, lr = 1e-06
I0822 23:26:26.237423 13823 solver.cpp:239] Iteration 244700 (9.65615 iter/s, 10.3561s/100 iters), loss = 0.028766
I0822 23:26:26.237475 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0287655 (* 1 = 0.0287655 loss)
I0822 23:26:26.237485 13823 sgd_solver.cpp:112] Iteration 244700, lr = 1e-06
I0822 23:26:36.535598 13823 solver.cpp:239] Iteration 244800 (9.71043 iter/s, 10.2982s/100 iters), loss = 0.0327656
I0822 23:26:36.535650 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.032765 (* 1 = 0.032765 loss)
I0822 23:26:36.535660 13823 sgd_solver.cpp:112] Iteration 244800, lr = 1e-06
I0822 23:26:46.859057 13823 solver.cpp:239] Iteration 244900 (9.68703 iter/s, 10.3231s/100 iters), loss = 0.0255251
I0822 23:26:46.859109 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0255245 (* 1 = 0.0255245 loss)
I0822 23:26:46.859119 13823 sgd_solver.cpp:112] Iteration 244900, lr = 1e-06
I0822 23:26:57.173080 13823 solver.cpp:239] Iteration 245000 (9.69631 iter/s, 10.3132s/100 iters), loss = 0.025986
I0822 23:26:57.173131 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0259854 (* 1 = 0.0259854 loss)
I0822 23:26:57.173141 13823 sgd_solver.cpp:112] Iteration 245000, lr = 1e-06
I0822 23:27:07.491859 13823 solver.cpp:239] Iteration 245100 (9.69182 iter/s, 10.318s/100 iters), loss = 0.0288994
I0822 23:27:07.491917 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0288989 (* 1 = 0.0288989 loss)
I0822 23:27:07.491928 13823 sgd_solver.cpp:112] Iteration 245100, lr = 1e-06
I0822 23:27:18.029426 13823 solver.cpp:239] Iteration 245200 (9.49059 iter/s, 10.5368s/100 iters), loss = 0.0266563
I0822 23:27:18.029481 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0266558 (* 1 = 0.0266558 loss)
I0822 23:27:18.029492 13823 sgd_solver.cpp:112] Iteration 245200, lr = 1e-06
I0822 23:27:28.413023 13823 solver.cpp:239] Iteration 245300 (9.6313 iter/s, 10.3828s/100 iters), loss = 0.0275763
I0822 23:27:28.413072 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0275758 (* 1 = 0.0275758 loss)
I0822 23:27:28.413082 13823 sgd_solver.cpp:112] Iteration 245300, lr = 1e-06
I0822 23:27:38.923362 13823 solver.cpp:239] Iteration 245400 (9.51514 iter/s, 10.5096s/100 iters), loss = 0.026856
I0822 23:27:38.923426 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0268554 (* 1 = 0.0268554 loss)
I0822 23:27:38.923439 13823 sgd_solver.cpp:112] Iteration 245400, lr = 1e-06
I0822 23:27:49.509831 13823 solver.cpp:239] Iteration 245500 (9.44671 iter/s, 10.5857s/100 iters), loss = 0.0277412
I0822 23:27:49.509881 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0277406 (* 1 = 0.0277406 loss)
I0822 23:27:49.509891 13823 sgd_solver.cpp:112] Iteration 245500, lr = 1e-06
I0822 23:27:59.991998 13823 solver.cpp:239] Iteration 245600 (9.54069 iter/s, 10.4814s/100 iters), loss = 0.0238614
I0822 23:27:59.992048 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0238609 (* 1 = 0.0238609 loss)
I0822 23:27:59.992058 13823 sgd_solver.cpp:112] Iteration 245600, lr = 1e-06
I0822 23:28:10.397223 13823 solver.cpp:239] Iteration 245700 (9.61123 iter/s, 10.4045s/100 iters), loss = 0.033898
I0822 23:28:10.397274 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0338974 (* 1 = 0.0338974 loss)
I0822 23:28:10.397282 13823 sgd_solver.cpp:112] Iteration 245700, lr = 1e-06
I0822 23:28:20.868348 13823 solver.cpp:239] Iteration 245800 (9.55073 iter/s, 10.4704s/100 iters), loss = 0.0269127
I0822 23:28:20.868408 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0269121 (* 1 = 0.0269121 loss)
I0822 23:28:20.868419 13823 sgd_solver.cpp:112] Iteration 245800, lr = 1e-06
I0822 23:28:31.573086 13823 solver.cpp:239] Iteration 245900 (9.34229 iter/s, 10.704s/100 iters), loss = 0.0330557
I0822 23:28:31.573134 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0330551 (* 1 = 0.0330551 loss)
I0822 23:28:31.573144 13823 sgd_solver.cpp:112] Iteration 245900, lr = 1e-06
I0822 23:28:41.911036 13823 solver.cpp:239] Iteration 246000 (9.67374 iter/s, 10.3373s/100 iters), loss = 0.0258403
I0822 23:28:41.911085 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0258398 (* 1 = 0.0258398 loss)
I0822 23:28:41.911094 13823 sgd_solver.cpp:112] Iteration 246000, lr = 1e-06
I0822 23:28:52.401974 13823 solver.cpp:239] Iteration 246100 (9.53265 iter/s, 10.4903s/100 iters), loss = 0.0315447
I0822 23:28:52.402026 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0315441 (* 1 = 0.0315441 loss)
I0822 23:28:52.402036 13823 sgd_solver.cpp:112] Iteration 246100, lr = 1e-06
I0822 23:29:02.926972 13823 solver.cpp:239] Iteration 246200 (9.5018 iter/s, 10.5243s/100 iters), loss = 0.0245081
I0822 23:29:02.927029 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0245075 (* 1 = 0.0245075 loss)
I0822 23:29:02.927040 13823 sgd_solver.cpp:112] Iteration 246200, lr = 1e-06
I0822 23:29:13.450292 13823 solver.cpp:239] Iteration 246300 (9.5033 iter/s, 10.5227s/100 iters), loss = 0.026592
I0822 23:29:13.450348 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0265915 (* 1 = 0.0265915 loss)
I0822 23:29:13.450359 13823 sgd_solver.cpp:112] Iteration 246300, lr = 1e-06
I0822 23:29:23.977962 13823 solver.cpp:239] Iteration 246400 (9.49936 iter/s, 10.527s/100 iters), loss = 0.0306884
I0822 23:29:23.978011 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0306879 (* 1 = 0.0306879 loss)
I0822 23:29:23.978021 13823 sgd_solver.cpp:112] Iteration 246400, lr = 1e-06
I0822 23:29:34.442968 13823 solver.cpp:239] Iteration 246500 (9.55623 iter/s, 10.4644s/100 iters), loss = 0.0265274
I0822 23:29:34.443020 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0265269 (* 1 = 0.0265269 loss)
I0822 23:29:34.443029 13823 sgd_solver.cpp:112] Iteration 246500, lr = 1e-06
I0822 23:29:44.997504 13823 solver.cpp:239] Iteration 246600 (9.47516 iter/s, 10.5539s/100 iters), loss = 0.0358331
I0822 23:29:44.997557 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0358326 (* 1 = 0.0358326 loss)
I0822 23:29:44.997567 13823 sgd_solver.cpp:112] Iteration 246600, lr = 1e-06
I0822 23:29:55.308233 13823 solver.cpp:239] Iteration 246700 (9.6992 iter/s, 10.3101s/100 iters), loss = 0.025655
I0822 23:29:55.308282 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0256545 (* 1 = 0.0256545 loss)
I0822 23:29:55.308292 13823 sgd_solver.cpp:112] Iteration 246700, lr = 1e-06
I0822 23:30:05.861531 13823 solver.cpp:239] Iteration 246800 (9.47625 iter/s, 10.5527s/100 iters), loss = 0.0272554
I0822 23:30:05.861580 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0272548 (* 1 = 0.0272548 loss)
I0822 23:30:05.861588 13823 sgd_solver.cpp:112] Iteration 246800, lr = 1e-06
I0822 23:30:16.475005 13823 solver.cpp:239] Iteration 246900 (9.42251 iter/s, 10.6129s/100 iters), loss = 0.0289789
I0822 23:30:16.475055 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0289783 (* 1 = 0.0289783 loss)
I0822 23:30:16.475065 13823 sgd_solver.cpp:112] Iteration 246900, lr = 1e-06
I0822 23:30:27.076902 13823 solver.cpp:239] Iteration 247000 (9.4328 iter/s, 10.6013s/100 iters), loss = 0.0277024
I0822 23:30:27.076952 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0277019 (* 1 = 0.0277019 loss)
I0822 23:30:27.076962 13823 sgd_solver.cpp:112] Iteration 247000, lr = 1e-06
I0822 23:30:37.840560 13823 solver.cpp:239] Iteration 247100 (9.29103 iter/s, 10.7631s/100 iters), loss = 0.0275482
I0822 23:30:37.840612 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0275476 (* 1 = 0.0275476 loss)
I0822 23:30:37.840621 13823 sgd_solver.cpp:112] Iteration 247100, lr = 1e-06
I0822 23:30:48.558230 13823 solver.cpp:239] Iteration 247200 (9.33088 iter/s, 10.7171s/100 iters), loss = 0.0307972
I0822 23:30:48.558277 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0307967 (* 1 = 0.0307967 loss)
I0822 23:30:48.558287 13823 sgd_solver.cpp:112] Iteration 247200, lr = 1e-06
I0822 23:30:59.246587 13823 solver.cpp:239] Iteration 247300 (9.35646 iter/s, 10.6878s/100 iters), loss = 0.0283358
I0822 23:30:59.246637 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0283353 (* 1 = 0.0283353 loss)
I0822 23:30:59.246646 13823 sgd_solver.cpp:112] Iteration 247300, lr = 1e-06
I0822 23:31:09.884160 13823 solver.cpp:239] Iteration 247400 (9.40112 iter/s, 10.637s/100 iters), loss = 0.0317819
I0822 23:31:09.884210 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0317813 (* 1 = 0.0317813 loss)
I0822 23:31:09.884220 13823 sgd_solver.cpp:112] Iteration 247400, lr = 1e-06
I0822 23:31:20.443641 13823 solver.cpp:239] Iteration 247500 (9.47064 iter/s, 10.5589s/100 iters), loss = 0.0262972
I0822 23:31:20.443691 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0262967 (* 1 = 0.0262967 loss)
I0822 23:31:20.443699 13823 sgd_solver.cpp:112] Iteration 247500, lr = 1e-06
I0822 23:31:31.190088 13823 solver.cpp:239] Iteration 247600 (9.30586 iter/s, 10.7459s/100 iters), loss = 0.0271243
I0822 23:31:31.190138 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0271238 (* 1 = 0.0271238 loss)
I0822 23:31:31.190147 13823 sgd_solver.cpp:112] Iteration 247600, lr = 1e-06
I0822 23:31:41.688340 13823 solver.cpp:239] Iteration 247700 (9.52586 iter/s, 10.4977s/100 iters), loss = 0.0274922
I0822 23:31:41.688391 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0274916 (* 1 = 0.0274916 loss)
I0822 23:31:41.688400 13823 sgd_solver.cpp:112] Iteration 247700, lr = 1e-06
I0822 23:31:52.113829 13823 solver.cpp:239] Iteration 247800 (9.59234 iter/s, 10.425s/100 iters), loss = 0.0253699
I0822 23:31:52.113878 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0253694 (* 1 = 0.0253694 loss)
I0822 23:31:52.113888 13823 sgd_solver.cpp:112] Iteration 247800, lr = 1e-06
I0822 23:32:03.027089 13823 solver.cpp:239] Iteration 247900 (9.1636 iter/s, 10.9127s/100 iters), loss = 0.0269423
I0822 23:32:03.027137 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0269418 (* 1 = 0.0269418 loss)
I0822 23:32:03.027146 13823 sgd_solver.cpp:112] Iteration 247900, lr = 1e-06
I0822 23:32:13.616053 13823 solver.cpp:239] Iteration 248000 (9.44423 iter/s, 10.5885s/100 iters), loss = 0.0279244
I0822 23:32:13.616104 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0279239 (* 1 = 0.0279239 loss)
I0822 23:32:13.616114 13823 sgd_solver.cpp:112] Iteration 248000, lr = 1e-06
I0822 23:32:24.342963 13823 solver.cpp:239] Iteration 248100 (9.32277 iter/s, 10.7264s/100 iters), loss = 0.0278813
I0822 23:32:24.343015 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0278807 (* 1 = 0.0278807 loss)
I0822 23:32:24.343025 13823 sgd_solver.cpp:112] Iteration 248100, lr = 1e-06
I0822 23:32:35.417446 13823 solver.cpp:239] Iteration 248200 (9.03017 iter/s, 11.074s/100 iters), loss = 0.0269508
I0822 23:32:35.417503 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0269502 (* 1 = 0.0269502 loss)
I0822 23:32:35.417515 13823 sgd_solver.cpp:112] Iteration 248200, lr = 1e-06
I0822 23:32:46.150558 13823 solver.cpp:239] Iteration 248300 (9.31738 iter/s, 10.7326s/100 iters), loss = 0.0291861
I0822 23:32:46.150607 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0291856 (* 1 = 0.0291856 loss)
I0822 23:32:46.150616 13823 sgd_solver.cpp:112] Iteration 248300, lr = 1e-06
I0822 23:32:56.998090 13823 solver.cpp:239] Iteration 248400 (9.21909 iter/s, 10.8471s/100 iters), loss = 0.0440415
I0822 23:32:56.998140 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0440409 (* 1 = 0.0440409 loss)
I0822 23:32:56.998150 13823 sgd_solver.cpp:112] Iteration 248400, lr = 1e-06
I0822 23:33:08.139140 13823 solver.cpp:239] Iteration 248500 (8.9762 iter/s, 11.1406s/100 iters), loss = 0.0231715
I0822 23:33:08.139204 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.023171 (* 1 = 0.023171 loss)
I0822 23:33:08.139216 13823 sgd_solver.cpp:112] Iteration 248500, lr = 1e-06
I0822 23:33:19.078578 13823 solver.cpp:239] Iteration 248600 (9.14163 iter/s, 10.939s/100 iters), loss = 0.0292062
I0822 23:33:19.078634 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0292057 (* 1 = 0.0292057 loss)
I0822 23:33:19.078644 13823 sgd_solver.cpp:112] Iteration 248600, lr = 1e-06
I0822 23:33:29.830276 13823 solver.cpp:239] Iteration 248700 (9.30124 iter/s, 10.7513s/100 iters), loss = 0.0373242
I0822 23:33:29.830327 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0373237 (* 1 = 0.0373237 loss)
I0822 23:33:29.830337 13823 sgd_solver.cpp:112] Iteration 248700, lr = 1e-06
I0822 23:33:40.475446 13823 solver.cpp:239] Iteration 248800 (9.39431 iter/s, 10.6447s/100 iters), loss = 0.027462
I0822 23:33:40.475500 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0274614 (* 1 = 0.0274614 loss)
I0822 23:33:40.475509 13823 sgd_solver.cpp:112] Iteration 248800, lr = 1e-06
I0822 23:33:50.967007 13823 solver.cpp:239] Iteration 248900 (9.53185 iter/s, 10.4911s/100 iters), loss = 0.0315299
I0822 23:33:50.967063 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0315294 (* 1 = 0.0315294 loss)
I0822 23:33:50.967074 13823 sgd_solver.cpp:112] Iteration 248900, lr = 1e-06
I0822 23:34:01.695304 13823 solver.cpp:239] Iteration 249000 (9.32151 iter/s, 10.7279s/100 iters), loss = 0.0267994
I0822 23:34:01.695353 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0267988 (* 1 = 0.0267988 loss)
I0822 23:34:01.695363 13823 sgd_solver.cpp:112] Iteration 249000, lr = 1e-06
I0822 23:34:12.392094 13823 solver.cpp:239] Iteration 249100 (9.34896 iter/s, 10.6964s/100 iters), loss = 0.0245436
I0822 23:34:12.392150 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0245431 (* 1 = 0.0245431 loss)
I0822 23:34:12.392160 13823 sgd_solver.cpp:112] Iteration 249100, lr = 1e-06
I0822 23:34:23.250205 13823 solver.cpp:239] Iteration 249200 (9.21006 iter/s, 10.8577s/100 iters), loss = 0.0263769
I0822 23:34:23.250259 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0263764 (* 1 = 0.0263764 loss)
I0822 23:34:23.250269 13823 sgd_solver.cpp:112] Iteration 249200, lr = 1e-06
I0822 23:34:33.918313 13823 solver.cpp:239] Iteration 249300 (9.37409 iter/s, 10.6677s/100 iters), loss = 0.0256154
I0822 23:34:33.918365 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0256149 (* 1 = 0.0256149 loss)
I0822 23:34:33.918373 13823 sgd_solver.cpp:112] Iteration 249300, lr = 1e-06
I0822 23:34:44.869339 13823 solver.cpp:239] Iteration 249400 (9.1319 iter/s, 10.9506s/100 iters), loss = 0.0271643
I0822 23:34:44.869390 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0271637 (* 1 = 0.0271637 loss)
I0822 23:34:44.869400 13823 sgd_solver.cpp:112] Iteration 249400, lr = 1e-06
I0822 23:34:55.828167 13823 solver.cpp:239] Iteration 249500 (9.12539 iter/s, 10.9584s/100 iters), loss = 0.0238746
I0822 23:34:55.828233 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0238741 (* 1 = 0.0238741 loss)
I0822 23:34:55.828246 13823 sgd_solver.cpp:112] Iteration 249500, lr = 1e-06
I0822 23:35:06.911571 13823 solver.cpp:239] Iteration 249600 (9.02283 iter/s, 11.083s/100 iters), loss = 0.0299962
I0822 23:35:06.911623 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0299956 (* 1 = 0.0299956 loss)
I0822 23:35:06.911633 13823 sgd_solver.cpp:112] Iteration 249600, lr = 1e-06
I0822 23:35:17.941557 13823 solver.cpp:239] Iteration 249700 (9.06651 iter/s, 11.0296s/100 iters), loss = 0.0334988
I0822 23:35:17.941607 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0334982 (* 1 = 0.0334982 loss)
I0822 23:35:17.941617 13823 sgd_solver.cpp:112] Iteration 249700, lr = 1e-06
I0822 23:35:28.788837 13823 solver.cpp:239] Iteration 249800 (9.21922 iter/s, 10.8469s/100 iters), loss = 0.0289007
I0822 23:35:28.788897 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0289002 (* 1 = 0.0289002 loss)
I0822 23:35:28.788909 13823 sgd_solver.cpp:112] Iteration 249800, lr = 1e-06
I0822 23:35:39.921643 13823 solver.cpp:239] Iteration 249900 (8.98277 iter/s, 11.1324s/100 iters), loss = 0.0251391
I0822 23:35:39.921706 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0251386 (* 1 = 0.0251386 loss)
I0822 23:35:39.921720 13823 sgd_solver.cpp:112] Iteration 249900, lr = 1e-06
I0822 23:35:50.931390 13823 solver.cpp:239] Iteration 250000 (9.08317 iter/s, 11.0094s/100 iters), loss = 0.0276432
I0822 23:35:50.931439 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0276427 (* 1 = 0.0276427 loss)
I0822 23:35:50.931449 13823 sgd_solver.cpp:112] Iteration 250000, lr = 1e-06
I0822 23:36:01.884207 13823 solver.cpp:239] Iteration 250100 (9.13037 iter/s, 10.9525s/100 iters), loss = 0.0276123
I0822 23:36:01.884254 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0276117 (* 1 = 0.0276117 loss)
I0822 23:36:01.884263 13823 sgd_solver.cpp:112] Iteration 250100, lr = 1e-06
I0822 23:36:12.694737 13823 solver.cpp:239] Iteration 250200 (9.25054 iter/s, 10.8102s/100 iters), loss = 0.0264819
I0822 23:36:12.694792 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0264813 (* 1 = 0.0264813 loss)
I0822 23:36:12.694802 13823 sgd_solver.cpp:112] Iteration 250200, lr = 1e-06
I0822 23:36:23.946223 13823 solver.cpp:239] Iteration 250300 (8.888 iter/s, 11.2511s/100 iters), loss = 0.0297372
I0822 23:36:23.946285 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0297366 (* 1 = 0.0297366 loss)
I0822 23:36:23.946295 13823 sgd_solver.cpp:112] Iteration 250300, lr = 1e-06
I0822 23:36:34.915598 13823 solver.cpp:239] Iteration 250400 (9.11658 iter/s, 10.969s/100 iters), loss = 0.0247985
I0822 23:36:34.915652 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0247979 (* 1 = 0.0247979 loss)
I0822 23:36:34.915663 13823 sgd_solver.cpp:112] Iteration 250400, lr = 1e-06
I0822 23:36:46.041477 13823 solver.cpp:239] Iteration 250500 (8.98833 iter/s, 11.1255s/100 iters), loss = 0.0244129
I0822 23:36:46.041529 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0244123 (* 1 = 0.0244123 loss)
I0822 23:36:46.041539 13823 sgd_solver.cpp:112] Iteration 250500, lr = 1e-06
I0822 23:36:57.105238 13823 solver.cpp:239] Iteration 250600 (9.03879 iter/s, 11.0634s/100 iters), loss = 0.0322448
I0822 23:36:57.105289 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0322443 (* 1 = 0.0322443 loss)
I0822 23:36:57.105299 13823 sgd_solver.cpp:112] Iteration 250600, lr = 1e-06
I0822 23:37:08.001351 13823 solver.cpp:239] Iteration 250700 (9.17786 iter/s, 10.8958s/100 iters), loss = 0.0265709
I0822 23:37:08.001402 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0265703 (* 1 = 0.0265703 loss)
I0822 23:37:08.001412 13823 sgd_solver.cpp:112] Iteration 250700, lr = 1e-06
I0822 23:37:19.003540 13823 solver.cpp:239] Iteration 250800 (9.08937 iter/s, 11.0019s/100 iters), loss = 0.0244533
I0822 23:37:19.003589 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0244527 (* 1 = 0.0244527 loss)
I0822 23:37:19.003598 13823 sgd_solver.cpp:112] Iteration 250800, lr = 1e-06
I0822 23:37:30.033596 13823 solver.cpp:239] Iteration 250900 (9.0664 iter/s, 11.0297s/100 iters), loss = 0.0303604
I0822 23:37:30.033650 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0303598 (* 1 = 0.0303598 loss)
I0822 23:37:30.033659 13823 sgd_solver.cpp:112] Iteration 250900, lr = 1e-06
I0822 23:37:41.179793 13823 solver.cpp:239] Iteration 251000 (8.97192 iter/s, 11.1459s/100 iters), loss = 0.0363199
I0822 23:37:41.179843 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0363193 (* 1 = 0.0363193 loss)
I0822 23:37:41.179852 13823 sgd_solver.cpp:112] Iteration 251000, lr = 1e-06
I0822 23:37:52.204962 13823 solver.cpp:239] Iteration 251100 (9.07041 iter/s, 11.0249s/100 iters), loss = 0.0274092
I0822 23:37:52.205010 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0274087 (* 1 = 0.0274087 loss)
I0822 23:37:52.205020 13823 sgd_solver.cpp:112] Iteration 251100, lr = 1e-06
I0822 23:38:03.352177 13823 solver.cpp:239] Iteration 251200 (8.97109 iter/s, 11.1469s/100 iters), loss = 0.0332456
I0822 23:38:03.352231 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.033245 (* 1 = 0.033245 loss)
I0822 23:38:03.352241 13823 sgd_solver.cpp:112] Iteration 251200, lr = 1e-06
I0822 23:38:14.661326 13823 solver.cpp:239] Iteration 251300 (8.84264 iter/s, 11.3088s/100 iters), loss = 0.0285173
I0822 23:38:14.661375 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0285168 (* 1 = 0.0285168 loss)
I0822 23:38:14.661384 13823 sgd_solver.cpp:112] Iteration 251300, lr = 1e-06
I0822 23:38:25.837255 13823 solver.cpp:239] Iteration 251400 (8.94804 iter/s, 11.1756s/100 iters), loss = 0.0261332
I0822 23:38:25.837312 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0261326 (* 1 = 0.0261326 loss)
I0822 23:38:25.837323 13823 sgd_solver.cpp:112] Iteration 251400, lr = 1e-06
I0822 23:38:37.140249 13823 solver.cpp:239] Iteration 251500 (8.84745 iter/s, 11.3027s/100 iters), loss = 0.0289525
I0822 23:38:37.140309 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0289519 (* 1 = 0.0289519 loss)
I0822 23:38:37.140321 13823 sgd_solver.cpp:112] Iteration 251500, lr = 1e-06
I0822 23:38:48.355440 13823 solver.cpp:239] Iteration 251600 (8.91671 iter/s, 11.2149s/100 iters), loss = 0.0376807
I0822 23:38:48.355489 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0376801 (* 1 = 0.0376801 loss)
I0822 23:38:48.355499 13823 sgd_solver.cpp:112] Iteration 251600, lr = 1e-06
I0822 23:38:59.243692 13823 solver.cpp:239] Iteration 251700 (9.18444 iter/s, 10.888s/100 iters), loss = 0.0310355
I0822 23:38:59.243741 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0310349 (* 1 = 0.0310349 loss)
I0822 23:38:59.243749 13823 sgd_solver.cpp:112] Iteration 251700, lr = 1e-06
I0822 23:39:10.453883 13823 solver.cpp:239] Iteration 251800 (8.92068 iter/s, 11.2099s/100 iters), loss = 0.0266195
I0822 23:39:10.453935 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0266189 (* 1 = 0.0266189 loss)
I0822 23:39:10.453944 13823 sgd_solver.cpp:112] Iteration 251800, lr = 1e-06
I0822 23:39:21.767241 13823 solver.cpp:239] Iteration 251900 (8.83933 iter/s, 11.3131s/100 iters), loss = 0.0271277
I0822 23:39:21.767299 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0271271 (* 1 = 0.0271271 loss)
I0822 23:39:21.767311 13823 sgd_solver.cpp:112] Iteration 251900, lr = 1e-06
I0822 23:39:32.973863 13823 solver.cpp:239] Iteration 252000 (8.92352 iter/s, 11.2063s/100 iters), loss = 0.0228827
I0822 23:39:32.973919 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0228821 (* 1 = 0.0228821 loss)
I0822 23:39:32.973929 13823 sgd_solver.cpp:112] Iteration 252000, lr = 1e-06
I0822 23:39:44.397709 13823 solver.cpp:239] Iteration 252100 (8.75383 iter/s, 11.4236s/100 iters), loss = 0.0272764
I0822 23:39:44.397770 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0272758 (* 1 = 0.0272758 loss)
I0822 23:39:44.397781 13823 sgd_solver.cpp:112] Iteration 252100, lr = 1e-06
I0822 23:39:55.699573 13823 solver.cpp:239] Iteration 252200 (8.84831 iter/s, 11.3016s/100 iters), loss = 0.0295656
I0822 23:39:55.699627 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0295651 (* 1 = 0.0295651 loss)
I0822 23:39:55.699637 13823 sgd_solver.cpp:112] Iteration 252200, lr = 1e-06
I0822 23:40:06.878998 13823 solver.cpp:239] Iteration 252300 (8.94521 iter/s, 11.1792s/100 iters), loss = 0.0291723
I0822 23:40:06.879047 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0291717 (* 1 = 0.0291717 loss)
I0822 23:40:06.879056 13823 sgd_solver.cpp:112] Iteration 252300, lr = 1e-06
I0822 23:40:18.164736 13823 solver.cpp:239] Iteration 252400 (8.86094 iter/s, 11.2855s/100 iters), loss = 0.0240569
I0822 23:40:18.164793 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0240563 (* 1 = 0.0240563 loss)
I0822 23:40:18.164803 13823 sgd_solver.cpp:112] Iteration 252400, lr = 1e-06
I0822 23:40:29.323237 13823 solver.cpp:239] Iteration 252500 (8.96198 iter/s, 11.1582s/100 iters), loss = 0.0344403
I0822 23:40:29.323289 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0344397 (* 1 = 0.0344397 loss)
I0822 23:40:29.323299 13823 sgd_solver.cpp:112] Iteration 252500, lr = 1e-06
I0822 23:40:40.582610 13823 solver.cpp:239] Iteration 252600 (8.88169 iter/s, 11.2591s/100 iters), loss = 0.0302941
I0822 23:40:40.582671 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0302935 (* 1 = 0.0302935 loss)
I0822 23:40:40.582682 13823 sgd_solver.cpp:112] Iteration 252600, lr = 1e-06
I0822 23:40:51.628659 13823 solver.cpp:239] Iteration 252700 (9.05322 iter/s, 11.0458s/100 iters), loss = 0.0254068
I0822 23:40:51.628710 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0254062 (* 1 = 0.0254062 loss)
I0822 23:40:51.628720 13823 sgd_solver.cpp:112] Iteration 252700, lr = 1e-06
I0822 23:41:02.768558 13823 solver.cpp:239] Iteration 252800 (8.97694 iter/s, 11.1397s/100 iters), loss = 0.0255345
I0822 23:41:02.768607 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0255339 (* 1 = 0.0255339 loss)
I0822 23:41:02.768616 13823 sgd_solver.cpp:112] Iteration 252800, lr = 1e-06
I0822 23:41:14.269920 13823 solver.cpp:239] Iteration 252900 (8.6948 iter/s, 11.5011s/100 iters), loss = 0.0278328
I0822 23:41:14.269973 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0278323 (* 1 = 0.0278323 loss)
I0822 23:41:14.269984 13823 sgd_solver.cpp:112] Iteration 252900, lr = 1e-06
I0822 23:41:25.773777 13823 solver.cpp:239] Iteration 253000 (8.69292 iter/s, 11.5036s/100 iters), loss = 0.0295643
I0822 23:41:25.773833 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0295637 (* 1 = 0.0295637 loss)
I0822 23:41:25.773844 13823 sgd_solver.cpp:112] Iteration 253000, lr = 1e-06
I0822 23:41:37.343578 13823 solver.cpp:239] Iteration 253100 (8.64337 iter/s, 11.5696s/100 iters), loss = 0.0259196
I0822 23:41:37.343636 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.025919 (* 1 = 0.025919 loss)
I0822 23:41:37.343648 13823 sgd_solver.cpp:112] Iteration 253100, lr = 1e-06
I0822 23:41:48.596329 13823 solver.cpp:239] Iteration 253200 (8.8869 iter/s, 11.2525s/100 iters), loss = 0.0288256
I0822 23:41:48.596379 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.028825 (* 1 = 0.028825 loss)
I0822 23:41:48.596388 13823 sgd_solver.cpp:112] Iteration 253200, lr = 1e-06
I0822 23:41:59.940593 13823 solver.cpp:239] Iteration 253300 (8.81521 iter/s, 11.344s/100 iters), loss = 0.0276889
I0822 23:41:59.940651 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0276883 (* 1 = 0.0276883 loss)
I0822 23:41:59.940662 13823 sgd_solver.cpp:112] Iteration 253300, lr = 1e-06
I0822 23:42:11.170642 13823 solver.cpp:239] Iteration 253400 (8.90486 iter/s, 11.2298s/100 iters), loss = 0.0238035
I0822 23:42:11.170692 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0238029 (* 1 = 0.0238029 loss)
I0822 23:42:11.170702 13823 sgd_solver.cpp:112] Iteration 253400, lr = 1e-06
I0822 23:42:22.477275 13823 solver.cpp:239] Iteration 253500 (8.84454 iter/s, 11.3064s/100 iters), loss = 0.0253573
I0822 23:42:22.477331 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0253567 (* 1 = 0.0253567 loss)
I0822 23:42:22.477342 13823 sgd_solver.cpp:112] Iteration 253500, lr = 1e-06
I0822 23:42:33.554836 13823 solver.cpp:239] Iteration 253600 (9.02744 iter/s, 11.0773s/100 iters), loss = 0.0315309
I0822 23:42:33.554886 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0315303 (* 1 = 0.0315303 loss)
I0822 23:42:33.554895 13823 sgd_solver.cpp:112] Iteration 253600, lr = 1e-06
I0822 23:42:44.980041 13823 solver.cpp:239] Iteration 253700 (8.75275 iter/s, 11.425s/100 iters), loss = 0.0355008
I0822 23:42:44.980096 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0355002 (* 1 = 0.0355002 loss)
I0822 23:42:44.980108 13823 sgd_solver.cpp:112] Iteration 253700, lr = 1e-06
I0822 23:42:56.152983 13823 solver.cpp:239] Iteration 253800 (8.95037 iter/s, 11.1727s/100 iters), loss = 0.0283117
I0822 23:42:56.153033 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0283111 (* 1 = 0.0283111 loss)
I0822 23:42:56.153043 13823 sgd_solver.cpp:112] Iteration 253800, lr = 1e-06
I0822 23:43:07.448947 13823 solver.cpp:239] Iteration 253900 (8.85288 iter/s, 11.2958s/100 iters), loss = 0.0343383
I0822 23:43:07.449000 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0343378 (* 1 = 0.0343378 loss)
I0822 23:43:07.449012 13823 sgd_solver.cpp:112] Iteration 253900, lr = 1e-06
I0822 23:43:18.814944 13823 solver.cpp:239] Iteration 254000 (8.79834 iter/s, 11.3658s/100 iters), loss = 0.0293533
I0822 23:43:18.815002 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0293527 (* 1 = 0.0293527 loss)
I0822 23:43:18.815014 13823 sgd_solver.cpp:112] Iteration 254000, lr = 1e-06
I0822 23:43:30.399881 13823 solver.cpp:239] Iteration 254100 (8.63206 iter/s, 11.5847s/100 iters), loss = 0.033334
I0822 23:43:30.399943 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0333335 (* 1 = 0.0333335 loss)
I0822 23:43:30.399955 13823 sgd_solver.cpp:112] Iteration 254100, lr = 1e-06
I0822 23:43:41.854598 13823 solver.cpp:239] Iteration 254200 (8.73019 iter/s, 11.4545s/100 iters), loss = 0.0264484
I0822 23:43:41.854647 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0264478 (* 1 = 0.0264478 loss)
I0822 23:43:41.854657 13823 sgd_solver.cpp:112] Iteration 254200, lr = 1e-06
I0822 23:43:53.256214 13823 solver.cpp:239] Iteration 254300 (8.77084 iter/s, 11.4014s/100 iters), loss = 0.0291272
I0822 23:43:53.256273 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0291266 (* 1 = 0.0291266 loss)
I0822 23:43:53.256283 13823 sgd_solver.cpp:112] Iteration 254300, lr = 1e-06
I0822 23:44:04.979152 13823 solver.cpp:239] Iteration 254400 (8.53044 iter/s, 11.7227s/100 iters), loss = 0.0264662
I0822 23:44:04.979207 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0264657 (* 1 = 0.0264657 loss)
I0822 23:44:04.979216 13823 sgd_solver.cpp:112] Iteration 254400, lr = 1e-06
I0822 23:44:16.471024 13823 solver.cpp:239] Iteration 254500 (8.70196 iter/s, 11.4917s/100 iters), loss = 0.0253625
I0822 23:44:16.471083 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.025362 (* 1 = 0.025362 loss)
I0822 23:44:16.471096 13823 sgd_solver.cpp:112] Iteration 254500, lr = 1e-06
I0822 23:44:28.280211 13823 solver.cpp:239] Iteration 254600 (8.46813 iter/s, 11.809s/100 iters), loss = 0.0291379
I0822 23:44:28.280272 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0291373 (* 1 = 0.0291373 loss)
I0822 23:44:28.280282 13823 sgd_solver.cpp:112] Iteration 254600, lr = 1e-06
I0822 23:44:39.819027 13823 solver.cpp:239] Iteration 254700 (8.66655 iter/s, 11.5386s/100 iters), loss = 0.0248848
I0822 23:44:39.819085 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0248842 (* 1 = 0.0248842 loss)
I0822 23:44:39.819097 13823 sgd_solver.cpp:112] Iteration 254700, lr = 1e-06
I0822 23:44:51.373512 13823 solver.cpp:239] Iteration 254800 (8.6548 iter/s, 11.5543s/100 iters), loss = 0.0309984
I0822 23:44:51.373569 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0309979 (* 1 = 0.0309979 loss)
I0822 23:44:51.373580 13823 sgd_solver.cpp:112] Iteration 254800, lr = 1e-06
I0822 23:45:02.878278 13823 solver.cpp:239] Iteration 254900 (8.6922 iter/s, 11.5046s/100 iters), loss = 0.0260729
I0822 23:45:02.878330 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0260723 (* 1 = 0.0260723 loss)
I0822 23:45:02.878340 13823 sgd_solver.cpp:112] Iteration 254900, lr = 1e-06
I0822 23:45:14.411341 13823 solver.cpp:239] Iteration 255000 (8.67086 iter/s, 11.5329s/100 iters), loss = 0.0273197
I0822 23:45:14.411397 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0273192 (* 1 = 0.0273192 loss)
I0822 23:45:14.411408 13823 sgd_solver.cpp:112] Iteration 255000, lr = 1e-06
I0822 23:45:26.152129 13823 solver.cpp:239] Iteration 255100 (8.51745 iter/s, 11.7406s/100 iters), loss = 0.0288242
I0822 23:45:26.152195 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0288237 (* 1 = 0.0288237 loss)
I0822 23:45:26.152209 13823 sgd_solver.cpp:112] Iteration 255100, lr = 1e-06
I0822 23:45:37.858196 13823 solver.cpp:239] Iteration 255200 (8.54272 iter/s, 11.7059s/100 iters), loss = 0.0290534
I0822 23:45:37.858251 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0290528 (* 1 = 0.0290528 loss)
I0822 23:45:37.858263 13823 sgd_solver.cpp:112] Iteration 255200, lr = 1e-06
I0822 23:45:49.394285 13823 solver.cpp:239] Iteration 255300 (8.66859 iter/s, 11.5359s/100 iters), loss = 0.0404061
I0822 23:45:49.394348 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0404055 (* 1 = 0.0404055 loss)
I0822 23:45:49.394361 13823 sgd_solver.cpp:112] Iteration 255300, lr = 1e-06
I0822 23:46:00.533812 13823 solver.cpp:239] Iteration 255400 (8.97719 iter/s, 11.1393s/100 iters), loss = 0.0263799
I0822 23:46:00.533872 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0263794 (* 1 = 0.0263794 loss)
I0822 23:46:00.533885 13823 sgd_solver.cpp:112] Iteration 255400, lr = 1e-06
I0822 23:46:12.074733 13823 solver.cpp:239] Iteration 255500 (8.66496 iter/s, 11.5407s/100 iters), loss = 0.0275012
I0822 23:46:12.074790 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0275006 (* 1 = 0.0275006 loss)
I0822 23:46:12.074801 13823 sgd_solver.cpp:112] Iteration 255500, lr = 1e-06
I0822 23:46:23.368749 13823 solver.cpp:239] Iteration 255600 (8.85439 iter/s, 11.2938s/100 iters), loss = 0.0308594
I0822 23:46:23.368804 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0308589 (* 1 = 0.0308589 loss)
I0822 23:46:23.368815 13823 sgd_solver.cpp:112] Iteration 255600, lr = 1e-06
I0822 23:46:33.472895 13823 solver.cpp:239] Iteration 255700 (9.89708 iter/s, 10.104s/100 iters), loss = 0.0273002
I0822 23:46:33.472939 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0272997 (* 1 = 0.0272997 loss)
I0822 23:46:33.472946 13823 sgd_solver.cpp:112] Iteration 255700, lr = 1e-06
I0822 23:46:42.917443 13823 solver.cpp:239] Iteration 255800 (10.5883 iter/s, 9.44441s/100 iters), loss = 0.0335365
I0822 23:46:42.917490 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.033536 (* 1 = 0.033536 loss)
I0822 23:46:42.917498 13823 sgd_solver.cpp:112] Iteration 255800, lr = 1e-06
I0822 23:46:52.689262 13823 solver.cpp:239] Iteration 255900 (10.2337 iter/s, 9.77167s/100 iters), loss = 0.036313
I0822 23:46:52.689316 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0363125 (* 1 = 0.0363125 loss)
I0822 23:46:52.689326 13823 sgd_solver.cpp:112] Iteration 255900, lr = 1e-06
I0822 23:47:02.385510 13823 solver.cpp:239] Iteration 256000 (10.3134 iter/s, 9.6961s/100 iters), loss = 0.0260667
I0822 23:47:02.385562 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0260661 (* 1 = 0.0260661 loss)
I0822 23:47:02.385571 13823 sgd_solver.cpp:112] Iteration 256000, lr = 1e-06
I0822 23:47:11.989377 13823 solver.cpp:239] Iteration 256100 (10.4126 iter/s, 9.60371s/100 iters), loss = 0.0307293
I0822 23:47:11.989439 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0307287 (* 1 = 0.0307287 loss)
I0822 23:47:11.989452 13823 sgd_solver.cpp:112] Iteration 256100, lr = 1e-06
I0822 23:47:21.606438 13823 solver.cpp:239] Iteration 256200 (10.3984 iter/s, 9.61691s/100 iters), loss = 0.030335
I0822 23:47:21.606488 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0303344 (* 1 = 0.0303344 loss)
I0822 23:47:21.606498 13823 sgd_solver.cpp:112] Iteration 256200, lr = 1e-06
I0822 23:47:30.889415 13823 solver.cpp:239] Iteration 256300 (10.7726 iter/s, 9.28284s/100 iters), loss = 0.0284381
I0822 23:47:30.889467 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0284376 (* 1 = 0.0284376 loss)
I0822 23:47:30.889475 13823 sgd_solver.cpp:112] Iteration 256300, lr = 1e-06
I0822 23:47:40.776742 13823 solver.cpp:239] Iteration 256400 (10.1141 iter/s, 9.88718s/100 iters), loss = 0.0263109
I0822 23:47:40.776793 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0263104 (* 1 = 0.0263104 loss)
I0822 23:47:40.776803 13823 sgd_solver.cpp:112] Iteration 256400, lr = 1e-06
I0822 23:47:50.125048 13823 solver.cpp:239] Iteration 256500 (10.6973 iter/s, 9.34817s/100 iters), loss = 0.03078
I0822 23:47:50.125099 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0307794 (* 1 = 0.0307794 loss)
I0822 23:47:50.125108 13823 sgd_solver.cpp:112] Iteration 256500, lr = 1e-06
I0822 23:47:59.764210 13823 solver.cpp:239] Iteration 256600 (10.3745 iter/s, 9.63902s/100 iters), loss = 0.024104
I0822 23:47:59.764264 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0241035 (* 1 = 0.0241035 loss)
I0822 23:47:59.764274 13823 sgd_solver.cpp:112] Iteration 256600, lr = 1e-06
I0822 23:48:09.608427 13823 solver.cpp:239] Iteration 256700 (10.1584 iter/s, 9.84407s/100 iters), loss = 0.0301352
I0822 23:48:09.608487 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0301347 (* 1 = 0.0301347 loss)
I0822 23:48:09.608498 13823 sgd_solver.cpp:112] Iteration 256700, lr = 1e-06
I0822 23:48:19.236629 13823 solver.cpp:239] Iteration 256800 (10.3863 iter/s, 9.62805s/100 iters), loss = 0.0232253
I0822 23:48:19.236694 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0232247 (* 1 = 0.0232247 loss)
I0822 23:48:19.236704 13823 sgd_solver.cpp:112] Iteration 256800, lr = 1e-06
I0822 23:48:28.947535 13823 solver.cpp:239] Iteration 256900 (10.2979 iter/s, 9.71075s/100 iters), loss = 0.0258505
I0822 23:48:28.947597 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0258499 (* 1 = 0.0258499 loss)
I0822 23:48:28.947608 13823 sgd_solver.cpp:112] Iteration 256900, lr = 1e-06
I0822 23:48:38.539731 13823 solver.cpp:239] Iteration 257000 (10.4253 iter/s, 9.59205s/100 iters), loss = 0.0275454
I0822 23:48:38.539783 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0275448 (* 1 = 0.0275448 loss)
I0822 23:48:38.539793 13823 sgd_solver.cpp:112] Iteration 257000, lr = 1e-06
I0822 23:48:48.635521 13823 solver.cpp:239] Iteration 257100 (9.90526 iter/s, 10.0956s/100 iters), loss = 0.0221656
I0822 23:48:48.635583 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.022165 (* 1 = 0.022165 loss)
I0822 23:48:48.635596 13823 sgd_solver.cpp:112] Iteration 257100, lr = 1e-06
I0822 23:48:58.265189 13823 solver.cpp:239] Iteration 257200 (10.3847 iter/s, 9.62952s/100 iters), loss = 0.0273692
I0822 23:48:58.265241 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0273686 (* 1 = 0.0273686 loss)
I0822 23:48:58.265250 13823 sgd_solver.cpp:112] Iteration 257200, lr = 1e-06
I0822 23:49:08.163419 13823 solver.cpp:239] Iteration 257300 (10.103 iter/s, 9.89809s/100 iters), loss = 0.0318695
I0822 23:49:08.163468 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.031869 (* 1 = 0.031869 loss)
I0822 23:49:08.163477 13823 sgd_solver.cpp:112] Iteration 257300, lr = 1e-06
I0822 23:49:17.887406 13823 solver.cpp:239] Iteration 257400 (10.284 iter/s, 9.72385s/100 iters), loss = 0.0292827
I0822 23:49:17.887461 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0292822 (* 1 = 0.0292822 loss)
I0822 23:49:17.887471 13823 sgd_solver.cpp:112] Iteration 257400, lr = 1e-06
I0822 23:49:27.628047 13823 solver.cpp:239] Iteration 257500 (10.2664 iter/s, 9.7405s/100 iters), loss = 0.0253078
I0822 23:49:27.628100 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0253073 (* 1 = 0.0253073 loss)
I0822 23:49:27.628109 13823 sgd_solver.cpp:112] Iteration 257500, lr = 1e-06
I0822 23:49:37.277128 13823 solver.cpp:239] Iteration 257600 (10.3638 iter/s, 9.64895s/100 iters), loss = 0.026237
I0822 23:49:37.277179 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0262365 (* 1 = 0.0262365 loss)
I0822 23:49:37.277187 13823 sgd_solver.cpp:112] Iteration 257600, lr = 1e-06
I0822 23:49:47.013351 13823 solver.cpp:239] Iteration 257700 (10.2711 iter/s, 9.73609s/100 iters), loss = 0.0285579
I0822 23:49:47.013403 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0285574 (* 1 = 0.0285574 loss)
I0822 23:49:47.013413 13823 sgd_solver.cpp:112] Iteration 257700, lr = 1e-06
I0822 23:49:56.733785 13823 solver.cpp:239] Iteration 257800 (10.2878 iter/s, 9.7203s/100 iters), loss = 0.0253979
I0822 23:49:56.733850 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0253974 (* 1 = 0.0253974 loss)
I0822 23:49:56.733862 13823 sgd_solver.cpp:112] Iteration 257800, lr = 1e-06
I0822 23:50:06.376308 13823 solver.cpp:239] Iteration 257900 (10.3709 iter/s, 9.64238s/100 iters), loss = 0.0261317
I0822 23:50:06.376360 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0261312 (* 1 = 0.0261312 loss)
I0822 23:50:06.376370 13823 sgd_solver.cpp:112] Iteration 257900, lr = 1e-06
I0822 23:50:16.193328 13823 solver.cpp:239] Iteration 258000 (10.1865 iter/s, 9.81689s/100 iters), loss = 0.0268462
I0822 23:50:16.193388 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0268457 (* 1 = 0.0268457 loss)
I0822 23:50:16.193399 13823 sgd_solver.cpp:112] Iteration 258000, lr = 1e-06
I0822 23:50:25.735625 13823 solver.cpp:239] Iteration 258100 (10.4798 iter/s, 9.54216s/100 iters), loss = 0.0277456
I0822 23:50:25.735678 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0277451 (* 1 = 0.0277451 loss)
I0822 23:50:25.735688 13823 sgd_solver.cpp:112] Iteration 258100, lr = 1e-06
I0822 23:50:35.671279 13823 solver.cpp:239] Iteration 258200 (10.0649 iter/s, 9.93553s/100 iters), loss = 0.0277024
I0822 23:50:35.671330 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0277019 (* 1 = 0.0277019 loss)
I0822 23:50:35.671340 13823 sgd_solver.cpp:112] Iteration 258200, lr = 1e-06
I0822 23:50:45.488729 13823 solver.cpp:239] Iteration 258300 (10.1861 iter/s, 9.81732s/100 iters), loss = 0.032357
I0822 23:50:45.488780 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0323564 (* 1 = 0.0323564 loss)
I0822 23:50:45.488790 13823 sgd_solver.cpp:112] Iteration 258300, lr = 1e-06
I0822 23:50:54.845644 13823 solver.cpp:239] Iteration 258400 (10.6874 iter/s, 9.35679s/100 iters), loss = 0.0304894
I0822 23:50:54.845695 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0304889 (* 1 = 0.0304889 loss)
I0822 23:50:54.845705 13823 sgd_solver.cpp:112] Iteration 258400, lr = 1e-06
I0822 23:51:04.477077 13823 solver.cpp:239] Iteration 258500 (10.3828 iter/s, 9.6313s/100 iters), loss = 0.0266022
I0822 23:51:04.477135 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0266016 (* 1 = 0.0266016 loss)
I0822 23:51:04.477146 13823 sgd_solver.cpp:112] Iteration 258500, lr = 1e-06
I0822 23:51:14.406564 13823 solver.cpp:239] Iteration 258600 (10.0711 iter/s, 9.92935s/100 iters), loss = 0.0322795
I0822 23:51:14.406617 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0322789 (* 1 = 0.0322789 loss)
I0822 23:51:14.406627 13823 sgd_solver.cpp:112] Iteration 258600, lr = 1e-06
I0822 23:51:24.142982 13823 solver.cpp:239] Iteration 258700 (10.2709 iter/s, 9.73629s/100 iters), loss = 0.0261316
I0822 23:51:24.143041 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0261311 (* 1 = 0.0261311 loss)
I0822 23:51:24.143054 13823 sgd_solver.cpp:112] Iteration 258700, lr = 1e-06
I0822 23:51:33.876984 13823 solver.cpp:239] Iteration 258800 (10.2734 iter/s, 9.73387s/100 iters), loss = 0.0371823
I0822 23:51:33.877034 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0371818 (* 1 = 0.0371818 loss)
I0822 23:51:33.877043 13823 sgd_solver.cpp:112] Iteration 258800, lr = 1e-06
I0822 23:51:43.656122 13823 solver.cpp:239] Iteration 258900 (10.226 iter/s, 9.77902s/100 iters), loss = 0.0410179
I0822 23:51:43.656177 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0410174 (* 1 = 0.0410174 loss)
I0822 23:51:43.656186 13823 sgd_solver.cpp:112] Iteration 258900, lr = 1e-06
I0822 23:51:53.581616 13823 solver.cpp:239] Iteration 259000 (10.0752 iter/s, 9.92537s/100 iters), loss = 0.0229539
I0822 23:51:53.581667 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0229533 (* 1 = 0.0229533 loss)
I0822 23:51:53.581676 13823 sgd_solver.cpp:112] Iteration 259000, lr = 1e-06
I0822 23:52:03.347805 13823 solver.cpp:239] Iteration 259100 (10.2395 iter/s, 9.76606s/100 iters), loss = 0.027415
I0822 23:52:03.347867 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0274145 (* 1 = 0.0274145 loss)
I0822 23:52:03.347878 13823 sgd_solver.cpp:112] Iteration 259100, lr = 1e-06
I0822 23:52:13.314347 13823 solver.cpp:239] Iteration 259200 (10.0337 iter/s, 9.96641s/100 iters), loss = 0.0247149
I0822 23:52:13.314399 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0247144 (* 1 = 0.0247144 loss)
I0822 23:52:13.314409 13823 sgd_solver.cpp:112] Iteration 259200, lr = 1e-06
I0822 23:52:22.990236 13823 solver.cpp:239] Iteration 259300 (10.3351 iter/s, 9.67577s/100 iters), loss = 0.0252112
I0822 23:52:22.990288 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0252107 (* 1 = 0.0252107 loss)
I0822 23:52:22.990298 13823 sgd_solver.cpp:112] Iteration 259300, lr = 1e-06
I0822 23:52:32.933614 13823 solver.cpp:239] Iteration 259400 (10.0571 iter/s, 9.94326s/100 iters), loss = 0.0247864
I0822 23:52:32.933676 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0247859 (* 1 = 0.0247859 loss)
I0822 23:52:32.933686 13823 sgd_solver.cpp:112] Iteration 259400, lr = 1e-06
I0822 23:52:42.541882 13823 solver.cpp:239] Iteration 259500 (10.4078 iter/s, 9.60814s/100 iters), loss = 0.0410416
I0822 23:52:42.541930 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0410411 (* 1 = 0.0410411 loss)
I0822 23:52:42.541939 13823 sgd_solver.cpp:112] Iteration 259500, lr = 1e-06
I0822 23:52:52.379654 13823 solver.cpp:239] Iteration 259600 (10.165 iter/s, 9.83765s/100 iters), loss = 0.030251
I0822 23:52:52.379719 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0302504 (* 1 = 0.0302504 loss)
I0822 23:52:52.379732 13823 sgd_solver.cpp:112] Iteration 259600, lr = 1e-06
I0822 23:53:02.215812 13823 solver.cpp:239] Iteration 259700 (10.1667 iter/s, 9.83603s/100 iters), loss = 0.0272345
I0822 23:53:02.215864 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.027234 (* 1 = 0.027234 loss)
I0822 23:53:02.215874 13823 sgd_solver.cpp:112] Iteration 259700, lr = 1e-06
I0822 23:53:12.274025 13823 solver.cpp:239] Iteration 259800 (9.94224 iter/s, 10.0581s/100 iters), loss = 0.0319923
I0822 23:53:12.274075 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0319917 (* 1 = 0.0319917 loss)
I0822 23:53:12.274085 13823 sgd_solver.cpp:112] Iteration 259800, lr = 1e-06
I0822 23:53:21.950942 13823 solver.cpp:239] Iteration 259900 (10.334 iter/s, 9.6768s/100 iters), loss = 0.0275045
I0822 23:53:21.950992 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.027504 (* 1 = 0.027504 loss)
I0822 23:53:21.951002 13823 sgd_solver.cpp:112] Iteration 259900, lr = 1e-06
I0822 23:53:31.687834 13823 solver.cpp:464] Snapshotting to binary proto file ./model_112/cascade_mobilenet_112_iter_260000.caffemodel
I0822 23:53:31.725229 13823 sgd_solver.cpp:284] Snapshotting solver state to binary proto file ./model_112/cascade_mobilenet_112_iter_260000.solverstate
I0822 23:53:31.798327 13823 solver.cpp:347] Iteration 260000, Testing net (#0)
I0822 23:54:38.344650 13823 solver.cpp:414]     Test net output #0: landmark_loss = 0.0220684 (* 1 = 0.0220684 loss)
I0822 23:54:38.439419 13823 solver.cpp:239] Iteration 260000 (1.30739 iter/s, 76.488s/100 iters), loss = 0.0253904
I0822 23:54:38.439471 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0253899 (* 1 = 0.0253899 loss)
I0822 23:54:38.439483 13823 sgd_solver.cpp:112] Iteration 260000, lr = 1e-06
I0822 23:54:48.599386 13823 solver.cpp:239] Iteration 260100 (9.84266 iter/s, 10.1599s/100 iters), loss = 0.0232849
I0822 23:54:48.599437 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0232844 (* 1 = 0.0232844 loss)
I0822 23:54:48.599447 13823 sgd_solver.cpp:112] Iteration 260100, lr = 1e-06
I0822 23:54:58.529175 13823 solver.cpp:239] Iteration 260200 (10.0708 iter/s, 9.92968s/100 iters), loss = 0.0244231
I0822 23:54:58.529217 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0244226 (* 1 = 0.0244226 loss)
I0822 23:54:58.529224 13823 sgd_solver.cpp:112] Iteration 260200, lr = 1e-06
I0822 23:55:08.690865 13823 solver.cpp:239] Iteration 260300 (9.84098 iter/s, 10.1616s/100 iters), loss = 0.0237257
I0822 23:55:08.690915 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0237251 (* 1 = 0.0237251 loss)
I0822 23:55:08.690925 13823 sgd_solver.cpp:112] Iteration 260300, lr = 1e-06
I0822 23:55:18.960907 13823 solver.cpp:239] Iteration 260400 (9.73716 iter/s, 10.2699s/100 iters), loss = 0.0269384
I0822 23:55:18.960958 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0269379 (* 1 = 0.0269379 loss)
I0822 23:55:18.960968 13823 sgd_solver.cpp:112] Iteration 260400, lr = 1e-06
I0822 23:55:29.102171 13823 solver.cpp:239] Iteration 260500 (9.86081 iter/s, 10.1412s/100 iters), loss = 0.0268108
I0822 23:55:29.102222 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0268103 (* 1 = 0.0268103 loss)
I0822 23:55:29.102231 13823 sgd_solver.cpp:112] Iteration 260500, lr = 1e-06
I0822 23:55:39.285126 13823 solver.cpp:239] Iteration 260600 (9.82044 iter/s, 10.1828s/100 iters), loss = 0.0390217
I0822 23:55:39.285178 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0390211 (* 1 = 0.0390211 loss)
I0822 23:55:39.285188 13823 sgd_solver.cpp:112] Iteration 260600, lr = 1e-06
I0822 23:55:49.689136 13823 solver.cpp:239] Iteration 260700 (9.61178 iter/s, 10.4039s/100 iters), loss = 0.0273689
I0822 23:55:49.689203 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0273684 (* 1 = 0.0273684 loss)
I0822 23:55:49.689215 13823 sgd_solver.cpp:112] Iteration 260700, lr = 1e-06
I0822 23:55:59.810346 13823 solver.cpp:239] Iteration 260800 (9.88036 iter/s, 10.1211s/100 iters), loss = 0.0254726
I0822 23:55:59.810398 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0254721 (* 1 = 0.0254721 loss)
I0822 23:55:59.810408 13823 sgd_solver.cpp:112] Iteration 260800, lr = 1e-06
I0822 23:56:10.029726 13823 solver.cpp:239] Iteration 260900 (9.78544 iter/s, 10.2193s/100 iters), loss = 0.0248928
I0822 23:56:10.029783 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0248922 (* 1 = 0.0248922 loss)
I0822 23:56:10.029795 13823 sgd_solver.cpp:112] Iteration 260900, lr = 1e-06
I0822 23:56:20.272593 13823 solver.cpp:239] Iteration 261000 (9.763 iter/s, 10.2428s/100 iters), loss = 0.0257851
I0822 23:56:20.272644 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0257846 (* 1 = 0.0257846 loss)
I0822 23:56:20.272655 13823 sgd_solver.cpp:112] Iteration 261000, lr = 1e-06
I0822 23:56:30.665984 13823 solver.cpp:239] Iteration 261100 (9.6216 iter/s, 10.3933s/100 iters), loss = 0.0260667
I0822 23:56:30.666039 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0260661 (* 1 = 0.0260661 loss)
I0822 23:56:30.666049 13823 sgd_solver.cpp:112] Iteration 261100, lr = 1e-06
I0822 23:56:40.922024 13823 solver.cpp:239] Iteration 261200 (9.75046 iter/s, 10.2559s/100 iters), loss = 0.0335923
I0822 23:56:40.922083 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0335918 (* 1 = 0.0335918 loss)
I0822 23:56:40.922096 13823 sgd_solver.cpp:112] Iteration 261200, lr = 1e-06
I0822 23:56:51.367812 13823 solver.cpp:239] Iteration 261300 (9.57334 iter/s, 10.4457s/100 iters), loss = 0.02526
I0822 23:56:51.367864 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0252595 (* 1 = 0.0252595 loss)
I0822 23:56:51.367873 13823 sgd_solver.cpp:112] Iteration 261300, lr = 1e-06
I0822 23:57:01.824805 13823 solver.cpp:239] Iteration 261400 (9.56308 iter/s, 10.4569s/100 iters), loss = 0.0274715
I0822 23:57:01.824856 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.027471 (* 1 = 0.027471 loss)
I0822 23:57:01.824867 13823 sgd_solver.cpp:112] Iteration 261400, lr = 1e-06
I0822 23:57:11.856307 13823 solver.cpp:239] Iteration 261500 (9.9687 iter/s, 10.0314s/100 iters), loss = 0.0254742
I0822 23:57:11.856364 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0254736 (* 1 = 0.0254736 loss)
I0822 23:57:11.856374 13823 sgd_solver.cpp:112] Iteration 261500, lr = 1e-06
I0822 23:57:22.200598 13823 solver.cpp:239] Iteration 261600 (9.66727 iter/s, 10.3442s/100 iters), loss = 0.025776
I0822 23:57:22.200651 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0257755 (* 1 = 0.0257755 loss)
I0822 23:57:22.200661 13823 sgd_solver.cpp:112] Iteration 261600, lr = 1e-06
I0822 23:57:32.467875 13823 solver.cpp:239] Iteration 261700 (9.73978 iter/s, 10.2672s/100 iters), loss = 0.024687
I0822 23:57:32.467926 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0246865 (* 1 = 0.0246865 loss)
I0822 23:57:32.467936 13823 sgd_solver.cpp:112] Iteration 261700, lr = 1e-06
I0822 23:57:42.815773 13823 solver.cpp:239] Iteration 261800 (9.6639 iter/s, 10.3478s/100 iters), loss = 0.0241008
I0822 23:57:42.815824 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0241003 (* 1 = 0.0241003 loss)
I0822 23:57:42.815834 13823 sgd_solver.cpp:112] Iteration 261800, lr = 1e-06
I0822 23:57:53.270445 13823 solver.cpp:239] Iteration 261900 (9.5652 iter/s, 10.4546s/100 iters), loss = 0.0316575
I0822 23:57:53.270501 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0316569 (* 1 = 0.0316569 loss)
I0822 23:57:53.270512 13823 sgd_solver.cpp:112] Iteration 261900, lr = 1e-06
I0822 23:58:03.318331 13823 solver.cpp:239] Iteration 262000 (9.95245 iter/s, 10.0478s/100 iters), loss = 0.024227
I0822 23:58:03.318382 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0242265 (* 1 = 0.0242265 loss)
I0822 23:58:03.318392 13823 sgd_solver.cpp:112] Iteration 262000, lr = 1e-06
I0822 23:58:13.622606 13823 solver.cpp:239] Iteration 262100 (9.70481 iter/s, 10.3042s/100 iters), loss = 0.0265218
I0822 23:58:13.622665 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0265212 (* 1 = 0.0265212 loss)
I0822 23:58:13.622676 13823 sgd_solver.cpp:112] Iteration 262100, lr = 1e-06
I0822 23:58:23.917129 13823 solver.cpp:239] Iteration 262200 (9.71401 iter/s, 10.2944s/100 iters), loss = 0.0276303
I0822 23:58:23.917186 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0276298 (* 1 = 0.0276298 loss)
I0822 23:58:23.917197 13823 sgd_solver.cpp:112] Iteration 262200, lr = 1e-06
I0822 23:58:34.332338 13823 solver.cpp:239] Iteration 262300 (9.60145 iter/s, 10.4151s/100 iters), loss = 0.0246553
I0822 23:58:34.332391 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0246548 (* 1 = 0.0246548 loss)
I0822 23:58:34.332401 13823 sgd_solver.cpp:112] Iteration 262300, lr = 1e-06
I0822 23:58:45.039611 13823 solver.cpp:239] Iteration 262400 (9.33954 iter/s, 10.7072s/100 iters), loss = 0.0328699
I0822 23:58:45.039672 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0328693 (* 1 = 0.0328693 loss)
I0822 23:58:45.039685 13823 sgd_solver.cpp:112] Iteration 262400, lr = 1e-06
I0822 23:58:55.429531 13823 solver.cpp:239] Iteration 262500 (9.62482 iter/s, 10.3898s/100 iters), loss = 0.0242726
I0822 23:58:55.429584 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0242721 (* 1 = 0.0242721 loss)
I0822 23:58:55.429594 13823 sgd_solver.cpp:112] Iteration 262500, lr = 1e-06
I0822 23:59:05.456794 13823 solver.cpp:239] Iteration 262600 (9.97291 iter/s, 10.0272s/100 iters), loss = 0.0259198
I0822 23:59:05.456837 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0259193 (* 1 = 0.0259193 loss)
I0822 23:59:05.456845 13823 sgd_solver.cpp:112] Iteration 262600, lr = 1e-06
I0822 23:59:15.576493 13823 solver.cpp:239] Iteration 262700 (9.88181 iter/s, 10.1196s/100 iters), loss = 0.0331747
I0822 23:59:15.576542 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0331741 (* 1 = 0.0331741 loss)
I0822 23:59:15.576552 13823 sgd_solver.cpp:112] Iteration 262700, lr = 1e-06
I0822 23:59:25.867578 13823 solver.cpp:239] Iteration 262800 (9.71724 iter/s, 10.291s/100 iters), loss = 0.031135
I0822 23:59:25.867619 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0311344 (* 1 = 0.0311344 loss)
I0822 23:59:25.867626 13823 sgd_solver.cpp:112] Iteration 262800, lr = 1e-06
I0822 23:59:35.963248 13823 solver.cpp:239] Iteration 262900 (9.90533 iter/s, 10.0956s/100 iters), loss = 0.0262718
I0822 23:59:35.963299 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0262712 (* 1 = 0.0262712 loss)
I0822 23:59:35.963310 13823 sgd_solver.cpp:112] Iteration 262900, lr = 1e-06
I0822 23:59:46.199290 13823 solver.cpp:239] Iteration 263000 (9.7695 iter/s, 10.2359s/100 iters), loss = 0.0377675
I0822 23:59:46.199340 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0377669 (* 1 = 0.0377669 loss)
I0822 23:59:46.199349 13823 sgd_solver.cpp:112] Iteration 263000, lr = 1e-06
I0822 23:59:56.168872 13823 solver.cpp:239] Iteration 263100 (10.0306 iter/s, 9.96949s/100 iters), loss = 0.0411729
I0822 23:59:56.168915 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0411724 (* 1 = 0.0411724 loss)
I0822 23:59:56.168921 13823 sgd_solver.cpp:112] Iteration 263100, lr = 1e-06
I0823 00:00:06.076201 13823 solver.cpp:239] Iteration 263200 (10.0936 iter/s, 9.90724s/100 iters), loss = 0.0250857
I0823 00:00:06.076254 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0250852 (* 1 = 0.0250852 loss)
I0823 00:00:06.076261 13823 sgd_solver.cpp:112] Iteration 263200, lr = 1e-06
I0823 00:00:16.251786 13823 solver.cpp:239] Iteration 263300 (9.82755 iter/s, 10.1755s/100 iters), loss = 0.0245503
I0823 00:00:16.251842 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0245498 (* 1 = 0.0245498 loss)
I0823 00:00:16.251852 13823 sgd_solver.cpp:112] Iteration 263300, lr = 1e-06
I0823 00:00:26.513607 13823 solver.cpp:239] Iteration 263400 (9.74495 iter/s, 10.2617s/100 iters), loss = 0.028769
I0823 00:00:26.513660 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0287684 (* 1 = 0.0287684 loss)
I0823 00:00:26.513669 13823 sgd_solver.cpp:112] Iteration 263400, lr = 1e-06
I0823 00:00:36.679124 13823 solver.cpp:239] Iteration 263500 (9.83728 iter/s, 10.1654s/100 iters), loss = 0.0252008
I0823 00:00:36.679183 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0252002 (* 1 = 0.0252002 loss)
I0823 00:00:36.679195 13823 sgd_solver.cpp:112] Iteration 263500, lr = 1e-06
I0823 00:00:47.350523 13823 solver.cpp:239] Iteration 263600 (9.37093 iter/s, 10.6713s/100 iters), loss = 0.0274773
I0823 00:00:47.350576 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0274768 (* 1 = 0.0274768 loss)
I0823 00:00:47.350586 13823 sgd_solver.cpp:112] Iteration 263600, lr = 1e-06
I0823 00:00:57.742035 13823 solver.cpp:239] Iteration 263700 (9.62314 iter/s, 10.3916s/100 iters), loss = 0.0285514
I0823 00:00:57.742087 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0285509 (* 1 = 0.0285509 loss)
I0823 00:00:57.742096 13823 sgd_solver.cpp:112] Iteration 263700, lr = 1e-06
I0823 00:01:08.275192 13823 solver.cpp:239] Iteration 263800 (9.49365 iter/s, 10.5334s/100 iters), loss = 0.0260424
I0823 00:01:08.275243 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0260418 (* 1 = 0.0260418 loss)
I0823 00:01:08.275251 13823 sgd_solver.cpp:112] Iteration 263800, lr = 1e-06
I0823 00:01:18.574079 13823 solver.cpp:239] Iteration 263900 (9.7096 iter/s, 10.2991s/100 iters), loss = 0.0291967
I0823 00:01:18.574134 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0291961 (* 1 = 0.0291961 loss)
I0823 00:01:18.574147 13823 sgd_solver.cpp:112] Iteration 263900, lr = 1e-06
I0823 00:01:28.941865 13823 solver.cpp:239] Iteration 264000 (9.64508 iter/s, 10.368s/100 iters), loss = 0.0307072
I0823 00:01:28.941917 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0307066 (* 1 = 0.0307066 loss)
I0823 00:01:28.941927 13823 sgd_solver.cpp:112] Iteration 264000, lr = 1e-06
I0823 00:01:39.293005 13823 solver.cpp:239] Iteration 264100 (9.6606 iter/s, 10.3513s/100 iters), loss = 0.0269727
I0823 00:01:39.293071 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0269721 (* 1 = 0.0269721 loss)
I0823 00:01:39.293087 13823 sgd_solver.cpp:112] Iteration 264100, lr = 1e-06
I0823 00:01:50.134768 13823 solver.cpp:239] Iteration 264200 (9.22344 iter/s, 10.8419s/100 iters), loss = 0.026744
I0823 00:01:50.134826 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0267434 (* 1 = 0.0267434 loss)
I0823 00:01:50.134837 13823 sgd_solver.cpp:112] Iteration 264200, lr = 1e-06
I0823 00:02:00.748664 13823 solver.cpp:239] Iteration 264300 (9.42145 iter/s, 10.6141s/100 iters), loss = 0.0290328
I0823 00:02:00.748724 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0290322 (* 1 = 0.0290322 loss)
I0823 00:02:00.748739 13823 sgd_solver.cpp:112] Iteration 264300, lr = 1e-06
I0823 00:02:11.250286 13823 solver.cpp:239] Iteration 264400 (9.52218 iter/s, 10.5018s/100 iters), loss = 0.0252019
I0823 00:02:11.250345 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0252013 (* 1 = 0.0252013 loss)
I0823 00:02:11.250356 13823 sgd_solver.cpp:112] Iteration 264400, lr = 1e-06
I0823 00:02:22.008183 13823 solver.cpp:239] Iteration 264500 (9.29535 iter/s, 10.7581s/100 iters), loss = 0.0268156
I0823 00:02:22.008235 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0268151 (* 1 = 0.0268151 loss)
I0823 00:02:22.008245 13823 sgd_solver.cpp:112] Iteration 264500, lr = 1e-06
I0823 00:02:32.670879 13823 solver.cpp:239] Iteration 264600 (9.37834 iter/s, 10.6629s/100 iters), loss = 0.0262892
I0823 00:02:32.670930 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0262886 (* 1 = 0.0262886 loss)
I0823 00:02:32.670939 13823 sgd_solver.cpp:112] Iteration 264600, lr = 1e-06
I0823 00:02:42.894263 13823 solver.cpp:239] Iteration 264700 (9.78134 iter/s, 10.2235s/100 iters), loss = 0.0269905
I0823 00:02:42.894306 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.02699 (* 1 = 0.02699 loss)
I0823 00:02:42.894316 13823 sgd_solver.cpp:112] Iteration 264700, lr = 1e-06
I0823 00:02:53.778074 13823 solver.cpp:239] Iteration 264800 (9.18781 iter/s, 10.884s/100 iters), loss = 0.0278432
I0823 00:02:53.778146 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0278427 (* 1 = 0.0278427 loss)
I0823 00:02:53.778162 13823 sgd_solver.cpp:112] Iteration 264800, lr = 1e-06
I0823 00:03:04.071204 13823 solver.cpp:239] Iteration 264900 (9.71509 iter/s, 10.2933s/100 iters), loss = 0.0254132
I0823 00:03:04.071255 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0254127 (* 1 = 0.0254127 loss)
I0823 00:03:04.071265 13823 sgd_solver.cpp:112] Iteration 264900, lr = 1e-06
I0823 00:03:14.639190 13823 solver.cpp:239] Iteration 265000 (9.4624 iter/s, 10.5681s/100 iters), loss = 0.0288168
I0823 00:03:14.639232 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0288163 (* 1 = 0.0288163 loss)
I0823 00:03:14.639240 13823 sgd_solver.cpp:112] Iteration 265000, lr = 1e-06
I0823 00:03:24.902190 13823 solver.cpp:239] Iteration 265100 (9.7436 iter/s, 10.2632s/100 iters), loss = 0.0257959
I0823 00:03:24.902251 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0257954 (* 1 = 0.0257954 loss)
I0823 00:03:24.902266 13823 sgd_solver.cpp:112] Iteration 265100, lr = 1e-06
I0823 00:03:35.918778 13823 solver.cpp:239] Iteration 265200 (9.0771 iter/s, 11.0167s/100 iters), loss = 0.0253341
I0823 00:03:35.918840 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0253336 (* 1 = 0.0253336 loss)
I0823 00:03:35.918853 13823 sgd_solver.cpp:112] Iteration 265200, lr = 1e-06
I0823 00:03:46.660337 13823 solver.cpp:239] Iteration 265300 (9.30952 iter/s, 10.7417s/100 iters), loss = 0.0247247
I0823 00:03:46.660394 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0247242 (* 1 = 0.0247242 loss)
I0823 00:03:46.660404 13823 sgd_solver.cpp:112] Iteration 265300, lr = 1e-06
I0823 00:03:57.523313 13823 solver.cpp:239] Iteration 265400 (9.20547 iter/s, 10.8631s/100 iters), loss = 0.025783
I0823 00:03:57.523380 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0257825 (* 1 = 0.0257825 loss)
I0823 00:03:57.523394 13823 sgd_solver.cpp:112] Iteration 265400, lr = 1e-06
I0823 00:04:08.278174 13823 solver.cpp:239] Iteration 265500 (9.29801 iter/s, 10.755s/100 iters), loss = 0.0313955
I0823 00:04:08.278229 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.031395 (* 1 = 0.031395 loss)
I0823 00:04:08.278240 13823 sgd_solver.cpp:112] Iteration 265500, lr = 1e-06
I0823 00:04:19.124181 13823 solver.cpp:239] Iteration 265600 (9.21987 iter/s, 10.8461s/100 iters), loss = 0.0245949
I0823 00:04:19.124233 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0245944 (* 1 = 0.0245944 loss)
I0823 00:04:19.124243 13823 sgd_solver.cpp:112] Iteration 265600, lr = 1e-06
I0823 00:04:30.132740 13823 solver.cpp:239] Iteration 265700 (9.08373 iter/s, 11.0087s/100 iters), loss = 0.0250937
I0823 00:04:30.132791 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0250931 (* 1 = 0.0250931 loss)
I0823 00:04:30.132800 13823 sgd_solver.cpp:112] Iteration 265700, lr = 1e-06
I0823 00:04:40.964529 13823 solver.cpp:239] Iteration 265800 (9.23198 iter/s, 10.8319s/100 iters), loss = 0.0271395
I0823 00:04:40.964577 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.027139 (* 1 = 0.027139 loss)
I0823 00:04:40.964586 13823 sgd_solver.cpp:112] Iteration 265800, lr = 1e-06
I0823 00:04:51.754576 13823 solver.cpp:239] Iteration 265900 (9.26769 iter/s, 10.7902s/100 iters), loss = 0.0273849
I0823 00:04:51.754627 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0273844 (* 1 = 0.0273844 loss)
I0823 00:04:51.754637 13823 sgd_solver.cpp:112] Iteration 265900, lr = 1e-06
I0823 00:05:02.695578 13823 solver.cpp:239] Iteration 266000 (9.13983 iter/s, 10.9411s/100 iters), loss = 0.0283556
I0823 00:05:02.695629 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0283551 (* 1 = 0.0283551 loss)
I0823 00:05:02.695639 13823 sgd_solver.cpp:112] Iteration 266000, lr = 1e-06
I0823 00:05:13.496166 13823 solver.cpp:239] Iteration 266100 (9.25866 iter/s, 10.8007s/100 iters), loss = 0.0269518
I0823 00:05:13.496229 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0269513 (* 1 = 0.0269513 loss)
I0823 00:05:13.496242 13823 sgd_solver.cpp:112] Iteration 266100, lr = 1e-06
I0823 00:05:24.384050 13823 solver.cpp:239] Iteration 266200 (9.18443 iter/s, 10.888s/100 iters), loss = 0.0271312
I0823 00:05:24.384107 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0271307 (* 1 = 0.0271307 loss)
I0823 00:05:24.384119 13823 sgd_solver.cpp:112] Iteration 266200, lr = 1e-06
I0823 00:05:35.042428 13823 solver.cpp:239] Iteration 266300 (9.3822 iter/s, 10.6585s/100 iters), loss = 0.0280975
I0823 00:05:35.042479 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.028097 (* 1 = 0.028097 loss)
I0823 00:05:35.042490 13823 sgd_solver.cpp:112] Iteration 266300, lr = 1e-06
I0823 00:05:45.479889 13823 solver.cpp:239] Iteration 266400 (9.58078 iter/s, 10.4376s/100 iters), loss = 0.0240223
I0823 00:05:45.479938 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0240218 (* 1 = 0.0240218 loss)
I0823 00:05:45.479948 13823 sgd_solver.cpp:112] Iteration 266400, lr = 1e-06
I0823 00:05:56.268340 13823 solver.cpp:239] Iteration 266500 (9.26908 iter/s, 10.7886s/100 iters), loss = 0.0286856
I0823 00:05:56.268401 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0286851 (* 1 = 0.0286851 loss)
I0823 00:05:56.268414 13823 sgd_solver.cpp:112] Iteration 266500, lr = 1e-06
I0823 00:06:07.169198 13823 solver.cpp:239] Iteration 266600 (9.17351 iter/s, 10.901s/100 iters), loss = 0.0245565
I0823 00:06:07.169265 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.024556 (* 1 = 0.024556 loss)
I0823 00:06:07.169276 13823 sgd_solver.cpp:112] Iteration 266600, lr = 1e-06
I0823 00:06:18.060562 13823 solver.cpp:239] Iteration 266700 (9.18151 iter/s, 10.8915s/100 iters), loss = 0.0240214
I0823 00:06:18.060613 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0240209 (* 1 = 0.0240209 loss)
I0823 00:06:18.060623 13823 sgd_solver.cpp:112] Iteration 266700, lr = 1e-06
I0823 00:06:28.955123 13823 solver.cpp:239] Iteration 266800 (9.17881 iter/s, 10.8947s/100 iters), loss = 0.02561
I0823 00:06:28.955173 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0256094 (* 1 = 0.0256094 loss)
I0823 00:06:28.955183 13823 sgd_solver.cpp:112] Iteration 266800, lr = 1e-06
I0823 00:06:39.815798 13823 solver.cpp:239] Iteration 266900 (9.20745 iter/s, 10.8608s/100 iters), loss = 0.0329146
I0823 00:06:39.815847 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0329141 (* 1 = 0.0329141 loss)
I0823 00:06:39.815856 13823 sgd_solver.cpp:112] Iteration 266900, lr = 1e-06
I0823 00:06:50.825628 13823 solver.cpp:239] Iteration 267000 (9.08271 iter/s, 11.0099s/100 iters), loss = 0.0294974
I0823 00:06:50.825683 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0294968 (* 1 = 0.0294968 loss)
I0823 00:06:50.825693 13823 sgd_solver.cpp:112] Iteration 267000, lr = 1e-06
I0823 00:07:01.703810 13823 solver.cpp:239] Iteration 267100 (9.19264 iter/s, 10.8783s/100 iters), loss = 0.0240492
I0823 00:07:01.703863 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0240486 (* 1 = 0.0240486 loss)
I0823 00:07:01.703873 13823 sgd_solver.cpp:112] Iteration 267100, lr = 1e-06
I0823 00:07:12.952883 13823 solver.cpp:239] Iteration 267200 (8.88955 iter/s, 11.2492s/100 iters), loss = 0.0241273
I0823 00:07:12.952934 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0241268 (* 1 = 0.0241268 loss)
I0823 00:07:12.952944 13823 sgd_solver.cpp:112] Iteration 267200, lr = 1e-06
I0823 00:07:23.940454 13823 solver.cpp:239] Iteration 267300 (9.10112 iter/s, 10.9877s/100 iters), loss = 0.0249785
I0823 00:07:23.940506 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0249779 (* 1 = 0.0249779 loss)
I0823 00:07:23.940515 13823 sgd_solver.cpp:112] Iteration 267300, lr = 1e-06
I0823 00:07:34.664777 13823 solver.cpp:239] Iteration 267400 (9.32453 iter/s, 10.7244s/100 iters), loss = 0.0233325
I0823 00:07:34.664829 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0233319 (* 1 = 0.0233319 loss)
I0823 00:07:34.664839 13823 sgd_solver.cpp:112] Iteration 267400, lr = 1e-06
I0823 00:07:45.387650 13823 solver.cpp:239] Iteration 267500 (9.3258 iter/s, 10.7229s/100 iters), loss = 0.0283838
I0823 00:07:45.387706 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0283832 (* 1 = 0.0283832 loss)
I0823 00:07:45.387715 13823 sgd_solver.cpp:112] Iteration 267500, lr = 1e-06
I0823 00:07:56.252223 13823 solver.cpp:239] Iteration 267600 (9.20417 iter/s, 10.8646s/100 iters), loss = 0.0312935
I0823 00:07:56.252274 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0312929 (* 1 = 0.0312929 loss)
I0823 00:07:56.252283 13823 sgd_solver.cpp:112] Iteration 267600, lr = 1e-06
I0823 00:08:06.872061 13823 solver.cpp:239] Iteration 267700 (9.41628 iter/s, 10.6199s/100 iters), loss = 0.0262614
I0823 00:08:06.872109 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0262609 (* 1 = 0.0262609 loss)
I0823 00:08:06.872118 13823 sgd_solver.cpp:112] Iteration 267700, lr = 1e-06
I0823 00:08:18.130184 13823 solver.cpp:239] Iteration 267800 (8.88241 iter/s, 11.2582s/100 iters), loss = 0.0289435
I0823 00:08:18.130239 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.028943 (* 1 = 0.028943 loss)
I0823 00:08:18.130250 13823 sgd_solver.cpp:112] Iteration 267800, lr = 1e-06
I0823 00:08:29.016088 13823 solver.cpp:239] Iteration 267900 (9.18614 iter/s, 10.886s/100 iters), loss = 0.0298531
I0823 00:08:29.016144 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0298526 (* 1 = 0.0298526 loss)
I0823 00:08:29.016155 13823 sgd_solver.cpp:112] Iteration 267900, lr = 1e-06
I0823 00:08:39.983609 13823 solver.cpp:239] Iteration 268000 (9.11778 iter/s, 10.9676s/100 iters), loss = 0.0306208
I0823 00:08:39.983661 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0306203 (* 1 = 0.0306203 loss)
I0823 00:08:39.983671 13823 sgd_solver.cpp:112] Iteration 268000, lr = 1e-06
I0823 00:08:50.930272 13823 solver.cpp:239] Iteration 268100 (9.13515 iter/s, 10.9467s/100 iters), loss = 0.0254336
I0823 00:08:50.930322 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0254331 (* 1 = 0.0254331 loss)
I0823 00:08:50.930332 13823 sgd_solver.cpp:112] Iteration 268100, lr = 1e-06
I0823 00:09:02.323406 13823 solver.cpp:239] Iteration 268200 (8.77716 iter/s, 11.3932s/100 iters), loss = 0.0282447
I0823 00:09:02.323465 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0282441 (* 1 = 0.0282441 loss)
I0823 00:09:02.323478 13823 sgd_solver.cpp:112] Iteration 268200, lr = 1e-06
I0823 00:09:13.547763 13823 solver.cpp:239] Iteration 268300 (8.90915 iter/s, 11.2244s/100 iters), loss = 0.0260515
I0823 00:09:13.547822 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.026051 (* 1 = 0.026051 loss)
I0823 00:09:13.547834 13823 sgd_solver.cpp:112] Iteration 268300, lr = 1e-06
I0823 00:09:24.561039 13823 solver.cpp:239] Iteration 268400 (9.07991 iter/s, 11.0133s/100 iters), loss = 0.0275139
I0823 00:09:24.561090 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0275134 (* 1 = 0.0275134 loss)
I0823 00:09:24.561100 13823 sgd_solver.cpp:112] Iteration 268400, lr = 1e-06
I0823 00:09:35.752157 13823 solver.cpp:239] Iteration 268500 (8.93561 iter/s, 11.1912s/100 iters), loss = 0.0287041
I0823 00:09:35.752213 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0287036 (* 1 = 0.0287036 loss)
I0823 00:09:35.752223 13823 sgd_solver.cpp:112] Iteration 268500, lr = 1e-06
I0823 00:09:47.007849 13823 solver.cpp:239] Iteration 268600 (8.88435 iter/s, 11.2557s/100 iters), loss = 0.0272794
I0823 00:09:47.007903 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0272788 (* 1 = 0.0272788 loss)
I0823 00:09:47.007915 13823 sgd_solver.cpp:112] Iteration 268600, lr = 1e-06
I0823 00:09:57.951081 13823 solver.cpp:239] Iteration 268700 (9.13803 iter/s, 10.9433s/100 iters), loss = 0.0255074
I0823 00:09:57.951133 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0255069 (* 1 = 0.0255069 loss)
I0823 00:09:57.951143 13823 sgd_solver.cpp:112] Iteration 268700, lr = 1e-06
I0823 00:10:08.994676 13823 solver.cpp:239] Iteration 268800 (9.05498 iter/s, 11.0436s/100 iters), loss = 0.0249363
I0823 00:10:08.994735 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0249358 (* 1 = 0.0249358 loss)
I0823 00:10:08.994746 13823 sgd_solver.cpp:112] Iteration 268800, lr = 1e-06
I0823 00:10:20.033658 13823 solver.cpp:239] Iteration 268900 (9.05877 iter/s, 11.039s/100 iters), loss = 0.0257479
I0823 00:10:20.033726 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0257474 (* 1 = 0.0257474 loss)
I0823 00:10:20.033743 13823 sgd_solver.cpp:112] Iteration 268900, lr = 1e-06
I0823 00:10:31.279978 13823 solver.cpp:239] Iteration 269000 (8.89177 iter/s, 11.2464s/100 iters), loss = 0.0267812
I0823 00:10:31.280045 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0267807 (* 1 = 0.0267807 loss)
I0823 00:10:31.280062 13823 sgd_solver.cpp:112] Iteration 269000, lr = 1e-06
I0823 00:10:42.500226 13823 solver.cpp:239] Iteration 269100 (8.91243 iter/s, 11.2203s/100 iters), loss = 0.0297646
I0823 00:10:42.500281 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0297641 (* 1 = 0.0297641 loss)
I0823 00:10:42.500293 13823 sgd_solver.cpp:112] Iteration 269100, lr = 1e-06
I0823 00:10:53.794317 13823 solver.cpp:239] Iteration 269200 (8.85415 iter/s, 11.2941s/100 iters), loss = 0.023939
I0823 00:10:53.794384 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0239385 (* 1 = 0.0239385 loss)
I0823 00:10:53.794400 13823 sgd_solver.cpp:112] Iteration 269200, lr = 1e-06
I0823 00:11:04.796092 13823 solver.cpp:239] Iteration 269300 (9.08942 iter/s, 11.0018s/100 iters), loss = 0.0234675
I0823 00:11:04.796156 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0234669 (* 1 = 0.0234669 loss)
I0823 00:11:04.796169 13823 sgd_solver.cpp:112] Iteration 269300, lr = 1e-06
I0823 00:11:15.917294 13823 solver.cpp:239] Iteration 269400 (8.99181 iter/s, 11.1212s/100 iters), loss = 0.0266872
I0823 00:11:15.917349 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0266867 (* 1 = 0.0266867 loss)
I0823 00:11:15.917359 13823 sgd_solver.cpp:112] Iteration 269400, lr = 1e-06
I0823 00:11:27.051645 13823 solver.cpp:239] Iteration 269500 (8.98119 iter/s, 11.1344s/100 iters), loss = 0.0297863
I0823 00:11:27.051693 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0297857 (* 1 = 0.0297857 loss)
I0823 00:11:27.051703 13823 sgd_solver.cpp:112] Iteration 269500, lr = 1e-06
I0823 00:11:38.022900 13823 solver.cpp:239] Iteration 269600 (9.1147 iter/s, 10.9713s/100 iters), loss = 0.0321605
I0823 00:11:38.022953 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0321599 (* 1 = 0.0321599 loss)
I0823 00:11:38.022963 13823 sgd_solver.cpp:112] Iteration 269600, lr = 1e-06
I0823 00:11:49.254343 13823 solver.cpp:239] Iteration 269700 (8.90355 iter/s, 11.2315s/100 iters), loss = 0.0286199
I0823 00:11:49.254395 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0286193 (* 1 = 0.0286193 loss)
I0823 00:11:49.254403 13823 sgd_solver.cpp:112] Iteration 269700, lr = 1e-06
I0823 00:12:00.338210 13823 solver.cpp:239] Iteration 269800 (9.0221 iter/s, 11.0839s/100 iters), loss = 0.0309947
I0823 00:12:00.338275 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0309941 (* 1 = 0.0309941 loss)
I0823 00:12:00.338287 13823 sgd_solver.cpp:112] Iteration 269800, lr = 1e-06
I0823 00:12:11.949285 13823 solver.cpp:239] Iteration 269900 (8.61245 iter/s, 11.6111s/100 iters), loss = 0.0404529
I0823 00:12:11.949334 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0404524 (* 1 = 0.0404524 loss)
I0823 00:12:11.949343 13823 sgd_solver.cpp:112] Iteration 269900, lr = 1e-06
I0823 00:12:23.212961 13823 solver.cpp:239] Iteration 270000 (8.87807 iter/s, 11.2637s/100 iters), loss = 0.0288801
I0823 00:12:23.213014 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0288795 (* 1 = 0.0288795 loss)
I0823 00:12:23.213023 13823 sgd_solver.cpp:112] Iteration 270000, lr = 1e-06
I0823 00:12:34.454041 13823 solver.cpp:239] Iteration 270100 (8.89592 iter/s, 11.2411s/100 iters), loss = 0.0267823
I0823 00:12:34.454100 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0267817 (* 1 = 0.0267817 loss)
I0823 00:12:34.454113 13823 sgd_solver.cpp:112] Iteration 270100, lr = 1e-06
I0823 00:12:45.453464 13823 solver.cpp:239] Iteration 270200 (9.09137 iter/s, 10.9994s/100 iters), loss = 0.0269921
I0823 00:12:45.453512 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0269915 (* 1 = 0.0269915 loss)
I0823 00:12:45.453521 13823 sgd_solver.cpp:112] Iteration 270200, lr = 1e-06
I0823 00:12:56.344357 13823 solver.cpp:239] Iteration 270300 (9.18196 iter/s, 10.8909s/100 iters), loss = 0.0377332
I0823 00:12:56.344410 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0377327 (* 1 = 0.0377327 loss)
I0823 00:12:56.344421 13823 sgd_solver.cpp:112] Iteration 270300, lr = 1e-06
I0823 00:13:07.771610 13823 solver.cpp:239] Iteration 270400 (8.75099 iter/s, 11.4273s/100 iters), loss = 0.0245529
I0823 00:13:07.771672 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0245524 (* 1 = 0.0245524 loss)
I0823 00:13:07.771683 13823 sgd_solver.cpp:112] Iteration 270400, lr = 1e-06
I0823 00:13:19.192723 13823 solver.cpp:239] Iteration 270500 (8.7557 iter/s, 11.4211s/100 iters), loss = 0.0275789
I0823 00:13:19.192775 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0275784 (* 1 = 0.0275784 loss)
I0823 00:13:19.192785 13823 sgd_solver.cpp:112] Iteration 270500, lr = 1e-06
I0823 00:13:30.633621 13823 solver.cpp:239] Iteration 270600 (8.74056 iter/s, 11.4409s/100 iters), loss = 0.0294102
I0823 00:13:30.633680 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0294096 (* 1 = 0.0294096 loss)
I0823 00:13:30.633692 13823 sgd_solver.cpp:112] Iteration 270600, lr = 1e-06
I0823 00:13:41.821676 13823 solver.cpp:239] Iteration 270700 (8.93809 iter/s, 11.1881s/100 iters), loss = 0.0287413
I0823 00:13:41.821724 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0287407 (* 1 = 0.0287407 loss)
I0823 00:13:41.821733 13823 sgd_solver.cpp:112] Iteration 270700, lr = 1e-06
I0823 00:13:52.970158 13823 solver.cpp:239] Iteration 270800 (8.96981 iter/s, 11.1485s/100 iters), loss = 0.0240724
I0823 00:13:52.970219 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0240718 (* 1 = 0.0240718 loss)
I0823 00:13:52.970232 13823 sgd_solver.cpp:112] Iteration 270800, lr = 1e-06
I0823 00:14:04.204005 13823 solver.cpp:239] Iteration 270900 (8.90166 iter/s, 11.2339s/100 iters), loss = 0.0252218
I0823 00:14:04.204061 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0252212 (* 1 = 0.0252212 loss)
I0823 00:14:04.204071 13823 sgd_solver.cpp:112] Iteration 270900, lr = 1e-06
I0823 00:14:15.325434 13823 solver.cpp:239] Iteration 271000 (8.99164 iter/s, 11.1214s/100 iters), loss = 0.0273088
I0823 00:14:15.325489 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0273083 (* 1 = 0.0273083 loss)
I0823 00:14:15.325501 13823 sgd_solver.cpp:112] Iteration 271000, lr = 1e-06
I0823 00:14:26.751722 13823 solver.cpp:239] Iteration 271100 (8.75174 iter/s, 11.4263s/100 iters), loss = 0.0330917
I0823 00:14:26.751785 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0330912 (* 1 = 0.0330912 loss)
I0823 00:14:26.751801 13823 sgd_solver.cpp:112] Iteration 271100, lr = 1e-06
I0823 00:14:38.098677 13823 solver.cpp:239] Iteration 271200 (8.81293 iter/s, 11.347s/100 iters), loss = 0.0368622
I0823 00:14:38.098737 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0368616 (* 1 = 0.0368616 loss)
I0823 00:14:38.098748 13823 sgd_solver.cpp:112] Iteration 271200, lr = 1e-06
I0823 00:14:49.475374 13823 solver.cpp:239] Iteration 271300 (8.78989 iter/s, 11.3767s/100 iters), loss = 0.0232276
I0823 00:14:49.475430 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.023227 (* 1 = 0.023227 loss)
I0823 00:14:49.475443 13823 sgd_solver.cpp:112] Iteration 271300, lr = 1e-06
I0823 00:15:00.761210 13823 solver.cpp:239] Iteration 271400 (8.86066 iter/s, 11.2858s/100 iters), loss = 0.0266049
I0823 00:15:00.761268 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0266044 (* 1 = 0.0266044 loss)
I0823 00:15:00.761279 13823 sgd_solver.cpp:112] Iteration 271400, lr = 1e-06
I0823 00:15:12.114306 13823 solver.cpp:239] Iteration 271500 (8.80816 iter/s, 11.3531s/100 iters), loss = 0.0259943
I0823 00:15:12.114368 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0259937 (* 1 = 0.0259937 loss)
I0823 00:15:12.114382 13823 sgd_solver.cpp:112] Iteration 271500, lr = 1e-06
I0823 00:15:23.621237 13823 solver.cpp:239] Iteration 271600 (8.69041 iter/s, 11.5069s/100 iters), loss = 0.0376098
I0823 00:15:23.621299 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0376093 (* 1 = 0.0376093 loss)
I0823 00:15:23.621311 13823 sgd_solver.cpp:112] Iteration 271600, lr = 1e-06
I0823 00:15:35.135244 13823 solver.cpp:239] Iteration 271700 (8.68507 iter/s, 11.514s/100 iters), loss = 0.0424106
I0823 00:15:35.135295 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.04241 (* 1 = 0.04241 loss)
I0823 00:15:35.135305 13823 sgd_solver.cpp:112] Iteration 271700, lr = 1e-06
I0823 00:15:46.624763 13823 solver.cpp:239] Iteration 271800 (8.70358 iter/s, 11.4895s/100 iters), loss = 0.0248683
I0823 00:15:46.624815 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0248678 (* 1 = 0.0248678 loss)
I0823 00:15:46.624825 13823 sgd_solver.cpp:112] Iteration 271800, lr = 1e-06
I0823 00:15:58.266405 13823 solver.cpp:239] Iteration 271900 (8.58985 iter/s, 11.6416s/100 iters), loss = 0.0324355
I0823 00:15:58.266464 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0324349 (* 1 = 0.0324349 loss)
I0823 00:15:58.266475 13823 sgd_solver.cpp:112] Iteration 271900, lr = 1e-06
I0823 00:16:09.827371 13823 solver.cpp:239] Iteration 272000 (8.6498 iter/s, 11.561s/100 iters), loss = 0.02833
I0823 00:16:09.827431 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0283294 (* 1 = 0.0283294 loss)
I0823 00:16:09.827442 13823 sgd_solver.cpp:112] Iteration 272000, lr = 1e-06
I0823 00:16:21.218142 13823 solver.cpp:239] Iteration 272100 (8.77904 iter/s, 11.3908s/100 iters), loss = 0.036067
I0823 00:16:21.218204 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0360664 (* 1 = 0.0360664 loss)
I0823 00:16:21.218215 13823 sgd_solver.cpp:112] Iteration 272100, lr = 1e-06
I0823 00:16:32.876264 13823 solver.cpp:239] Iteration 272200 (8.57771 iter/s, 11.6581s/100 iters), loss = 0.0245394
I0823 00:16:32.876318 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0245388 (* 1 = 0.0245388 loss)
I0823 00:16:32.876328 13823 sgd_solver.cpp:112] Iteration 272200, lr = 1e-06
I0823 00:16:44.543233 13823 solver.cpp:239] Iteration 272300 (8.5712 iter/s, 11.667s/100 iters), loss = 0.0294971
I0823 00:16:44.543292 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0294966 (* 1 = 0.0294966 loss)
I0823 00:16:44.543303 13823 sgd_solver.cpp:112] Iteration 272300, lr = 1e-06
I0823 00:16:56.154707 13823 solver.cpp:239] Iteration 272400 (8.61218 iter/s, 11.6115s/100 iters), loss = 0.0261103
I0823 00:16:56.154788 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0261097 (* 1 = 0.0261097 loss)
I0823 00:16:56.154801 13823 sgd_solver.cpp:112] Iteration 272400, lr = 1e-06
I0823 00:17:07.635249 13823 solver.cpp:239] Iteration 272500 (8.71041 iter/s, 11.4805s/100 iters), loss = 0.0292431
I0823 00:17:07.635313 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0292425 (* 1 = 0.0292425 loss)
I0823 00:17:07.635324 13823 sgd_solver.cpp:112] Iteration 272500, lr = 1e-06
I0823 00:17:19.043406 13823 solver.cpp:239] Iteration 272600 (8.76566 iter/s, 11.4081s/100 iters), loss = 0.0275689
I0823 00:17:19.043460 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0275683 (* 1 = 0.0275683 loss)
I0823 00:17:19.043471 13823 sgd_solver.cpp:112] Iteration 272600, lr = 1e-06
I0823 00:17:30.572072 13823 solver.cpp:239] Iteration 272700 (8.67403 iter/s, 11.5287s/100 iters), loss = 0.0246972
I0823 00:17:30.572122 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0246966 (* 1 = 0.0246966 loss)
I0823 00:17:30.572136 13823 sgd_solver.cpp:112] Iteration 272700, lr = 1e-06
I0823 00:17:42.217535 13823 solver.cpp:239] Iteration 272800 (8.58703 iter/s, 11.6455s/100 iters), loss = 0.0257535
I0823 00:17:42.217589 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0257529 (* 1 = 0.0257529 loss)
I0823 00:17:42.217599 13823 sgd_solver.cpp:112] Iteration 272800, lr = 1e-06
I0823 00:17:53.868885 13823 solver.cpp:239] Iteration 272900 (8.5827 iter/s, 11.6513s/100 iters), loss = 0.0278242
I0823 00:17:53.868943 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0278236 (* 1 = 0.0278236 loss)
I0823 00:17:53.868954 13823 sgd_solver.cpp:112] Iteration 272900, lr = 1e-06
I0823 00:18:05.465873 13823 solver.cpp:239] Iteration 273000 (8.62293 iter/s, 11.597s/100 iters), loss = 0.026202
I0823 00:18:05.465927 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0262014 (* 1 = 0.0262014 loss)
I0823 00:18:05.465937 13823 sgd_solver.cpp:112] Iteration 273000, lr = 1e-06
I0823 00:18:17.127399 13823 solver.cpp:239] Iteration 273100 (8.57521 iter/s, 11.6615s/100 iters), loss = 0.027303
I0823 00:18:17.127452 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0273024 (* 1 = 0.0273024 loss)
I0823 00:18:17.127461 13823 sgd_solver.cpp:112] Iteration 273100, lr = 1e-06
I0823 00:18:28.591071 13823 solver.cpp:239] Iteration 273200 (8.72321 iter/s, 11.4637s/100 iters), loss = 0.0276819
I0823 00:18:28.591127 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0276813 (* 1 = 0.0276813 loss)
I0823 00:18:28.591140 13823 sgd_solver.cpp:112] Iteration 273200, lr = 1e-06
I0823 00:18:40.131880 13823 solver.cpp:239] Iteration 273300 (8.66491 iter/s, 11.5408s/100 iters), loss = 0.0254727
I0823 00:18:40.131930 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0254721 (* 1 = 0.0254721 loss)
I0823 00:18:40.131939 13823 sgd_solver.cpp:112] Iteration 273300, lr = 1e-06
I0823 00:18:51.666030 13823 solver.cpp:239] Iteration 273400 (8.66991 iter/s, 11.5341s/100 iters), loss = 0.0250686
I0823 00:18:51.666098 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.025068 (* 1 = 0.025068 loss)
I0823 00:18:51.666112 13823 sgd_solver.cpp:112] Iteration 273400, lr = 1e-06
I0823 00:19:03.218263 13823 solver.cpp:239] Iteration 273500 (8.65635 iter/s, 11.5522s/100 iters), loss = 0.0316791
I0823 00:19:03.218324 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0316785 (* 1 = 0.0316785 loss)
I0823 00:19:03.218336 13823 sgd_solver.cpp:112] Iteration 273500, lr = 1e-06
I0823 00:19:14.741247 13823 solver.cpp:239] Iteration 273600 (8.67832 iter/s, 11.523s/100 iters), loss = 0.0286252
I0823 00:19:14.741314 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0286246 (* 1 = 0.0286246 loss)
I0823 00:19:14.741331 13823 sgd_solver.cpp:112] Iteration 273600, lr = 1e-06
I0823 00:19:26.292593 13823 solver.cpp:239] Iteration 273700 (8.65701 iter/s, 11.5513s/100 iters), loss = 0.0329116
I0823 00:19:26.292655 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.032911 (* 1 = 0.032911 loss)
I0823 00:19:26.292667 13823 sgd_solver.cpp:112] Iteration 273700, lr = 1e-06
I0823 00:19:37.955081 13823 solver.cpp:239] Iteration 273800 (8.57451 iter/s, 11.6625s/100 iters), loss = 0.0261699
I0823 00:19:37.955144 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0261693 (* 1 = 0.0261693 loss)
I0823 00:19:37.955157 13823 sgd_solver.cpp:112] Iteration 273800, lr = 1e-06
I0823 00:19:49.608602 13823 solver.cpp:239] Iteration 273900 (8.58111 iter/s, 11.6535s/100 iters), loss = 0.025305
I0823 00:19:49.608659 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0253044 (* 1 = 0.0253044 loss)
I0823 00:19:49.608669 13823 sgd_solver.cpp:112] Iteration 273900, lr = 1e-06
I0823 00:19:59.250633 13823 solver.cpp:239] Iteration 274000 (10.3713 iter/s, 9.64201s/100 iters), loss = 0.0235933
I0823 00:19:59.250684 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0235927 (* 1 = 0.0235927 loss)
I0823 00:19:59.250694 13823 sgd_solver.cpp:112] Iteration 274000, lr = 1e-06
I0823 00:20:08.712237 13823 solver.cpp:239] Iteration 274100 (10.5691 iter/s, 9.46159s/100 iters), loss = 0.0261769
I0823 00:20:08.712291 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0261763 (* 1 = 0.0261763 loss)
I0823 00:20:08.712301 13823 sgd_solver.cpp:112] Iteration 274100, lr = 1e-06
I0823 00:20:18.029280 13823 solver.cpp:239] Iteration 274200 (10.733 iter/s, 9.31702s/100 iters), loss = 0.0254052
I0823 00:20:18.029340 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0254046 (* 1 = 0.0254046 loss)
I0823 00:20:18.029351 13823 sgd_solver.cpp:112] Iteration 274200, lr = 1e-06
I0823 00:20:27.556613 13823 solver.cpp:239] Iteration 274300 (10.4961 iter/s, 9.52731s/100 iters), loss = 0.0246318
I0823 00:20:27.556659 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0246312 (* 1 = 0.0246312 loss)
I0823 00:20:27.556669 13823 sgd_solver.cpp:112] Iteration 274300, lr = 1e-06
I0823 00:20:37.209141 13823 solver.cpp:239] Iteration 274400 (10.36 iter/s, 9.65252s/100 iters), loss = 0.025533
I0823 00:20:37.209182 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0255324 (* 1 = 0.0255324 loss)
I0823 00:20:37.209189 13823 sgd_solver.cpp:112] Iteration 274400, lr = 1e-06
I0823 00:20:46.837002 13823 solver.cpp:239] Iteration 274500 (10.3865 iter/s, 9.62786s/100 iters), loss = 0.0244812
I0823 00:20:46.837056 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0244806 (* 1 = 0.0244806 loss)
I0823 00:20:46.837065 13823 sgd_solver.cpp:112] Iteration 274500, lr = 1e-06
I0823 00:20:56.277557 13823 solver.cpp:239] Iteration 274600 (10.5926 iter/s, 9.44054s/100 iters), loss = 0.0286891
I0823 00:20:56.277599 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0286885 (* 1 = 0.0286885 loss)
I0823 00:20:56.277607 13823 sgd_solver.cpp:112] Iteration 274600, lr = 1e-06
I0823 00:21:05.625169 13823 solver.cpp:239] Iteration 274700 (10.6979 iter/s, 9.3476s/100 iters), loss = 0.0278048
I0823 00:21:05.625211 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0278042 (* 1 = 0.0278042 loss)
I0823 00:21:05.625218 13823 sgd_solver.cpp:112] Iteration 274700, lr = 1e-06
I0823 00:21:14.776818 13823 solver.cpp:239] Iteration 274800 (10.927 iter/s, 9.15164s/100 iters), loss = 0.0263698
I0823 00:21:14.776870 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0263692 (* 1 = 0.0263692 loss)
I0823 00:21:14.776878 13823 sgd_solver.cpp:112] Iteration 274800, lr = 1e-06
I0823 00:21:24.453719 13823 solver.cpp:239] Iteration 274900 (10.3339 iter/s, 9.67688s/100 iters), loss = 0.0220584
I0823 00:21:24.453779 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0220578 (* 1 = 0.0220578 loss)
I0823 00:21:24.453792 13823 sgd_solver.cpp:112] Iteration 274900, lr = 1e-06
I0823 00:21:34.201596 13823 solver.cpp:239] Iteration 275000 (10.2587 iter/s, 9.74785s/100 iters), loss = 0.034399
I0823 00:21:34.201654 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0343984 (* 1 = 0.0343984 loss)
I0823 00:21:34.201666 13823 sgd_solver.cpp:112] Iteration 275000, lr = 1e-06
I0823 00:21:43.903539 13823 solver.cpp:239] Iteration 275100 (10.3072 iter/s, 9.70192s/100 iters), loss = 0.0338815
I0823 00:21:43.903590 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0338809 (* 1 = 0.0338809 loss)
I0823 00:21:43.903600 13823 sgd_solver.cpp:112] Iteration 275100, lr = 1e-06
I0823 00:21:53.554504 13823 solver.cpp:239] Iteration 275200 (10.3617 iter/s, 9.65094s/100 iters), loss = 0.0332928
I0823 00:21:53.554554 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0332922 (* 1 = 0.0332922 loss)
I0823 00:21:53.554563 13823 sgd_solver.cpp:112] Iteration 275200, lr = 1e-06
I0823 00:22:03.540073 13823 solver.cpp:239] Iteration 275300 (10.0145 iter/s, 9.98555s/100 iters), loss = 0.0275802
I0823 00:22:03.540125 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0275796 (* 1 = 0.0275796 loss)
I0823 00:22:03.540139 13823 sgd_solver.cpp:112] Iteration 275300, lr = 1e-06
I0823 00:22:13.080157 13823 solver.cpp:239] Iteration 275400 (10.4821 iter/s, 9.54006s/100 iters), loss = 0.0286925
I0823 00:22:13.080214 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0286919 (* 1 = 0.0286919 loss)
I0823 00:22:13.080225 13823 sgd_solver.cpp:112] Iteration 275400, lr = 1e-06
I0823 00:22:22.647220 13823 solver.cpp:239] Iteration 275500 (10.4526 iter/s, 9.56703s/100 iters), loss = 0.024784
I0823 00:22:22.647275 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0247834 (* 1 = 0.0247834 loss)
I0823 00:22:22.647286 13823 sgd_solver.cpp:112] Iteration 275500, lr = 1e-06
I0823 00:22:32.287715 13823 solver.cpp:239] Iteration 275600 (10.3729 iter/s, 9.64047s/100 iters), loss = 0.0321289
I0823 00:22:32.287766 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0321283 (* 1 = 0.0321283 loss)
I0823 00:22:32.287776 13823 sgd_solver.cpp:112] Iteration 275600, lr = 1e-06
I0823 00:22:41.810631 13823 solver.cpp:239] Iteration 275700 (10.501 iter/s, 9.52289s/100 iters), loss = 0.0267551
I0823 00:22:41.810683 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0267545 (* 1 = 0.0267545 loss)
I0823 00:22:41.810693 13823 sgd_solver.cpp:112] Iteration 275700, lr = 1e-06
I0823 00:22:51.498368 13823 solver.cpp:239] Iteration 275800 (10.3224 iter/s, 9.68771s/100 iters), loss = 0.0251297
I0823 00:22:51.498420 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.025129 (* 1 = 0.025129 loss)
I0823 00:22:51.498430 13823 sgd_solver.cpp:112] Iteration 275800, lr = 1e-06
I0823 00:23:01.319869 13823 solver.cpp:239] Iteration 275900 (10.1818 iter/s, 9.82148s/100 iters), loss = 0.0261325
I0823 00:23:01.319918 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0261318 (* 1 = 0.0261318 loss)
I0823 00:23:01.319928 13823 sgd_solver.cpp:112] Iteration 275900, lr = 1e-06
I0823 00:23:11.092744 13823 solver.cpp:239] Iteration 276000 (10.2324 iter/s, 9.77285s/100 iters), loss = 0.0242403
I0823 00:23:11.092803 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0242396 (* 1 = 0.0242396 loss)
I0823 00:23:11.092818 13823 sgd_solver.cpp:112] Iteration 276000, lr = 1e-06
I0823 00:23:20.667037 13823 solver.cpp:239] Iteration 276100 (10.4447 iter/s, 9.57426s/100 iters), loss = 0.0289664
I0823 00:23:20.667088 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0289657 (* 1 = 0.0289657 loss)
I0823 00:23:20.667096 13823 sgd_solver.cpp:112] Iteration 276100, lr = 1e-06
I0823 00:23:30.293478 13823 solver.cpp:239] Iteration 276200 (10.3881 iter/s, 9.62642s/100 iters), loss = 0.0315262
I0823 00:23:30.293534 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0315255 (* 1 = 0.0315255 loss)
I0823 00:23:30.293547 13823 sgd_solver.cpp:112] Iteration 276200, lr = 1e-06
I0823 00:23:39.991933 13823 solver.cpp:239] Iteration 276300 (10.311 iter/s, 9.69843s/100 iters), loss = 0.0284656
I0823 00:23:39.991981 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0284649 (* 1 = 0.0284649 loss)
I0823 00:23:39.991991 13823 sgd_solver.cpp:112] Iteration 276300, lr = 1e-06
I0823 00:23:49.842906 13823 solver.cpp:239] Iteration 276400 (10.1513 iter/s, 9.85095s/100 iters), loss = 0.0256636
I0823 00:23:49.842958 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.025663 (* 1 = 0.025663 loss)
I0823 00:23:49.842967 13823 sgd_solver.cpp:112] Iteration 276400, lr = 1e-06
I0823 00:23:59.244534 13823 solver.cpp:239] Iteration 276500 (10.6365 iter/s, 9.4016s/100 iters), loss = 0.0299846
I0823 00:23:59.244576 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0299839 (* 1 = 0.0299839 loss)
I0823 00:23:59.244583 13823 sgd_solver.cpp:112] Iteration 276500, lr = 1e-06
I0823 00:24:08.650434 13823 solver.cpp:239] Iteration 276600 (10.6316 iter/s, 9.40589s/100 iters), loss = 0.0385378
I0823 00:24:08.650477 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0385371 (* 1 = 0.0385371 loss)
I0823 00:24:08.650485 13823 sgd_solver.cpp:112] Iteration 276600, lr = 1e-06
I0823 00:24:18.129894 13823 solver.cpp:239] Iteration 276700 (10.5491 iter/s, 9.47944s/100 iters), loss = 0.0277718
I0823 00:24:18.129945 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0277712 (* 1 = 0.0277712 loss)
I0823 00:24:18.129952 13823 sgd_solver.cpp:112] Iteration 276700, lr = 1e-06
I0823 00:24:27.519444 13823 solver.cpp:239] Iteration 276800 (10.6502 iter/s, 9.38952s/100 iters), loss = 0.0236607
I0823 00:24:27.519501 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0236601 (* 1 = 0.0236601 loss)
I0823 00:24:27.519515 13823 sgd_solver.cpp:112] Iteration 276800, lr = 1e-06
I0823 00:24:37.303961 13823 solver.cpp:239] Iteration 276900 (10.2203 iter/s, 9.78448s/100 iters), loss = 0.0243557
I0823 00:24:37.304018 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0243551 (* 1 = 0.0243551 loss)
I0823 00:24:37.304030 13823 sgd_solver.cpp:112] Iteration 276900, lr = 1e-06
I0823 00:24:46.981024 13823 solver.cpp:239] Iteration 277000 (10.3337 iter/s, 9.67703s/100 iters), loss = 0.0260611
I0823 00:24:46.981087 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0260605 (* 1 = 0.0260605 loss)
I0823 00:24:46.981101 13823 sgd_solver.cpp:112] Iteration 277000, lr = 1e-06
I0823 00:24:56.598650 13823 solver.cpp:239] Iteration 277100 (10.3976 iter/s, 9.61759s/100 iters), loss = 0.0284754
I0823 00:24:56.598704 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0284747 (* 1 = 0.0284747 loss)
I0823 00:24:56.598714 13823 sgd_solver.cpp:112] Iteration 277100, lr = 1e-06
I0823 00:25:06.603544 13823 solver.cpp:239] Iteration 277200 (9.99514 iter/s, 10.0049s/100 iters), loss = 0.0280619
I0823 00:25:06.603615 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0280613 (* 1 = 0.0280613 loss)
I0823 00:25:06.603632 13823 sgd_solver.cpp:112] Iteration 277200, lr = 1e-06
I0823 00:25:16.469236 13823 solver.cpp:239] Iteration 277300 (10.1362 iter/s, 9.86565s/100 iters), loss = 0.0273921
I0823 00:25:16.469290 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0273915 (* 1 = 0.0273915 loss)
I0823 00:25:16.469300 13823 sgd_solver.cpp:112] Iteration 277300, lr = 1e-06
I0823 00:25:26.164513 13823 solver.cpp:239] Iteration 277400 (10.3143 iter/s, 9.69525s/100 iters), loss = 0.0380929
I0823 00:25:26.164583 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0380923 (* 1 = 0.0380923 loss)
I0823 00:25:26.164600 13823 sgd_solver.cpp:112] Iteration 277400, lr = 1e-06
I0823 00:25:36.025405 13823 solver.cpp:239] Iteration 277500 (10.1411 iter/s, 9.86085s/100 iters), loss = 0.0320488
I0823 00:25:36.025455 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0320482 (* 1 = 0.0320482 loss)
I0823 00:25:36.025465 13823 sgd_solver.cpp:112] Iteration 277500, lr = 1e-06
I0823 00:25:45.729533 13823 solver.cpp:239] Iteration 277600 (10.3049 iter/s, 9.7041s/100 iters), loss = 0.0279602
I0823 00:25:45.729593 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0279595 (* 1 = 0.0279595 loss)
I0823 00:25:45.729605 13823 sgd_solver.cpp:112] Iteration 277600, lr = 1e-06
I0823 00:25:55.536878 13823 solver.cpp:239] Iteration 277700 (10.1965 iter/s, 9.80732s/100 iters), loss = 0.0294774
I0823 00:25:55.536921 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0294767 (* 1 = 0.0294767 loss)
I0823 00:25:55.536927 13823 sgd_solver.cpp:112] Iteration 277700, lr = 1e-06
I0823 00:26:04.982080 13823 solver.cpp:239] Iteration 277800 (10.5874 iter/s, 9.44518s/100 iters), loss = 0.0210101
I0823 00:26:04.982120 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0210095 (* 1 = 0.0210095 loss)
I0823 00:26:04.982128 13823 sgd_solver.cpp:112] Iteration 277800, lr = 1e-06
I0823 00:26:14.805800 13823 solver.cpp:239] Iteration 277900 (10.1795 iter/s, 9.8237s/100 iters), loss = 0.0290317
I0823 00:26:14.805853 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0290311 (* 1 = 0.0290311 loss)
I0823 00:26:14.805864 13823 sgd_solver.cpp:112] Iteration 277900, lr = 1e-06
I0823 00:26:24.512071 13823 solver.cpp:239] Iteration 278000 (10.3026 iter/s, 9.70624s/100 iters), loss = 0.0264473
I0823 00:26:24.512114 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0264467 (* 1 = 0.0264467 loss)
I0823 00:26:24.512121 13823 sgd_solver.cpp:112] Iteration 278000, lr = 1e-06
I0823 00:26:34.247370 13823 solver.cpp:239] Iteration 278100 (10.2719 iter/s, 9.73528s/100 iters), loss = 0.0352408
I0823 00:26:34.247426 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0352402 (* 1 = 0.0352402 loss)
I0823 00:26:34.247439 13823 sgd_solver.cpp:112] Iteration 278100, lr = 1e-06
I0823 00:26:44.141757 13823 solver.cpp:239] Iteration 278200 (10.1068 iter/s, 9.89435s/100 iters), loss = 0.0333567
I0823 00:26:44.141814 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0333561 (* 1 = 0.0333561 loss)
I0823 00:26:44.141827 13823 sgd_solver.cpp:112] Iteration 278200, lr = 1e-06
I0823 00:26:54.018221 13823 solver.cpp:239] Iteration 278300 (10.1251 iter/s, 9.87643s/100 iters), loss = 0.0277243
I0823 00:26:54.018275 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0277237 (* 1 = 0.0277237 loss)
I0823 00:26:54.018285 13823 sgd_solver.cpp:112] Iteration 278300, lr = 1e-06
I0823 00:27:03.911031 13823 solver.cpp:239] Iteration 278400 (10.1084 iter/s, 9.89278s/100 iters), loss = 0.0376595
I0823 00:27:03.911089 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0376589 (* 1 = 0.0376589 loss)
I0823 00:27:03.911103 13823 sgd_solver.cpp:112] Iteration 278400, lr = 1e-06
I0823 00:27:13.691874 13823 solver.cpp:239] Iteration 278500 (10.2241 iter/s, 9.78081s/100 iters), loss = 0.0264927
I0823 00:27:13.691928 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0264921 (* 1 = 0.0264921 loss)
I0823 00:27:13.691942 13823 sgd_solver.cpp:112] Iteration 278500, lr = 1e-06
I0823 00:27:23.596918 13823 solver.cpp:239] Iteration 278600 (10.0959 iter/s, 9.90501s/100 iters), loss = 0.0258608
I0823 00:27:23.596978 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0258601 (* 1 = 0.0258601 loss)
I0823 00:27:23.596992 13823 sgd_solver.cpp:112] Iteration 278600, lr = 1e-06
I0823 00:27:33.515027 13823 solver.cpp:239] Iteration 278700 (10.0826 iter/s, 9.91807s/100 iters), loss = 0.0270397
I0823 00:27:33.515079 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0270391 (* 1 = 0.0270391 loss)
I0823 00:27:33.515089 13823 sgd_solver.cpp:112] Iteration 278700, lr = 1e-06
I0823 00:27:43.488085 13823 solver.cpp:239] Iteration 278800 (10.027 iter/s, 9.97302s/100 iters), loss = 0.0368786
I0823 00:27:43.488139 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.036878 (* 1 = 0.036878 loss)
I0823 00:27:43.488149 13823 sgd_solver.cpp:112] Iteration 278800, lr = 1e-06
I0823 00:27:53.398699 13823 solver.cpp:239] Iteration 278900 (10.0902 iter/s, 9.91058s/100 iters), loss = 0.0277762
I0823 00:27:53.398752 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0277756 (* 1 = 0.0277756 loss)
I0823 00:27:53.398762 13823 sgd_solver.cpp:112] Iteration 278900, lr = 1e-06
I0823 00:28:03.082913 13823 solver.cpp:239] Iteration 279000 (10.3261 iter/s, 9.68418s/100 iters), loss = 0.0280168
I0823 00:28:03.082973 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0280162 (* 1 = 0.0280162 loss)
I0823 00:28:03.082986 13823 sgd_solver.cpp:112] Iteration 279000, lr = 1e-06
I0823 00:28:13.025147 13823 solver.cpp:239] Iteration 279100 (10.0581 iter/s, 9.9422s/100 iters), loss = 0.0285392
I0823 00:28:13.025205 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0285386 (* 1 = 0.0285386 loss)
I0823 00:28:13.025219 13823 sgd_solver.cpp:112] Iteration 279100, lr = 1e-06
I0823 00:28:22.941323 13823 solver.cpp:239] Iteration 279200 (10.0846 iter/s, 9.91614s/100 iters), loss = 0.0280001
I0823 00:28:22.941375 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0279995 (* 1 = 0.0279995 loss)
I0823 00:28:22.941385 13823 sgd_solver.cpp:112] Iteration 279200, lr = 1e-06
I0823 00:28:33.009097 13823 solver.cpp:239] Iteration 279300 (9.93271 iter/s, 10.0677s/100 iters), loss = 0.0251307
I0823 00:28:33.009147 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0251301 (* 1 = 0.0251301 loss)
I0823 00:28:33.009157 13823 sgd_solver.cpp:112] Iteration 279300, lr = 1e-06
I0823 00:28:42.984709 13823 solver.cpp:239] Iteration 279400 (10.0245 iter/s, 9.97558s/100 iters), loss = 0.0255447
I0823 00:28:42.984766 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0255441 (* 1 = 0.0255441 loss)
I0823 00:28:42.984781 13823 sgd_solver.cpp:112] Iteration 279400, lr = 1e-06
I0823 00:28:53.012212 13823 solver.cpp:239] Iteration 279500 (9.97261 iter/s, 10.0275s/100 iters), loss = 0.0252401
I0823 00:28:53.012259 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0252394 (* 1 = 0.0252394 loss)
I0823 00:28:53.012269 13823 sgd_solver.cpp:112] Iteration 279500, lr = 1e-06
I0823 00:29:02.770409 13823 solver.cpp:239] Iteration 279600 (10.2478 iter/s, 9.75817s/100 iters), loss = 0.0253007
I0823 00:29:02.770467 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0253001 (* 1 = 0.0253001 loss)
I0823 00:29:02.770479 13823 sgd_solver.cpp:112] Iteration 279600, lr = 1e-06
I0823 00:29:12.886173 13823 solver.cpp:239] Iteration 279700 (9.8856 iter/s, 10.1157s/100 iters), loss = 0.032148
I0823 00:29:12.886229 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0321474 (* 1 = 0.0321474 loss)
I0823 00:29:12.886242 13823 sgd_solver.cpp:112] Iteration 279700, lr = 1e-06
I0823 00:29:22.916580 13823 solver.cpp:239] Iteration 279800 (9.96972 iter/s, 10.0304s/100 iters), loss = 0.0248145
I0823 00:29:22.916633 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0248139 (* 1 = 0.0248139 loss)
I0823 00:29:22.916643 13823 sgd_solver.cpp:112] Iteration 279800, lr = 1e-06
I0823 00:29:33.017745 13823 solver.cpp:239] Iteration 279900 (9.89988 iter/s, 10.1011s/100 iters), loss = 0.0253488
I0823 00:29:33.017796 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0253482 (* 1 = 0.0253482 loss)
I0823 00:29:33.017805 13823 sgd_solver.cpp:112] Iteration 279900, lr = 1e-06
I0823 00:29:43.143604 13823 solver.cpp:464] Snapshotting to binary proto file ./model_112/cascade_mobilenet_112_iter_280000.caffemodel
I0823 00:29:43.186774 13823 sgd_solver.cpp:284] Snapshotting solver state to binary proto file ./model_112/cascade_mobilenet_112_iter_280000.solverstate
I0823 00:29:43.217871 13823 solver.cpp:347] Iteration 280000, Testing net (#0)
I0823 00:30:54.198186 13823 solver.cpp:414]     Test net output #0: landmark_loss = 0.0219509 (* 1 = 0.0219509 loss)
I0823 00:30:54.316496 13823 solver.cpp:239] Iteration 280000 (1.23003 iter/s, 81.2989s/100 iters), loss = 0.0227701
I0823 00:30:54.316552 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0227695 (* 1 = 0.0227695 loss)
I0823 00:30:54.316574 13823 sgd_solver.cpp:112] Iteration 280000, lr = 1e-06
I0823 00:31:04.418614 13823 solver.cpp:239] Iteration 280100 (9.89894 iter/s, 10.1021s/100 iters), loss = 0.0274428
I0823 00:31:04.418673 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0274422 (* 1 = 0.0274422 loss)
I0823 00:31:04.418686 13823 sgd_solver.cpp:112] Iteration 280100, lr = 1e-06
I0823 00:31:14.622102 13823 solver.cpp:239] Iteration 280200 (9.8006 iter/s, 10.2035s/100 iters), loss = 0.0265617
I0823 00:31:14.622157 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.026561 (* 1 = 0.026561 loss)
I0823 00:31:14.622170 13823 sgd_solver.cpp:112] Iteration 280200, lr = 1e-06
I0823 00:31:25.089602 13823 solver.cpp:239] Iteration 280300 (9.55341 iter/s, 10.4675s/100 iters), loss = 0.0289818
I0823 00:31:25.089659 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0289812 (* 1 = 0.0289812 loss)
I0823 00:31:25.089670 13823 sgd_solver.cpp:112] Iteration 280300, lr = 1e-06
I0823 00:31:35.403537 13823 solver.cpp:239] Iteration 280400 (9.69565 iter/s, 10.3139s/100 iters), loss = 0.0374973
I0823 00:31:35.403589 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0374966 (* 1 = 0.0374966 loss)
I0823 00:31:35.403599 13823 sgd_solver.cpp:112] Iteration 280400, lr = 1e-06
I0823 00:31:45.433229 13823 solver.cpp:239] Iteration 280500 (9.97043 iter/s, 10.0297s/100 iters), loss = 0.0262443
I0823 00:31:45.433282 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0262436 (* 1 = 0.0262436 loss)
I0823 00:31:45.433292 13823 sgd_solver.cpp:112] Iteration 280500, lr = 1e-06
I0823 00:31:55.691535 13823 solver.cpp:239] Iteration 280600 (9.74823 iter/s, 10.2583s/100 iters), loss = 0.0249281
I0823 00:31:55.691597 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0249275 (* 1 = 0.0249275 loss)
I0823 00:31:55.691609 13823 sgd_solver.cpp:112] Iteration 280600, lr = 1e-06
I0823 00:32:05.756078 13823 solver.cpp:239] Iteration 280700 (9.93591 iter/s, 10.0645s/100 iters), loss = 0.0243255
I0823 00:32:05.756139 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0243249 (* 1 = 0.0243249 loss)
I0823 00:32:05.756153 13823 sgd_solver.cpp:112] Iteration 280700, lr = 1e-06
I0823 00:32:16.035653 13823 solver.cpp:239] Iteration 280800 (9.72806 iter/s, 10.2795s/100 iters), loss = 0.028198
I0823 00:32:16.035706 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0281974 (* 1 = 0.0281974 loss)
I0823 00:32:16.035715 13823 sgd_solver.cpp:112] Iteration 280800, lr = 1e-06
I0823 00:32:26.486078 13823 solver.cpp:239] Iteration 280900 (9.56902 iter/s, 10.4504s/100 iters), loss = 0.0267926
I0823 00:32:26.486136 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.026792 (* 1 = 0.026792 loss)
I0823 00:32:26.486150 13823 sgd_solver.cpp:112] Iteration 280900, lr = 1e-06
I0823 00:32:36.924125 13823 solver.cpp:239] Iteration 281000 (9.58037 iter/s, 10.438s/100 iters), loss = 0.0244748
I0823 00:32:36.924183 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0244742 (* 1 = 0.0244742 loss)
I0823 00:32:36.924196 13823 sgd_solver.cpp:112] Iteration 281000, lr = 1e-06
I0823 00:32:47.153940 13823 solver.cpp:239] Iteration 281100 (9.77538 iter/s, 10.2298s/100 iters), loss = 0.0233488
I0823 00:32:47.153993 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0233482 (* 1 = 0.0233482 loss)
I0823 00:32:47.154003 13823 sgd_solver.cpp:112] Iteration 281100, lr = 1e-06
I0823 00:32:57.549360 13823 solver.cpp:239] Iteration 281200 (9.61965 iter/s, 10.3954s/100 iters), loss = 0.0410083
I0823 00:32:57.549410 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0410077 (* 1 = 0.0410077 loss)
I0823 00:32:57.549420 13823 sgd_solver.cpp:112] Iteration 281200, lr = 1e-06
I0823 00:33:07.939963 13823 solver.cpp:239] Iteration 281300 (9.62411 iter/s, 10.3906s/100 iters), loss = 0.0336259
I0823 00:33:07.940019 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0336253 (* 1 = 0.0336253 loss)
I0823 00:33:07.940029 13823 sgd_solver.cpp:112] Iteration 281300, lr = 1e-06
I0823 00:33:18.618623 13823 solver.cpp:239] Iteration 281400 (9.3645 iter/s, 10.6786s/100 iters), loss = 0.0280795
I0823 00:33:18.618670 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0280789 (* 1 = 0.0280789 loss)
I0823 00:33:18.618680 13823 sgd_solver.cpp:112] Iteration 281400, lr = 1e-06
I0823 00:33:29.295183 13823 solver.cpp:239] Iteration 281500 (9.36634 iter/s, 10.6765s/100 iters), loss = 0.0346929
I0823 00:33:29.295236 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0346923 (* 1 = 0.0346923 loss)
I0823 00:33:29.295245 13823 sgd_solver.cpp:112] Iteration 281500, lr = 1e-06
I0823 00:33:39.818125 13823 solver.cpp:239] Iteration 281600 (9.50307 iter/s, 10.5229s/100 iters), loss = 0.0293186
I0823 00:33:39.818178 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.029318 (* 1 = 0.029318 loss)
I0823 00:33:39.818187 13823 sgd_solver.cpp:112] Iteration 281600, lr = 1e-06
I0823 00:33:50.310627 13823 solver.cpp:239] Iteration 281700 (9.53065 iter/s, 10.4925s/100 iters), loss = 0.0333055
I0823 00:33:50.310686 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0333049 (* 1 = 0.0333049 loss)
I0823 00:33:50.310698 13823 sgd_solver.cpp:112] Iteration 281700, lr = 1e-06
I0823 00:34:01.018285 13823 solver.cpp:239] Iteration 281800 (9.33915 iter/s, 10.7076s/100 iters), loss = 0.0250587
I0823 00:34:01.018340 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0250581 (* 1 = 0.0250581 loss)
I0823 00:34:01.018352 13823 sgd_solver.cpp:112] Iteration 281800, lr = 1e-06
I0823 00:34:11.713603 13823 solver.cpp:239] Iteration 281900 (9.34992 iter/s, 10.6953s/100 iters), loss = 0.0296868
I0823 00:34:11.713667 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0296862 (* 1 = 0.0296862 loss)
I0823 00:34:11.713680 13823 sgd_solver.cpp:112] Iteration 281900, lr = 1e-06
I0823 00:34:22.212786 13823 solver.cpp:239] Iteration 282000 (9.52459 iter/s, 10.4991s/100 iters), loss = 0.0269291
I0823 00:34:22.212838 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0269285 (* 1 = 0.0269285 loss)
I0823 00:34:22.212849 13823 sgd_solver.cpp:112] Iteration 282000, lr = 1e-06
I0823 00:34:32.944970 13823 solver.cpp:239] Iteration 282100 (9.3178 iter/s, 10.7321s/100 iters), loss = 0.0262403
I0823 00:34:32.945030 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0262397 (* 1 = 0.0262397 loss)
I0823 00:34:32.945042 13823 sgd_solver.cpp:112] Iteration 282100, lr = 1e-06
I0823 00:34:43.585919 13823 solver.cpp:239] Iteration 282200 (9.39769 iter/s, 10.6409s/100 iters), loss = 0.0460292
I0823 00:34:43.585980 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0460287 (* 1 = 0.0460287 loss)
I0823 00:34:43.585991 13823 sgd_solver.cpp:112] Iteration 282200, lr = 1e-06
I0823 00:34:54.428663 13823 solver.cpp:239] Iteration 282300 (9.22279 iter/s, 10.8427s/100 iters), loss = 0.0342085
I0823 00:34:54.428712 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.034208 (* 1 = 0.034208 loss)
I0823 00:34:54.428722 13823 sgd_solver.cpp:112] Iteration 282300, lr = 1e-06
I0823 00:35:05.000813 13823 solver.cpp:239] Iteration 282400 (9.45904 iter/s, 10.5719s/100 iters), loss = 0.0271981
I0823 00:35:05.000876 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0271975 (* 1 = 0.0271975 loss)
I0823 00:35:05.000888 13823 sgd_solver.cpp:112] Iteration 282400, lr = 1e-06
I0823 00:35:15.592033 13823 solver.cpp:239] Iteration 282500 (9.44215 iter/s, 10.5908s/100 iters), loss = 0.0263416
I0823 00:35:15.592083 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.026341 (* 1 = 0.026341 loss)
I0823 00:35:15.592092 13823 sgd_solver.cpp:112] Iteration 282500, lr = 1e-06
I0823 00:35:26.037658 13823 solver.cpp:239] Iteration 282600 (9.57375 iter/s, 10.4452s/100 iters), loss = 0.0260271
I0823 00:35:26.037709 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0260265 (* 1 = 0.0260265 loss)
I0823 00:35:26.037719 13823 sgd_solver.cpp:112] Iteration 282600, lr = 1e-06
I0823 00:35:36.299053 13823 solver.cpp:239] Iteration 282700 (9.74563 iter/s, 10.261s/100 iters), loss = 0.0275081
I0823 00:35:36.299108 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0275076 (* 1 = 0.0275076 loss)
I0823 00:35:36.299119 13823 sgd_solver.cpp:112] Iteration 282700, lr = 1e-06
I0823 00:35:47.236330 13823 solver.cpp:239] Iteration 282800 (9.14338 iter/s, 10.9369s/100 iters), loss = 0.0304888
I0823 00:35:47.236379 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0304882 (* 1 = 0.0304882 loss)
I0823 00:35:47.236389 13823 sgd_solver.cpp:112] Iteration 282800, lr = 1e-06
I0823 00:35:57.917469 13823 solver.cpp:239] Iteration 282900 (9.36263 iter/s, 10.6808s/100 iters), loss = 0.0313835
I0823 00:35:57.917520 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.031383 (* 1 = 0.031383 loss)
I0823 00:35:57.917529 13823 sgd_solver.cpp:112] Iteration 282900, lr = 1e-06
I0823 00:36:08.321535 13823 solver.cpp:239] Iteration 283000 (9.61197 iter/s, 10.4037s/100 iters), loss = 0.267681
I0823 00:36:08.321599 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.26768 (* 1 = 0.26768 loss)
I0823 00:36:08.321610 13823 sgd_solver.cpp:112] Iteration 283000, lr = 1e-06
I0823 00:36:18.926921 13823 solver.cpp:239] Iteration 283100 (9.42951 iter/s, 10.605s/100 iters), loss = 0.0273121
I0823 00:36:18.926973 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0273115 (* 1 = 0.0273115 loss)
I0823 00:36:18.926982 13823 sgd_solver.cpp:112] Iteration 283100, lr = 1e-06
I0823 00:36:29.997397 13823 solver.cpp:239] Iteration 283200 (9.03334 iter/s, 11.0701s/100 iters), loss = 0.0282008
I0823 00:36:29.997447 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0282002 (* 1 = 0.0282002 loss)
I0823 00:36:29.997457 13823 sgd_solver.cpp:112] Iteration 283200, lr = 1e-06
I0823 00:36:40.901998 13823 solver.cpp:239] Iteration 283300 (9.17075 iter/s, 10.9042s/100 iters), loss = 0.0469314
I0823 00:36:40.902045 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0469308 (* 1 = 0.0469308 loss)
I0823 00:36:40.902055 13823 sgd_solver.cpp:112] Iteration 283300, lr = 1e-06
I0823 00:36:51.688625 13823 solver.cpp:239] Iteration 283400 (9.27104 iter/s, 10.7863s/100 iters), loss = 0.0273147
I0823 00:36:51.688676 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0273141 (* 1 = 0.0273141 loss)
I0823 00:36:51.688685 13823 sgd_solver.cpp:112] Iteration 283400, lr = 1e-06
I0823 00:37:02.585147 13823 solver.cpp:239] Iteration 283500 (9.17754 iter/s, 10.8962s/100 iters), loss = 0.0264538
I0823 00:37:02.585201 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0264532 (* 1 = 0.0264532 loss)
I0823 00:37:02.585211 13823 sgd_solver.cpp:112] Iteration 283500, lr = 1e-06
I0823 00:37:13.273667 13823 solver.cpp:239] Iteration 283600 (9.35613 iter/s, 10.6882s/100 iters), loss = 0.0314166
I0823 00:37:13.273726 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.031416 (* 1 = 0.031416 loss)
I0823 00:37:13.273737 13823 sgd_solver.cpp:112] Iteration 283600, lr = 1e-06
I0823 00:37:24.068624 13823 solver.cpp:239] Iteration 283700 (9.26388 iter/s, 10.7946s/100 iters), loss = 0.0256744
I0823 00:37:24.068672 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0256738 (* 1 = 0.0256738 loss)
I0823 00:37:24.068681 13823 sgd_solver.cpp:112] Iteration 283700, lr = 1e-06
I0823 00:37:34.998610 13823 solver.cpp:239] Iteration 283800 (9.14942 iter/s, 10.9297s/100 iters), loss = 0.0350948
I0823 00:37:34.998662 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0350942 (* 1 = 0.0350942 loss)
I0823 00:37:34.998673 13823 sgd_solver.cpp:112] Iteration 283800, lr = 1e-06
I0823 00:37:45.880668 13823 solver.cpp:239] Iteration 283900 (9.18972 iter/s, 10.8817s/100 iters), loss = 0.0312815
I0823 00:37:45.880720 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0312809 (* 1 = 0.0312809 loss)
I0823 00:37:45.880730 13823 sgd_solver.cpp:112] Iteration 283900, lr = 1e-06
I0823 00:37:56.840770 13823 solver.cpp:239] Iteration 284000 (9.12428 iter/s, 10.9598s/100 iters), loss = 0.0269246
I0823 00:37:56.840828 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.026924 (* 1 = 0.026924 loss)
I0823 00:37:56.840839 13823 sgd_solver.cpp:112] Iteration 284000, lr = 1e-06
I0823 00:38:07.999240 13823 solver.cpp:239] Iteration 284100 (8.96207 iter/s, 11.1581s/100 iters), loss = 0.0307875
I0823 00:38:07.999297 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0307869 (* 1 = 0.0307869 loss)
I0823 00:38:07.999308 13823 sgd_solver.cpp:112] Iteration 284100, lr = 1e-06
I0823 00:38:18.878268 13823 solver.cpp:239] Iteration 284200 (9.19227 iter/s, 10.8787s/100 iters), loss = 0.0259602
I0823 00:38:18.878321 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0259596 (* 1 = 0.0259596 loss)
I0823 00:38:18.878331 13823 sgd_solver.cpp:112] Iteration 284200, lr = 1e-06
I0823 00:38:29.295368 13823 solver.cpp:239] Iteration 284300 (9.59988 iter/s, 10.4168s/100 iters), loss = 0.0343048
I0823 00:38:29.295418 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0343042 (* 1 = 0.0343042 loss)
I0823 00:38:29.295426 13823 sgd_solver.cpp:112] Iteration 284300, lr = 1e-06
I0823 00:38:40.095496 13823 solver.cpp:239] Iteration 284400 (9.25941 iter/s, 10.7998s/100 iters), loss = 0.0312191
I0823 00:38:40.095544 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0312185 (* 1 = 0.0312185 loss)
I0823 00:38:40.095553 13823 sgd_solver.cpp:112] Iteration 284400, lr = 1e-06
I0823 00:38:51.049592 13823 solver.cpp:239] Iteration 284500 (9.12926 iter/s, 10.9538s/100 iters), loss = 0.0341386
I0823 00:38:51.049649 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0341379 (* 1 = 0.0341379 loss)
I0823 00:38:51.049660 13823 sgd_solver.cpp:112] Iteration 284500, lr = 1e-06
I0823 00:39:02.111070 13823 solver.cpp:239] Iteration 284600 (9.04063 iter/s, 11.0612s/100 iters), loss = 0.0252647
I0823 00:39:02.111127 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0252641 (* 1 = 0.0252641 loss)
I0823 00:39:02.111138 13823 sgd_solver.cpp:112] Iteration 284600, lr = 1e-06
I0823 00:39:13.009436 13823 solver.cpp:239] Iteration 284700 (9.17594 iter/s, 10.8981s/100 iters), loss = 0.0288257
I0823 00:39:13.009490 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0288251 (* 1 = 0.0288251 loss)
I0823 00:39:13.009500 13823 sgd_solver.cpp:112] Iteration 284700, lr = 1e-06
I0823 00:39:23.799322 13823 solver.cpp:239] Iteration 284800 (9.26819 iter/s, 10.7896s/100 iters), loss = 0.0328887
I0823 00:39:23.799377 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0328881 (* 1 = 0.0328881 loss)
I0823 00:39:23.799388 13823 sgd_solver.cpp:112] Iteration 284800, lr = 1e-06
I0823 00:39:34.559989 13823 solver.cpp:239] Iteration 284900 (9.29335 iter/s, 10.7604s/100 iters), loss = 0.0281771
I0823 00:39:34.560045 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0281764 (* 1 = 0.0281764 loss)
I0823 00:39:34.560056 13823 sgd_solver.cpp:112] Iteration 284900, lr = 1e-06
I0823 00:39:45.178252 13823 solver.cpp:239] Iteration 285000 (9.41798 iter/s, 10.618s/100 iters), loss = 0.030387
I0823 00:39:45.178301 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0303864 (* 1 = 0.0303864 loss)
I0823 00:39:45.178311 13823 sgd_solver.cpp:112] Iteration 285000, lr = 1e-06
I0823 00:39:55.959142 13823 solver.cpp:239] Iteration 285100 (9.27591 iter/s, 10.7806s/100 iters), loss = 0.0301541
I0823 00:39:55.959197 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0301535 (* 1 = 0.0301535 loss)
I0823 00:39:55.959208 13823 sgd_solver.cpp:112] Iteration 285100, lr = 1e-06
I0823 00:40:06.682438 13823 solver.cpp:239] Iteration 285200 (9.32573 iter/s, 10.723s/100 iters), loss = 0.0333895
I0823 00:40:06.682494 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0333889 (* 1 = 0.0333889 loss)
I0823 00:40:06.682504 13823 sgd_solver.cpp:112] Iteration 285200, lr = 1e-06
I0823 00:40:17.614007 13823 solver.cpp:239] Iteration 285300 (9.14804 iter/s, 10.9313s/100 iters), loss = 0.0261202
I0823 00:40:17.614061 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0261196 (* 1 = 0.0261196 loss)
I0823 00:40:17.614073 13823 sgd_solver.cpp:112] Iteration 285300, lr = 1e-06
I0823 00:40:28.582597 13823 solver.cpp:239] Iteration 285400 (9.11716 iter/s, 10.9683s/100 iters), loss = 0.025608
I0823 00:40:28.582648 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0256073 (* 1 = 0.0256073 loss)
I0823 00:40:28.582657 13823 sgd_solver.cpp:112] Iteration 285400, lr = 1e-06
I0823 00:40:39.515786 13823 solver.cpp:239] Iteration 285500 (9.14668 iter/s, 10.9329s/100 iters), loss = 0.027076
I0823 00:40:39.515836 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0270754 (* 1 = 0.0270754 loss)
I0823 00:40:39.515846 13823 sgd_solver.cpp:112] Iteration 285500, lr = 1e-06
I0823 00:40:50.397511 13823 solver.cpp:239] Iteration 285600 (9.18993 iter/s, 10.8815s/100 iters), loss = 0.0279019
I0823 00:40:50.397565 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0279013 (* 1 = 0.0279013 loss)
I0823 00:40:50.397575 13823 sgd_solver.cpp:112] Iteration 285600, lr = 1e-06
I0823 00:41:01.443339 13823 solver.cpp:239] Iteration 285700 (9.0534 iter/s, 11.0456s/100 iters), loss = 0.0266998
I0823 00:41:01.443392 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0266991 (* 1 = 0.0266991 loss)
I0823 00:41:01.443401 13823 sgd_solver.cpp:112] Iteration 285700, lr = 1e-06
I0823 00:41:12.510408 13823 solver.cpp:239] Iteration 285800 (9.03602 iter/s, 11.0668s/100 iters), loss = 0.0271872
I0823 00:41:12.510459 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0271866 (* 1 = 0.0271866 loss)
I0823 00:41:12.510468 13823 sgd_solver.cpp:112] Iteration 285800, lr = 1e-06
I0823 00:41:23.537113 13823 solver.cpp:239] Iteration 285900 (9.06909 iter/s, 11.0265s/100 iters), loss = 0.0271689
I0823 00:41:23.537163 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0271683 (* 1 = 0.0271683 loss)
I0823 00:41:23.537173 13823 sgd_solver.cpp:112] Iteration 285900, lr = 1e-06
I0823 00:41:34.778180 13823 solver.cpp:239] Iteration 286000 (8.89615 iter/s, 11.2408s/100 iters), loss = 0.0289886
I0823 00:41:34.778244 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.028988 (* 1 = 0.028988 loss)
I0823 00:41:34.778254 13823 sgd_solver.cpp:112] Iteration 286000, lr = 1e-06
I0823 00:41:45.629822 13823 solver.cpp:239] Iteration 286100 (9.21541 iter/s, 10.8514s/100 iters), loss = 0.0442982
I0823 00:41:45.629873 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0442976 (* 1 = 0.0442976 loss)
I0823 00:41:45.629884 13823 sgd_solver.cpp:112] Iteration 286100, lr = 1e-06
I0823 00:41:56.624243 13823 solver.cpp:239] Iteration 286200 (9.09572 iter/s, 10.9942s/100 iters), loss = 0.0299098
I0823 00:41:56.624292 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0299091 (* 1 = 0.0299091 loss)
I0823 00:41:56.624301 13823 sgd_solver.cpp:112] Iteration 286200, lr = 1e-06
I0823 00:42:07.414746 13823 solver.cpp:239] Iteration 286300 (9.2676 iter/s, 10.7903s/100 iters), loss = 0.0255692
I0823 00:42:07.414796 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0255686 (* 1 = 0.0255686 loss)
I0823 00:42:07.414805 13823 sgd_solver.cpp:112] Iteration 286300, lr = 1e-06
I0823 00:42:18.185520 13823 solver.cpp:239] Iteration 286400 (9.28458 iter/s, 10.7705s/100 iters), loss = 0.0263831
I0823 00:42:18.185571 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0263825 (* 1 = 0.0263825 loss)
I0823 00:42:18.185581 13823 sgd_solver.cpp:112] Iteration 286400, lr = 1e-06
I0823 00:42:29.132302 13823 solver.cpp:239] Iteration 286500 (9.13529 iter/s, 10.9466s/100 iters), loss = 0.0284505
I0823 00:42:29.132355 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0284499 (* 1 = 0.0284499 loss)
I0823 00:42:29.132365 13823 sgd_solver.cpp:112] Iteration 286500, lr = 1e-06
I0823 00:42:40.122777 13823 solver.cpp:239] Iteration 286600 (9.09898 iter/s, 10.9902s/100 iters), loss = 0.037205
I0823 00:42:40.122835 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0372044 (* 1 = 0.0372044 loss)
I0823 00:42:40.122846 13823 sgd_solver.cpp:112] Iteration 286600, lr = 1e-06
I0823 00:42:51.405966 13823 solver.cpp:239] Iteration 286700 (8.86293 iter/s, 11.283s/100 iters), loss = 0.026272
I0823 00:42:51.406026 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0262714 (* 1 = 0.0262714 loss)
I0823 00:42:51.406038 13823 sgd_solver.cpp:112] Iteration 286700, lr = 1e-06
I0823 00:43:02.723295 13823 solver.cpp:239] Iteration 286800 (8.83618 iter/s, 11.3171s/100 iters), loss = 0.0350987
I0823 00:43:02.723345 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0350981 (* 1 = 0.0350981 loss)
I0823 00:43:02.723354 13823 sgd_solver.cpp:112] Iteration 286800, lr = 1e-06
I0823 00:43:13.673399 13823 solver.cpp:239] Iteration 286900 (9.13251 iter/s, 10.9499s/100 iters), loss = 0.0363504
I0823 00:43:13.673460 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0363497 (* 1 = 0.0363497 loss)
I0823 00:43:13.673470 13823 sgd_solver.cpp:112] Iteration 286900, lr = 1e-06
I0823 00:43:24.946668 13823 solver.cpp:239] Iteration 287000 (8.87072 iter/s, 11.273s/100 iters), loss = 0.0250584
I0823 00:43:24.946722 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0250577 (* 1 = 0.0250577 loss)
I0823 00:43:24.946732 13823 sgd_solver.cpp:112] Iteration 287000, lr = 1e-06
I0823 00:43:36.092254 13823 solver.cpp:239] Iteration 287100 (8.97233 iter/s, 11.1454s/100 iters), loss = 0.0256212
I0823 00:43:36.092315 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0256206 (* 1 = 0.0256206 loss)
I0823 00:43:36.092329 13823 sgd_solver.cpp:112] Iteration 287100, lr = 1e-06
I0823 00:43:47.423385 13823 solver.cpp:239] Iteration 287200 (8.82542 iter/s, 11.3309s/100 iters), loss = 0.030374
I0823 00:43:47.423460 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0303733 (* 1 = 0.0303733 loss)
I0823 00:43:47.423473 13823 sgd_solver.cpp:112] Iteration 287200, lr = 1e-06
I0823 00:43:58.601020 13823 solver.cpp:239] Iteration 287300 (8.94662 iter/s, 11.1774s/100 iters), loss = 0.0274094
I0823 00:43:58.601080 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0274088 (* 1 = 0.0274088 loss)
I0823 00:43:58.601091 13823 sgd_solver.cpp:112] Iteration 287300, lr = 1e-06
I0823 00:44:09.780136 13823 solver.cpp:239] Iteration 287400 (8.94542 iter/s, 11.1789s/100 iters), loss = 0.0218272
I0823 00:44:09.780185 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0218265 (* 1 = 0.0218265 loss)
I0823 00:44:09.780194 13823 sgd_solver.cpp:112] Iteration 287400, lr = 1e-06
I0823 00:44:20.983217 13823 solver.cpp:239] Iteration 287500 (8.92628 iter/s, 11.2029s/100 iters), loss = 0.0292721
I0823 00:44:20.983278 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0292715 (* 1 = 0.0292715 loss)
I0823 00:44:20.983290 13823 sgd_solver.cpp:112] Iteration 287500, lr = 1e-06
I0823 00:44:32.347327 13823 solver.cpp:239] Iteration 287600 (8.7998 iter/s, 11.3639s/100 iters), loss = 0.0257487
I0823 00:44:32.347379 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0257481 (* 1 = 0.0257481 loss)
I0823 00:44:32.347389 13823 sgd_solver.cpp:112] Iteration 287600, lr = 1e-06
I0823 00:44:43.514683 13823 solver.cpp:239] Iteration 287700 (8.95483 iter/s, 11.1672s/100 iters), loss = 0.0287689
I0823 00:44:43.514732 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0287683 (* 1 = 0.0287683 loss)
I0823 00:44:43.514741 13823 sgd_solver.cpp:112] Iteration 287700, lr = 1e-06
I0823 00:44:54.517493 13823 solver.cpp:239] Iteration 287800 (9.08874 iter/s, 11.0026s/100 iters), loss = 0.038854
I0823 00:44:54.517541 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0388533 (* 1 = 0.0388533 loss)
I0823 00:44:54.517550 13823 sgd_solver.cpp:112] Iteration 287800, lr = 1e-06
I0823 00:45:05.369428 13823 solver.cpp:239] Iteration 287900 (9.2151 iter/s, 10.8518s/100 iters), loss = 0.0252617
I0823 00:45:05.369483 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0252611 (* 1 = 0.0252611 loss)
I0823 00:45:05.369493 13823 sgd_solver.cpp:112] Iteration 287900, lr = 1e-06
I0823 00:45:16.567040 13823 solver.cpp:239] Iteration 288000 (8.93063 iter/s, 11.1974s/100 iters), loss = 0.0284601
I0823 00:45:16.567095 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0284594 (* 1 = 0.0284594 loss)
I0823 00:45:16.567104 13823 sgd_solver.cpp:112] Iteration 288000, lr = 1e-06
I0823 00:45:27.576074 13823 solver.cpp:239] Iteration 288100 (9.0836 iter/s, 11.0088s/100 iters), loss = 0.0243064
I0823 00:45:27.576129 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0243057 (* 1 = 0.0243057 loss)
I0823 00:45:27.576148 13823 sgd_solver.cpp:112] Iteration 288100, lr = 1e-06
I0823 00:45:38.959220 13823 solver.cpp:239] Iteration 288200 (8.78506 iter/s, 11.383s/100 iters), loss = 0.0332318
I0823 00:45:38.959271 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0332311 (* 1 = 0.0332311 loss)
I0823 00:45:38.959281 13823 sgd_solver.cpp:112] Iteration 288200, lr = 1e-06
I0823 00:45:50.373106 13823 solver.cpp:239] Iteration 288300 (8.7614 iter/s, 11.4137s/100 iters), loss = 0.0289177
I0823 00:45:50.373167 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0289171 (* 1 = 0.0289171 loss)
I0823 00:45:50.373179 13823 sgd_solver.cpp:112] Iteration 288300, lr = 1e-06
I0823 00:46:01.430472 13823 solver.cpp:239] Iteration 288400 (9.0439 iter/s, 11.0572s/100 iters), loss = 0.0251913
I0823 00:46:01.430529 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0251907 (* 1 = 0.0251907 loss)
I0823 00:46:01.430542 13823 sgd_solver.cpp:112] Iteration 288400, lr = 1e-06
I0823 00:46:12.579314 13823 solver.cpp:239] Iteration 288500 (8.96968 iter/s, 11.1487s/100 iters), loss = 0.0348296
I0823 00:46:12.579376 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0348289 (* 1 = 0.0348289 loss)
I0823 00:46:12.579391 13823 sgd_solver.cpp:112] Iteration 288500, lr = 1e-06
I0823 00:46:23.385866 13823 solver.cpp:239] Iteration 288600 (9.25379 iter/s, 10.8064s/100 iters), loss = 0.0268624
I0823 00:46:23.385908 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0268617 (* 1 = 0.0268617 loss)
I0823 00:46:23.385916 13823 sgd_solver.cpp:112] Iteration 288600, lr = 1e-06
I0823 00:46:34.662457 13823 solver.cpp:239] Iteration 288700 (8.86806 iter/s, 11.2764s/100 iters), loss = 0.02801
I0823 00:46:34.662509 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0280093 (* 1 = 0.0280093 loss)
I0823 00:46:34.662519 13823 sgd_solver.cpp:112] Iteration 288700, lr = 1e-06
I0823 00:46:45.639405 13823 solver.cpp:239] Iteration 288800 (9.11014 iter/s, 10.9768s/100 iters), loss = 0.0265712
I0823 00:46:45.639466 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0265705 (* 1 = 0.0265705 loss)
I0823 00:46:45.639477 13823 sgd_solver.cpp:112] Iteration 288800, lr = 1e-06
I0823 00:46:57.033960 13823 solver.cpp:239] Iteration 288900 (8.77626 iter/s, 11.3944s/100 iters), loss = 0.026934
I0823 00:46:57.034021 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0269333 (* 1 = 0.0269333 loss)
I0823 00:46:57.034034 13823 sgd_solver.cpp:112] Iteration 288900, lr = 1e-06
I0823 00:47:08.241186 13823 solver.cpp:239] Iteration 289000 (8.92295 iter/s, 11.2071s/100 iters), loss = 0.0339878
I0823 00:47:08.241230 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0339871 (* 1 = 0.0339871 loss)
I0823 00:47:08.241237 13823 sgd_solver.cpp:112] Iteration 289000, lr = 1e-06
I0823 00:47:19.096065 13823 solver.cpp:239] Iteration 289100 (9.21258 iter/s, 10.8547s/100 iters), loss = 0.0300869
I0823 00:47:19.096127 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0300862 (* 1 = 0.0300862 loss)
I0823 00:47:19.096148 13823 sgd_solver.cpp:112] Iteration 289100, lr = 1e-06
I0823 00:47:30.357446 13823 solver.cpp:239] Iteration 289200 (8.88004 iter/s, 11.2612s/100 iters), loss = 0.0242401
I0823 00:47:30.357496 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0242394 (* 1 = 0.0242394 loss)
I0823 00:47:30.357506 13823 sgd_solver.cpp:112] Iteration 289200, lr = 1e-06
I0823 00:47:41.435111 13823 solver.cpp:239] Iteration 289300 (9.0273 iter/s, 11.0775s/100 iters), loss = 0.0234244
I0823 00:47:41.435159 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0234237 (* 1 = 0.0234237 loss)
I0823 00:47:41.435169 13823 sgd_solver.cpp:112] Iteration 289300, lr = 1e-06
I0823 00:47:52.408368 13823 solver.cpp:239] Iteration 289400 (9.11319 iter/s, 10.9731s/100 iters), loss = 0.027719
I0823 00:47:52.408419 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0277183 (* 1 = 0.0277183 loss)
I0823 00:47:52.408429 13823 sgd_solver.cpp:112] Iteration 289400, lr = 1e-06
I0823 00:48:03.662994 13823 solver.cpp:239] Iteration 289500 (8.88536 iter/s, 11.2545s/100 iters), loss = 0.0259035
I0823 00:48:03.663058 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0259028 (* 1 = 0.0259028 loss)
I0823 00:48:03.663069 13823 sgd_solver.cpp:112] Iteration 289500, lr = 1e-06
I0823 00:48:15.186151 13823 solver.cpp:239] Iteration 289600 (8.6783 iter/s, 11.523s/100 iters), loss = 0.0265883
I0823 00:48:15.186201 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0265876 (* 1 = 0.0265876 loss)
I0823 00:48:15.186211 13823 sgd_solver.cpp:112] Iteration 289600, lr = 1e-06
I0823 00:48:26.583444 13823 solver.cpp:239] Iteration 289700 (8.77413 iter/s, 11.3971s/100 iters), loss = 0.0264639
I0823 00:48:26.583494 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0264632 (* 1 = 0.0264632 loss)
I0823 00:48:26.583503 13823 sgd_solver.cpp:112] Iteration 289700, lr = 1e-06
I0823 00:48:38.074858 13823 solver.cpp:239] Iteration 289800 (8.70227 iter/s, 11.4913s/100 iters), loss = 0.0301178
I0823 00:48:38.074918 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0301171 (* 1 = 0.0301171 loss)
I0823 00:48:38.074929 13823 sgd_solver.cpp:112] Iteration 289800, lr = 1e-06
I0823 00:48:49.501482 13823 solver.cpp:239] Iteration 289900 (8.75162 iter/s, 11.4265s/100 iters), loss = 0.0285965
I0823 00:48:49.501543 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0285959 (* 1 = 0.0285959 loss)
I0823 00:48:49.501554 13823 sgd_solver.cpp:112] Iteration 289900, lr = 1e-06
I0823 00:49:01.055269 13823 solver.cpp:239] Iteration 290000 (8.65529 iter/s, 11.5536s/100 iters), loss = 0.0275955
I0823 00:49:01.055333 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0275948 (* 1 = 0.0275948 loss)
I0823 00:49:01.055347 13823 sgd_solver.cpp:112] Iteration 290000, lr = 1e-06
I0823 00:49:12.572155 13823 solver.cpp:239] Iteration 290100 (8.68303 iter/s, 11.5167s/100 iters), loss = 0.0329759
I0823 00:49:12.572214 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0329753 (* 1 = 0.0329753 loss)
I0823 00:49:12.572227 13823 sgd_solver.cpp:112] Iteration 290100, lr = 1e-06
I0823 00:49:23.912701 13823 solver.cpp:239] Iteration 290200 (8.81804 iter/s, 11.3404s/100 iters), loss = 0.0278941
I0823 00:49:23.912760 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0278934 (* 1 = 0.0278934 loss)
I0823 00:49:23.912770 13823 sgd_solver.cpp:112] Iteration 290200, lr = 1e-06
I0823 00:49:35.400900 13823 solver.cpp:239] Iteration 290300 (8.7047 iter/s, 11.488s/100 iters), loss = 0.0289364
I0823 00:49:35.400959 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0289358 (* 1 = 0.0289358 loss)
I0823 00:49:35.400969 13823 sgd_solver.cpp:112] Iteration 290300, lr = 1e-06
I0823 00:49:46.864147 13823 solver.cpp:239] Iteration 290400 (8.72365 iter/s, 11.4631s/100 iters), loss = 0.025326
I0823 00:49:46.864200 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0253253 (* 1 = 0.0253253 loss)
I0823 00:49:46.864209 13823 sgd_solver.cpp:112] Iteration 290400, lr = 1e-06
I0823 00:49:58.461817 13823 solver.cpp:239] Iteration 290500 (8.62253 iter/s, 11.5975s/100 iters), loss = 0.0327526
I0823 00:49:58.461870 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.032752 (* 1 = 0.032752 loss)
I0823 00:49:58.461880 13823 sgd_solver.cpp:112] Iteration 290500, lr = 1e-06
I0823 00:50:10.077891 13823 solver.cpp:239] Iteration 290600 (8.60887 iter/s, 11.6159s/100 iters), loss = 0.0245316
I0823 00:50:10.077951 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.024531 (* 1 = 0.024531 loss)
I0823 00:50:10.077963 13823 sgd_solver.cpp:112] Iteration 290600, lr = 1e-06
I0823 00:50:21.545701 13823 solver.cpp:239] Iteration 290700 (8.72017 iter/s, 11.4677s/100 iters), loss = 0.032677
I0823 00:50:21.545761 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0326763 (* 1 = 0.0326763 loss)
I0823 00:50:21.545773 13823 sgd_solver.cpp:112] Iteration 290700, lr = 1e-06
I0823 00:50:33.202155 13823 solver.cpp:239] Iteration 290800 (8.57905 iter/s, 11.6563s/100 iters), loss = 0.0238555
I0823 00:50:33.202210 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0238548 (* 1 = 0.0238548 loss)
I0823 00:50:33.202221 13823 sgd_solver.cpp:112] Iteration 290800, lr = 1e-06
I0823 00:50:44.712081 13823 solver.cpp:239] Iteration 290900 (8.68826 iter/s, 11.5098s/100 iters), loss = 0.0259914
I0823 00:50:44.712143 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0259907 (* 1 = 0.0259907 loss)
I0823 00:50:44.712154 13823 sgd_solver.cpp:112] Iteration 290900, lr = 1e-06
I0823 00:50:56.298275 13823 solver.cpp:239] Iteration 291000 (8.63107 iter/s, 11.586s/100 iters), loss = 0.0279259
I0823 00:50:56.298337 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0279253 (* 1 = 0.0279253 loss)
I0823 00:50:56.298350 13823 sgd_solver.cpp:112] Iteration 291000, lr = 1e-06
I0823 00:51:07.880914 13823 solver.cpp:239] Iteration 291100 (8.63372 iter/s, 11.5825s/100 iters), loss = 0.0273672
I0823 00:51:07.880982 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0273665 (* 1 = 0.0273665 loss)
I0823 00:51:07.880998 13823 sgd_solver.cpp:112] Iteration 291100, lr = 1e-06
I0823 00:51:19.405539 13823 solver.cpp:239] Iteration 291200 (8.67718 iter/s, 11.5245s/100 iters), loss = 0.0237372
I0823 00:51:19.405589 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0237366 (* 1 = 0.0237366 loss)
I0823 00:51:19.405597 13823 sgd_solver.cpp:112] Iteration 291200, lr = 1e-06
I0823 00:51:30.742871 13823 solver.cpp:239] Iteration 291300 (8.82052 iter/s, 11.3372s/100 iters), loss = 0.0217778
I0823 00:51:30.742934 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0217772 (* 1 = 0.0217772 loss)
I0823 00:51:30.742950 13823 sgd_solver.cpp:112] Iteration 291300, lr = 1e-06
I0823 00:51:42.403872 13823 solver.cpp:239] Iteration 291400 (8.5757 iter/s, 11.6609s/100 iters), loss = 0.0290576
I0823 00:51:42.403934 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.029057 (* 1 = 0.029057 loss)
I0823 00:51:42.403947 13823 sgd_solver.cpp:112] Iteration 291400, lr = 1e-06
I0823 00:51:53.767117 13823 solver.cpp:239] Iteration 291500 (8.80041 iter/s, 11.3631s/100 iters), loss = 0.0248263
I0823 00:51:53.767169 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0248257 (* 1 = 0.0248257 loss)
I0823 00:51:53.767179 13823 sgd_solver.cpp:112] Iteration 291500, lr = 1e-06
I0823 00:52:05.373775 13823 solver.cpp:239] Iteration 291600 (8.61585 iter/s, 11.6065s/100 iters), loss = 0.0258471
I0823 00:52:05.373833 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0258465 (* 1 = 0.0258465 loss)
I0823 00:52:05.373845 13823 sgd_solver.cpp:112] Iteration 291600, lr = 1e-06
I0823 00:52:16.864331 13823 solver.cpp:239] Iteration 291700 (8.7029 iter/s, 11.4904s/100 iters), loss = 0.0268169
I0823 00:52:16.864387 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0268163 (* 1 = 0.0268163 loss)
I0823 00:52:16.864396 13823 sgd_solver.cpp:112] Iteration 291700, lr = 1e-06
I0823 00:52:28.493432 13823 solver.cpp:239] Iteration 291800 (8.59922 iter/s, 11.629s/100 iters), loss = 0.0267072
I0823 00:52:28.493489 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0267065 (* 1 = 0.0267065 loss)
I0823 00:52:28.493499 13823 sgd_solver.cpp:112] Iteration 291800, lr = 1e-06
I0823 00:52:40.193784 13823 solver.cpp:239] Iteration 291900 (8.54685 iter/s, 11.7002s/100 iters), loss = 0.0293204
I0823 00:52:40.193842 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0293197 (* 1 = 0.0293197 loss)
I0823 00:52:40.193853 13823 sgd_solver.cpp:112] Iteration 291900, lr = 1e-06
I0823 00:52:52.124172 13823 solver.cpp:239] Iteration 292000 (8.38205 iter/s, 11.9302s/100 iters), loss = 0.0314166
I0823 00:52:52.124238 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0314159 (* 1 = 0.0314159 loss)
I0823 00:52:52.124251 13823 sgd_solver.cpp:112] Iteration 292000, lr = 1e-06
I0823 00:53:03.922405 13823 solver.cpp:239] Iteration 292100 (8.47594 iter/s, 11.7981s/100 iters), loss = 0.0260821
I0823 00:53:03.922457 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0260814 (* 1 = 0.0260814 loss)
I0823 00:53:03.922466 13823 sgd_solver.cpp:112] Iteration 292100, lr = 1e-06
I0823 00:53:14.675109 13823 solver.cpp:239] Iteration 292200 (9.30009 iter/s, 10.7526s/100 iters), loss = 0.026416
I0823 00:53:14.675161 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0264154 (* 1 = 0.0264154 loss)
I0823 00:53:14.675170 13823 sgd_solver.cpp:112] Iteration 292200, lr = 1e-06
I0823 00:53:24.138036 13823 solver.cpp:239] Iteration 292300 (10.5677 iter/s, 9.46281s/100 iters), loss = 0.0245594
I0823 00:53:24.138095 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0245588 (* 1 = 0.0245588 loss)
I0823 00:53:24.138106 13823 sgd_solver.cpp:112] Iteration 292300, lr = 1e-06
I0823 00:53:33.406098 13823 solver.cpp:239] Iteration 292400 (10.7899 iter/s, 9.26794s/100 iters), loss = 0.0278638
I0823 00:53:33.406150 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0278631 (* 1 = 0.0278631 loss)
I0823 00:53:33.406159 13823 sgd_solver.cpp:112] Iteration 292400, lr = 1e-06
I0823 00:53:42.994863 13823 solver.cpp:239] Iteration 292500 (10.429 iter/s, 9.58865s/100 iters), loss = 0.0252675
I0823 00:53:42.994922 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0252668 (* 1 = 0.0252668 loss)
I0823 00:53:42.994935 13823 sgd_solver.cpp:112] Iteration 292500, lr = 1e-06
I0823 00:53:52.886744 13823 solver.cpp:239] Iteration 292600 (10.1094 iter/s, 9.89176s/100 iters), loss = 0.0280835
I0823 00:53:52.886793 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0280828 (* 1 = 0.0280828 loss)
I0823 00:53:52.886803 13823 sgd_solver.cpp:112] Iteration 292600, lr = 1e-06
I0823 00:54:02.534088 13823 solver.cpp:239] Iteration 292700 (10.3657 iter/s, 9.64723s/100 iters), loss = 0.0325777
I0823 00:54:02.534139 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0325771 (* 1 = 0.0325771 loss)
I0823 00:54:02.534148 13823 sgd_solver.cpp:112] Iteration 292700, lr = 1e-06
I0823 00:54:12.139812 13823 solver.cpp:239] Iteration 292800 (10.4106 iter/s, 9.60561s/100 iters), loss = 0.0234653
I0823 00:54:12.139861 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0234646 (* 1 = 0.0234646 loss)
I0823 00:54:12.139871 13823 sgd_solver.cpp:112] Iteration 292800, lr = 1e-06
I0823 00:54:21.592306 13823 solver.cpp:239] Iteration 292900 (10.5793 iter/s, 9.45239s/100 iters), loss = 0.0326049
I0823 00:54:21.592358 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0326043 (* 1 = 0.0326043 loss)
I0823 00:54:21.592367 13823 sgd_solver.cpp:112] Iteration 292900, lr = 1e-06
I0823 00:54:31.034710 13823 solver.cpp:239] Iteration 293000 (10.5906 iter/s, 9.4423s/100 iters), loss = 0.0237545
I0823 00:54:31.034752 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0237539 (* 1 = 0.0237539 loss)
I0823 00:54:31.034760 13823 sgd_solver.cpp:112] Iteration 293000, lr = 1e-06
I0823 00:54:40.539922 13823 solver.cpp:239] Iteration 293100 (10.5207 iter/s, 9.50511s/100 iters), loss = 0.0263445
I0823 00:54:40.539974 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0263439 (* 1 = 0.0263439 loss)
I0823 00:54:40.539983 13823 sgd_solver.cpp:112] Iteration 293100, lr = 1e-06
I0823 00:54:50.330211 13823 solver.cpp:239] Iteration 293200 (10.2143 iter/s, 9.79018s/100 iters), loss = 0.0299754
I0823 00:54:50.330262 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0299747 (* 1 = 0.0299747 loss)
I0823 00:54:50.330272 13823 sgd_solver.cpp:112] Iteration 293200, lr = 1e-06
I0823 00:54:59.784886 13823 solver.cpp:239] Iteration 293300 (10.5769 iter/s, 9.45457s/100 iters), loss = 0.0265547
I0823 00:54:59.784936 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0265541 (* 1 = 0.0265541 loss)
I0823 00:54:59.784945 13823 sgd_solver.cpp:112] Iteration 293300, lr = 1e-06
I0823 00:55:09.328476 13823 solver.cpp:239] Iteration 293400 (10.4784 iter/s, 9.54348s/100 iters), loss = 0.0371765
I0823 00:55:09.328524 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0371758 (* 1 = 0.0371758 loss)
I0823 00:55:09.328534 13823 sgd_solver.cpp:112] Iteration 293400, lr = 1e-06
I0823 00:55:18.627168 13823 solver.cpp:239] Iteration 293500 (10.7543 iter/s, 9.29859s/100 iters), loss = 0.026262
I0823 00:55:18.627219 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0262614 (* 1 = 0.0262614 loss)
I0823 00:55:18.627229 13823 sgd_solver.cpp:112] Iteration 293500, lr = 1e-06
I0823 00:55:28.078100 13823 solver.cpp:239] Iteration 293600 (10.5811 iter/s, 9.45083s/100 iters), loss = 0.0250099
I0823 00:55:28.078141 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0250092 (* 1 = 0.0250092 loss)
I0823 00:55:28.078150 13823 sgd_solver.cpp:112] Iteration 293600, lr = 1e-06
I0823 00:55:37.896337 13823 solver.cpp:239] Iteration 293700 (10.1852 iter/s, 9.81814s/100 iters), loss = 0.0249228
I0823 00:55:37.896386 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0249221 (* 1 = 0.0249221 loss)
I0823 00:55:37.896395 13823 sgd_solver.cpp:112] Iteration 293700, lr = 1e-06
I0823 00:55:47.502097 13823 solver.cpp:239] Iteration 293800 (10.4105 iter/s, 9.60566s/100 iters), loss = 0.0290329
I0823 00:55:47.502137 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0290322 (* 1 = 0.0290322 loss)
I0823 00:55:47.502144 13823 sgd_solver.cpp:112] Iteration 293800, lr = 1e-06
I0823 00:55:56.866741 13823 solver.cpp:239] Iteration 293900 (10.6786 iter/s, 9.36455s/100 iters), loss = 0.0312974
I0823 00:55:56.866789 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0312967 (* 1 = 0.0312967 loss)
I0823 00:55:56.866798 13823 sgd_solver.cpp:112] Iteration 293900, lr = 1e-06
I0823 00:56:06.088243 13823 solver.cpp:239] Iteration 294000 (10.8443 iter/s, 9.22141s/100 iters), loss = 0.0259483
I0823 00:56:06.088284 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0259476 (* 1 = 0.0259476 loss)
I0823 00:56:06.088291 13823 sgd_solver.cpp:112] Iteration 294000, lr = 1e-06
I0823 00:56:15.538475 13823 solver.cpp:239] Iteration 294100 (10.5819 iter/s, 9.45014s/100 iters), loss = 0.0232204
I0823 00:56:15.538516 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0232197 (* 1 = 0.0232197 loss)
I0823 00:56:15.538524 13823 sgd_solver.cpp:112] Iteration 294100, lr = 1e-06
I0823 00:56:25.038300 13823 solver.cpp:239] Iteration 294200 (10.5266 iter/s, 9.49973s/100 iters), loss = 0.0318138
I0823 00:56:25.038341 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0318132 (* 1 = 0.0318132 loss)
I0823 00:56:25.038347 13823 sgd_solver.cpp:112] Iteration 294200, lr = 1e-06
I0823 00:56:34.295362 13823 solver.cpp:239] Iteration 294300 (10.8027 iter/s, 9.25697s/100 iters), loss = 0.0245614
I0823 00:56:34.295413 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0245607 (* 1 = 0.0245607 loss)
I0823 00:56:34.295423 13823 sgd_solver.cpp:112] Iteration 294300, lr = 1e-06
I0823 00:56:43.504986 13823 solver.cpp:239] Iteration 294400 (10.8583 iter/s, 9.20952s/100 iters), loss = 0.0341401
I0823 00:56:43.505026 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0341394 (* 1 = 0.0341394 loss)
I0823 00:56:43.505033 13823 sgd_solver.cpp:112] Iteration 294400, lr = 1e-06
I0823 00:56:52.830963 13823 solver.cpp:239] Iteration 294500 (10.7228 iter/s, 9.32589s/100 iters), loss = 0.026937
I0823 00:56:52.831012 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0269363 (* 1 = 0.0269363 loss)
I0823 00:56:52.831020 13823 sgd_solver.cpp:112] Iteration 294500, lr = 1e-06
I0823 00:57:02.058153 13823 solver.cpp:239] Iteration 294600 (10.8376 iter/s, 9.2271s/100 iters), loss = 0.0247609
I0823 00:57:02.058195 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0247603 (* 1 = 0.0247603 loss)
I0823 00:57:02.058203 13823 sgd_solver.cpp:112] Iteration 294600, lr = 1e-06
I0823 00:57:11.636986 13823 solver.cpp:239] Iteration 294700 (10.4398 iter/s, 9.57874s/100 iters), loss = 0.0291175
I0823 00:57:11.637040 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0291168 (* 1 = 0.0291168 loss)
I0823 00:57:11.637050 13823 sgd_solver.cpp:112] Iteration 294700, lr = 1e-06
I0823 00:57:21.283155 13823 solver.cpp:239] Iteration 294800 (10.3669 iter/s, 9.64607s/100 iters), loss = 0.0241134
I0823 00:57:21.283200 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0241127 (* 1 = 0.0241127 loss)
I0823 00:57:21.283208 13823 sgd_solver.cpp:112] Iteration 294800, lr = 1e-06
I0823 00:57:30.620457 13823 solver.cpp:239] Iteration 294900 (10.7098 iter/s, 9.33721s/100 iters), loss = 0.0267963
I0823 00:57:30.620497 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0267956 (* 1 = 0.0267956 loss)
I0823 00:57:30.620504 13823 sgd_solver.cpp:112] Iteration 294900, lr = 1e-06
I0823 00:57:40.232486 13823 solver.cpp:239] Iteration 295000 (10.4037 iter/s, 9.61194s/100 iters), loss = 0.0303013
I0823 00:57:40.232537 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0303007 (* 1 = 0.0303007 loss)
I0823 00:57:40.232547 13823 sgd_solver.cpp:112] Iteration 295000, lr = 1e-06
I0823 00:57:50.198349 13823 solver.cpp:239] Iteration 295100 (10.0344 iter/s, 9.96576s/100 iters), loss = 0.0289543
I0823 00:57:50.198400 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0289537 (* 1 = 0.0289537 loss)
I0823 00:57:50.198410 13823 sgd_solver.cpp:112] Iteration 295100, lr = 1e-06
I0823 00:57:59.952438 13823 solver.cpp:239] Iteration 295200 (10.2522 iter/s, 9.75399s/100 iters), loss = 0.0330743
I0823 00:57:59.952498 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0330736 (* 1 = 0.0330736 loss)
I0823 00:57:59.952507 13823 sgd_solver.cpp:112] Iteration 295200, lr = 1e-06
I0823 00:58:09.598909 13823 solver.cpp:239] Iteration 295300 (10.3666 iter/s, 9.64637s/100 iters), loss = 0.0255232
I0823 00:58:09.598949 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0255226 (* 1 = 0.0255226 loss)
I0823 00:58:09.598956 13823 sgd_solver.cpp:112] Iteration 295300, lr = 1e-06
I0823 00:58:19.181918 13823 solver.cpp:239] Iteration 295400 (10.4352 iter/s, 9.58292s/100 iters), loss = 0.0257729
I0823 00:58:19.181969 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0257722 (* 1 = 0.0257722 loss)
I0823 00:58:19.181979 13823 sgd_solver.cpp:112] Iteration 295400, lr = 1e-06
I0823 00:58:28.964056 13823 solver.cpp:239] Iteration 295500 (10.2228 iter/s, 9.78203s/100 iters), loss = 0.0298749
I0823 00:58:28.964112 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0298743 (* 1 = 0.0298743 loss)
I0823 00:58:28.964121 13823 sgd_solver.cpp:112] Iteration 295500, lr = 1e-06
I0823 00:58:38.765703 13823 solver.cpp:239] Iteration 295600 (10.2025 iter/s, 9.80154s/100 iters), loss = 0.0292243
I0823 00:58:38.765753 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0292236 (* 1 = 0.0292236 loss)
I0823 00:58:38.765763 13823 sgd_solver.cpp:112] Iteration 295600, lr = 1e-06
I0823 00:58:48.539736 13823 solver.cpp:239] Iteration 295700 (10.2313 iter/s, 9.77393s/100 iters), loss = 0.0350625
I0823 00:58:48.539783 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0350618 (* 1 = 0.0350618 loss)
I0823 00:58:48.539793 13823 sgd_solver.cpp:112] Iteration 295700, lr = 1e-06
I0823 00:58:58.655148 13823 solver.cpp:239] Iteration 295800 (9.886 iter/s, 10.1153s/100 iters), loss = 0.0281397
I0823 00:58:58.655201 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0281391 (* 1 = 0.0281391 loss)
I0823 00:58:58.655211 13823 sgd_solver.cpp:112] Iteration 295800, lr = 1e-06
I0823 00:59:08.335567 13823 solver.cpp:239] Iteration 295900 (10.3302 iter/s, 9.68032s/100 iters), loss = 0.0332694
I0823 00:59:08.335618 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0332688 (* 1 = 0.0332688 loss)
I0823 00:59:08.335628 13823 sgd_solver.cpp:112] Iteration 295900, lr = 1e-06
I0823 00:59:18.102298 13823 solver.cpp:239] Iteration 296000 (10.2389 iter/s, 9.76663s/100 iters), loss = 0.0337853
I0823 00:59:18.102349 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0337846 (* 1 = 0.0337846 loss)
I0823 00:59:18.102357 13823 sgd_solver.cpp:112] Iteration 296000, lr = 1e-06
I0823 00:59:27.951257 13823 solver.cpp:239] Iteration 296100 (10.1535 iter/s, 9.84886s/100 iters), loss = 0.0327962
I0823 00:59:27.951318 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0327956 (* 1 = 0.0327956 loss)
I0823 00:59:27.951329 13823 sgd_solver.cpp:112] Iteration 296100, lr = 1e-06
I0823 00:59:37.737776 13823 solver.cpp:239] Iteration 296200 (10.2182 iter/s, 9.78641s/100 iters), loss = 0.0254338
I0823 00:59:37.737828 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0254332 (* 1 = 0.0254332 loss)
I0823 00:59:37.737838 13823 sgd_solver.cpp:112] Iteration 296200, lr = 1e-06
I0823 00:59:47.341532 13823 solver.cpp:239] Iteration 296300 (10.4127 iter/s, 9.60366s/100 iters), loss = 0.0241872
I0823 00:59:47.341583 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0241866 (* 1 = 0.0241866 loss)
I0823 00:59:47.341593 13823 sgd_solver.cpp:112] Iteration 296300, lr = 1e-06
I0823 00:59:57.178316 13823 solver.cpp:239] Iteration 296400 (10.166 iter/s, 9.83669s/100 iters), loss = 0.0407036
I0823 00:59:57.178365 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0407029 (* 1 = 0.0407029 loss)
I0823 00:59:57.178375 13823 sgd_solver.cpp:112] Iteration 296400, lr = 1e-06
I0823 01:00:07.016283 13823 solver.cpp:239] Iteration 296500 (10.1648 iter/s, 9.83787s/100 iters), loss = 0.029021
I0823 01:00:07.016335 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0290203 (* 1 = 0.0290203 loss)
I0823 01:00:07.016345 13823 sgd_solver.cpp:112] Iteration 296500, lr = 1e-06
I0823 01:00:16.947674 13823 solver.cpp:239] Iteration 296600 (10.0692 iter/s, 9.93129s/100 iters), loss = 0.0250361
I0823 01:00:16.947726 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0250354 (* 1 = 0.0250354 loss)
I0823 01:00:16.947736 13823 sgd_solver.cpp:112] Iteration 296600, lr = 1e-06
I0823 01:00:26.611449 13823 solver.cpp:239] Iteration 296700 (10.348 iter/s, 9.66368s/100 iters), loss = 0.0241918
I0823 01:00:26.611505 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0241911 (* 1 = 0.0241911 loss)
I0823 01:00:26.611515 13823 sgd_solver.cpp:112] Iteration 296700, lr = 1e-06
I0823 01:00:36.524789 13823 solver.cpp:239] Iteration 296800 (10.0875 iter/s, 9.91324s/100 iters), loss = 0.0242541
I0823 01:00:36.524840 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0242534 (* 1 = 0.0242534 loss)
I0823 01:00:36.524849 13823 sgd_solver.cpp:112] Iteration 296800, lr = 1e-06
I0823 01:00:46.459175 13823 solver.cpp:239] Iteration 296900 (10.0661 iter/s, 9.93429s/100 iters), loss = 0.0362965
I0823 01:00:46.459229 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0362958 (* 1 = 0.0362958 loss)
I0823 01:00:46.459239 13823 sgd_solver.cpp:112] Iteration 296900, lr = 1e-06
I0823 01:00:56.507341 13823 solver.cpp:239] Iteration 297000 (9.95216 iter/s, 10.0481s/100 iters), loss = 0.027785
I0823 01:00:56.507391 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0277843 (* 1 = 0.0277843 loss)
I0823 01:00:56.507400 13823 sgd_solver.cpp:112] Iteration 297000, lr = 1e-06
I0823 01:01:06.068715 13823 solver.cpp:239] Iteration 297100 (10.4588 iter/s, 9.56129s/100 iters), loss = 0.0245313
I0823 01:01:06.068756 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0245306 (* 1 = 0.0245306 loss)
I0823 01:01:06.068763 13823 sgd_solver.cpp:112] Iteration 297100, lr = 1e-06
I0823 01:01:15.482131 13823 solver.cpp:239] Iteration 297200 (10.6232 iter/s, 9.41333s/100 iters), loss = 0.0283772
I0823 01:01:15.482170 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0283766 (* 1 = 0.0283766 loss)
I0823 01:01:15.482177 13823 sgd_solver.cpp:112] Iteration 297200, lr = 1e-06
I0823 01:01:24.963254 13823 solver.cpp:239] Iteration 297300 (10.5474 iter/s, 9.48104s/100 iters), loss = 0.026809
I0823 01:01:24.963304 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0268083 (* 1 = 0.0268083 loss)
I0823 01:01:24.963315 13823 sgd_solver.cpp:112] Iteration 297300, lr = 1e-06
I0823 01:01:34.995726 13823 solver.cpp:239] Iteration 297400 (9.96773 iter/s, 10.0324s/100 iters), loss = 0.0450248
I0823 01:01:34.995785 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0450241 (* 1 = 0.0450241 loss)
I0823 01:01:34.995796 13823 sgd_solver.cpp:112] Iteration 297400, lr = 1e-06
I0823 01:01:44.724898 13823 solver.cpp:239] Iteration 297500 (10.2785 iter/s, 9.72907s/100 iters), loss = 0.0246382
I0823 01:01:44.724949 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0246375 (* 1 = 0.0246375 loss)
I0823 01:01:44.724959 13823 sgd_solver.cpp:112] Iteration 297500, lr = 1e-06
I0823 01:01:54.415249 13823 solver.cpp:239] Iteration 297600 (10.3196 iter/s, 9.69025s/100 iters), loss = 0.0371821
I0823 01:01:54.415313 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0371814 (* 1 = 0.0371814 loss)
I0823 01:01:54.415325 13823 sgd_solver.cpp:112] Iteration 297600, lr = 1e-06
I0823 01:02:04.246436 13823 solver.cpp:239] Iteration 297700 (10.1718 iter/s, 9.83108s/100 iters), loss = 0.0345552
I0823 01:02:04.246487 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0345546 (* 1 = 0.0345546 loss)
I0823 01:02:04.246496 13823 sgd_solver.cpp:112] Iteration 297700, lr = 1e-06
I0823 01:02:14.312558 13823 solver.cpp:239] Iteration 297800 (9.9344 iter/s, 10.066s/100 iters), loss = 0.0272694
I0823 01:02:14.312609 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0272687 (* 1 = 0.0272687 loss)
I0823 01:02:14.312619 13823 sgd_solver.cpp:112] Iteration 297800, lr = 1e-06
I0823 01:02:24.473865 13823 solver.cpp:239] Iteration 297900 (9.84135 iter/s, 10.1612s/100 iters), loss = 0.0267163
I0823 01:02:24.473915 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0267156 (* 1 = 0.0267156 loss)
I0823 01:02:24.473924 13823 sgd_solver.cpp:112] Iteration 297900, lr = 1e-06
I0823 01:02:34.482802 13823 solver.cpp:239] Iteration 298000 (9.99116 iter/s, 10.0088s/100 iters), loss = 0.0316319
I0823 01:02:34.482853 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0316313 (* 1 = 0.0316313 loss)
I0823 01:02:34.482862 13823 sgd_solver.cpp:112] Iteration 298000, lr = 1e-06
I0823 01:02:44.502444 13823 solver.cpp:239] Iteration 298100 (9.98049 iter/s, 10.0195s/100 iters), loss = 0.0261135
I0823 01:02:44.502503 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0261128 (* 1 = 0.0261128 loss)
I0823 01:02:44.502516 13823 sgd_solver.cpp:112] Iteration 298100, lr = 1e-06
I0823 01:02:54.319694 13823 solver.cpp:239] Iteration 298200 (10.1863 iter/s, 9.81715s/100 iters), loss = 0.219559
I0823 01:02:54.319744 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.219558 (* 1 = 0.219558 loss)
I0823 01:02:54.319753 13823 sgd_solver.cpp:112] Iteration 298200, lr = 1e-06
I0823 01:03:04.184223 13823 solver.cpp:239] Iteration 298300 (10.1374 iter/s, 9.86444s/100 iters), loss = 0.026743
I0823 01:03:04.184273 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0267424 (* 1 = 0.0267424 loss)
I0823 01:03:04.184281 13823 sgd_solver.cpp:112] Iteration 298300, lr = 1e-06
I0823 01:03:14.260790 13823 solver.cpp:239] Iteration 298400 (9.92411 iter/s, 10.0765s/100 iters), loss = 0.0237539
I0823 01:03:14.260850 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0237532 (* 1 = 0.0237532 loss)
I0823 01:03:14.260861 13823 sgd_solver.cpp:112] Iteration 298400, lr = 1e-06
I0823 01:03:24.170492 13823 solver.cpp:239] Iteration 298500 (10.0912 iter/s, 9.9096s/100 iters), loss = 0.0271609
I0823 01:03:24.170542 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0271603 (* 1 = 0.0271603 loss)
I0823 01:03:24.170552 13823 sgd_solver.cpp:112] Iteration 298500, lr = 1e-06
I0823 01:03:34.271828 13823 solver.cpp:239] Iteration 298600 (9.89977 iter/s, 10.1012s/100 iters), loss = 0.0273928
I0823 01:03:34.271878 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0273921 (* 1 = 0.0273921 loss)
I0823 01:03:34.271888 13823 sgd_solver.cpp:112] Iteration 298600, lr = 1e-06
I0823 01:03:44.376890 13823 solver.cpp:239] Iteration 298700 (9.89612 iter/s, 10.105s/100 iters), loss = 0.0259122
I0823 01:03:44.376940 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0259115 (* 1 = 0.0259115 loss)
I0823 01:03:44.376950 13823 sgd_solver.cpp:112] Iteration 298700, lr = 1e-06
I0823 01:03:54.392969 13823 solver.cpp:239] Iteration 298800 (9.98404 iter/s, 10.016s/100 iters), loss = 0.0287284
I0823 01:03:54.393020 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0287278 (* 1 = 0.0287278 loss)
I0823 01:03:54.393029 13823 sgd_solver.cpp:112] Iteration 298800, lr = 1e-06
I0823 01:04:04.534565 13823 solver.cpp:239] Iteration 298900 (9.86047 iter/s, 10.1415s/100 iters), loss = 0.0299416
I0823 01:04:04.534622 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.029941 (* 1 = 0.029941 loss)
I0823 01:04:04.534633 13823 sgd_solver.cpp:112] Iteration 298900, lr = 1e-06
I0823 01:04:14.633164 13823 solver.cpp:239] Iteration 299000 (9.90246 iter/s, 10.0985s/100 iters), loss = 0.0372402
I0823 01:04:14.633221 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0372395 (* 1 = 0.0372395 loss)
I0823 01:04:14.633232 13823 sgd_solver.cpp:112] Iteration 299000, lr = 1e-06
I0823 01:04:24.652180 13823 solver.cpp:239] Iteration 299100 (9.98112 iter/s, 10.0189s/100 iters), loss = 0.0261886
I0823 01:04:24.652245 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.026188 (* 1 = 0.026188 loss)
I0823 01:04:24.652257 13823 sgd_solver.cpp:112] Iteration 299100, lr = 1e-06
I0823 01:04:34.591933 13823 solver.cpp:239] Iteration 299200 (10.0607 iter/s, 9.93965s/100 iters), loss = 0.0275252
I0823 01:04:34.591984 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0275245 (* 1 = 0.0275245 loss)
I0823 01:04:34.591992 13823 sgd_solver.cpp:112] Iteration 299200, lr = 1e-06
I0823 01:04:44.757179 13823 solver.cpp:239] Iteration 299300 (9.83753 iter/s, 10.1652s/100 iters), loss = 0.039771
I0823 01:04:44.757239 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0397703 (* 1 = 0.0397703 loss)
I0823 01:04:44.757249 13823 sgd_solver.cpp:112] Iteration 299300, lr = 1e-06
I0823 01:04:55.065575 13823 solver.cpp:239] Iteration 299400 (9.70092 iter/s, 10.3083s/100 iters), loss = 0.0239064
I0823 01:04:55.065629 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0239058 (* 1 = 0.0239058 loss)
I0823 01:04:55.065639 13823 sgd_solver.cpp:112] Iteration 299400, lr = 1e-06
I0823 01:05:05.285007 13823 solver.cpp:239] Iteration 299500 (9.78537 iter/s, 10.2193s/100 iters), loss = 0.0250379
I0823 01:05:05.285059 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0250372 (* 1 = 0.0250372 loss)
I0823 01:05:05.285068 13823 sgd_solver.cpp:112] Iteration 299500, lr = 1e-06
I0823 01:05:15.433387 13823 solver.cpp:239] Iteration 299600 (9.85388 iter/s, 10.1483s/100 iters), loss = 0.0275062
I0823 01:05:15.433449 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0275055 (* 1 = 0.0275055 loss)
I0823 01:05:15.433461 13823 sgd_solver.cpp:112] Iteration 299600, lr = 1e-06
I0823 01:05:25.825836 13823 solver.cpp:239] Iteration 299700 (9.62247 iter/s, 10.3923s/100 iters), loss = 0.0226475
I0823 01:05:25.825893 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0226468 (* 1 = 0.0226468 loss)
I0823 01:05:25.825904 13823 sgd_solver.cpp:112] Iteration 299700, lr = 1e-06
I0823 01:05:36.071568 13823 solver.cpp:239] Iteration 299800 (9.76025 iter/s, 10.2456s/100 iters), loss = 0.0231529
I0823 01:05:36.071619 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0231522 (* 1 = 0.0231522 loss)
I0823 01:05:36.071629 13823 sgd_solver.cpp:112] Iteration 299800, lr = 1e-06
I0823 01:05:46.106447 13823 solver.cpp:239] Iteration 299900 (9.96533 iter/s, 10.0348s/100 iters), loss = 0.0286246
I0823 01:05:46.106499 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0286239 (* 1 = 0.0286239 loss)
I0823 01:05:46.106508 13823 sgd_solver.cpp:112] Iteration 299900, lr = 1e-06
I0823 01:05:56.029300 13823 solver.cpp:464] Snapshotting to binary proto file ./model_112/cascade_mobilenet_112_iter_300000.caffemodel
I0823 01:05:56.115559 13823 sgd_solver.cpp:284] Snapshotting solver state to binary proto file ./model_112/cascade_mobilenet_112_iter_300000.solverstate
I0823 01:05:56.160259 13823 solver.cpp:347] Iteration 300000, Testing net (#0)
I0823 01:07:09.965678 13823 solver.cpp:414]     Test net output #0: landmark_loss = 0.0220054 (* 1 = 0.0220054 loss)
I0823 01:07:10.084200 13823 solver.cpp:239] Iteration 300000 (1.1908 iter/s, 83.9775s/100 iters), loss = 0.0304221
I0823 01:07:10.084236 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0304215 (* 1 = 0.0304215 loss)
I0823 01:07:10.084247 13823 sgd_solver.cpp:112] Iteration 300000, lr = 1e-06
I0823 01:07:20.379211 13823 solver.cpp:239] Iteration 300100 (9.7135 iter/s, 10.2949s/100 iters), loss = 0.027423
I0823 01:07:20.379253 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0274223 (* 1 = 0.0274223 loss)
I0823 01:07:20.379261 13823 sgd_solver.cpp:112] Iteration 300100, lr = 1e-06
I0823 01:07:30.439085 13823 solver.cpp:239] Iteration 300200 (9.94056 iter/s, 10.0598s/100 iters), loss = 0.0292952
I0823 01:07:30.439146 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0292946 (* 1 = 0.0292946 loss)
I0823 01:07:30.439160 13823 sgd_solver.cpp:112] Iteration 300200, lr = 1e-06
I0823 01:07:40.755467 13823 solver.cpp:239] Iteration 300300 (9.6934 iter/s, 10.3163s/100 iters), loss = 0.0234129
I0823 01:07:40.755522 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0234122 (* 1 = 0.0234122 loss)
I0823 01:07:40.755532 13823 sgd_solver.cpp:112] Iteration 300300, lr = 1e-06
I0823 01:07:51.354563 13823 solver.cpp:239] Iteration 300400 (9.43484 iter/s, 10.599s/100 iters), loss = 0.0264393
I0823 01:07:51.354629 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0264386 (* 1 = 0.0264386 loss)
I0823 01:07:51.354643 13823 sgd_solver.cpp:112] Iteration 300400, lr = 1e-06
I0823 01:08:01.914333 13823 solver.cpp:239] Iteration 300500 (9.46998 iter/s, 10.5597s/100 iters), loss = 0.0280882
I0823 01:08:01.914393 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0280875 (* 1 = 0.0280875 loss)
I0823 01:08:01.914405 13823 sgd_solver.cpp:112] Iteration 300500, lr = 1e-06
I0823 01:08:12.459903 13823 solver.cpp:239] Iteration 300600 (9.48273 iter/s, 10.5455s/100 iters), loss = 0.0288185
I0823 01:08:12.459954 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0288178 (* 1 = 0.0288178 loss)
I0823 01:08:12.459964 13823 sgd_solver.cpp:112] Iteration 300600, lr = 1e-06
I0823 01:08:23.035921 13823 solver.cpp:239] Iteration 300700 (9.45543 iter/s, 10.5759s/100 iters), loss = 0.0291159
I0823 01:08:23.035984 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0291152 (* 1 = 0.0291152 loss)
I0823 01:08:23.035995 13823 sgd_solver.cpp:112] Iteration 300700, lr = 1e-06
I0823 01:08:33.714989 13823 solver.cpp:239] Iteration 300800 (9.36419 iter/s, 10.679s/100 iters), loss = 0.0427837
I0823 01:08:33.715046 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.042783 (* 1 = 0.042783 loss)
I0823 01:08:33.715060 13823 sgd_solver.cpp:112] Iteration 300800, lr = 1e-06
I0823 01:08:44.418107 13823 solver.cpp:239] Iteration 300900 (9.34315 iter/s, 10.703s/100 iters), loss = 0.0259339
I0823 01:08:44.418160 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0259333 (* 1 = 0.0259333 loss)
I0823 01:08:44.418170 13823 sgd_solver.cpp:112] Iteration 300900, lr = 1e-06
I0823 01:08:55.043329 13823 solver.cpp:239] Iteration 301000 (9.41164 iter/s, 10.6251s/100 iters), loss = 0.0308024
I0823 01:08:55.043386 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0308018 (* 1 = 0.0308018 loss)
I0823 01:08:55.043399 13823 sgd_solver.cpp:112] Iteration 301000, lr = 1e-06
I0823 01:09:05.704295 13823 solver.cpp:239] Iteration 301100 (9.38009 iter/s, 10.6609s/100 iters), loss = 0.0267965
I0823 01:09:05.704349 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0267959 (* 1 = 0.0267959 loss)
I0823 01:09:05.704360 13823 sgd_solver.cpp:112] Iteration 301100, lr = 1e-06
I0823 01:09:16.003803 13823 solver.cpp:239] Iteration 301200 (9.70894 iter/s, 10.2998s/100 iters), loss = 0.0291307
I0823 01:09:16.003865 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.02913 (* 1 = 0.02913 loss)
I0823 01:09:16.003876 13823 sgd_solver.cpp:112] Iteration 301200, lr = 1e-06
I0823 01:09:26.409657 13823 solver.cpp:239] Iteration 301300 (9.60964 iter/s, 10.4062s/100 iters), loss = 0.0271971
I0823 01:09:26.409711 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0271964 (* 1 = 0.0271964 loss)
I0823 01:09:26.409723 13823 sgd_solver.cpp:112] Iteration 301300, lr = 1e-06
I0823 01:09:37.036175 13823 solver.cpp:239] Iteration 301400 (9.41009 iter/s, 10.6269s/100 iters), loss = 0.0255762
I0823 01:09:37.036238 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0255755 (* 1 = 0.0255755 loss)
I0823 01:09:37.036250 13823 sgd_solver.cpp:112] Iteration 301400, lr = 1e-06
I0823 01:09:47.718343 13823 solver.cpp:239] Iteration 301500 (9.36108 iter/s, 10.6825s/100 iters), loss = 0.0436995
I0823 01:09:47.718402 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0436988 (* 1 = 0.0436988 loss)
I0823 01:09:47.718413 13823 sgd_solver.cpp:112] Iteration 301500, lr = 1e-06
I0823 01:09:58.403129 13823 solver.cpp:239] Iteration 301600 (9.35879 iter/s, 10.6851s/100 iters), loss = 0.0266976
I0823 01:09:58.403182 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0266969 (* 1 = 0.0266969 loss)
I0823 01:09:58.403193 13823 sgd_solver.cpp:112] Iteration 301600, lr = 1e-06
I0823 01:10:09.017518 13823 solver.cpp:239] Iteration 301700 (9.42087 iter/s, 10.6147s/100 iters), loss = 0.0271786
I0823 01:10:09.017578 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0271779 (* 1 = 0.0271779 loss)
I0823 01:10:09.017590 13823 sgd_solver.cpp:112] Iteration 301700, lr = 1e-06
I0823 01:10:20.023331 13823 solver.cpp:239] Iteration 301800 (9.08582 iter/s, 11.0062s/100 iters), loss = 0.0274635
I0823 01:10:20.023382 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0274628 (* 1 = 0.0274628 loss)
I0823 01:10:20.023391 13823 sgd_solver.cpp:112] Iteration 301800, lr = 1e-06
I0823 01:10:30.555824 13823 solver.cpp:239] Iteration 301900 (9.49413 iter/s, 10.5328s/100 iters), loss = 0.025937
I0823 01:10:30.555872 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0259363 (* 1 = 0.0259363 loss)
I0823 01:10:30.555882 13823 sgd_solver.cpp:112] Iteration 301900, lr = 1e-06
I0823 01:10:41.533059 13823 solver.cpp:239] Iteration 302000 (9.10948 iter/s, 10.9776s/100 iters), loss = 0.0247904
I0823 01:10:41.533113 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0247897 (* 1 = 0.0247897 loss)
I0823 01:10:41.533123 13823 sgd_solver.cpp:112] Iteration 302000, lr = 1e-06
I0823 01:10:52.280045 13823 solver.cpp:239] Iteration 302100 (9.30465 iter/s, 10.7473s/100 iters), loss = 0.0422077
I0823 01:10:52.280095 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.042207 (* 1 = 0.042207 loss)
I0823 01:10:52.280104 13823 sgd_solver.cpp:112] Iteration 302100, lr = 1e-06
I0823 01:11:03.127238 13823 solver.cpp:239] Iteration 302200 (9.2187 iter/s, 10.8475s/100 iters), loss = 0.0310111
I0823 01:11:03.127288 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0310104 (* 1 = 0.0310104 loss)
I0823 01:11:03.127297 13823 sgd_solver.cpp:112] Iteration 302200, lr = 1e-06
I0823 01:11:13.769505 13823 solver.cpp:239] Iteration 302300 (9.39622 iter/s, 10.6426s/100 iters), loss = 0.0274494
I0823 01:11:13.769556 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0274488 (* 1 = 0.0274488 loss)
I0823 01:11:13.769565 13823 sgd_solver.cpp:112] Iteration 302300, lr = 1e-06
I0823 01:11:24.571713 13823 solver.cpp:239] Iteration 302400 (9.2571 iter/s, 10.8025s/100 iters), loss = 0.0400164
I0823 01:11:24.571765 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0400157 (* 1 = 0.0400157 loss)
I0823 01:11:24.571774 13823 sgd_solver.cpp:112] Iteration 302400, lr = 1e-06
I0823 01:11:35.468330 13823 solver.cpp:239] Iteration 302500 (9.1769 iter/s, 10.8969s/100 iters), loss = 0.0252842
I0823 01:11:35.468394 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0252835 (* 1 = 0.0252835 loss)
I0823 01:11:35.468405 13823 sgd_solver.cpp:112] Iteration 302500, lr = 1e-06
I0823 01:11:46.109380 13823 solver.cpp:239] Iteration 302600 (9.39733 iter/s, 10.6413s/100 iters), loss = 0.0286557
I0823 01:11:46.109444 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.028655 (* 1 = 0.028655 loss)
I0823 01:11:46.109454 13823 sgd_solver.cpp:112] Iteration 302600, lr = 1e-06
I0823 01:11:57.104986 13823 solver.cpp:239] Iteration 302700 (9.09431 iter/s, 10.9959s/100 iters), loss = 0.0246858
I0823 01:11:57.105041 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0246851 (* 1 = 0.0246851 loss)
I0823 01:11:57.105051 13823 sgd_solver.cpp:112] Iteration 302700, lr = 1e-06
I0823 01:12:08.097301 13823 solver.cpp:239] Iteration 302800 (9.09703 iter/s, 10.9926s/100 iters), loss = 0.0248536
I0823 01:12:08.097359 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0248529 (* 1 = 0.0248529 loss)
I0823 01:12:08.097370 13823 sgd_solver.cpp:112] Iteration 302800, lr = 1e-06
I0823 01:12:18.793844 13823 solver.cpp:239] Iteration 302900 (9.34858 iter/s, 10.6968s/100 iters), loss = 0.0281013
I0823 01:12:18.793896 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0281006 (* 1 = 0.0281006 loss)
I0823 01:12:18.793906 13823 sgd_solver.cpp:112] Iteration 302900, lr = 1e-06
I0823 01:12:29.832442 13823 solver.cpp:239] Iteration 303000 (9.05889 iter/s, 11.0389s/100 iters), loss = 0.0238192
I0823 01:12:29.832496 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0238185 (* 1 = 0.0238185 loss)
I0823 01:12:29.832506 13823 sgd_solver.cpp:112] Iteration 303000, lr = 1e-06
I0823 01:12:40.708304 13823 solver.cpp:239] Iteration 303100 (9.19445 iter/s, 10.8761s/100 iters), loss = 0.0318759
I0823 01:12:40.708356 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0318752 (* 1 = 0.0318752 loss)
I0823 01:12:40.708365 13823 sgd_solver.cpp:112] Iteration 303100, lr = 1e-06
I0823 01:12:51.581660 13823 solver.cpp:239] Iteration 303200 (9.19657 iter/s, 10.8736s/100 iters), loss = 0.0262326
I0823 01:12:51.581723 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0262319 (* 1 = 0.0262319 loss)
I0823 01:12:51.581734 13823 sgd_solver.cpp:112] Iteration 303200, lr = 1e-06
I0823 01:13:02.948928 13823 solver.cpp:239] Iteration 303300 (8.79699 iter/s, 11.3675s/100 iters), loss = 0.0261353
I0823 01:13:02.948987 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0261346 (* 1 = 0.0261346 loss)
I0823 01:13:02.949000 13823 sgd_solver.cpp:112] Iteration 303300, lr = 1e-06
I0823 01:13:13.744518 13823 solver.cpp:239] Iteration 303400 (9.26283 iter/s, 10.7958s/100 iters), loss = 0.0252452
I0823 01:13:13.744580 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0252445 (* 1 = 0.0252445 loss)
I0823 01:13:13.744593 13823 sgd_solver.cpp:112] Iteration 303400, lr = 1e-06
I0823 01:13:24.928910 13823 solver.cpp:239] Iteration 303500 (8.94083 iter/s, 11.1846s/100 iters), loss = 0.0269513
I0823 01:13:24.928969 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0269506 (* 1 = 0.0269506 loss)
I0823 01:13:24.928982 13823 sgd_solver.cpp:112] Iteration 303500, lr = 1e-06
I0823 01:13:35.810544 13823 solver.cpp:239] Iteration 303600 (9.1896 iter/s, 10.8819s/100 iters), loss = 0.0252599
I0823 01:13:35.810595 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0252591 (* 1 = 0.0252591 loss)
I0823 01:13:35.810604 13823 sgd_solver.cpp:112] Iteration 303600, lr = 1e-06
I0823 01:13:46.464556 13823 solver.cpp:239] Iteration 303700 (9.38593 iter/s, 10.6542s/100 iters), loss = 0.0258671
I0823 01:13:46.464607 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0258664 (* 1 = 0.0258664 loss)
I0823 01:13:46.464617 13823 sgd_solver.cpp:112] Iteration 303700, lr = 1e-06
I0823 01:13:57.161108 13823 solver.cpp:239] Iteration 303800 (9.34861 iter/s, 10.6968s/100 iters), loss = 0.0258432
I0823 01:13:57.161157 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0258425 (* 1 = 0.0258425 loss)
I0823 01:13:57.161166 13823 sgd_solver.cpp:112] Iteration 303800, lr = 1e-06
I0823 01:14:07.977790 13823 solver.cpp:239] Iteration 303900 (9.24479 iter/s, 10.8169s/100 iters), loss = 0.0250189
I0823 01:14:07.977841 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0250181 (* 1 = 0.0250181 loss)
I0823 01:14:07.977850 13823 sgd_solver.cpp:112] Iteration 303900, lr = 1e-06
I0823 01:14:18.859400 13823 solver.cpp:239] Iteration 304000 (9.18963 iter/s, 10.8818s/100 iters), loss = 0.0264299
I0823 01:14:18.859450 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0264292 (* 1 = 0.0264292 loss)
I0823 01:14:18.859459 13823 sgd_solver.cpp:112] Iteration 304000, lr = 1e-06
I0823 01:14:30.028762 13823 solver.cpp:239] Iteration 304100 (8.95288 iter/s, 11.1696s/100 iters), loss = 0.0256039
I0823 01:14:30.028815 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0256031 (* 1 = 0.0256031 loss)
I0823 01:14:30.028825 13823 sgd_solver.cpp:112] Iteration 304100, lr = 1e-06
I0823 01:14:40.796813 13823 solver.cpp:239] Iteration 304200 (9.28655 iter/s, 10.7683s/100 iters), loss = 0.0266304
I0823 01:14:40.796871 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0266297 (* 1 = 0.0266297 loss)
I0823 01:14:40.796882 13823 sgd_solver.cpp:112] Iteration 304200, lr = 1e-06
I0823 01:14:51.616003 13823 solver.cpp:239] Iteration 304300 (9.24267 iter/s, 10.8194s/100 iters), loss = 0.0332298
I0823 01:14:51.616053 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0332291 (* 1 = 0.0332291 loss)
I0823 01:14:51.616063 13823 sgd_solver.cpp:112] Iteration 304300, lr = 1e-06
I0823 01:15:02.981604 13823 solver.cpp:239] Iteration 304400 (8.79831 iter/s, 11.3658s/100 iters), loss = 0.0262309
I0823 01:15:02.981657 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0262302 (* 1 = 0.0262302 loss)
I0823 01:15:02.981667 13823 sgd_solver.cpp:112] Iteration 304400, lr = 1e-06
I0823 01:15:13.853361 13823 solver.cpp:239] Iteration 304500 (9.19798 iter/s, 10.872s/100 iters), loss = 0.0291725
I0823 01:15:13.853421 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0291718 (* 1 = 0.0291718 loss)
I0823 01:15:13.853432 13823 sgd_solver.cpp:112] Iteration 304500, lr = 1e-06
I0823 01:15:24.817828 13823 solver.cpp:239] Iteration 304600 (9.12022 iter/s, 10.9647s/100 iters), loss = 0.0270425
I0823 01:15:24.817883 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0270418 (* 1 = 0.0270418 loss)
I0823 01:15:24.817893 13823 sgd_solver.cpp:112] Iteration 304600, lr = 1e-06
I0823 01:15:35.999653 13823 solver.cpp:239] Iteration 304700 (8.94293 iter/s, 11.182s/100 iters), loss = 0.0247606
I0823 01:15:35.999706 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0247599 (* 1 = 0.0247599 loss)
I0823 01:15:35.999714 13823 sgd_solver.cpp:112] Iteration 304700, lr = 1e-06
I0823 01:15:47.046805 13823 solver.cpp:239] Iteration 304800 (9.05195 iter/s, 11.0473s/100 iters), loss = 0.0283489
I0823 01:15:47.046854 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0283482 (* 1 = 0.0283482 loss)
I0823 01:15:47.046864 13823 sgd_solver.cpp:112] Iteration 304800, lr = 1e-06
I0823 01:15:58.373289 13823 solver.cpp:239] Iteration 304900 (8.82872 iter/s, 11.3267s/100 iters), loss = 0.03357
I0823 01:15:58.373347 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0335693 (* 1 = 0.0335693 loss)
I0823 01:15:58.373358 13823 sgd_solver.cpp:112] Iteration 304900, lr = 1e-06
I0823 01:16:09.279949 13823 solver.cpp:239] Iteration 305000 (9.16856 iter/s, 10.9068s/100 iters), loss = 0.0254304
I0823 01:16:09.280001 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0254297 (* 1 = 0.0254297 loss)
I0823 01:16:09.280010 13823 sgd_solver.cpp:112] Iteration 305000, lr = 1e-06
I0823 01:16:20.406752 13823 solver.cpp:239] Iteration 305100 (8.98717 iter/s, 11.127s/100 iters), loss = 0.0251362
I0823 01:16:20.406814 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0251355 (* 1 = 0.0251355 loss)
I0823 01:16:20.406826 13823 sgd_solver.cpp:112] Iteration 305100, lr = 1e-06
I0823 01:16:31.572950 13823 solver.cpp:239] Iteration 305200 (8.95547 iter/s, 11.1664s/100 iters), loss = 0.0286087
I0823 01:16:31.573012 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0286081 (* 1 = 0.0286081 loss)
I0823 01:16:31.573024 13823 sgd_solver.cpp:112] Iteration 305200, lr = 1e-06
I0823 01:16:42.617183 13823 solver.cpp:239] Iteration 305300 (9.05437 iter/s, 11.0444s/100 iters), loss = 0.0253481
I0823 01:16:42.617233 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0253474 (* 1 = 0.0253474 loss)
I0823 01:16:42.617242 13823 sgd_solver.cpp:112] Iteration 305300, lr = 1e-06
I0823 01:16:53.344254 13823 solver.cpp:239] Iteration 305400 (9.32207 iter/s, 10.7272s/100 iters), loss = 0.0270346
I0823 01:16:53.344306 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0270339 (* 1 = 0.0270339 loss)
I0823 01:16:53.344316 13823 sgd_solver.cpp:112] Iteration 305400, lr = 1e-06
I0823 01:17:04.334858 13823 solver.cpp:239] Iteration 305500 (9.09855 iter/s, 10.9908s/100 iters), loss = 0.0237365
I0823 01:17:04.334908 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0237358 (* 1 = 0.0237358 loss)
I0823 01:17:04.334916 13823 sgd_solver.cpp:112] Iteration 305500, lr = 1e-06
I0823 01:17:15.291702 13823 solver.cpp:239] Iteration 305600 (9.12658 iter/s, 10.957s/100 iters), loss = 0.0236523
I0823 01:17:15.291751 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0236516 (* 1 = 0.0236516 loss)
I0823 01:17:15.291760 13823 sgd_solver.cpp:112] Iteration 305600, lr = 1e-06
I0823 01:17:26.522135 13823 solver.cpp:239] Iteration 305700 (8.90425 iter/s, 11.2306s/100 iters), loss = 0.0303427
I0823 01:17:26.522191 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.030342 (* 1 = 0.030342 loss)
I0823 01:17:26.522200 13823 sgd_solver.cpp:112] Iteration 305700, lr = 1e-06
I0823 01:17:37.825786 13823 solver.cpp:239] Iteration 305800 (8.84658 iter/s, 11.3038s/100 iters), loss = 0.0408165
I0823 01:17:37.825851 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0408159 (* 1 = 0.0408159 loss)
I0823 01:17:37.825865 13823 sgd_solver.cpp:112] Iteration 305800, lr = 1e-06
I0823 01:17:49.364943 13823 solver.cpp:239] Iteration 305900 (8.66604 iter/s, 11.5393s/100 iters), loss = 0.0253813
I0823 01:17:49.364992 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0253806 (* 1 = 0.0253806 loss)
I0823 01:17:49.365001 13823 sgd_solver.cpp:112] Iteration 305900, lr = 1e-06
I0823 01:18:00.574338 13823 solver.cpp:239] Iteration 306000 (8.92097 iter/s, 11.2095s/100 iters), loss = 0.028168
I0823 01:18:00.574400 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0281673 (* 1 = 0.0281673 loss)
I0823 01:18:00.574414 13823 sgd_solver.cpp:112] Iteration 306000, lr = 1e-06
I0823 01:18:12.053481 13823 solver.cpp:239] Iteration 306100 (8.71135 iter/s, 11.4793s/100 iters), loss = 0.0292931
I0823 01:18:12.053531 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0292924 (* 1 = 0.0292924 loss)
I0823 01:18:12.053540 13823 sgd_solver.cpp:112] Iteration 306100, lr = 1e-06
I0823 01:18:23.338922 13823 solver.cpp:239] Iteration 306200 (8.86086 iter/s, 11.2856s/100 iters), loss = 0.0445883
I0823 01:18:23.338973 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0445876 (* 1 = 0.0445876 loss)
I0823 01:18:23.338982 13823 sgd_solver.cpp:112] Iteration 306200, lr = 1e-06
I0823 01:18:34.720012 13823 solver.cpp:239] Iteration 306300 (8.7864 iter/s, 11.3812s/100 iters), loss = 0.0276417
I0823 01:18:34.720070 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.027641 (* 1 = 0.027641 loss)
I0823 01:18:34.720082 13823 sgd_solver.cpp:112] Iteration 306300, lr = 1e-06
I0823 01:18:46.286845 13823 solver.cpp:239] Iteration 306400 (8.64531 iter/s, 11.567s/100 iters), loss = 0.0262368
I0823 01:18:46.286895 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0262361 (* 1 = 0.0262361 loss)
I0823 01:18:46.286904 13823 sgd_solver.cpp:112] Iteration 306400, lr = 1e-06
I0823 01:18:57.789783 13823 solver.cpp:239] Iteration 306500 (8.69333 iter/s, 11.5031s/100 iters), loss = 0.0312615
I0823 01:18:57.789844 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0312608 (* 1 = 0.0312608 loss)
I0823 01:18:57.789855 13823 sgd_solver.cpp:112] Iteration 306500, lr = 1e-06
I0823 01:19:09.264214 13823 solver.cpp:239] Iteration 306600 (8.71493 iter/s, 11.4746s/100 iters), loss = 0.0251611
I0823 01:19:09.264277 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0251604 (* 1 = 0.0251604 loss)
I0823 01:19:09.264291 13823 sgd_solver.cpp:112] Iteration 306600, lr = 1e-06
I0823 01:19:20.639962 13823 solver.cpp:239] Iteration 306700 (8.79054 iter/s, 11.3759s/100 iters), loss = 0.0296825
I0823 01:19:20.640013 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0296818 (* 1 = 0.0296818 loss)
I0823 01:19:20.640023 13823 sgd_solver.cpp:112] Iteration 306700, lr = 1e-06
I0823 01:19:31.511413 13823 solver.cpp:239] Iteration 306800 (9.1983 iter/s, 10.8716s/100 iters), loss = 0.0308707
I0823 01:19:31.511453 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.03087 (* 1 = 0.03087 loss)
I0823 01:19:31.511461 13823 sgd_solver.cpp:112] Iteration 306800, lr = 1e-06
I0823 01:19:42.872833 13823 solver.cpp:239] Iteration 306900 (8.80162 iter/s, 11.3615s/100 iters), loss = 0.0279814
I0823 01:19:42.872896 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0279806 (* 1 = 0.0279806 loss)
I0823 01:19:42.872910 13823 sgd_solver.cpp:112] Iteration 306900, lr = 1e-06
I0823 01:19:54.143402 13823 solver.cpp:239] Iteration 307000 (8.87258 iter/s, 11.2707s/100 iters), loss = 0.0423036
I0823 01:19:54.143471 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0423029 (* 1 = 0.0423029 loss)
I0823 01:19:54.143487 13823 sgd_solver.cpp:112] Iteration 307000, lr = 1e-06
I0823 01:20:05.442791 13823 solver.cpp:239] Iteration 307100 (8.84995 iter/s, 11.2995s/100 iters), loss = 0.0287298
I0823 01:20:05.442840 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0287291 (* 1 = 0.0287291 loss)
I0823 01:20:05.442849 13823 sgd_solver.cpp:112] Iteration 307100, lr = 1e-06
I0823 01:20:16.922330 13823 solver.cpp:239] Iteration 307200 (8.71106 iter/s, 11.4797s/100 iters), loss = 0.0275395
I0823 01:20:16.922384 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0275388 (* 1 = 0.0275388 loss)
I0823 01:20:16.922394 13823 sgd_solver.cpp:112] Iteration 307200, lr = 1e-06
I0823 01:20:28.281061 13823 solver.cpp:239] Iteration 307300 (8.80371 iter/s, 11.3588s/100 iters), loss = 0.0301695
I0823 01:20:28.281113 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0301688 (* 1 = 0.0301688 loss)
I0823 01:20:28.281124 13823 sgd_solver.cpp:112] Iteration 307300, lr = 1e-06
I0823 01:20:39.572892 13823 solver.cpp:239] Iteration 307400 (8.85587 iter/s, 11.2919s/100 iters), loss = 0.0269668
I0823 01:20:39.572948 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0269661 (* 1 = 0.0269661 loss)
I0823 01:20:39.572959 13823 sgd_solver.cpp:112] Iteration 307400, lr = 1e-06
I0823 01:20:51.063506 13823 solver.cpp:239] Iteration 307500 (8.70268 iter/s, 11.4907s/100 iters), loss = 0.0256071
I0823 01:20:51.063561 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0256064 (* 1 = 0.0256064 loss)
I0823 01:20:51.063572 13823 sgd_solver.cpp:112] Iteration 307500, lr = 1e-06
I0823 01:21:02.410864 13823 solver.cpp:239] Iteration 307600 (8.81254 iter/s, 11.3475s/100 iters), loss = 0.0257101
I0823 01:21:02.410914 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0257094 (* 1 = 0.0257094 loss)
I0823 01:21:02.410924 13823 sgd_solver.cpp:112] Iteration 307600, lr = 1e-06
I0823 01:21:14.089509 13823 solver.cpp:239] Iteration 307700 (8.56256 iter/s, 11.6788s/100 iters), loss = 0.0257439
I0823 01:21:14.089561 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0257432 (* 1 = 0.0257432 loss)
I0823 01:21:14.089570 13823 sgd_solver.cpp:112] Iteration 307700, lr = 1e-06
I0823 01:21:25.428586 13823 solver.cpp:239] Iteration 307800 (8.81898 iter/s, 11.3392s/100 iters), loss = 0.0300967
I0823 01:21:25.428637 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.030096 (* 1 = 0.030096 loss)
I0823 01:21:25.428645 13823 sgd_solver.cpp:112] Iteration 307800, lr = 1e-06
I0823 01:21:36.794941 13823 solver.cpp:239] Iteration 307900 (8.79782 iter/s, 11.3665s/100 iters), loss = 0.0284731
I0823 01:21:36.794999 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0284723 (* 1 = 0.0284723 loss)
I0823 01:21:36.795011 13823 sgd_solver.cpp:112] Iteration 307900, lr = 1e-06
I0823 01:21:48.336879 13823 solver.cpp:239] Iteration 308000 (8.66399 iter/s, 11.542s/100 iters), loss = 0.0275977
I0823 01:21:48.336931 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.027597 (* 1 = 0.027597 loss)
I0823 01:21:48.336941 13823 sgd_solver.cpp:112] Iteration 308000, lr = 1e-06
I0823 01:21:59.608171 13823 solver.cpp:239] Iteration 308100 (8.87203 iter/s, 11.2714s/100 iters), loss = 0.0225784
I0823 01:21:59.608234 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0225776 (* 1 = 0.0225776 loss)
I0823 01:21:59.608247 13823 sgd_solver.cpp:112] Iteration 308100, lr = 1e-06
I0823 01:22:11.193635 13823 solver.cpp:239] Iteration 308200 (8.63144 iter/s, 11.5855s/100 iters), loss = 0.0282841
I0823 01:22:11.193696 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0282834 (* 1 = 0.0282834 loss)
I0823 01:22:11.193707 13823 sgd_solver.cpp:112] Iteration 308200, lr = 1e-06
I0823 01:22:22.472568 13823 solver.cpp:239] Iteration 308300 (8.86602 iter/s, 11.279s/100 iters), loss = 0.0378231
I0823 01:22:22.472623 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0378223 (* 1 = 0.0378223 loss)
I0823 01:22:22.472635 13823 sgd_solver.cpp:112] Iteration 308300, lr = 1e-06
I0823 01:22:33.756878 13823 solver.cpp:239] Iteration 308400 (8.8618 iter/s, 11.2844s/100 iters), loss = 0.0309971
I0823 01:22:33.756928 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0309964 (* 1 = 0.0309964 loss)
I0823 01:22:33.756937 13823 sgd_solver.cpp:112] Iteration 308400, lr = 1e-06
I0823 01:22:44.946677 13823 solver.cpp:239] Iteration 308500 (8.93664 iter/s, 11.1899s/100 iters), loss = 0.0266364
I0823 01:22:44.946727 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0266357 (* 1 = 0.0266357 loss)
I0823 01:22:44.946736 13823 sgd_solver.cpp:112] Iteration 308500, lr = 1e-06
I0823 01:22:56.616148 13823 solver.cpp:239] Iteration 308600 (8.56931 iter/s, 11.6696s/100 iters), loss = 0.0260595
I0823 01:22:56.616206 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0260588 (* 1 = 0.0260588 loss)
I0823 01:22:56.616219 13823 sgd_solver.cpp:112] Iteration 308600, lr = 1e-06
I0823 01:23:07.984985 13823 solver.cpp:239] Iteration 308700 (8.79592 iter/s, 11.3689s/100 iters), loss = 0.0261091
I0823 01:23:07.985041 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0261084 (* 1 = 0.0261084 loss)
I0823 01:23:07.985051 13823 sgd_solver.cpp:112] Iteration 308700, lr = 1e-06
I0823 01:23:19.589689 13823 solver.cpp:239] Iteration 308800 (8.61714 iter/s, 11.6048s/100 iters), loss = 0.0359499
I0823 01:23:19.589751 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0359492 (* 1 = 0.0359492 loss)
I0823 01:23:19.589763 13823 sgd_solver.cpp:112] Iteration 308800, lr = 1e-06
I0823 01:23:31.092496 13823 solver.cpp:239] Iteration 308900 (8.69348 iter/s, 11.5029s/100 iters), loss = 0.0250473
I0823 01:23:31.092550 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0250466 (* 1 = 0.0250466 loss)
I0823 01:23:31.092559 13823 sgd_solver.cpp:112] Iteration 308900, lr = 1e-06
I0823 01:23:42.727741 13823 solver.cpp:239] Iteration 309000 (8.59452 iter/s, 11.6353s/100 iters), loss = 0.0226346
I0823 01:23:42.727797 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0226339 (* 1 = 0.0226339 loss)
I0823 01:23:42.727809 13823 sgd_solver.cpp:112] Iteration 309000, lr = 1e-06
I0823 01:23:54.043465 13823 solver.cpp:239] Iteration 309100 (8.83721 iter/s, 11.3158s/100 iters), loss = 0.0250614
I0823 01:23:54.043530 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0250607 (* 1 = 0.0250607 loss)
I0823 01:23:54.043542 13823 sgd_solver.cpp:112] Iteration 309100, lr = 1e-06
I0823 01:24:05.675973 13823 solver.cpp:239] Iteration 309200 (8.59655 iter/s, 11.6326s/100 iters), loss = 0.0344627
I0823 01:24:05.676026 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.034462 (* 1 = 0.034462 loss)
I0823 01:24:05.676036 13823 sgd_solver.cpp:112] Iteration 309200, lr = 1e-06
I0823 01:24:17.162391 13823 solver.cpp:239] Iteration 309300 (8.70588 iter/s, 11.4865s/100 iters), loss = 0.0294077
I0823 01:24:17.162454 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.029407 (* 1 = 0.029407 loss)
I0823 01:24:17.162467 13823 sgd_solver.cpp:112] Iteration 309300, lr = 1e-06
I0823 01:24:28.689313 13823 solver.cpp:239] Iteration 309400 (8.67529 iter/s, 11.527s/100 iters), loss = 0.0244147
I0823 01:24:28.689363 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.024414 (* 1 = 0.024414 loss)
I0823 01:24:28.689373 13823 sgd_solver.cpp:112] Iteration 309400, lr = 1e-06
I0823 01:24:40.276576 13823 solver.cpp:239] Iteration 309500 (8.63011 iter/s, 11.5873s/100 iters), loss = 0.0250031
I0823 01:24:40.276635 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0250024 (* 1 = 0.0250024 loss)
I0823 01:24:40.276648 13823 sgd_solver.cpp:112] Iteration 309500, lr = 1e-06
I0823 01:24:51.932723 13823 solver.cpp:239] Iteration 309600 (8.57912 iter/s, 11.6562s/100 iters), loss = 0.0258407
I0823 01:24:51.932772 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0258399 (* 1 = 0.0258399 loss)
I0823 01:24:51.932782 13823 sgd_solver.cpp:112] Iteration 309600, lr = 1e-06
I0823 01:25:03.481889 13823 solver.cpp:239] Iteration 309700 (8.65858 iter/s, 11.5492s/100 iters), loss = 0.0271094
I0823 01:25:03.481940 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0271087 (* 1 = 0.0271087 loss)
I0823 01:25:03.481948 13823 sgd_solver.cpp:112] Iteration 309700, lr = 1e-06
I0823 01:25:15.215129 13823 solver.cpp:239] Iteration 309800 (8.52275 iter/s, 11.7333s/100 iters), loss = 0.02588
I0823 01:25:15.215193 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0258793 (* 1 = 0.0258793 loss)
I0823 01:25:15.215209 13823 sgd_solver.cpp:112] Iteration 309800, lr = 1e-06
I0823 01:25:26.673907 13823 solver.cpp:239] Iteration 309900 (8.7269 iter/s, 11.4588s/100 iters), loss = 0.0252135
I0823 01:25:26.673967 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0252127 (* 1 = 0.0252127 loss)
I0823 01:25:26.673980 13823 sgd_solver.cpp:112] Iteration 309900, lr = 1e-06
I0823 01:25:38.158272 13823 solver.cpp:239] Iteration 310000 (8.70745 iter/s, 11.4844s/100 iters), loss = 0.0251939
I0823 01:25:38.158335 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0251932 (* 1 = 0.0251932 loss)
I0823 01:25:38.158346 13823 sgd_solver.cpp:112] Iteration 310000, lr = 1e-06
I0823 01:25:49.815608 13823 solver.cpp:239] Iteration 310100 (8.57825 iter/s, 11.6574s/100 iters), loss = 0.0304935
I0823 01:25:49.815665 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0304928 (* 1 = 0.0304928 loss)
I0823 01:25:49.815676 13823 sgd_solver.cpp:112] Iteration 310100, lr = 1e-06
I0823 01:26:01.452775 13823 solver.cpp:239] Iteration 310200 (8.59312 iter/s, 11.6372s/100 iters), loss = 0.0249064
I0823 01:26:01.452826 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0249057 (* 1 = 0.0249057 loss)
I0823 01:26:01.452836 13823 sgd_solver.cpp:112] Iteration 310200, lr = 1e-06
I0823 01:26:13.163419 13823 solver.cpp:239] Iteration 310300 (8.5392 iter/s, 11.7107s/100 iters), loss = 0.0327401
I0823 01:26:13.163478 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0327394 (* 1 = 0.0327394 loss)
I0823 01:26:13.163489 13823 sgd_solver.cpp:112] Iteration 310300, lr = 1e-06
I0823 01:26:24.789494 13823 solver.cpp:239] Iteration 310400 (8.60132 iter/s, 11.6261s/100 iters), loss = 0.0272174
I0823 01:26:24.789546 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0272167 (* 1 = 0.0272167 loss)
I0823 01:26:24.789556 13823 sgd_solver.cpp:112] Iteration 310400, lr = 1e-06
I0823 01:26:34.565584 13823 solver.cpp:239] Iteration 310500 (10.229 iter/s, 9.77613s/100 iters), loss = 0.0244988
I0823 01:26:34.565639 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0244981 (* 1 = 0.0244981 loss)
I0823 01:26:34.565649 13823 sgd_solver.cpp:112] Iteration 310500, lr = 1e-06
I0823 01:26:44.283640 13823 solver.cpp:239] Iteration 310600 (10.2901 iter/s, 9.71809s/100 iters), loss = 0.0260448
I0823 01:26:44.283694 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.026044 (* 1 = 0.026044 loss)
I0823 01:26:44.283704 13823 sgd_solver.cpp:112] Iteration 310600, lr = 1e-06
I0823 01:26:53.739396 13823 solver.cpp:239] Iteration 310700 (10.5755 iter/s, 9.45579s/100 iters), loss = 0.025687
I0823 01:26:53.739447 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0256863 (* 1 = 0.0256863 loss)
I0823 01:26:53.739457 13823 sgd_solver.cpp:112] Iteration 310700, lr = 1e-06
I0823 01:27:03.090170 13823 solver.cpp:239] Iteration 310800 (10.6943 iter/s, 9.35081s/100 iters), loss = 0.0289402
I0823 01:27:03.090221 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0289395 (* 1 = 0.0289395 loss)
I0823 01:27:03.090230 13823 sgd_solver.cpp:112] Iteration 310800, lr = 1e-06
I0823 01:27:12.584470 13823 solver.cpp:239] Iteration 310900 (10.5326 iter/s, 9.49433s/100 iters), loss = 0.0287314
I0823 01:27:12.584522 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0287307 (* 1 = 0.0287307 loss)
I0823 01:27:12.584530 13823 sgd_solver.cpp:112] Iteration 310900, lr = 1e-06
I0823 01:27:22.096032 13823 solver.cpp:239] Iteration 311000 (10.5135 iter/s, 9.51159s/100 iters), loss = 0.0253849
I0823 01:27:22.096083 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0253842 (* 1 = 0.0253842 loss)
I0823 01:27:22.096093 13823 sgd_solver.cpp:112] Iteration 311000, lr = 1e-06
I0823 01:27:31.606587 13823 solver.cpp:239] Iteration 311100 (10.5146 iter/s, 9.51059s/100 iters), loss = 0.0254851
I0823 01:27:31.606629 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0254844 (* 1 = 0.0254844 loss)
I0823 01:27:31.606637 13823 sgd_solver.cpp:112] Iteration 311100, lr = 1e-06
I0823 01:27:41.022130 13823 solver.cpp:239] Iteration 311200 (10.6207 iter/s, 9.41558s/100 iters), loss = 0.0265588
I0823 01:27:41.022171 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0265581 (* 1 = 0.0265581 loss)
I0823 01:27:41.022179 13823 sgd_solver.cpp:112] Iteration 311200, lr = 1e-06
I0823 01:27:50.664422 13823 solver.cpp:239] Iteration 311300 (10.3709 iter/s, 9.64233s/100 iters), loss = 0.0264279
I0823 01:27:50.664463 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0264272 (* 1 = 0.0264272 loss)
I0823 01:27:50.664471 13823 sgd_solver.cpp:112] Iteration 311300, lr = 1e-06
I0823 01:28:00.340831 13823 solver.cpp:239] Iteration 311400 (10.3344 iter/s, 9.67645s/100 iters), loss = 0.0353686
I0823 01:28:00.340883 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0353679 (* 1 = 0.0353679 loss)
I0823 01:28:00.340891 13823 sgd_solver.cpp:112] Iteration 311400, lr = 1e-06
I0823 01:28:10.352216 13823 solver.cpp:239] Iteration 311500 (9.9886 iter/s, 10.0114s/100 iters), loss = 0.0240153
I0823 01:28:10.352267 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0240146 (* 1 = 0.0240146 loss)
I0823 01:28:10.352277 13823 sgd_solver.cpp:112] Iteration 311500, lr = 1e-06
I0823 01:28:20.061437 13823 solver.cpp:239] Iteration 311600 (10.2995 iter/s, 9.70925s/100 iters), loss = 0.031327
I0823 01:28:20.061498 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0313263 (* 1 = 0.0313263 loss)
I0823 01:28:20.061511 13823 sgd_solver.cpp:112] Iteration 311600, lr = 1e-06
I0823 01:28:29.621999 13823 solver.cpp:239] Iteration 311700 (10.4596 iter/s, 9.56058s/100 iters), loss = 0.0263227
I0823 01:28:29.622040 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.026322 (* 1 = 0.026322 loss)
I0823 01:28:29.622048 13823 sgd_solver.cpp:112] Iteration 311700, lr = 1e-06
I0823 01:28:39.330787 13823 solver.cpp:239] Iteration 311800 (10.2999 iter/s, 9.70882s/100 iters), loss = 0.0341978
I0823 01:28:39.330850 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0341971 (* 1 = 0.0341971 loss)
I0823 01:28:39.330864 13823 sgd_solver.cpp:112] Iteration 311800, lr = 1e-06
I0823 01:28:49.077529 13823 solver.cpp:239] Iteration 311900 (10.2598 iter/s, 9.74676s/100 iters), loss = 0.0273639
I0823 01:28:49.077589 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0273632 (* 1 = 0.0273632 loss)
I0823 01:28:49.077601 13823 sgd_solver.cpp:112] Iteration 311900, lr = 1e-06
I0823 01:28:58.656839 13823 solver.cpp:239] Iteration 312000 (10.4391 iter/s, 9.57933s/100 iters), loss = 0.0267982
I0823 01:28:58.656890 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0267975 (* 1 = 0.0267975 loss)
I0823 01:28:58.656899 13823 sgd_solver.cpp:112] Iteration 312000, lr = 1e-06
I0823 01:29:08.370728 13823 solver.cpp:239] Iteration 312100 (10.2945 iter/s, 9.71391s/100 iters), loss = 0.0247331
I0823 01:29:08.370787 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0247324 (* 1 = 0.0247324 loss)
I0823 01:29:08.370800 13823 sgd_solver.cpp:112] Iteration 312100, lr = 1e-06
I0823 01:29:18.035610 13823 solver.cpp:239] Iteration 312200 (10.3467 iter/s, 9.6649s/100 iters), loss = 0.0355314
I0823 01:29:18.035662 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0355306 (* 1 = 0.0355306 loss)
I0823 01:29:18.035672 13823 sgd_solver.cpp:112] Iteration 312200, lr = 1e-06
I0823 01:29:27.819007 13823 solver.cpp:239] Iteration 312300 (10.2214 iter/s, 9.78342s/100 iters), loss = 0.0366071
I0823 01:29:27.819061 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0366064 (* 1 = 0.0366064 loss)
I0823 01:29:27.819069 13823 sgd_solver.cpp:112] Iteration 312300, lr = 1e-06
I0823 01:29:37.618844 13823 solver.cpp:239] Iteration 312400 (10.2042 iter/s, 9.79986s/100 iters), loss = 0.0241547
I0823 01:29:37.618894 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.024154 (* 1 = 0.024154 loss)
I0823 01:29:37.618903 13823 sgd_solver.cpp:112] Iteration 312400, lr = 1e-06
I0823 01:29:47.303745 13823 solver.cpp:239] Iteration 312500 (10.3253 iter/s, 9.68492s/100 iters), loss = 0.0315485
I0823 01:29:47.303810 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0315477 (* 1 = 0.0315477 loss)
I0823 01:29:47.303822 13823 sgd_solver.cpp:112] Iteration 312500, lr = 1e-06
I0823 01:29:56.870102 13823 solver.cpp:239] Iteration 312600 (10.4533 iter/s, 9.56637s/100 iters), loss = 0.0282691
I0823 01:29:56.870154 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0282684 (* 1 = 0.0282684 loss)
I0823 01:29:56.870163 13823 sgd_solver.cpp:112] Iteration 312600, lr = 1e-06
I0823 01:30:06.575587 13823 solver.cpp:239] Iteration 312700 (10.3034 iter/s, 9.7055s/100 iters), loss = 0.0380841
I0823 01:30:06.575637 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0380834 (* 1 = 0.0380834 loss)
I0823 01:30:06.575646 13823 sgd_solver.cpp:112] Iteration 312700, lr = 1e-06
I0823 01:30:16.068197 13823 solver.cpp:239] Iteration 312800 (10.5345 iter/s, 9.49263s/100 iters), loss = 0.0284721
I0823 01:30:16.068245 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0284714 (* 1 = 0.0284714 loss)
I0823 01:30:16.068255 13823 sgd_solver.cpp:112] Iteration 312800, lr = 1e-06
I0823 01:30:25.583837 13823 solver.cpp:239] Iteration 312900 (10.509 iter/s, 9.51566s/100 iters), loss = 0.0245644
I0823 01:30:25.583889 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0245637 (* 1 = 0.0245637 loss)
I0823 01:30:25.583897 13823 sgd_solver.cpp:112] Iteration 312900, lr = 1e-06
I0823 01:30:35.085762 13823 solver.cpp:239] Iteration 313000 (10.5242 iter/s, 9.50194s/100 iters), loss = 0.0262706
I0823 01:30:35.085813 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0262699 (* 1 = 0.0262699 loss)
I0823 01:30:35.085824 13823 sgd_solver.cpp:112] Iteration 313000, lr = 1e-06
I0823 01:30:44.914757 13823 solver.cpp:239] Iteration 313100 (10.174 iter/s, 9.82901s/100 iters), loss = 0.0352861
I0823 01:30:44.914808 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0352854 (* 1 = 0.0352854 loss)
I0823 01:30:44.914816 13823 sgd_solver.cpp:112] Iteration 313100, lr = 1e-06
I0823 01:30:54.628746 13823 solver.cpp:239] Iteration 313200 (10.2944 iter/s, 9.71401s/100 iters), loss = 0.0250637
I0823 01:30:54.628798 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0250629 (* 1 = 0.0250629 loss)
I0823 01:30:54.628806 13823 sgd_solver.cpp:112] Iteration 313200, lr = 1e-06
I0823 01:31:04.490119 13823 solver.cpp:239] Iteration 313300 (10.1406 iter/s, 9.86139s/100 iters), loss = 0.0316803
I0823 01:31:04.490180 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0316796 (* 1 = 0.0316796 loss)
I0823 01:31:04.490190 13823 sgd_solver.cpp:112] Iteration 313300, lr = 1e-06
I0823 01:31:14.500897 13823 solver.cpp:239] Iteration 313400 (9.98922 iter/s, 10.0108s/100 iters), loss = 0.0257834
I0823 01:31:14.500949 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0257827 (* 1 = 0.0257827 loss)
I0823 01:31:14.500958 13823 sgd_solver.cpp:112] Iteration 313400, lr = 1e-06
I0823 01:31:24.289633 13823 solver.cpp:239] Iteration 313500 (10.2158 iter/s, 9.78875s/100 iters), loss = 0.0375786
I0823 01:31:24.289685 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0375778 (* 1 = 0.0375778 loss)
I0823 01:31:24.289695 13823 sgd_solver.cpp:112] Iteration 313500, lr = 1e-06
I0823 01:31:34.156692 13823 solver.cpp:239] Iteration 313600 (10.1347 iter/s, 9.86708s/100 iters), loss = 0.0231839
I0823 01:31:34.156733 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0231831 (* 1 = 0.0231831 loss)
I0823 01:31:34.156741 13823 sgd_solver.cpp:112] Iteration 313600, lr = 1e-06
I0823 01:31:43.482719 13823 solver.cpp:239] Iteration 313700 (10.7227 iter/s, 9.32605s/100 iters), loss = 0.0256273
I0823 01:31:43.482765 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0256266 (* 1 = 0.0256266 loss)
I0823 01:31:43.482774 13823 sgd_solver.cpp:112] Iteration 313700, lr = 1e-06
I0823 01:31:53.481102 13823 solver.cpp:239] Iteration 313800 (10.0016 iter/s, 9.9984s/100 iters), loss = 0.0280037
I0823 01:31:53.481153 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.028003 (* 1 = 0.028003 loss)
I0823 01:31:53.481163 13823 sgd_solver.cpp:112] Iteration 313800, lr = 1e-06
I0823 01:32:02.794315 13823 solver.cpp:239] Iteration 313900 (10.7374 iter/s, 9.31322s/100 iters), loss = 0.0339486
I0823 01:32:02.794365 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0339479 (* 1 = 0.0339479 loss)
I0823 01:32:02.794375 13823 sgd_solver.cpp:112] Iteration 313900, lr = 1e-06
I0823 01:32:12.640933 13823 solver.cpp:239] Iteration 314000 (10.1558 iter/s, 9.84663s/100 iters), loss = 0.0339266
I0823 01:32:12.640985 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0339259 (* 1 = 0.0339259 loss)
I0823 01:32:12.640995 13823 sgd_solver.cpp:112] Iteration 314000, lr = 1e-06
I0823 01:32:22.546243 13823 solver.cpp:239] Iteration 314100 (10.0956 iter/s, 9.90532s/100 iters), loss = 0.0288096
I0823 01:32:22.546295 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0288089 (* 1 = 0.0288089 loss)
I0823 01:32:22.546305 13823 sgd_solver.cpp:112] Iteration 314100, lr = 1e-06
I0823 01:32:32.341634 13823 solver.cpp:239] Iteration 314200 (10.2089 iter/s, 9.7954s/100 iters), loss = 0.0376042
I0823 01:32:32.341683 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0376035 (* 1 = 0.0376035 loss)
I0823 01:32:32.341693 13823 sgd_solver.cpp:112] Iteration 314200, lr = 1e-06
I0823 01:32:42.164208 13823 solver.cpp:239] Iteration 314300 (10.1806 iter/s, 9.82259s/100 iters), loss = 0.0254496
I0823 01:32:42.164258 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0254488 (* 1 = 0.0254488 loss)
I0823 01:32:42.164268 13823 sgd_solver.cpp:112] Iteration 314300, lr = 1e-06
I0823 01:32:51.752461 13823 solver.cpp:239] Iteration 314400 (10.4294 iter/s, 9.58826s/100 iters), loss = 0.0327816
I0823 01:32:51.752513 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0327808 (* 1 = 0.0327808 loss)
I0823 01:32:51.752523 13823 sgd_solver.cpp:112] Iteration 314400, lr = 1e-06
I0823 01:33:01.536998 13823 solver.cpp:239] Iteration 314500 (10.2202 iter/s, 9.78454s/100 iters), loss = 0.0274568
I0823 01:33:01.537051 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.027456 (* 1 = 0.027456 loss)
I0823 01:33:01.537061 13823 sgd_solver.cpp:112] Iteration 314500, lr = 1e-06
I0823 01:33:11.507025 13823 solver.cpp:239] Iteration 314600 (10.0301 iter/s, 9.97004s/100 iters), loss = 0.0303466
I0823 01:33:11.507076 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0303458 (* 1 = 0.0303458 loss)
I0823 01:33:11.507084 13823 sgd_solver.cpp:112] Iteration 314600, lr = 1e-06
I0823 01:33:21.400333 13823 solver.cpp:239] Iteration 314700 (10.1078 iter/s, 9.89332s/100 iters), loss = 0.0268381
I0823 01:33:21.400385 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0268373 (* 1 = 0.0268373 loss)
I0823 01:33:21.400395 13823 sgd_solver.cpp:112] Iteration 314700, lr = 1e-06
I0823 01:33:30.904237 13823 solver.cpp:239] Iteration 314800 (10.522 iter/s, 9.50391s/100 iters), loss = 0.0268152
I0823 01:33:30.904291 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0268144 (* 1 = 0.0268144 loss)
I0823 01:33:30.904300 13823 sgd_solver.cpp:112] Iteration 314800, lr = 1e-06
I0823 01:33:40.789098 13823 solver.cpp:239] Iteration 314900 (10.1165 iter/s, 9.88487s/100 iters), loss = 0.0266682
I0823 01:33:40.789149 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0266674 (* 1 = 0.0266674 loss)
I0823 01:33:40.789160 13823 sgd_solver.cpp:112] Iteration 314900, lr = 1e-06
I0823 01:33:50.543236 13823 solver.cpp:239] Iteration 315000 (10.2521 iter/s, 9.75414s/100 iters), loss = 0.0275728
I0823 01:33:50.543287 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.027572 (* 1 = 0.027572 loss)
I0823 01:33:50.543296 13823 sgd_solver.cpp:112] Iteration 315000, lr = 1e-06
I0823 01:34:00.257606 13823 solver.cpp:239] Iteration 315100 (10.294 iter/s, 9.71438s/100 iters), loss = 0.0279371
I0823 01:34:00.257649 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0279363 (* 1 = 0.0279363 loss)
I0823 01:34:00.257658 13823 sgd_solver.cpp:112] Iteration 315100, lr = 1e-06
I0823 01:34:09.799866 13823 solver.cpp:239] Iteration 315200 (10.4797 iter/s, 9.54227s/100 iters), loss = 0.0348542
I0823 01:34:09.799917 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0348534 (* 1 = 0.0348534 loss)
I0823 01:34:09.799927 13823 sgd_solver.cpp:112] Iteration 315200, lr = 1e-06
I0823 01:34:19.974144 13823 solver.cpp:239] Iteration 315300 (9.8287 iter/s, 10.1743s/100 iters), loss = 0.0283151
I0823 01:34:19.974195 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0283143 (* 1 = 0.0283143 loss)
I0823 01:34:19.974205 13823 sgd_solver.cpp:112] Iteration 315300, lr = 1e-06
I0823 01:34:30.067840 13823 solver.cpp:239] Iteration 315400 (9.90716 iter/s, 10.0937s/100 iters), loss = 0.0562899
I0823 01:34:30.067889 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0562891 (* 1 = 0.0562891 loss)
I0823 01:34:30.067898 13823 sgd_solver.cpp:112] Iteration 315400, lr = 1e-06
I0823 01:34:39.861969 13823 solver.cpp:239] Iteration 315500 (10.2102 iter/s, 9.79414s/100 iters), loss = 0.0254031
I0823 01:34:39.862021 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0254023 (* 1 = 0.0254023 loss)
I0823 01:34:39.862031 13823 sgd_solver.cpp:112] Iteration 315500, lr = 1e-06
I0823 01:34:49.840351 13823 solver.cpp:239] Iteration 315600 (10.0217 iter/s, 9.97839s/100 iters), loss = 0.0256886
I0823 01:34:49.840402 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0256878 (* 1 = 0.0256878 loss)
I0823 01:34:49.840412 13823 sgd_solver.cpp:112] Iteration 315600, lr = 1e-06
I0823 01:34:59.787259 13823 solver.cpp:239] Iteration 315700 (10.0534 iter/s, 9.94692s/100 iters), loss = 0.242633
I0823 01:34:59.787300 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.242632 (* 1 = 0.242632 loss)
I0823 01:34:59.787307 13823 sgd_solver.cpp:112] Iteration 315700, lr = 1e-06
I0823 01:35:09.474382 13823 solver.cpp:239] Iteration 315800 (10.323 iter/s, 9.68714s/100 iters), loss = 0.0307043
I0823 01:35:09.474431 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0307035 (* 1 = 0.0307035 loss)
I0823 01:35:09.474440 13823 sgd_solver.cpp:112] Iteration 315800, lr = 1e-06
I0823 01:35:19.205852 13823 solver.cpp:239] Iteration 315900 (10.2759 iter/s, 9.73148s/100 iters), loss = 0.031586
I0823 01:35:19.205904 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0315852 (* 1 = 0.0315852 loss)
I0823 01:35:19.205914 13823 sgd_solver.cpp:112] Iteration 315900, lr = 1e-06
I0823 01:35:28.988741 13823 solver.cpp:239] Iteration 316000 (10.2219 iter/s, 9.78289s/100 iters), loss = 0.0242047
I0823 01:35:28.988793 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0242039 (* 1 = 0.0242039 loss)
I0823 01:35:28.988803 13823 sgd_solver.cpp:112] Iteration 316000, lr = 1e-06
I0823 01:35:38.750109 13823 solver.cpp:239] Iteration 316100 (10.2445 iter/s, 9.76138s/100 iters), loss = 0.0283826
I0823 01:35:38.750150 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0283818 (* 1 = 0.0283818 loss)
I0823 01:35:38.750157 13823 sgd_solver.cpp:112] Iteration 316100, lr = 1e-06
I0823 01:35:48.563547 13823 solver.cpp:239] Iteration 316200 (10.1901 iter/s, 9.81345s/100 iters), loss = 0.0245139
I0823 01:35:48.563598 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.024513 (* 1 = 0.024513 loss)
I0823 01:35:48.563608 13823 sgd_solver.cpp:112] Iteration 316200, lr = 1e-06
I0823 01:35:58.359535 13823 solver.cpp:239] Iteration 316300 (10.2083 iter/s, 9.79599s/100 iters), loss = 0.0326383
I0823 01:35:58.359596 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0326374 (* 1 = 0.0326374 loss)
I0823 01:35:58.359606 13823 sgd_solver.cpp:112] Iteration 316300, lr = 1e-06
I0823 01:36:07.699820 13823 solver.cpp:239] Iteration 316400 (10.7063 iter/s, 9.34028s/100 iters), loss = 0.0238737
I0823 01:36:07.699862 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0238729 (* 1 = 0.0238729 loss)
I0823 01:36:07.699869 13823 sgd_solver.cpp:112] Iteration 316400, lr = 1e-06
I0823 01:36:17.659647 13823 solver.cpp:239] Iteration 316500 (10.0403 iter/s, 9.95984s/100 iters), loss = 0.0276689
I0823 01:36:17.659696 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.027668 (* 1 = 0.027668 loss)
I0823 01:36:17.659704 13823 sgd_solver.cpp:112] Iteration 316500, lr = 1e-06
I0823 01:36:27.590451 13823 solver.cpp:239] Iteration 316600 (10.0697 iter/s, 9.93081s/100 iters), loss = 0.0368355
I0823 01:36:27.590502 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0368346 (* 1 = 0.0368346 loss)
I0823 01:36:27.590512 13823 sgd_solver.cpp:112] Iteration 316600, lr = 1e-06
I0823 01:36:37.724150 13823 solver.cpp:239] Iteration 316700 (9.86806 iter/s, 10.1337s/100 iters), loss = 0.0290487
I0823 01:36:37.724200 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0290479 (* 1 = 0.0290479 loss)
I0823 01:36:37.724210 13823 sgd_solver.cpp:112] Iteration 316700, lr = 1e-06
I0823 01:36:47.560742 13823 solver.cpp:239] Iteration 316800 (10.1661 iter/s, 9.83659s/100 iters), loss = 0.0256731
I0823 01:36:47.560803 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0256722 (* 1 = 0.0256722 loss)
I0823 01:36:47.560815 13823 sgd_solver.cpp:112] Iteration 316800, lr = 1e-06
I0823 01:36:57.251838 13823 solver.cpp:239] Iteration 316900 (10.3188 iter/s, 9.69109s/100 iters), loss = 0.0232459
I0823 01:36:57.251878 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.023245 (* 1 = 0.023245 loss)
I0823 01:36:57.251885 13823 sgd_solver.cpp:112] Iteration 316900, lr = 1e-06
I0823 01:37:07.106637 13823 solver.cpp:239] Iteration 317000 (10.1473 iter/s, 9.85481s/100 iters), loss = 0.0242027
I0823 01:37:07.106689 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0242019 (* 1 = 0.0242019 loss)
I0823 01:37:07.106698 13823 sgd_solver.cpp:112] Iteration 317000, lr = 1e-06
I0823 01:37:17.177673 13823 solver.cpp:239] Iteration 317100 (9.92946 iter/s, 10.071s/100 iters), loss = 0.0318257
I0823 01:37:17.177724 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0318249 (* 1 = 0.0318249 loss)
I0823 01:37:17.177733 13823 sgd_solver.cpp:112] Iteration 317100, lr = 1e-06
I0823 01:37:27.025467 13823 solver.cpp:239] Iteration 317200 (10.1546 iter/s, 9.8478s/100 iters), loss = 0.0718961
I0823 01:37:27.025516 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0718953 (* 1 = 0.0718953 loss)
I0823 01:37:27.025526 13823 sgd_solver.cpp:112] Iteration 317200, lr = 1e-06
I0823 01:37:36.940356 13823 solver.cpp:239] Iteration 317300 (10.0858 iter/s, 9.91489s/100 iters), loss = 0.0261231
I0823 01:37:36.940405 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0261223 (* 1 = 0.0261223 loss)
I0823 01:37:36.940414 13823 sgd_solver.cpp:112] Iteration 317300, lr = 1e-06
I0823 01:37:46.926623 13823 solver.cpp:239] Iteration 317400 (10.0137 iter/s, 9.98627s/100 iters), loss = 0.0266015
I0823 01:37:46.926674 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0266007 (* 1 = 0.0266007 loss)
I0823 01:37:46.926684 13823 sgd_solver.cpp:112] Iteration 317400, lr = 1e-06
I0823 01:37:57.024513 13823 solver.cpp:239] Iteration 317500 (9.90306 iter/s, 10.0979s/100 iters), loss = 0.032013
I0823 01:37:57.024581 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0320121 (* 1 = 0.0320121 loss)
I0823 01:37:57.024595 13823 sgd_solver.cpp:112] Iteration 317500, lr = 1e-06
I0823 01:38:07.315212 13823 solver.cpp:239] Iteration 317600 (9.71752 iter/s, 10.2907s/100 iters), loss = 0.0273726
I0823 01:38:07.315261 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0273718 (* 1 = 0.0273718 loss)
I0823 01:38:07.315271 13823 sgd_solver.cpp:112] Iteration 317600, lr = 1e-06
I0823 01:38:17.394703 13823 solver.cpp:239] Iteration 317700 (9.92113 iter/s, 10.0795s/100 iters), loss = 0.0315189
I0823 01:38:17.394755 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.031518 (* 1 = 0.031518 loss)
I0823 01:38:17.394764 13823 sgd_solver.cpp:112] Iteration 317700, lr = 1e-06
I0823 01:38:27.665901 13823 solver.cpp:239] Iteration 317800 (9.73596 iter/s, 10.2712s/100 iters), loss = 0.0343936
I0823 01:38:27.665963 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0343927 (* 1 = 0.0343927 loss)
I0823 01:38:27.665976 13823 sgd_solver.cpp:112] Iteration 317800, lr = 1e-06
I0823 01:38:37.776417 13823 solver.cpp:239] Iteration 317900 (9.8907 iter/s, 10.1105s/100 iters), loss = 0.0293489
I0823 01:38:37.776476 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0293481 (* 1 = 0.0293481 loss)
I0823 01:38:37.776487 13823 sgd_solver.cpp:112] Iteration 317900, lr = 1e-06
I0823 01:38:47.983243 13823 solver.cpp:239] Iteration 318000 (9.79737 iter/s, 10.2068s/100 iters), loss = 0.0247114
I0823 01:38:47.983294 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0247106 (* 1 = 0.0247106 loss)
I0823 01:38:47.983302 13823 sgd_solver.cpp:112] Iteration 318000, lr = 1e-06
I0823 01:38:58.090297 13823 solver.cpp:239] Iteration 318100 (9.89408 iter/s, 10.1071s/100 iters), loss = 0.0279918
I0823 01:38:58.090349 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0279909 (* 1 = 0.0279909 loss)
I0823 01:38:58.090359 13823 sgd_solver.cpp:112] Iteration 318100, lr = 1e-06
I0823 01:39:08.351241 13823 solver.cpp:239] Iteration 318200 (9.74569 iter/s, 10.2609s/100 iters), loss = 0.0250372
I0823 01:39:08.351296 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0250364 (* 1 = 0.0250364 loss)
I0823 01:39:08.351306 13823 sgd_solver.cpp:112] Iteration 318200, lr = 1e-06
I0823 01:39:18.469226 13823 solver.cpp:239] Iteration 318300 (9.88339 iter/s, 10.118s/100 iters), loss = 0.0252463
I0823 01:39:18.469276 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0252455 (* 1 = 0.0252455 loss)
I0823 01:39:18.469285 13823 sgd_solver.cpp:112] Iteration 318300, lr = 1e-06
I0823 01:39:28.603493 13823 solver.cpp:239] Iteration 318400 (9.86751 iter/s, 10.1343s/100 iters), loss = 0.0240952
I0823 01:39:28.603549 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0240943 (* 1 = 0.0240943 loss)
I0823 01:39:28.603560 13823 sgd_solver.cpp:112] Iteration 318400, lr = 1e-06
I0823 01:39:38.522167 13823 solver.cpp:239] Iteration 318500 (10.082 iter/s, 9.91867s/100 iters), loss = 0.05079
I0823 01:39:38.522220 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0507891 (* 1 = 0.0507891 loss)
I0823 01:39:38.522230 13823 sgd_solver.cpp:112] Iteration 318500, lr = 1e-06
I0823 01:39:48.665232 13823 solver.cpp:239] Iteration 318600 (9.85896 iter/s, 10.1431s/100 iters), loss = 0.0294992
I0823 01:39:48.665282 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0294984 (* 1 = 0.0294984 loss)
I0823 01:39:48.665292 13823 sgd_solver.cpp:112] Iteration 318600, lr = 1e-06
I0823 01:39:58.530499 13823 solver.cpp:239] Iteration 318700 (10.1366 iter/s, 9.86526s/100 iters), loss = 0.0262076
I0823 01:39:58.530548 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0262067 (* 1 = 0.0262067 loss)
I0823 01:39:58.530557 13823 sgd_solver.cpp:112] Iteration 318700, lr = 1e-06
I0823 01:40:08.832008 13823 solver.cpp:239] Iteration 318800 (9.70731 iter/s, 10.3015s/100 iters), loss = 0.0267442
I0823 01:40:08.832057 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0267434 (* 1 = 0.0267434 loss)
I0823 01:40:08.832067 13823 sgd_solver.cpp:112] Iteration 318800, lr = 1e-06
I0823 01:40:18.990401 13823 solver.cpp:239] Iteration 318900 (9.84408 iter/s, 10.1584s/100 iters), loss = 0.0269732
I0823 01:40:18.990458 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0269724 (* 1 = 0.0269724 loss)
I0823 01:40:18.990468 13823 sgd_solver.cpp:112] Iteration 318900, lr = 1e-06
I0823 01:40:29.174360 13823 solver.cpp:239] Iteration 319000 (9.81937 iter/s, 10.184s/100 iters), loss = 0.028085
I0823 01:40:29.174412 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0280842 (* 1 = 0.0280842 loss)
I0823 01:40:29.174422 13823 sgd_solver.cpp:112] Iteration 319000, lr = 1e-06
I0823 01:40:39.716586 13823 solver.cpp:239] Iteration 319100 (9.48566 iter/s, 10.5422s/100 iters), loss = 0.02997
I0823 01:40:39.716636 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0299692 (* 1 = 0.0299692 loss)
I0823 01:40:39.716645 13823 sgd_solver.cpp:112] Iteration 319100, lr = 1e-06
I0823 01:40:49.955106 13823 solver.cpp:239] Iteration 319200 (9.76704 iter/s, 10.2385s/100 iters), loss = 0.0234881
I0823 01:40:49.955157 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0234873 (* 1 = 0.0234873 loss)
I0823 01:40:49.955168 13823 sgd_solver.cpp:112] Iteration 319200, lr = 1e-06
I0823 01:41:00.372503 13823 solver.cpp:239] Iteration 319300 (9.59933 iter/s, 10.4174s/100 iters), loss = 0.0255841
I0823 01:41:00.372551 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0255833 (* 1 = 0.0255833 loss)
I0823 01:41:00.372560 13823 sgd_solver.cpp:112] Iteration 319300, lr = 1e-06
I0823 01:41:10.702939 13823 solver.cpp:239] Iteration 319400 (9.68013 iter/s, 10.3304s/100 iters), loss = 0.0250423
I0823 01:41:10.702993 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0250414 (* 1 = 0.0250414 loss)
I0823 01:41:10.703004 13823 sgd_solver.cpp:112] Iteration 319400, lr = 1e-06
I0823 01:41:21.095522 13823 solver.cpp:239] Iteration 319500 (9.62225 iter/s, 10.3926s/100 iters), loss = 0.0305179
I0823 01:41:21.095571 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0305171 (* 1 = 0.0305171 loss)
I0823 01:41:21.095582 13823 sgd_solver.cpp:112] Iteration 319500, lr = 1e-06
I0823 01:41:31.512385 13823 solver.cpp:239] Iteration 319600 (9.59982 iter/s, 10.4169s/100 iters), loss = 0.0278535
I0823 01:41:31.512449 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0278527 (* 1 = 0.0278527 loss)
I0823 01:41:31.512459 13823 sgd_solver.cpp:112] Iteration 319600, lr = 1e-06
I0823 01:41:41.807910 13823 solver.cpp:239] Iteration 319700 (9.71297 iter/s, 10.2955s/100 iters), loss = 0.0386643
I0823 01:41:41.807962 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0386635 (* 1 = 0.0386635 loss)
I0823 01:41:41.807972 13823 sgd_solver.cpp:112] Iteration 319700, lr = 1e-06
I0823 01:41:52.143328 13823 solver.cpp:239] Iteration 319800 (9.67547 iter/s, 10.3354s/100 iters), loss = 0.0311813
I0823 01:41:52.143389 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0311805 (* 1 = 0.0311805 loss)
I0823 01:41:52.143401 13823 sgd_solver.cpp:112] Iteration 319800, lr = 1e-06
I0823 01:42:02.446887 13823 solver.cpp:239] Iteration 319900 (9.70539 iter/s, 10.3035s/100 iters), loss = 0.0266931
I0823 01:42:02.446938 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0266923 (* 1 = 0.0266923 loss)
I0823 01:42:02.446949 13823 sgd_solver.cpp:112] Iteration 319900, lr = 1e-06
I0823 01:42:12.815555 13823 solver.cpp:464] Snapshotting to binary proto file ./model_112/cascade_mobilenet_112_iter_320000.caffemodel
I0823 01:42:12.858644 13823 sgd_solver.cpp:284] Snapshotting solver state to binary proto file ./model_112/cascade_mobilenet_112_iter_320000.solverstate
I0823 01:42:12.889727 13823 solver.cpp:347] Iteration 320000, Testing net (#0)
I0823 01:43:25.182785 13823 solver.cpp:414]     Test net output #0: landmark_loss = 0.0219925 (* 1 = 0.0219925 loss)
I0823 01:43:25.295182 13823 solver.cpp:239] Iteration 320000 (1.20702 iter/s, 82.8484s/100 iters), loss = 0.0252359
I0823 01:43:25.295220 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0252351 (* 1 = 0.0252351 loss)
I0823 01:43:25.295229 13823 sgd_solver.cpp:112] Iteration 320000, lr = 1e-06
I0823 01:43:35.770577 13823 solver.cpp:239] Iteration 320100 (9.54652 iter/s, 10.475s/100 iters), loss = 0.0237827
I0823 01:43:35.770627 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0237819 (* 1 = 0.0237819 loss)
I0823 01:43:35.770635 13823 sgd_solver.cpp:112] Iteration 320100, lr = 1e-06
I0823 01:43:46.597158 13823 solver.cpp:239] Iteration 320200 (9.23686 iter/s, 10.8262s/100 iters), loss = 0.0242948
I0823 01:43:46.597214 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0242939 (* 1 = 0.0242939 loss)
I0823 01:43:46.597225 13823 sgd_solver.cpp:112] Iteration 320200, lr = 1e-06
I0823 01:43:57.120884 13823 solver.cpp:239] Iteration 320300 (9.50268 iter/s, 10.5233s/100 iters), loss = 0.0295716
I0823 01:43:57.120934 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0295708 (* 1 = 0.0295708 loss)
I0823 01:43:57.120944 13823 sgd_solver.cpp:112] Iteration 320300, lr = 1e-06
I0823 01:44:07.856212 13823 solver.cpp:239] Iteration 320400 (9.31536 iter/s, 10.735s/100 iters), loss = 0.0233802
I0823 01:44:07.856274 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0233794 (* 1 = 0.0233794 loss)
I0823 01:44:07.856287 13823 sgd_solver.cpp:112] Iteration 320400, lr = 1e-06
I0823 01:44:18.970690 13823 solver.cpp:239] Iteration 320500 (8.99759 iter/s, 11.1141s/100 iters), loss = 0.0249589
I0823 01:44:18.970741 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.024958 (* 1 = 0.024958 loss)
I0823 01:44:18.970749 13823 sgd_solver.cpp:112] Iteration 320500, lr = 1e-06
I0823 01:44:29.887481 13823 solver.cpp:239] Iteration 320600 (9.16051 iter/s, 10.9164s/100 iters), loss = 0.025639
I0823 01:44:29.887537 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0256382 (* 1 = 0.0256382 loss)
I0823 01:44:29.887547 13823 sgd_solver.cpp:112] Iteration 320600, lr = 1e-06
I0823 01:44:40.865283 13823 solver.cpp:239] Iteration 320700 (9.10959 iter/s, 10.9774s/100 iters), loss = 0.0242443
I0823 01:44:40.865342 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0242435 (* 1 = 0.0242435 loss)
I0823 01:44:40.865355 13823 sgd_solver.cpp:112] Iteration 320700, lr = 1e-06
I0823 01:44:51.828613 13823 solver.cpp:239] Iteration 320800 (9.12162 iter/s, 10.963s/100 iters), loss = 0.0432949
I0823 01:44:51.828668 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0432941 (* 1 = 0.0432941 loss)
I0823 01:44:51.828680 13823 sgd_solver.cpp:112] Iteration 320800, lr = 1e-06
I0823 01:45:02.896092 13823 solver.cpp:239] Iteration 320900 (9.03577 iter/s, 11.0671s/100 iters), loss = 0.0247012
I0823 01:45:02.896145 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0247004 (* 1 = 0.0247004 loss)
I0823 01:45:02.896155 13823 sgd_solver.cpp:112] Iteration 320900, lr = 1e-06
I0823 01:45:13.701313 13823 solver.cpp:239] Iteration 321000 (9.25507 iter/s, 10.8049s/100 iters), loss = 0.0245417
I0823 01:45:13.701365 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0245409 (* 1 = 0.0245409 loss)
I0823 01:45:13.701375 13823 sgd_solver.cpp:112] Iteration 321000, lr = 1e-06
I0823 01:45:24.613468 13823 solver.cpp:239] Iteration 321100 (9.16437 iter/s, 10.9118s/100 iters), loss = 0.0287755
I0823 01:45:24.613518 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0287747 (* 1 = 0.0287747 loss)
I0823 01:45:24.613528 13823 sgd_solver.cpp:112] Iteration 321100, lr = 1e-06
I0823 01:45:35.678673 13823 solver.cpp:239] Iteration 321200 (9.03761 iter/s, 11.0649s/100 iters), loss = 0.0334709
I0823 01:45:35.678723 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0334701 (* 1 = 0.0334701 loss)
I0823 01:45:35.678732 13823 sgd_solver.cpp:112] Iteration 321200, lr = 1e-06
I0823 01:45:46.513136 13823 solver.cpp:239] Iteration 321300 (9.23008 iter/s, 10.8341s/100 iters), loss = 0.0259669
I0823 01:45:46.513190 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0259661 (* 1 = 0.0259661 loss)
I0823 01:45:46.513200 13823 sgd_solver.cpp:112] Iteration 321300, lr = 1e-06
I0823 01:45:57.463696 13823 solver.cpp:239] Iteration 321400 (9.13222 iter/s, 10.9502s/100 iters), loss = 0.0274035
I0823 01:45:57.463752 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0274027 (* 1 = 0.0274027 loss)
I0823 01:45:57.463762 13823 sgd_solver.cpp:112] Iteration 321400, lr = 1e-06
I0823 01:46:08.493816 13823 solver.cpp:239] Iteration 321500 (9.06635 iter/s, 11.0298s/100 iters), loss = 0.0350699
I0823 01:46:08.493876 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0350691 (* 1 = 0.0350691 loss)
I0823 01:46:08.493888 13823 sgd_solver.cpp:112] Iteration 321500, lr = 1e-06
I0823 01:46:19.551393 13823 solver.cpp:239] Iteration 321600 (9.04383 iter/s, 11.0573s/100 iters), loss = 0.0284444
I0823 01:46:19.551451 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0284436 (* 1 = 0.0284436 loss)
I0823 01:46:19.551462 13823 sgd_solver.cpp:112] Iteration 321600, lr = 1e-06
I0823 01:46:30.388978 13823 solver.cpp:239] Iteration 321700 (9.22741 iter/s, 10.8373s/100 iters), loss = 0.0267362
I0823 01:46:30.389036 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0267354 (* 1 = 0.0267354 loss)
I0823 01:46:30.389046 13823 sgd_solver.cpp:112] Iteration 321700, lr = 1e-06
I0823 01:46:41.279641 13823 solver.cpp:239] Iteration 321800 (9.18243 iter/s, 10.8904s/100 iters), loss = 0.0290293
I0823 01:46:41.279700 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0290284 (* 1 = 0.0290284 loss)
I0823 01:46:41.279712 13823 sgd_solver.cpp:112] Iteration 321800, lr = 1e-06
I0823 01:46:52.339737 13823 solver.cpp:239] Iteration 321900 (9.04176 iter/s, 11.0598s/100 iters), loss = 0.0334823
I0823 01:46:52.339808 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0334814 (* 1 = 0.0334814 loss)
I0823 01:46:52.339826 13823 sgd_solver.cpp:112] Iteration 321900, lr = 1e-06
I0823 01:47:03.280552 13823 solver.cpp:239] Iteration 322000 (9.14034 iter/s, 10.9405s/100 iters), loss = 0.0274939
I0823 01:47:03.280608 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0274931 (* 1 = 0.0274931 loss)
I0823 01:47:03.280622 13823 sgd_solver.cpp:112] Iteration 322000, lr = 1e-06
I0823 01:47:14.493854 13823 solver.cpp:239] Iteration 322100 (8.91821 iter/s, 11.213s/100 iters), loss = 0.0290079
I0823 01:47:14.493912 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0290071 (* 1 = 0.0290071 loss)
I0823 01:47:14.493923 13823 sgd_solver.cpp:112] Iteration 322100, lr = 1e-06
I0823 01:47:25.547050 13823 solver.cpp:239] Iteration 322200 (9.04739 iter/s, 11.0529s/100 iters), loss = 0.0228337
I0823 01:47:25.547103 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0228329 (* 1 = 0.0228329 loss)
I0823 01:47:25.547113 13823 sgd_solver.cpp:112] Iteration 322200, lr = 1e-06
I0823 01:47:36.577327 13823 solver.cpp:239] Iteration 322300 (9.06618 iter/s, 11.03s/100 iters), loss = 0.025876
I0823 01:47:36.577378 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0258752 (* 1 = 0.0258752 loss)
I0823 01:47:36.577388 13823 sgd_solver.cpp:112] Iteration 322300, lr = 1e-06
I0823 01:47:47.528213 13823 solver.cpp:239] Iteration 322400 (9.1319 iter/s, 10.9506s/100 iters), loss = 0.0266015
I0823 01:47:47.528270 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0266007 (* 1 = 0.0266007 loss)
I0823 01:47:47.528280 13823 sgd_solver.cpp:112] Iteration 322400, lr = 1e-06
I0823 01:47:58.698612 13823 solver.cpp:239] Iteration 322500 (8.95245 iter/s, 11.1701s/100 iters), loss = 0.023883
I0823 01:47:58.698671 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0238822 (* 1 = 0.0238822 loss)
I0823 01:47:58.698684 13823 sgd_solver.cpp:112] Iteration 322500, lr = 1e-06
I0823 01:48:09.981482 13823 solver.cpp:239] Iteration 322600 (8.8632 iter/s, 11.2826s/100 iters), loss = 0.02545
I0823 01:48:09.981539 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0254492 (* 1 = 0.0254492 loss)
I0823 01:48:09.981550 13823 sgd_solver.cpp:112] Iteration 322600, lr = 1e-06
I0823 01:48:21.247092 13823 solver.cpp:239] Iteration 322700 (8.87678 iter/s, 11.2653s/100 iters), loss = 0.0244058
I0823 01:48:21.247153 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.024405 (* 1 = 0.024405 loss)
I0823 01:48:21.247165 13823 sgd_solver.cpp:112] Iteration 322700, lr = 1e-06
I0823 01:48:32.369565 13823 solver.cpp:239] Iteration 322800 (8.99101 iter/s, 11.1222s/100 iters), loss = 0.0233885
I0823 01:48:32.369623 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0233877 (* 1 = 0.0233877 loss)
I0823 01:48:32.369637 13823 sgd_solver.cpp:112] Iteration 322800, lr = 1e-06
I0823 01:48:43.747516 13823 solver.cpp:239] Iteration 322900 (8.78913 iter/s, 11.3777s/100 iters), loss = 0.0235757
I0823 01:48:43.747577 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0235749 (* 1 = 0.0235749 loss)
I0823 01:48:43.747589 13823 sgd_solver.cpp:112] Iteration 322900, lr = 1e-06
I0823 01:48:54.572147 13823 solver.cpp:239] Iteration 323000 (9.2384 iter/s, 10.8244s/100 iters), loss = 0.029275
I0823 01:48:54.572198 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0292741 (* 1 = 0.0292741 loss)
I0823 01:48:54.572207 13823 sgd_solver.cpp:112] Iteration 323000, lr = 1e-06
I0823 01:49:05.691247 13823 solver.cpp:239] Iteration 323100 (8.99373 iter/s, 11.1189s/100 iters), loss = 0.0294782
I0823 01:49:05.691298 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0294774 (* 1 = 0.0294774 loss)
I0823 01:49:05.691308 13823 sgd_solver.cpp:112] Iteration 323100, lr = 1e-06
I0823 01:49:16.759141 13823 solver.cpp:239] Iteration 323200 (9.03533 iter/s, 11.0677s/100 iters), loss = 0.0281747
I0823 01:49:16.759202 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0281739 (* 1 = 0.0281739 loss)
I0823 01:49:16.759214 13823 sgd_solver.cpp:112] Iteration 323200, lr = 1e-06
I0823 01:49:27.604108 13823 solver.cpp:239] Iteration 323300 (9.22107 iter/s, 10.8447s/100 iters), loss = 0.0281985
I0823 01:49:27.604163 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0281977 (* 1 = 0.0281977 loss)
I0823 01:49:27.604173 13823 sgd_solver.cpp:112] Iteration 323300, lr = 1e-06
I0823 01:49:38.866307 13823 solver.cpp:239] Iteration 323400 (8.87944 iter/s, 11.262s/100 iters), loss = 0.0368774
I0823 01:49:38.866358 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0368766 (* 1 = 0.0368766 loss)
I0823 01:49:38.866366 13823 sgd_solver.cpp:112] Iteration 323400, lr = 1e-06
I0823 01:49:49.699940 13823 solver.cpp:239] Iteration 323500 (9.2307 iter/s, 10.8334s/100 iters), loss = 0.0241531
I0823 01:49:49.699998 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0241523 (* 1 = 0.0241523 loss)
I0823 01:49:49.700011 13823 sgd_solver.cpp:112] Iteration 323500, lr = 1e-06
I0823 01:50:00.864522 13823 solver.cpp:239] Iteration 323600 (8.95708 iter/s, 11.1644s/100 iters), loss = 0.0347964
I0823 01:50:00.864583 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0347956 (* 1 = 0.0347956 loss)
I0823 01:50:00.864595 13823 sgd_solver.cpp:112] Iteration 323600, lr = 1e-06
I0823 01:50:12.145602 13823 solver.cpp:239] Iteration 323700 (8.86458 iter/s, 11.2809s/100 iters), loss = 0.0256863
I0823 01:50:12.145654 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0256854 (* 1 = 0.0256854 loss)
I0823 01:50:12.145664 13823 sgd_solver.cpp:112] Iteration 323700, lr = 1e-06
I0823 01:50:23.472831 13823 solver.cpp:239] Iteration 323800 (8.82845 iter/s, 11.327s/100 iters), loss = 0.0240576
I0823 01:50:23.472885 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0240568 (* 1 = 0.0240568 loss)
I0823 01:50:23.472895 13823 sgd_solver.cpp:112] Iteration 323800, lr = 1e-06
I0823 01:50:34.382138 13823 solver.cpp:239] Iteration 323900 (9.16666 iter/s, 10.9091s/100 iters), loss = 0.0281171
I0823 01:50:34.382189 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0281163 (* 1 = 0.0281163 loss)
I0823 01:50:34.382197 13823 sgd_solver.cpp:112] Iteration 323900, lr = 1e-06
I0823 01:50:45.586884 13823 solver.cpp:239] Iteration 324000 (8.92495 iter/s, 11.2045s/100 iters), loss = 0.0272486
I0823 01:50:45.586936 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0272478 (* 1 = 0.0272478 loss)
I0823 01:50:45.586946 13823 sgd_solver.cpp:112] Iteration 324000, lr = 1e-06
I0823 01:50:56.830549 13823 solver.cpp:239] Iteration 324100 (8.89406 iter/s, 11.2435s/100 iters), loss = 0.0254177
I0823 01:50:56.830606 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0254169 (* 1 = 0.0254169 loss)
I0823 01:50:56.830617 13823 sgd_solver.cpp:112] Iteration 324100, lr = 1e-06
I0823 01:51:07.765211 13823 solver.cpp:239] Iteration 324200 (9.1454 iter/s, 10.9345s/100 iters), loss = 0.190618
I0823 01:51:07.765269 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.190618 (* 1 = 0.190618 loss)
I0823 01:51:07.765280 13823 sgd_solver.cpp:112] Iteration 324200, lr = 1e-06
I0823 01:51:19.144646 13823 solver.cpp:239] Iteration 324300 (8.78794 iter/s, 11.3792s/100 iters), loss = 0.0275387
I0823 01:51:19.144709 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0275379 (* 1 = 0.0275379 loss)
I0823 01:51:19.144722 13823 sgd_solver.cpp:112] Iteration 324300, lr = 1e-06
I0823 01:51:30.313125 13823 solver.cpp:239] Iteration 324400 (8.95393 iter/s, 11.1683s/100 iters), loss = 0.026455
I0823 01:51:30.313176 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0264542 (* 1 = 0.0264542 loss)
I0823 01:51:30.313186 13823 sgd_solver.cpp:112] Iteration 324400, lr = 1e-06
I0823 01:51:41.593847 13823 solver.cpp:239] Iteration 324500 (8.86483 iter/s, 11.2805s/100 iters), loss = 0.0237719
I0823 01:51:41.593900 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0237711 (* 1 = 0.0237711 loss)
I0823 01:51:41.593911 13823 sgd_solver.cpp:112] Iteration 324500, lr = 1e-06
I0823 01:51:52.781967 13823 solver.cpp:239] Iteration 324600 (8.9382 iter/s, 11.1879s/100 iters), loss = 0.0238752
I0823 01:51:52.782016 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0238744 (* 1 = 0.0238744 loss)
I0823 01:51:52.782027 13823 sgd_solver.cpp:112] Iteration 324600, lr = 1e-06
I0823 01:52:04.053906 13823 solver.cpp:239] Iteration 324700 (8.87173 iter/s, 11.2718s/100 iters), loss = 0.0470453
I0823 01:52:04.053970 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0470445 (* 1 = 0.0470445 loss)
I0823 01:52:04.053983 13823 sgd_solver.cpp:112] Iteration 324700, lr = 1e-06
I0823 01:52:15.318127 13823 solver.cpp:239] Iteration 324800 (8.87782 iter/s, 11.264s/100 iters), loss = 0.0279377
I0823 01:52:15.318179 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0279369 (* 1 = 0.0279369 loss)
I0823 01:52:15.318188 13823 sgd_solver.cpp:112] Iteration 324800, lr = 1e-06
I0823 01:52:26.757540 13823 solver.cpp:239] Iteration 324900 (8.74184 iter/s, 11.4392s/100 iters), loss = 0.024967
I0823 01:52:26.757602 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0249662 (* 1 = 0.0249662 loss)
I0823 01:52:26.757611 13823 sgd_solver.cpp:112] Iteration 324900, lr = 1e-06
I0823 01:52:37.851754 13823 solver.cpp:239] Iteration 325000 (9.01386 iter/s, 11.094s/100 iters), loss = 0.0239209
I0823 01:52:37.851804 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0239201 (* 1 = 0.0239201 loss)
I0823 01:52:37.851811 13823 sgd_solver.cpp:112] Iteration 325000, lr = 1e-06
I0823 01:52:49.354128 13823 solver.cpp:239] Iteration 325100 (8.69399 iter/s, 11.5022s/100 iters), loss = 0.0330368
I0823 01:52:49.354192 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.033036 (* 1 = 0.033036 loss)
I0823 01:52:49.354205 13823 sgd_solver.cpp:112] Iteration 325100, lr = 1e-06
I0823 01:53:00.854334 13823 solver.cpp:239] Iteration 325200 (8.69563 iter/s, 11.5s/100 iters), loss = 0.0244965
I0823 01:53:00.854387 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0244956 (* 1 = 0.0244956 loss)
I0823 01:53:00.854396 13823 sgd_solver.cpp:112] Iteration 325200, lr = 1e-06
I0823 01:53:12.276810 13823 solver.cpp:239] Iteration 325300 (8.7548 iter/s, 11.4223s/100 iters), loss = 0.0464787
I0823 01:53:12.276870 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0464779 (* 1 = 0.0464779 loss)
I0823 01:53:12.276881 13823 sgd_solver.cpp:112] Iteration 325300, lr = 1e-06
I0823 01:53:23.658105 13823 solver.cpp:239] Iteration 325400 (8.78648 iter/s, 11.3811s/100 iters), loss = 0.0257038
I0823 01:53:23.658160 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.025703 (* 1 = 0.025703 loss)
I0823 01:53:23.658171 13823 sgd_solver.cpp:112] Iteration 325400, lr = 1e-06
I0823 01:53:34.932386 13823 solver.cpp:239] Iteration 325500 (8.86987 iter/s, 11.2741s/100 iters), loss = 0.0414622
I0823 01:53:34.932440 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0414614 (* 1 = 0.0414614 loss)
I0823 01:53:34.932451 13823 sgd_solver.cpp:112] Iteration 325500, lr = 1e-06
I0823 01:53:46.119462 13823 solver.cpp:239] Iteration 325600 (8.93901 iter/s, 11.1869s/100 iters), loss = 0.024502
I0823 01:53:46.119513 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0245012 (* 1 = 0.0245012 loss)
I0823 01:53:46.119522 13823 sgd_solver.cpp:112] Iteration 325600, lr = 1e-06
I0823 01:53:57.611416 13823 solver.cpp:239] Iteration 325700 (8.70186 iter/s, 11.4918s/100 iters), loss = 0.0283422
I0823 01:53:57.611474 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0283413 (* 1 = 0.0283413 loss)
I0823 01:53:57.611486 13823 sgd_solver.cpp:112] Iteration 325700, lr = 1e-06
I0823 01:54:08.915410 13823 solver.cpp:239] Iteration 325800 (8.84656 iter/s, 11.3038s/100 iters), loss = 0.0369656
I0823 01:54:08.915462 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0369647 (* 1 = 0.0369647 loss)
I0823 01:54:08.915470 13823 sgd_solver.cpp:112] Iteration 325800, lr = 1e-06
I0823 01:54:20.356236 13823 solver.cpp:239] Iteration 325900 (8.74074 iter/s, 11.4407s/100 iters), loss = 0.0393649
I0823 01:54:20.356289 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.039364 (* 1 = 0.039364 loss)
I0823 01:54:20.356299 13823 sgd_solver.cpp:112] Iteration 325900, lr = 1e-06
I0823 01:54:31.771761 13823 solver.cpp:239] Iteration 326000 (8.76012 iter/s, 11.4154s/100 iters), loss = 0.0272072
I0823 01:54:31.771818 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0272064 (* 1 = 0.0272064 loss)
I0823 01:54:31.771829 13823 sgd_solver.cpp:112] Iteration 326000, lr = 1e-06
I0823 01:54:43.197911 13823 solver.cpp:239] Iteration 326100 (8.75198 iter/s, 11.426s/100 iters), loss = 0.0321049
I0823 01:54:43.197973 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.032104 (* 1 = 0.032104 loss)
I0823 01:54:43.197986 13823 sgd_solver.cpp:112] Iteration 326100, lr = 1e-06
I0823 01:54:54.691000 13823 solver.cpp:239] Iteration 326200 (8.701 iter/s, 11.4929s/100 iters), loss = 0.0306698
I0823 01:54:54.691056 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.030669 (* 1 = 0.030669 loss)
I0823 01:54:54.691067 13823 sgd_solver.cpp:112] Iteration 326200, lr = 1e-06
I0823 01:55:05.958717 13823 solver.cpp:239] Iteration 326300 (8.87503 iter/s, 11.2676s/100 iters), loss = 0.0218601
I0823 01:55:05.958768 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0218593 (* 1 = 0.0218593 loss)
I0823 01:55:05.958778 13823 sgd_solver.cpp:112] Iteration 326300, lr = 1e-06
I0823 01:55:17.454222 13823 solver.cpp:239] Iteration 326400 (8.69916 iter/s, 11.4954s/100 iters), loss = 0.0250584
I0823 01:55:17.454279 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0250576 (* 1 = 0.0250576 loss)
I0823 01:55:17.454290 13823 sgd_solver.cpp:112] Iteration 326400, lr = 1e-06
I0823 01:55:29.108656 13823 solver.cpp:239] Iteration 326500 (8.58053 iter/s, 11.6543s/100 iters), loss = 0.0232696
I0823 01:55:29.108708 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0232688 (* 1 = 0.0232688 loss)
I0823 01:55:29.108717 13823 sgd_solver.cpp:112] Iteration 326500, lr = 1e-06
I0823 01:55:40.784735 13823 solver.cpp:239] Iteration 326600 (8.56462 iter/s, 11.6759s/100 iters), loss = 0.0311708
I0823 01:55:40.784787 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.03117 (* 1 = 0.03117 loss)
I0823 01:55:40.784797 13823 sgd_solver.cpp:112] Iteration 326600, lr = 1e-06
I0823 01:55:52.241189 13823 solver.cpp:239] Iteration 326700 (8.72881 iter/s, 11.4563s/100 iters), loss = 0.0251542
I0823 01:55:52.241238 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0251533 (* 1 = 0.0251533 loss)
I0823 01:55:52.241247 13823 sgd_solver.cpp:112] Iteration 326700, lr = 1e-06
I0823 01:56:03.488055 13823 solver.cpp:239] Iteration 326800 (8.89147 iter/s, 11.2467s/100 iters), loss = 0.0230566
I0823 01:56:03.488107 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0230558 (* 1 = 0.0230558 loss)
I0823 01:56:03.488117 13823 sgd_solver.cpp:112] Iteration 326800, lr = 1e-06
I0823 01:56:14.963876 13823 solver.cpp:239] Iteration 326900 (8.71408 iter/s, 11.4757s/100 iters), loss = 0.02436
I0823 01:56:14.963923 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0243592 (* 1 = 0.0243592 loss)
I0823 01:56:14.963933 13823 sgd_solver.cpp:112] Iteration 326900, lr = 1e-06
I0823 01:56:26.290699 13823 solver.cpp:239] Iteration 327000 (8.8287 iter/s, 11.3267s/100 iters), loss = 0.0354256
I0823 01:56:26.290750 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0354248 (* 1 = 0.0354248 loss)
I0823 01:56:26.290758 13823 sgd_solver.cpp:112] Iteration 327000, lr = 1e-06
I0823 01:56:37.832595 13823 solver.cpp:239] Iteration 327100 (8.66419 iter/s, 11.5418s/100 iters), loss = 0.0295059
I0823 01:56:37.832653 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0295051 (* 1 = 0.0295051 loss)
I0823 01:56:37.832665 13823 sgd_solver.cpp:112] Iteration 327100, lr = 1e-06
I0823 01:56:49.380957 13823 solver.cpp:239] Iteration 327200 (8.65934 iter/s, 11.5482s/100 iters), loss = 0.0370804
I0823 01:56:49.381016 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0370796 (* 1 = 0.0370796 loss)
I0823 01:56:49.381027 13823 sgd_solver.cpp:112] Iteration 327200, lr = 1e-06
I0823 01:57:00.831249 13823 solver.cpp:239] Iteration 327300 (8.7335 iter/s, 11.4502s/100 iters), loss = 0.0275445
I0823 01:57:00.831298 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0275437 (* 1 = 0.0275437 loss)
I0823 01:57:00.831308 13823 sgd_solver.cpp:112] Iteration 327300, lr = 1e-06
I0823 01:57:12.308513 13823 solver.cpp:239] Iteration 327400 (8.71297 iter/s, 11.4771s/100 iters), loss = 0.02594
I0823 01:57:12.308563 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0259392 (* 1 = 0.0259392 loss)
I0823 01:57:12.308573 13823 sgd_solver.cpp:112] Iteration 327400, lr = 1e-06
I0823 01:57:23.792234 13823 solver.cpp:239] Iteration 327500 (8.70807 iter/s, 11.4836s/100 iters), loss = 0.0278277
I0823 01:57:23.792294 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0278269 (* 1 = 0.0278269 loss)
I0823 01:57:23.792305 13823 sgd_solver.cpp:112] Iteration 327500, lr = 1e-06
I0823 01:57:35.362105 13823 solver.cpp:239] Iteration 327600 (8.64324 iter/s, 11.5697s/100 iters), loss = 0.0345654
I0823 01:57:35.362162 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0345646 (* 1 = 0.0345646 loss)
I0823 01:57:35.362174 13823 sgd_solver.cpp:112] Iteration 327600, lr = 1e-06
I0823 01:57:46.780025 13823 solver.cpp:239] Iteration 327700 (8.75826 iter/s, 11.4178s/100 iters), loss = 0.0261103
I0823 01:57:46.780077 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0261094 (* 1 = 0.0261094 loss)
I0823 01:57:46.780087 13823 sgd_solver.cpp:112] Iteration 327700, lr = 1e-06
I0823 01:57:58.337998 13823 solver.cpp:239] Iteration 327800 (8.65212 iter/s, 11.5579s/100 iters), loss = 0.0252637
I0823 01:57:58.338049 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0252629 (* 1 = 0.0252629 loss)
I0823 01:57:58.338059 13823 sgd_solver.cpp:112] Iteration 327800, lr = 1e-06
I0823 01:58:10.066807 13823 solver.cpp:239] Iteration 327900 (8.5261 iter/s, 11.7287s/100 iters), loss = 0.040015
I0823 01:58:10.066869 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0400142 (* 1 = 0.0400142 loss)
I0823 01:58:10.066879 13823 sgd_solver.cpp:112] Iteration 327900, lr = 1e-06
I0823 01:58:21.626615 13823 solver.cpp:239] Iteration 328000 (8.65076 iter/s, 11.5597s/100 iters), loss = 0.0263726
I0823 01:58:21.626670 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0263718 (* 1 = 0.0263718 loss)
I0823 01:58:21.626680 13823 sgd_solver.cpp:112] Iteration 328000, lr = 1e-06
I0823 01:58:33.047638 13823 solver.cpp:239] Iteration 328100 (8.75587 iter/s, 11.4209s/100 iters), loss = 0.023461
I0823 01:58:33.047690 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0234602 (* 1 = 0.0234602 loss)
I0823 01:58:33.047700 13823 sgd_solver.cpp:112] Iteration 328100, lr = 1e-06
I0823 01:58:44.626296 13823 solver.cpp:239] Iteration 328200 (8.63666 iter/s, 11.5785s/100 iters), loss = 0.0247008
I0823 01:58:44.626348 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0247 (* 1 = 0.0247 loss)
I0823 01:58:44.626358 13823 sgd_solver.cpp:112] Iteration 328200, lr = 1e-06
I0823 01:58:55.951122 13823 solver.cpp:239] Iteration 328300 (8.83025 iter/s, 11.3247s/100 iters), loss = 0.0271839
I0823 01:58:55.951172 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0271831 (* 1 = 0.0271831 loss)
I0823 01:58:55.951181 13823 sgd_solver.cpp:112] Iteration 328300, lr = 1e-06
I0823 01:59:07.304352 13823 solver.cpp:239] Iteration 328400 (8.80815 iter/s, 11.3531s/100 iters), loss = 0.0263661
I0823 01:59:07.304402 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0263653 (* 1 = 0.0263653 loss)
I0823 01:59:07.304411 13823 sgd_solver.cpp:112] Iteration 328400, lr = 1e-06
I0823 01:59:18.985832 13823 solver.cpp:239] Iteration 328500 (8.56064 iter/s, 11.6814s/100 iters), loss = 0.0289776
I0823 01:59:18.985893 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0289767 (* 1 = 0.0289767 loss)
I0823 01:59:18.985904 13823 sgd_solver.cpp:112] Iteration 328500, lr = 1e-06
I0823 01:59:30.272997 13823 solver.cpp:239] Iteration 328600 (8.85971 iter/s, 11.2871s/100 iters), loss = 0.0295902
I0823 01:59:30.273061 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0295894 (* 1 = 0.0295894 loss)
I0823 01:59:30.273072 13823 sgd_solver.cpp:112] Iteration 328600, lr = 1e-06
I0823 01:59:41.451411 13823 solver.cpp:239] Iteration 328700 (8.9459 iter/s, 11.1783s/100 iters), loss = 0.0248843
I0823 01:59:41.451460 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0248835 (* 1 = 0.0248835 loss)
I0823 01:59:41.451469 13823 sgd_solver.cpp:112] Iteration 328700, lr = 1e-06
I0823 01:59:51.100494 13823 solver.cpp:239] Iteration 328800 (10.3638 iter/s, 9.64899s/100 iters), loss = 0.0251759
I0823 01:59:51.100540 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0251751 (* 1 = 0.0251751 loss)
I0823 01:59:51.100549 13823 sgd_solver.cpp:112] Iteration 328800, lr = 1e-06
I0823 02:00:00.575170 13823 solver.cpp:239] Iteration 328900 (10.5546 iter/s, 9.47458s/100 iters), loss = 0.0287493
I0823 02:00:00.575222 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0287485 (* 1 = 0.0287485 loss)
I0823 02:00:00.575232 13823 sgd_solver.cpp:112] Iteration 328900, lr = 1e-06
I0823 02:00:10.168933 13823 solver.cpp:239] Iteration 329000 (10.4235 iter/s, 9.59367s/100 iters), loss = 0.0668534
I0823 02:00:10.168984 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0668525 (* 1 = 0.0668525 loss)
I0823 02:00:10.168993 13823 sgd_solver.cpp:112] Iteration 329000, lr = 1e-06
I0823 02:00:19.506059 13823 solver.cpp:239] Iteration 329100 (10.71 iter/s, 9.33703s/100 iters), loss = 0.0226419
I0823 02:00:19.506111 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0226411 (* 1 = 0.0226411 loss)
I0823 02:00:19.506121 13823 sgd_solver.cpp:112] Iteration 329100, lr = 1e-06
I0823 02:00:28.997790 13823 solver.cpp:239] Iteration 329200 (10.5356 iter/s, 9.49164s/100 iters), loss = 0.0267623
I0823 02:00:28.997843 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0267615 (* 1 = 0.0267615 loss)
I0823 02:00:28.997853 13823 sgd_solver.cpp:112] Iteration 329200, lr = 1e-06
I0823 02:00:38.489624 13823 solver.cpp:239] Iteration 329300 (10.5355 iter/s, 9.49174s/100 iters), loss = 0.0283299
I0823 02:00:38.489665 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0283291 (* 1 = 0.0283291 loss)
I0823 02:00:38.489671 13823 sgd_solver.cpp:112] Iteration 329300, lr = 1e-06
I0823 02:00:48.009058 13823 solver.cpp:239] Iteration 329400 (10.5049 iter/s, 9.51936s/100 iters), loss = 0.0261297
I0823 02:00:48.009100 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0261289 (* 1 = 0.0261289 loss)
I0823 02:00:48.009109 13823 sgd_solver.cpp:112] Iteration 329400, lr = 1e-06
I0823 02:00:57.288240 13823 solver.cpp:239] Iteration 329500 (10.7769 iter/s, 9.2791s/100 iters), loss = 0.0279383
I0823 02:00:57.288281 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0279375 (* 1 = 0.0279375 loss)
I0823 02:00:57.288288 13823 sgd_solver.cpp:112] Iteration 329500, lr = 1e-06
I0823 02:01:06.863844 13823 solver.cpp:239] Iteration 329600 (10.4433 iter/s, 9.57552s/100 iters), loss = 0.0249159
I0823 02:01:06.863894 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.024915 (* 1 = 0.024915 loss)
I0823 02:01:06.863903 13823 sgd_solver.cpp:112] Iteration 329600, lr = 1e-06
I0823 02:01:16.449295 13823 solver.cpp:239] Iteration 329700 (10.4326 iter/s, 9.58536s/100 iters), loss = 0.0278912
I0823 02:01:16.449344 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0278903 (* 1 = 0.0278903 loss)
I0823 02:01:16.449353 13823 sgd_solver.cpp:112] Iteration 329700, lr = 1e-06
I0823 02:01:26.044960 13823 solver.cpp:239] Iteration 329800 (10.4215 iter/s, 9.59558s/100 iters), loss = 0.0265627
I0823 02:01:26.045008 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0265618 (* 1 = 0.0265618 loss)
I0823 02:01:26.045017 13823 sgd_solver.cpp:112] Iteration 329800, lr = 1e-06
I0823 02:01:35.480824 13823 solver.cpp:239] Iteration 329900 (10.598 iter/s, 9.43578s/100 iters), loss = 0.0270187
I0823 02:01:35.480865 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0270178 (* 1 = 0.0270178 loss)
I0823 02:01:35.480872 13823 sgd_solver.cpp:112] Iteration 329900, lr = 1e-06
I0823 02:01:44.894234 13823 solver.cpp:239] Iteration 330000 (10.6232 iter/s, 9.41333s/100 iters), loss = 0.0256122
I0823 02:01:44.894286 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0256113 (* 1 = 0.0256113 loss)
I0823 02:01:44.894295 13823 sgd_solver.cpp:112] Iteration 330000, lr = 1e-06
I0823 02:01:54.532786 13823 solver.cpp:239] Iteration 330100 (10.3751 iter/s, 9.63847s/100 iters), loss = 0.0254787
I0823 02:01:54.532829 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0254778 (* 1 = 0.0254778 loss)
I0823 02:01:54.532835 13823 sgd_solver.cpp:112] Iteration 330100, lr = 1e-06
I0823 02:02:04.226066 13823 solver.cpp:239] Iteration 330200 (10.3165 iter/s, 9.6932s/100 iters), loss = 0.0275585
I0823 02:02:04.226128 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0275577 (* 1 = 0.0275577 loss)
I0823 02:02:04.226140 13823 sgd_solver.cpp:112] Iteration 330200, lr = 1e-06
I0823 02:02:13.904953 13823 solver.cpp:239] Iteration 330300 (10.3319 iter/s, 9.67879s/100 iters), loss = 0.0231158
I0823 02:02:13.905015 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0231149 (* 1 = 0.0231149 loss)
I0823 02:02:13.905026 13823 sgd_solver.cpp:112] Iteration 330300, lr = 1e-06
I0823 02:02:23.282188 13823 solver.cpp:239] Iteration 330400 (10.6642 iter/s, 9.37714s/100 iters), loss = 0.0334847
I0823 02:02:23.282243 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0334838 (* 1 = 0.0334838 loss)
I0823 02:02:23.282253 13823 sgd_solver.cpp:112] Iteration 330400, lr = 1e-06
I0823 02:02:32.760720 13823 solver.cpp:239] Iteration 330500 (10.5503 iter/s, 9.47845s/100 iters), loss = 0.0246499
I0823 02:02:32.760762 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0246491 (* 1 = 0.0246491 loss)
I0823 02:02:32.760769 13823 sgd_solver.cpp:112] Iteration 330500, lr = 1e-06
I0823 02:02:42.428838 13823 solver.cpp:239] Iteration 330600 (10.3434 iter/s, 9.66804s/100 iters), loss = 0.0266002
I0823 02:02:42.428887 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0265993 (* 1 = 0.0265993 loss)
I0823 02:02:42.428896 13823 sgd_solver.cpp:112] Iteration 330600, lr = 1e-06
I0823 02:02:51.958829 13823 solver.cpp:239] Iteration 330700 (10.4933 iter/s, 9.52991s/100 iters), loss = 0.0247956
I0823 02:02:51.958889 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0247947 (* 1 = 0.0247947 loss)
I0823 02:02:51.958900 13823 sgd_solver.cpp:112] Iteration 330700, lr = 1e-06
I0823 02:03:01.764766 13823 solver.cpp:239] Iteration 330800 (10.198 iter/s, 9.80584s/100 iters), loss = 0.0325685
I0823 02:03:01.764822 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0325677 (* 1 = 0.0325677 loss)
I0823 02:03:01.764832 13823 sgd_solver.cpp:112] Iteration 330800, lr = 1e-06
I0823 02:03:11.275995 13823 solver.cpp:239] Iteration 330900 (10.514 iter/s, 9.51114s/100 iters), loss = 0.0396046
I0823 02:03:11.276044 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0396037 (* 1 = 0.0396037 loss)
I0823 02:03:11.276053 13823 sgd_solver.cpp:112] Iteration 330900, lr = 1e-06
I0823 02:03:20.669549 13823 solver.cpp:239] Iteration 331000 (10.6457 iter/s, 9.39348s/100 iters), loss = 0.0272245
I0823 02:03:20.669598 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0272237 (* 1 = 0.0272237 loss)
I0823 02:03:20.669607 13823 sgd_solver.cpp:112] Iteration 331000, lr = 1e-06
I0823 02:03:30.387185 13823 solver.cpp:239] Iteration 331100 (10.2907 iter/s, 9.71755s/100 iters), loss = 0.0271293
I0823 02:03:30.387236 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0271284 (* 1 = 0.0271284 loss)
I0823 02:03:30.387246 13823 sgd_solver.cpp:112] Iteration 331100, lr = 1e-06
I0823 02:03:39.768962 13823 solver.cpp:239] Iteration 331200 (10.6591 iter/s, 9.3817s/100 iters), loss = 0.0233598
I0823 02:03:39.769013 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.023359 (* 1 = 0.023359 loss)
I0823 02:03:39.769022 13823 sgd_solver.cpp:112] Iteration 331200, lr = 1e-06
I0823 02:03:49.149300 13823 solver.cpp:239] Iteration 331300 (10.6607 iter/s, 9.38026s/100 iters), loss = 0.0247365
I0823 02:03:49.149341 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0247357 (* 1 = 0.0247357 loss)
I0823 02:03:49.149348 13823 sgd_solver.cpp:112] Iteration 331300, lr = 1e-06
I0823 02:03:58.948452 13823 solver.cpp:239] Iteration 331400 (10.205 iter/s, 9.79908s/100 iters), loss = 0.0242112
I0823 02:03:58.948498 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0242104 (* 1 = 0.0242104 loss)
I0823 02:03:58.948505 13823 sgd_solver.cpp:112] Iteration 331400, lr = 1e-06
I0823 02:04:08.620564 13823 solver.cpp:239] Iteration 331500 (10.3391 iter/s, 9.67204s/100 iters), loss = 0.0245929
I0823 02:04:08.620616 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0245921 (* 1 = 0.0245921 loss)
I0823 02:04:08.620626 13823 sgd_solver.cpp:112] Iteration 331500, lr = 1e-06
I0823 02:04:18.261343 13823 solver.cpp:239] Iteration 331600 (10.3727 iter/s, 9.6407s/100 iters), loss = 0.0253356
I0823 02:04:18.261384 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0253348 (* 1 = 0.0253348 loss)
I0823 02:04:18.261392 13823 sgd_solver.cpp:112] Iteration 331600, lr = 1e-06
I0823 02:04:28.106024 13823 solver.cpp:239] Iteration 331700 (10.1578 iter/s, 9.84461s/100 iters), loss = 0.0258644
I0823 02:04:28.106072 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0258636 (* 1 = 0.0258636 loss)
I0823 02:04:28.106082 13823 sgd_solver.cpp:112] Iteration 331700, lr = 1e-06
I0823 02:04:37.567991 13823 solver.cpp:239] Iteration 331800 (10.5687 iter/s, 9.46189s/100 iters), loss = 0.0249819
I0823 02:04:37.568043 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0249811 (* 1 = 0.0249811 loss)
I0823 02:04:37.568053 13823 sgd_solver.cpp:112] Iteration 331800, lr = 1e-06
I0823 02:04:46.962620 13823 solver.cpp:239] Iteration 331900 (10.6445 iter/s, 9.39456s/100 iters), loss = 0.0250782
I0823 02:04:46.962662 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0250774 (* 1 = 0.0250774 loss)
I0823 02:04:46.962669 13823 sgd_solver.cpp:112] Iteration 331900, lr = 1e-06
I0823 02:04:56.810760 13823 solver.cpp:239] Iteration 332000 (10.1543 iter/s, 9.84807s/100 iters), loss = 0.0287888
I0823 02:04:56.810811 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.028788 (* 1 = 0.028788 loss)
I0823 02:04:56.810819 13823 sgd_solver.cpp:112] Iteration 332000, lr = 1e-06
I0823 02:05:06.259557 13823 solver.cpp:239] Iteration 332100 (10.5834 iter/s, 9.44872s/100 iters), loss = 0.0276133
I0823 02:05:06.259604 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0276125 (* 1 = 0.0276125 loss)
I0823 02:05:06.259613 13823 sgd_solver.cpp:112] Iteration 332100, lr = 1e-06
I0823 02:05:15.814630 13823 solver.cpp:239] Iteration 332200 (10.4657 iter/s, 9.555s/100 iters), loss = 0.0275574
I0823 02:05:15.814671 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0275566 (* 1 = 0.0275566 loss)
I0823 02:05:15.814678 13823 sgd_solver.cpp:112] Iteration 332200, lr = 1e-06
I0823 02:05:25.212708 13823 solver.cpp:239] Iteration 332300 (10.6405 iter/s, 9.39801s/100 iters), loss = 0.0288247
I0823 02:05:25.212750 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0288239 (* 1 = 0.0288239 loss)
I0823 02:05:25.212759 13823 sgd_solver.cpp:112] Iteration 332300, lr = 1e-06
I0823 02:05:34.709962 13823 solver.cpp:239] Iteration 332400 (10.5294 iter/s, 9.49719s/100 iters), loss = 0.0285153
I0823 02:05:34.710008 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0285144 (* 1 = 0.0285144 loss)
I0823 02:05:34.710017 13823 sgd_solver.cpp:112] Iteration 332400, lr = 1e-06
I0823 02:05:44.145239 13823 solver.cpp:239] Iteration 332500 (10.5986 iter/s, 9.43521s/100 iters), loss = 0.0661426
I0823 02:05:44.145279 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0661417 (* 1 = 0.0661417 loss)
I0823 02:05:44.145287 13823 sgd_solver.cpp:112] Iteration 332500, lr = 1e-06
I0823 02:05:53.655858 13823 solver.cpp:239] Iteration 332600 (10.5146 iter/s, 9.51055s/100 iters), loss = 0.024606
I0823 02:05:53.655910 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0246051 (* 1 = 0.0246051 loss)
I0823 02:05:53.655920 13823 sgd_solver.cpp:112] Iteration 332600, lr = 1e-06
I0823 02:06:03.244827 13823 solver.cpp:239] Iteration 332700 (10.4287 iter/s, 9.58889s/100 iters), loss = 0.0346032
I0823 02:06:03.244875 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0346024 (* 1 = 0.0346024 loss)
I0823 02:06:03.244885 13823 sgd_solver.cpp:112] Iteration 332700, lr = 1e-06
I0823 02:06:12.823734 13823 solver.cpp:239] Iteration 332800 (10.4397 iter/s, 9.57884s/100 iters), loss = 0.0246519
I0823 02:06:12.823774 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0246511 (* 1 = 0.0246511 loss)
I0823 02:06:12.823781 13823 sgd_solver.cpp:112] Iteration 332800, lr = 1e-06
I0823 02:06:22.698690 13823 solver.cpp:239] Iteration 332900 (10.1267 iter/s, 9.87489s/100 iters), loss = 0.0287105
I0823 02:06:22.698747 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0287097 (* 1 = 0.0287097 loss)
I0823 02:06:22.698757 13823 sgd_solver.cpp:112] Iteration 332900, lr = 1e-06
I0823 02:06:32.406124 13823 solver.cpp:239] Iteration 333000 (10.3015 iter/s, 9.70736s/100 iters), loss = 0.0282398
I0823 02:06:32.406174 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0282389 (* 1 = 0.0282389 loss)
I0823 02:06:32.406183 13823 sgd_solver.cpp:112] Iteration 333000, lr = 1e-06
I0823 02:06:42.231233 13823 solver.cpp:239] Iteration 333100 (10.1781 iter/s, 9.82504s/100 iters), loss = 0.0259591
I0823 02:06:42.231284 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0259583 (* 1 = 0.0259583 loss)
I0823 02:06:42.231294 13823 sgd_solver.cpp:112] Iteration 333100, lr = 1e-06
I0823 02:06:51.879979 13823 solver.cpp:239] Iteration 333200 (10.3641 iter/s, 9.64867s/100 iters), loss = 0.0263703
I0823 02:06:51.880029 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0263695 (* 1 = 0.0263695 loss)
I0823 02:06:51.880038 13823 sgd_solver.cpp:112] Iteration 333200, lr = 1e-06
I0823 02:07:01.496614 13823 solver.cpp:239] Iteration 333300 (10.3987 iter/s, 9.61656s/100 iters), loss = 0.0264399
I0823 02:07:01.496664 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.026439 (* 1 = 0.026439 loss)
I0823 02:07:01.496673 13823 sgd_solver.cpp:112] Iteration 333300, lr = 1e-06
I0823 02:07:11.323139 13823 solver.cpp:239] Iteration 333400 (10.1766 iter/s, 9.82645s/100 iters), loss = 0.0249047
I0823 02:07:11.323190 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0249039 (* 1 = 0.0249039 loss)
I0823 02:07:11.323199 13823 sgd_solver.cpp:112] Iteration 333400, lr = 1e-06
I0823 02:07:20.921798 13823 solver.cpp:239] Iteration 333500 (10.4182 iter/s, 9.59859s/100 iters), loss = 0.0273873
I0823 02:07:20.921851 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0273865 (* 1 = 0.0273865 loss)
I0823 02:07:20.921860 13823 sgd_solver.cpp:112] Iteration 333500, lr = 1e-06
I0823 02:07:30.802356 13823 solver.cpp:239] Iteration 333600 (10.121 iter/s, 9.88048s/100 iters), loss = 0.0274701
I0823 02:07:30.802413 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0274692 (* 1 = 0.0274692 loss)
I0823 02:07:30.802424 13823 sgd_solver.cpp:112] Iteration 333600, lr = 1e-06
I0823 02:07:40.755964 13823 solver.cpp:239] Iteration 333700 (10.0467 iter/s, 9.95353s/100 iters), loss = 0.0266448
I0823 02:07:40.756016 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0266439 (* 1 = 0.0266439 loss)
I0823 02:07:40.756026 13823 sgd_solver.cpp:112] Iteration 333700, lr = 1e-06
I0823 02:07:50.777586 13823 solver.cpp:239] Iteration 333800 (9.9785 iter/s, 10.0215s/100 iters), loss = 0.0381612
I0823 02:07:50.777637 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0381604 (* 1 = 0.0381604 loss)
I0823 02:07:50.777647 13823 sgd_solver.cpp:112] Iteration 333800, lr = 1e-06
I0823 02:08:00.480893 13823 solver.cpp:239] Iteration 333900 (10.3058 iter/s, 9.70324s/100 iters), loss = 0.0283188
I0823 02:08:00.480942 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0283179 (* 1 = 0.0283179 loss)
I0823 02:08:00.480952 13823 sgd_solver.cpp:112] Iteration 333900, lr = 1e-06
I0823 02:08:10.593627 13823 solver.cpp:239] Iteration 334000 (9.88859 iter/s, 10.1127s/100 iters), loss = 0.0272897
I0823 02:08:10.593677 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0272889 (* 1 = 0.0272889 loss)
I0823 02:08:10.593686 13823 sgd_solver.cpp:112] Iteration 334000, lr = 1e-06
I0823 02:08:20.601400 13823 solver.cpp:239] Iteration 334100 (9.99231 iter/s, 10.0077s/100 iters), loss = 0.0245293
I0823 02:08:20.601460 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0245284 (* 1 = 0.0245284 loss)
I0823 02:08:20.601472 13823 sgd_solver.cpp:112] Iteration 334100, lr = 1e-06
I0823 02:08:30.371908 13823 solver.cpp:239] Iteration 334200 (10.235 iter/s, 9.77043s/100 iters), loss = 0.0266754
I0823 02:08:30.371969 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0266746 (* 1 = 0.0266746 loss)
I0823 02:08:30.371981 13823 sgd_solver.cpp:112] Iteration 334200, lr = 1e-06
I0823 02:08:40.268873 13823 solver.cpp:239] Iteration 334300 (10.1042 iter/s, 9.89689s/100 iters), loss = 0.0244232
I0823 02:08:40.268923 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0244224 (* 1 = 0.0244224 loss)
I0823 02:08:40.268934 13823 sgd_solver.cpp:112] Iteration 334300, lr = 1e-06
I0823 02:08:49.820914 13823 solver.cpp:239] Iteration 334400 (10.469 iter/s, 9.55197s/100 iters), loss = 0.235479
I0823 02:08:49.820963 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.235478 (* 1 = 0.235478 loss)
I0823 02:08:49.820973 13823 sgd_solver.cpp:112] Iteration 334400, lr = 1e-06
I0823 02:08:59.969172 13823 solver.cpp:239] Iteration 334500 (9.85397 iter/s, 10.1482s/100 iters), loss = 0.0602585
I0823 02:08:59.969224 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0602576 (* 1 = 0.0602576 loss)
I0823 02:08:59.969233 13823 sgd_solver.cpp:112] Iteration 334500, lr = 1e-06
I0823 02:09:09.735543 13823 solver.cpp:239] Iteration 334600 (10.2393 iter/s, 9.7663s/100 iters), loss = 0.0240375
I0823 02:09:09.735600 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0240366 (* 1 = 0.0240366 loss)
I0823 02:09:09.735612 13823 sgd_solver.cpp:112] Iteration 334600, lr = 1e-06
I0823 02:09:19.680655 13823 solver.cpp:239] Iteration 334700 (10.0553 iter/s, 9.94504s/100 iters), loss = 0.0296345
I0823 02:09:19.680703 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0296337 (* 1 = 0.0296337 loss)
I0823 02:09:19.680713 13823 sgd_solver.cpp:112] Iteration 334700, lr = 1e-06
I0823 02:09:29.728850 13823 solver.cpp:239] Iteration 334800 (9.9521 iter/s, 10.0481s/100 iters), loss = 0.0255682
I0823 02:09:29.728904 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0255674 (* 1 = 0.0255674 loss)
I0823 02:09:29.728915 13823 sgd_solver.cpp:112] Iteration 334800, lr = 1e-06
I0823 02:09:39.691321 13823 solver.cpp:239] Iteration 334900 (10.0377 iter/s, 9.9624s/100 iters), loss = 0.0290229
I0823 02:09:39.691372 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.029022 (* 1 = 0.029022 loss)
I0823 02:09:39.691381 13823 sgd_solver.cpp:112] Iteration 334900, lr = 1e-06
I0823 02:09:49.778182 13823 solver.cpp:239] Iteration 335000 (9.91395 iter/s, 10.0868s/100 iters), loss = 0.028851
I0823 02:09:49.778234 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0288501 (* 1 = 0.0288501 loss)
I0823 02:09:49.778244 13823 sgd_solver.cpp:112] Iteration 335000, lr = 1e-06
I0823 02:09:59.605749 13823 solver.cpp:239] Iteration 335100 (10.1755 iter/s, 9.8275s/100 iters), loss = 0.0286593
I0823 02:09:59.605798 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0286584 (* 1 = 0.0286584 loss)
I0823 02:09:59.605808 13823 sgd_solver.cpp:112] Iteration 335100, lr = 1e-06
I0823 02:10:09.501142 13823 solver.cpp:239] Iteration 335200 (10.1058 iter/s, 9.89533s/100 iters), loss = 0.034085
I0823 02:10:09.501194 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0340841 (* 1 = 0.0340841 loss)
I0823 02:10:09.501204 13823 sgd_solver.cpp:112] Iteration 335200, lr = 1e-06
I0823 02:10:19.772063 13823 solver.cpp:239] Iteration 335300 (9.73629 iter/s, 10.2709s/100 iters), loss = 0.0270754
I0823 02:10:19.772119 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0270745 (* 1 = 0.0270745 loss)
I0823 02:10:19.772130 13823 sgd_solver.cpp:112] Iteration 335300, lr = 1e-06
I0823 02:10:29.891640 13823 solver.cpp:239] Iteration 335400 (9.88191 iter/s, 10.1195s/100 iters), loss = 0.0285593
I0823 02:10:29.891690 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0285584 (* 1 = 0.0285584 loss)
I0823 02:10:29.891698 13823 sgd_solver.cpp:112] Iteration 335400, lr = 1e-06
I0823 02:10:40.247376 13823 solver.cpp:239] Iteration 335500 (9.65655 iter/s, 10.3557s/100 iters), loss = 0.0278675
I0823 02:10:40.247436 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0278667 (* 1 = 0.0278667 loss)
I0823 02:10:40.247447 13823 sgd_solver.cpp:112] Iteration 335500, lr = 1e-06
I0823 02:10:50.317651 13823 solver.cpp:239] Iteration 335600 (9.93029 iter/s, 10.0702s/100 iters), loss = 0.0295972
I0823 02:10:50.317703 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0295964 (* 1 = 0.0295964 loss)
I0823 02:10:50.317713 13823 sgd_solver.cpp:112] Iteration 335600, lr = 1e-06
I0823 02:11:00.476850 13823 solver.cpp:239] Iteration 335700 (9.84336 iter/s, 10.1591s/100 iters), loss = 0.031414
I0823 02:11:00.476900 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0314132 (* 1 = 0.0314132 loss)
I0823 02:11:00.476910 13823 sgd_solver.cpp:112] Iteration 335700, lr = 1e-06
I0823 02:11:10.527442 13823 solver.cpp:239] Iteration 335800 (9.94973 iter/s, 10.0505s/100 iters), loss = 0.0244239
I0823 02:11:10.527493 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0244231 (* 1 = 0.0244231 loss)
I0823 02:11:10.527501 13823 sgd_solver.cpp:112] Iteration 335800, lr = 1e-06
I0823 02:11:20.862349 13823 solver.cpp:239] Iteration 335900 (9.67601 iter/s, 10.3348s/100 iters), loss = 0.0279573
I0823 02:11:20.862399 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0279565 (* 1 = 0.0279565 loss)
I0823 02:11:20.862408 13823 sgd_solver.cpp:112] Iteration 335900, lr = 1e-06
I0823 02:11:30.854082 13823 solver.cpp:239] Iteration 336000 (10.0083 iter/s, 9.99167s/100 iters), loss = 0.0242099
I0823 02:11:30.854135 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.024209 (* 1 = 0.024209 loss)
I0823 02:11:30.854144 13823 sgd_solver.cpp:112] Iteration 336000, lr = 1e-06
I0823 02:11:40.866529 13823 solver.cpp:239] Iteration 336100 (9.98763 iter/s, 10.0124s/100 iters), loss = 0.0269283
I0823 02:11:40.866582 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0269274 (* 1 = 0.0269274 loss)
I0823 02:11:40.866592 13823 sgd_solver.cpp:112] Iteration 336100, lr = 1e-06
I0823 02:11:50.953238 13823 solver.cpp:239] Iteration 336200 (9.9141 iter/s, 10.0866s/100 iters), loss = 0.0522342
I0823 02:11:50.953287 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0522333 (* 1 = 0.0522333 loss)
I0823 02:11:50.953297 13823 sgd_solver.cpp:112] Iteration 336200, lr = 1e-06
I0823 02:12:01.057638 13823 solver.cpp:239] Iteration 336300 (9.89674 iter/s, 10.1043s/100 iters), loss = 0.0248941
I0823 02:12:01.057691 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0248932 (* 1 = 0.0248932 loss)
I0823 02:12:01.057701 13823 sgd_solver.cpp:112] Iteration 336300, lr = 1e-06
I0823 02:12:10.993885 13823 solver.cpp:239] Iteration 336400 (10.0642 iter/s, 9.93618s/100 iters), loss = 0.0258174
I0823 02:12:10.993937 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0258165 (* 1 = 0.0258165 loss)
I0823 02:12:10.993945 13823 sgd_solver.cpp:112] Iteration 336400, lr = 1e-06
I0823 02:12:21.238507 13823 solver.cpp:239] Iteration 336500 (9.76128 iter/s, 10.2446s/100 iters), loss = 0.0252824
I0823 02:12:21.238556 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0252816 (* 1 = 0.0252816 loss)
I0823 02:12:21.238566 13823 sgd_solver.cpp:112] Iteration 336500, lr = 1e-06
I0823 02:12:31.341014 13823 solver.cpp:239] Iteration 336600 (9.89859 iter/s, 10.1024s/100 iters), loss = 0.0355079
I0823 02:12:31.341063 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0355071 (* 1 = 0.0355071 loss)
I0823 02:12:31.341071 13823 sgd_solver.cpp:112] Iteration 336600, lr = 1e-06
I0823 02:12:41.647331 13823 solver.cpp:239] Iteration 336700 (9.70285 iter/s, 10.3063s/100 iters), loss = 0.0271512
I0823 02:12:41.647392 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0271504 (* 1 = 0.0271504 loss)
I0823 02:12:41.647402 13823 sgd_solver.cpp:112] Iteration 336700, lr = 1e-06
I0823 02:12:51.783460 13823 solver.cpp:239] Iteration 336800 (9.86577 iter/s, 10.1361s/100 iters), loss = 0.0245184
I0823 02:12:51.783511 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0245175 (* 1 = 0.0245175 loss)
I0823 02:12:51.783520 13823 sgd_solver.cpp:112] Iteration 336800, lr = 1e-06
I0823 02:13:02.278595 13823 solver.cpp:239] Iteration 336900 (9.52828 iter/s, 10.4951s/100 iters), loss = 0.0226801
I0823 02:13:02.278647 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0226793 (* 1 = 0.0226793 loss)
I0823 02:13:02.278656 13823 sgd_solver.cpp:112] Iteration 336900, lr = 1e-06
I0823 02:13:12.598191 13823 solver.cpp:239] Iteration 337000 (9.69036 iter/s, 10.3195s/100 iters), loss = 0.0250116
I0823 02:13:12.598248 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0250107 (* 1 = 0.0250107 loss)
I0823 02:13:12.598258 13823 sgd_solver.cpp:112] Iteration 337000, lr = 1e-06
I0823 02:13:22.813729 13823 solver.cpp:239] Iteration 337100 (9.78908 iter/s, 10.2155s/100 iters), loss = 0.0458209
I0823 02:13:22.813779 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0458201 (* 1 = 0.0458201 loss)
I0823 02:13:22.813788 13823 sgd_solver.cpp:112] Iteration 337100, lr = 1e-06
I0823 02:13:33.351604 13823 solver.cpp:239] Iteration 337200 (9.48964 iter/s, 10.5378s/100 iters), loss = 0.0332757
I0823 02:13:33.351666 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0332749 (* 1 = 0.0332749 loss)
I0823 02:13:33.351680 13823 sgd_solver.cpp:112] Iteration 337200, lr = 1e-06
I0823 02:13:43.503010 13823 solver.cpp:239] Iteration 337300 (9.85092 iter/s, 10.1513s/100 iters), loss = 0.0284175
I0823 02:13:43.503059 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0284167 (* 1 = 0.0284167 loss)
I0823 02:13:43.503068 13823 sgd_solver.cpp:112] Iteration 337300, lr = 1e-06
I0823 02:13:53.861353 13823 solver.cpp:239] Iteration 337400 (9.65411 iter/s, 10.3583s/100 iters), loss = 0.0265803
I0823 02:13:53.861405 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0265794 (* 1 = 0.0265794 loss)
I0823 02:13:53.861415 13823 sgd_solver.cpp:112] Iteration 337400, lr = 1e-06
I0823 02:14:04.233566 13823 solver.cpp:239] Iteration 337500 (9.6412 iter/s, 10.3721s/100 iters), loss = 0.0335039
I0823 02:14:04.233621 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0335031 (* 1 = 0.0335031 loss)
I0823 02:14:04.233631 13823 sgd_solver.cpp:112] Iteration 337500, lr = 1e-06
I0823 02:14:14.417410 13823 solver.cpp:239] Iteration 337600 (9.81954 iter/s, 10.1838s/100 iters), loss = 0.0281165
I0823 02:14:14.417464 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0281157 (* 1 = 0.0281157 loss)
I0823 02:14:14.417474 13823 sgd_solver.cpp:112] Iteration 337600, lr = 1e-06
I0823 02:14:24.633554 13823 solver.cpp:239] Iteration 337700 (9.78849 iter/s, 10.2161s/100 iters), loss = 0.0267121
I0823 02:14:24.633610 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0267113 (* 1 = 0.0267113 loss)
I0823 02:14:24.633620 13823 sgd_solver.cpp:112] Iteration 337700, lr = 1e-06
I0823 02:14:34.768523 13823 solver.cpp:239] Iteration 337800 (9.86689 iter/s, 10.1349s/100 iters), loss = 0.04979
I0823 02:14:34.768575 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0497892 (* 1 = 0.0497892 loss)
I0823 02:14:34.768584 13823 sgd_solver.cpp:112] Iteration 337800, lr = 1e-06
I0823 02:14:45.203366 13823 solver.cpp:239] Iteration 337900 (9.58333 iter/s, 10.4348s/100 iters), loss = 0.0266743
I0823 02:14:45.203418 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0266735 (* 1 = 0.0266735 loss)
I0823 02:14:45.203429 13823 sgd_solver.cpp:112] Iteration 337900, lr = 1e-06
I0823 02:14:55.799535 13823 solver.cpp:239] Iteration 338000 (9.43743 iter/s, 10.5961s/100 iters), loss = 0.25814
I0823 02:14:55.799584 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.258139 (* 1 = 0.258139 loss)
I0823 02:14:55.799593 13823 sgd_solver.cpp:112] Iteration 338000, lr = 1e-06
I0823 02:15:06.256417 13823 solver.cpp:239] Iteration 338100 (9.56314 iter/s, 10.4568s/100 iters), loss = 0.0270267
I0823 02:15:06.256466 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0270259 (* 1 = 0.0270259 loss)
I0823 02:15:06.256476 13823 sgd_solver.cpp:112] Iteration 338100, lr = 1e-06
I0823 02:15:16.686102 13823 solver.cpp:239] Iteration 338200 (9.58807 iter/s, 10.4296s/100 iters), loss = 0.0312693
I0823 02:15:16.686153 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0312685 (* 1 = 0.0312685 loss)
I0823 02:15:16.686162 13823 sgd_solver.cpp:112] Iteration 338200, lr = 1e-06
I0823 02:15:27.001770 13823 solver.cpp:239] Iteration 338300 (9.69405 iter/s, 10.3156s/100 iters), loss = 0.0275974
I0823 02:15:27.001821 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0275966 (* 1 = 0.0275966 loss)
I0823 02:15:27.001832 13823 sgd_solver.cpp:112] Iteration 338300, lr = 1e-06
I0823 02:15:37.473028 13823 solver.cpp:239] Iteration 338400 (9.55001 iter/s, 10.4712s/100 iters), loss = 0.0273628
I0823 02:15:37.473088 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.027362 (* 1 = 0.027362 loss)
I0823 02:15:37.473098 13823 sgd_solver.cpp:112] Iteration 338400, lr = 1e-06
I0823 02:15:48.072325 13823 solver.cpp:239] Iteration 338500 (9.43465 iter/s, 10.5992s/100 iters), loss = 0.0232667
I0823 02:15:48.072383 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0232659 (* 1 = 0.0232659 loss)
I0823 02:15:48.072396 13823 sgd_solver.cpp:112] Iteration 338500, lr = 1e-06
I0823 02:15:58.589773 13823 solver.cpp:239] Iteration 338600 (9.50807 iter/s, 10.5174s/100 iters), loss = 0.0303191
I0823 02:15:58.589824 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0303183 (* 1 = 0.0303183 loss)
I0823 02:15:58.589833 13823 sgd_solver.cpp:112] Iteration 338600, lr = 1e-06
I0823 02:16:09.295437 13823 solver.cpp:239] Iteration 338700 (9.3409 iter/s, 10.7056s/100 iters), loss = 0.0295268
I0823 02:16:09.295495 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.029526 (* 1 = 0.029526 loss)
I0823 02:16:09.295505 13823 sgd_solver.cpp:112] Iteration 338700, lr = 1e-06
I0823 02:16:19.516758 13823 solver.cpp:239] Iteration 338800 (9.78353 iter/s, 10.2213s/100 iters), loss = 0.0257563
I0823 02:16:19.516818 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0257555 (* 1 = 0.0257555 loss)
I0823 02:16:19.516829 13823 sgd_solver.cpp:112] Iteration 338800, lr = 1e-06
I0823 02:16:30.126966 13823 solver.cpp:239] Iteration 338900 (9.42494 iter/s, 10.6101s/100 iters), loss = 0.0246812
I0823 02:16:30.127014 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0246803 (* 1 = 0.0246803 loss)
I0823 02:16:30.127023 13823 sgd_solver.cpp:112] Iteration 338900, lr = 1e-06
I0823 02:16:40.603178 13823 solver.cpp:239] Iteration 339000 (9.54549 iter/s, 10.4762s/100 iters), loss = 0.0243893
I0823 02:16:40.603230 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0243884 (* 1 = 0.0243884 loss)
I0823 02:16:40.603240 13823 sgd_solver.cpp:112] Iteration 339000, lr = 1e-06
I0823 02:16:51.109755 13823 solver.cpp:239] Iteration 339100 (9.51791 iter/s, 10.5065s/100 iters), loss = 0.031896
I0823 02:16:51.109812 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0318952 (* 1 = 0.0318952 loss)
I0823 02:16:51.109822 13823 sgd_solver.cpp:112] Iteration 339100, lr = 1e-06
I0823 02:17:01.891324 13823 solver.cpp:239] Iteration 339200 (9.27514 iter/s, 10.7815s/100 iters), loss = 0.0244497
I0823 02:17:01.891376 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0244488 (* 1 = 0.0244488 loss)
I0823 02:17:01.891386 13823 sgd_solver.cpp:112] Iteration 339200, lr = 1e-06
I0823 02:17:12.693869 13823 solver.cpp:239] Iteration 339300 (9.25713 iter/s, 10.8025s/100 iters), loss = 0.0271679
I0823 02:17:12.693930 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.027167 (* 1 = 0.027167 loss)
I0823 02:17:12.693941 13823 sgd_solver.cpp:112] Iteration 339300, lr = 1e-06
I0823 02:17:23.126222 13823 solver.cpp:239] Iteration 339400 (9.58563 iter/s, 10.4323s/100 iters), loss = 0.0306132
I0823 02:17:23.126274 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0306123 (* 1 = 0.0306123 loss)
I0823 02:17:23.126283 13823 sgd_solver.cpp:112] Iteration 339400, lr = 1e-06
I0823 02:17:33.980695 13823 solver.cpp:239] Iteration 339500 (9.2127 iter/s, 10.8546s/100 iters), loss = 0.032118
I0823 02:17:33.980753 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0321172 (* 1 = 0.0321172 loss)
I0823 02:17:33.980765 13823 sgd_solver.cpp:112] Iteration 339500, lr = 1e-06
I0823 02:17:44.384743 13823 solver.cpp:239] Iteration 339600 (9.61153 iter/s, 10.4042s/100 iters), loss = 0.0328182
I0823 02:17:44.384793 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0328173 (* 1 = 0.0328173 loss)
I0823 02:17:44.384802 13823 sgd_solver.cpp:112] Iteration 339600, lr = 1e-06
I0823 02:17:55.136145 13823 solver.cpp:239] Iteration 339700 (9.301 iter/s, 10.7515s/100 iters), loss = 0.0260958
I0823 02:17:55.136198 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0260949 (* 1 = 0.0260949 loss)
I0823 02:17:55.136209 13823 sgd_solver.cpp:112] Iteration 339700, lr = 1e-06
I0823 02:18:06.043121 13823 solver.cpp:239] Iteration 339800 (9.16833 iter/s, 10.9071s/100 iters), loss = 0.045075
I0823 02:18:06.043174 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0450741 (* 1 = 0.0450741 loss)
I0823 02:18:06.043184 13823 sgd_solver.cpp:112] Iteration 339800, lr = 1e-06
I0823 02:18:16.899129 13823 solver.cpp:239] Iteration 339900 (9.21138 iter/s, 10.8561s/100 iters), loss = 0.0238995
I0823 02:18:16.899184 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0238987 (* 1 = 0.0238987 loss)
I0823 02:18:16.899194 13823 sgd_solver.cpp:112] Iteration 339900, lr = 1e-06
I0823 02:18:27.374531 13823 solver.cpp:464] Snapshotting to binary proto file ./model_112/cascade_mobilenet_112_iter_340000.caffemodel
I0823 02:18:27.464813 13823 sgd_solver.cpp:284] Snapshotting solver state to binary proto file ./model_112/cascade_mobilenet_112_iter_340000.solverstate
I0823 02:18:27.507372 13823 solver.cpp:347] Iteration 340000, Testing net (#0)
I0823 02:19:38.122381 13823 solver.cpp:414]     Test net output #0: landmark_loss = 0.0218655 (* 1 = 0.0218655 loss)
I0823 02:19:38.213404 13823 solver.cpp:239] Iteration 340000 (1.22978 iter/s, 81.3155s/100 iters), loss = 0.0257207
I0823 02:19:38.213443 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0257198 (* 1 = 0.0257198 loss)
I0823 02:19:38.213452 13823 sgd_solver.cpp:112] Iteration 340000, lr = 1e-06
I0823 02:19:49.332859 13823 solver.cpp:239] Iteration 340100 (8.99315 iter/s, 11.1196s/100 iters), loss = 0.0262142
I0823 02:19:49.332916 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0262134 (* 1 = 0.0262134 loss)
I0823 02:19:49.332926 13823 sgd_solver.cpp:112] Iteration 340100, lr = 1e-06
I0823 02:20:00.081092 13823 solver.cpp:239] Iteration 340200 (9.30377 iter/s, 10.7483s/100 iters), loss = 0.025989
I0823 02:20:00.081141 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0259882 (* 1 = 0.0259882 loss)
I0823 02:20:00.081151 13823 sgd_solver.cpp:112] Iteration 340200, lr = 1e-06
I0823 02:20:11.165876 13823 solver.cpp:239] Iteration 340300 (9.02128 iter/s, 11.0849s/100 iters), loss = 0.0262818
I0823 02:20:11.165928 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0262809 (* 1 = 0.0262809 loss)
I0823 02:20:11.165938 13823 sgd_solver.cpp:112] Iteration 340300, lr = 1e-06
I0823 02:20:22.386211 13823 solver.cpp:239] Iteration 340400 (8.91231 iter/s, 11.2204s/100 iters), loss = 0.0375603
I0823 02:20:22.386276 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0375594 (* 1 = 0.0375594 loss)
I0823 02:20:22.386287 13823 sgd_solver.cpp:112] Iteration 340400, lr = 1e-06
I0823 02:20:33.303581 13823 solver.cpp:239] Iteration 340500 (9.15964 iter/s, 10.9175s/100 iters), loss = 0.029357
I0823 02:20:33.303639 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0293561 (* 1 = 0.0293561 loss)
I0823 02:20:33.303650 13823 sgd_solver.cpp:112] Iteration 340500, lr = 1e-06
I0823 02:20:44.485846 13823 solver.cpp:239] Iteration 340600 (8.94266 iter/s, 11.1824s/100 iters), loss = 0.0250719
I0823 02:20:44.485903 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.025071 (* 1 = 0.025071 loss)
I0823 02:20:44.485914 13823 sgd_solver.cpp:112] Iteration 340600, lr = 1e-06
I0823 02:20:55.857154 13823 solver.cpp:239] Iteration 340700 (8.79399 iter/s, 11.3714s/100 iters), loss = 0.0304338
I0823 02:20:55.857220 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0304329 (* 1 = 0.0304329 loss)
I0823 02:20:55.857234 13823 sgd_solver.cpp:112] Iteration 340700, lr = 1e-06
I0823 02:21:07.209548 13823 solver.cpp:239] Iteration 340800 (8.80865 iter/s, 11.3525s/100 iters), loss = 0.0268869
I0823 02:21:07.209604 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.026886 (* 1 = 0.026886 loss)
I0823 02:21:07.209614 13823 sgd_solver.cpp:112] Iteration 340800, lr = 1e-06
I0823 02:21:18.439918 13823 solver.cpp:239] Iteration 340900 (8.90435 iter/s, 11.2305s/100 iters), loss = 0.0357883
I0823 02:21:18.439970 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0357874 (* 1 = 0.0357874 loss)
I0823 02:21:18.439980 13823 sgd_solver.cpp:112] Iteration 340900, lr = 1e-06
I0823 02:21:29.352741 13823 solver.cpp:239] Iteration 341000 (9.16346 iter/s, 10.9129s/100 iters), loss = 0.024734
I0823 02:21:29.352797 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0247331 (* 1 = 0.0247331 loss)
I0823 02:21:29.352808 13823 sgd_solver.cpp:112] Iteration 341000, lr = 1e-06
I0823 02:21:40.599526 13823 solver.cpp:239] Iteration 341100 (8.89136 iter/s, 11.2469s/100 iters), loss = 0.0265689
I0823 02:21:40.599587 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.026568 (* 1 = 0.026568 loss)
I0823 02:21:40.599598 13823 sgd_solver.cpp:112] Iteration 341100, lr = 1e-06
I0823 02:21:51.333123 13823 solver.cpp:239] Iteration 341200 (9.31648 iter/s, 10.7337s/100 iters), loss = 0.0266194
I0823 02:21:51.333184 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0266186 (* 1 = 0.0266186 loss)
I0823 02:21:51.333194 13823 sgd_solver.cpp:112] Iteration 341200, lr = 1e-06
I0823 02:22:02.439952 13823 solver.cpp:239] Iteration 341300 (9.00341 iter/s, 11.1069s/100 iters), loss = 0.0244387
I0823 02:22:02.440001 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0244378 (* 1 = 0.0244378 loss)
I0823 02:22:02.440009 13823 sgd_solver.cpp:112] Iteration 341300, lr = 1e-06
I0823 02:22:13.486229 13823 solver.cpp:239] Iteration 341400 (9.05276 iter/s, 11.0464s/100 iters), loss = 0.0396051
I0823 02:22:13.486287 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0396043 (* 1 = 0.0396043 loss)
I0823 02:22:13.486299 13823 sgd_solver.cpp:112] Iteration 341400, lr = 1e-06
I0823 02:22:24.487124 13823 solver.cpp:239] Iteration 341500 (9.09011 iter/s, 11.001s/100 iters), loss = 0.0263246
I0823 02:22:24.487175 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0263237 (* 1 = 0.0263237 loss)
I0823 02:22:24.487185 13823 sgd_solver.cpp:112] Iteration 341500, lr = 1e-06
I0823 02:22:35.203619 13823 solver.cpp:239] Iteration 341600 (9.33135 iter/s, 10.7166s/100 iters), loss = 0.0276133
I0823 02:22:35.203667 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0276124 (* 1 = 0.0276124 loss)
I0823 02:22:35.203677 13823 sgd_solver.cpp:112] Iteration 341600, lr = 1e-06
I0823 02:22:46.136184 13823 solver.cpp:239] Iteration 341700 (9.14692 iter/s, 10.9326s/100 iters), loss = 0.0272486
I0823 02:22:46.136240 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0272478 (* 1 = 0.0272478 loss)
I0823 02:22:46.136251 13823 sgd_solver.cpp:112] Iteration 341700, lr = 1e-06
I0823 02:22:57.292433 13823 solver.cpp:239] Iteration 341800 (8.96353 iter/s, 11.1563s/100 iters), loss = 0.0241178
I0823 02:22:57.292485 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0241169 (* 1 = 0.0241169 loss)
I0823 02:22:57.292495 13823 sgd_solver.cpp:112] Iteration 341800, lr = 1e-06
I0823 02:23:08.368219 13823 solver.cpp:239] Iteration 341900 (9.02865 iter/s, 11.0759s/100 iters), loss = 0.0290845
I0823 02:23:08.368270 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0290837 (* 1 = 0.0290837 loss)
I0823 02:23:08.368280 13823 sgd_solver.cpp:112] Iteration 341900, lr = 1e-06
I0823 02:23:19.772845 13823 solver.cpp:239] Iteration 342000 (8.76832 iter/s, 11.4047s/100 iters), loss = 0.0261158
I0823 02:23:19.772900 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.026115 (* 1 = 0.026115 loss)
I0823 02:23:19.772912 13823 sgd_solver.cpp:112] Iteration 342000, lr = 1e-06
I0823 02:23:30.956336 13823 solver.cpp:239] Iteration 342100 (8.9417 iter/s, 11.1836s/100 iters), loss = 0.0278391
I0823 02:23:30.956383 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0278382 (* 1 = 0.0278382 loss)
I0823 02:23:30.956393 13823 sgd_solver.cpp:112] Iteration 342100, lr = 1e-06
I0823 02:23:42.111340 13823 solver.cpp:239] Iteration 342200 (8.96453 iter/s, 11.1551s/100 iters), loss = 0.025234
I0823 02:23:42.111400 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0252331 (* 1 = 0.0252331 loss)
I0823 02:23:42.111413 13823 sgd_solver.cpp:112] Iteration 342200, lr = 1e-06
I0823 02:23:53.243149 13823 solver.cpp:239] Iteration 342300 (8.98322 iter/s, 11.1319s/100 iters), loss = 0.0270842
I0823 02:23:53.243201 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0270833 (* 1 = 0.0270833 loss)
I0823 02:23:53.243209 13823 sgd_solver.cpp:112] Iteration 342300, lr = 1e-06
I0823 02:24:04.213778 13823 solver.cpp:239] Iteration 342400 (9.1152 iter/s, 10.9707s/100 iters), loss = 0.0338246
I0823 02:24:04.213829 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0338238 (* 1 = 0.0338238 loss)
I0823 02:24:04.213837 13823 sgd_solver.cpp:112] Iteration 342400, lr = 1e-06
I0823 02:24:15.130848 13823 solver.cpp:239] Iteration 342500 (9.15992 iter/s, 10.9171s/100 iters), loss = 0.0307978
I0823 02:24:15.130905 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0307969 (* 1 = 0.0307969 loss)
I0823 02:24:15.130916 13823 sgd_solver.cpp:112] Iteration 342500, lr = 1e-06
I0823 02:24:26.101487 13823 solver.cpp:239] Iteration 342600 (9.1152 iter/s, 10.9707s/100 iters), loss = 0.0277081
I0823 02:24:26.101539 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0277072 (* 1 = 0.0277072 loss)
I0823 02:24:26.101549 13823 sgd_solver.cpp:112] Iteration 342600, lr = 1e-06
I0823 02:24:37.126196 13823 solver.cpp:239] Iteration 342700 (9.07049 iter/s, 11.0248s/100 iters), loss = 0.0312513
I0823 02:24:37.126257 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0312504 (* 1 = 0.0312504 loss)
I0823 02:24:37.126269 13823 sgd_solver.cpp:112] Iteration 342700, lr = 1e-06
I0823 02:24:47.980552 13823 solver.cpp:239] Iteration 342800 (9.21285 iter/s, 10.8544s/100 iters), loss = 0.035161
I0823 02:24:47.980602 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0351601 (* 1 = 0.0351601 loss)
I0823 02:24:47.980612 13823 sgd_solver.cpp:112] Iteration 342800, lr = 1e-06
I0823 02:24:59.068691 13823 solver.cpp:239] Iteration 342900 (9.01861 iter/s, 11.0882s/100 iters), loss = 0.0310153
I0823 02:24:59.068747 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0310144 (* 1 = 0.0310144 loss)
I0823 02:24:59.068758 13823 sgd_solver.cpp:112] Iteration 342900, lr = 1e-06
I0823 02:25:10.316395 13823 solver.cpp:239] Iteration 343000 (8.89067 iter/s, 11.2478s/100 iters), loss = 0.0264637
I0823 02:25:10.316452 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0264628 (* 1 = 0.0264628 loss)
I0823 02:25:10.316463 13823 sgd_solver.cpp:112] Iteration 343000, lr = 1e-06
I0823 02:25:21.551723 13823 solver.cpp:239] Iteration 343100 (8.90046 iter/s, 11.2354s/100 iters), loss = 0.026909
I0823 02:25:21.551776 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0269081 (* 1 = 0.0269081 loss)
I0823 02:25:21.551786 13823 sgd_solver.cpp:112] Iteration 343100, lr = 1e-06
I0823 02:25:32.945781 13823 solver.cpp:239] Iteration 343200 (8.77647 iter/s, 11.3941s/100 iters), loss = 0.0252931
I0823 02:25:32.945838 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0252922 (* 1 = 0.0252922 loss)
I0823 02:25:32.945849 13823 sgd_solver.cpp:112] Iteration 343200, lr = 1e-06
I0823 02:25:44.238140 13823 solver.cpp:239] Iteration 343300 (8.85551 iter/s, 11.2924s/100 iters), loss = 0.0274596
I0823 02:25:44.238201 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0274587 (* 1 = 0.0274587 loss)
I0823 02:25:44.238214 13823 sgd_solver.cpp:112] Iteration 343300, lr = 1e-06
I0823 02:25:55.801128 13823 solver.cpp:239] Iteration 343400 (8.64825 iter/s, 11.563s/100 iters), loss = 0.0246481
I0823 02:25:55.801179 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0246472 (* 1 = 0.0246472 loss)
I0823 02:25:55.801189 13823 sgd_solver.cpp:112] Iteration 343400, lr = 1e-06
I0823 02:26:07.339006 13823 solver.cpp:239] Iteration 343500 (8.66707 iter/s, 11.5379s/100 iters), loss = 0.0223111
I0823 02:26:07.339066 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0223102 (* 1 = 0.0223102 loss)
I0823 02:26:07.339078 13823 sgd_solver.cpp:112] Iteration 343500, lr = 1e-06
I0823 02:26:18.526124 13823 solver.cpp:239] Iteration 343600 (8.93882 iter/s, 11.1872s/100 iters), loss = 0.0231264
I0823 02:26:18.526175 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0231255 (* 1 = 0.0231255 loss)
I0823 02:26:18.526183 13823 sgd_solver.cpp:112] Iteration 343600, lr = 1e-06
I0823 02:26:29.917515 13823 solver.cpp:239] Iteration 343700 (8.77853 iter/s, 11.3914s/100 iters), loss = 0.0281855
I0823 02:26:29.917577 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0281846 (* 1 = 0.0281846 loss)
I0823 02:26:29.917588 13823 sgd_solver.cpp:112] Iteration 343700, lr = 1e-06
I0823 02:26:40.951797 13823 solver.cpp:239] Iteration 343800 (9.06264 iter/s, 11.0343s/100 iters), loss = 0.0268073
I0823 02:26:40.951853 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0268064 (* 1 = 0.0268064 loss)
I0823 02:26:40.951862 13823 sgd_solver.cpp:112] Iteration 343800, lr = 1e-06
I0823 02:26:52.305052 13823 solver.cpp:239] Iteration 343900 (8.80802 iter/s, 11.3533s/100 iters), loss = 0.0250532
I0823 02:26:52.305107 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0250523 (* 1 = 0.0250523 loss)
I0823 02:26:52.305119 13823 sgd_solver.cpp:112] Iteration 343900, lr = 1e-06
I0823 02:27:03.849496 13823 solver.cpp:239] Iteration 344000 (8.66215 iter/s, 11.5445s/100 iters), loss = 0.0259144
I0823 02:27:03.849555 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0259135 (* 1 = 0.0259135 loss)
I0823 02:27:03.849567 13823 sgd_solver.cpp:112] Iteration 344000, lr = 1e-06
I0823 02:27:15.011895 13823 solver.cpp:239] Iteration 344100 (8.95862 iter/s, 11.1624s/100 iters), loss = 0.0371719
I0823 02:27:15.011960 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.037171 (* 1 = 0.037171 loss)
I0823 02:27:15.011973 13823 sgd_solver.cpp:112] Iteration 344100, lr = 1e-06
I0823 02:27:26.274541 13823 solver.cpp:239] Iteration 344200 (8.87889 iter/s, 11.2627s/100 iters), loss = 0.0269659
I0823 02:27:26.274600 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.026965 (* 1 = 0.026965 loss)
I0823 02:27:26.274611 13823 sgd_solver.cpp:112] Iteration 344200, lr = 1e-06
I0823 02:27:37.631281 13823 solver.cpp:239] Iteration 344300 (8.80532 iter/s, 11.3568s/100 iters), loss = 0.0255036
I0823 02:27:37.631332 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0255027 (* 1 = 0.0255027 loss)
I0823 02:27:37.631341 13823 sgd_solver.cpp:112] Iteration 344300, lr = 1e-06
I0823 02:27:49.070473 13823 solver.cpp:239] Iteration 344400 (8.74185 iter/s, 11.4392s/100 iters), loss = 0.0301655
I0823 02:27:49.070534 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0301646 (* 1 = 0.0301646 loss)
I0823 02:27:49.070549 13823 sgd_solver.cpp:112] Iteration 344400, lr = 1e-06
I0823 02:28:00.367125 13823 solver.cpp:239] Iteration 344500 (8.85216 iter/s, 11.2967s/100 iters), loss = 0.0291353
I0823 02:28:00.367177 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0291343 (* 1 = 0.0291343 loss)
I0823 02:28:00.367185 13823 sgd_solver.cpp:112] Iteration 344500, lr = 1e-06
I0823 02:28:11.645818 13823 solver.cpp:239] Iteration 344600 (8.86625 iter/s, 11.2787s/100 iters), loss = 0.027421
I0823 02:28:11.645869 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0274201 (* 1 = 0.0274201 loss)
I0823 02:28:11.645879 13823 sgd_solver.cpp:112] Iteration 344600, lr = 1e-06
I0823 02:28:22.807633 13823 solver.cpp:239] Iteration 344700 (8.95909 iter/s, 11.1618s/100 iters), loss = 0.0265143
I0823 02:28:22.807684 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0265134 (* 1 = 0.0265134 loss)
I0823 02:28:22.807694 13823 sgd_solver.cpp:112] Iteration 344700, lr = 1e-06
I0823 02:28:34.139430 13823 solver.cpp:239] Iteration 344800 (8.8247 iter/s, 11.3318s/100 iters), loss = 0.0277537
I0823 02:28:34.139490 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0277528 (* 1 = 0.0277528 loss)
I0823 02:28:34.139504 13823 sgd_solver.cpp:112] Iteration 344800, lr = 1e-06
I0823 02:28:45.412983 13823 solver.cpp:239] Iteration 344900 (8.8703 iter/s, 11.2736s/100 iters), loss = 0.0250189
I0823 02:28:45.413044 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.025018 (* 1 = 0.025018 loss)
I0823 02:28:45.413059 13823 sgd_solver.cpp:112] Iteration 344900, lr = 1e-06
I0823 02:28:56.941560 13823 solver.cpp:239] Iteration 345000 (8.67408 iter/s, 11.5286s/100 iters), loss = 0.0267225
I0823 02:28:56.941615 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0267216 (* 1 = 0.0267216 loss)
I0823 02:28:56.941627 13823 sgd_solver.cpp:112] Iteration 345000, lr = 1e-06
I0823 02:29:08.524642 13823 solver.cpp:239] Iteration 345100 (8.63326 iter/s, 11.5831s/100 iters), loss = 0.0247656
I0823 02:29:08.524695 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0247647 (* 1 = 0.0247647 loss)
I0823 02:29:08.524705 13823 sgd_solver.cpp:112] Iteration 345100, lr = 1e-06
I0823 02:29:20.023872 13823 solver.cpp:239] Iteration 345200 (8.69621 iter/s, 11.4993s/100 iters), loss = 0.0314631
I0823 02:29:20.023924 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0314622 (* 1 = 0.0314622 loss)
I0823 02:29:20.023934 13823 sgd_solver.cpp:112] Iteration 345200, lr = 1e-06
I0823 02:29:31.495985 13823 solver.cpp:239] Iteration 345300 (8.71677 iter/s, 11.4721s/100 iters), loss = 0.0258135
I0823 02:29:31.496035 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0258126 (* 1 = 0.0258126 loss)
I0823 02:29:31.496045 13823 sgd_solver.cpp:112] Iteration 345300, lr = 1e-06
I0823 02:29:42.864190 13823 solver.cpp:239] Iteration 345400 (8.79645 iter/s, 11.3682s/100 iters), loss = 0.0275832
I0823 02:29:42.864259 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0275823 (* 1 = 0.0275823 loss)
I0823 02:29:42.864274 13823 sgd_solver.cpp:112] Iteration 345400, lr = 1e-06
I0823 02:29:54.452572 13823 solver.cpp:239] Iteration 345500 (8.62932 iter/s, 11.5884s/100 iters), loss = 0.0282825
I0823 02:29:54.452627 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0282816 (* 1 = 0.0282816 loss)
I0823 02:29:54.452639 13823 sgd_solver.cpp:112] Iteration 345500, lr = 1e-06
I0823 02:30:05.899538 13823 solver.cpp:239] Iteration 345600 (8.73592 iter/s, 11.447s/100 iters), loss = 0.027623
I0823 02:30:05.899595 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0276221 (* 1 = 0.0276221 loss)
I0823 02:30:05.899605 13823 sgd_solver.cpp:112] Iteration 345600, lr = 1e-06
I0823 02:30:17.061619 13823 solver.cpp:239] Iteration 345700 (8.95889 iter/s, 11.1621s/100 iters), loss = 0.0307037
I0823 02:30:17.061671 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0307028 (* 1 = 0.0307028 loss)
I0823 02:30:17.061681 13823 sgd_solver.cpp:112] Iteration 345700, lr = 1e-06
I0823 02:30:28.330857 13823 solver.cpp:239] Iteration 345800 (8.8737 iter/s, 11.2693s/100 iters), loss = 0.0271475
I0823 02:30:28.330915 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0271465 (* 1 = 0.0271465 loss)
I0823 02:30:28.330929 13823 sgd_solver.cpp:112] Iteration 345800, lr = 1e-06
I0823 02:30:39.780047 13823 solver.cpp:239] Iteration 345900 (8.73423 iter/s, 11.4492s/100 iters), loss = 0.0256312
I0823 02:30:39.780117 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0256303 (* 1 = 0.0256303 loss)
I0823 02:30:39.780143 13823 sgd_solver.cpp:112] Iteration 345900, lr = 1e-06
I0823 02:30:51.399128 13823 solver.cpp:239] Iteration 346000 (8.60653 iter/s, 11.6191s/100 iters), loss = 0.0307812
I0823 02:30:51.399183 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0307803 (* 1 = 0.0307803 loss)
I0823 02:30:51.399194 13823 sgd_solver.cpp:112] Iteration 346000, lr = 1e-06
I0823 02:31:02.919286 13823 solver.cpp:239] Iteration 346100 (8.68042 iter/s, 11.5202s/100 iters), loss = 0.0302691
I0823 02:31:02.919335 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0302682 (* 1 = 0.0302682 loss)
I0823 02:31:02.919345 13823 sgd_solver.cpp:112] Iteration 346100, lr = 1e-06
I0823 02:31:13.872079 13823 solver.cpp:239] Iteration 346200 (9.13008 iter/s, 10.9528s/100 iters), loss = 0.0251747
I0823 02:31:13.872134 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0251738 (* 1 = 0.0251738 loss)
I0823 02:31:13.872144 13823 sgd_solver.cpp:112] Iteration 346200, lr = 1e-06
I0823 02:31:24.803419 13823 solver.cpp:239] Iteration 346300 (9.148 iter/s, 10.9314s/100 iters), loss = 0.0251271
I0823 02:31:24.803481 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0251262 (* 1 = 0.0251262 loss)
I0823 02:31:24.803494 13823 sgd_solver.cpp:112] Iteration 346300, lr = 1e-06
I0823 02:31:36.571286 13823 solver.cpp:239] Iteration 346400 (8.49771 iter/s, 11.7679s/100 iters), loss = 0.0264904
I0823 02:31:36.571357 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0264895 (* 1 = 0.0264895 loss)
I0823 02:31:36.571372 13823 sgd_solver.cpp:112] Iteration 346400, lr = 1e-06
I0823 02:31:48.267179 13823 solver.cpp:239] Iteration 346500 (8.55001 iter/s, 11.6959s/100 iters), loss = 0.0255581
I0823 02:31:48.267235 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0255572 (* 1 = 0.0255572 loss)
I0823 02:31:48.267247 13823 sgd_solver.cpp:112] Iteration 346500, lr = 1e-06
I0823 02:31:59.811645 13823 solver.cpp:239] Iteration 346600 (8.66215 iter/s, 11.5445s/100 iters), loss = 0.0281963
I0823 02:31:59.811704 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0281954 (* 1 = 0.0281954 loss)
I0823 02:31:59.811717 13823 sgd_solver.cpp:112] Iteration 346600, lr = 1e-06
I0823 02:32:11.520447 13823 solver.cpp:239] Iteration 346700 (8.54057 iter/s, 11.7088s/100 iters), loss = 0.0247048
I0823 02:32:11.520503 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0247039 (* 1 = 0.0247039 loss)
I0823 02:32:11.520512 13823 sgd_solver.cpp:112] Iteration 346700, lr = 1e-06
I0823 02:32:23.186676 13823 solver.cpp:239] Iteration 346800 (8.57174 iter/s, 11.6662s/100 iters), loss = 0.0370254
I0823 02:32:23.186739 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0370245 (* 1 = 0.0370245 loss)
I0823 02:32:23.186753 13823 sgd_solver.cpp:112] Iteration 346800, lr = 1e-06
I0823 02:32:34.754961 13823 solver.cpp:239] Iteration 346900 (8.64432 iter/s, 11.5683s/100 iters), loss = 0.0270693
I0823 02:32:34.755013 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0270684 (* 1 = 0.0270684 loss)
I0823 02:32:34.755023 13823 sgd_solver.cpp:112] Iteration 346900, lr = 1e-06
I0823 02:32:45.133569 13823 solver.cpp:239] Iteration 347000 (9.6352 iter/s, 10.3786s/100 iters), loss = 0.0281072
I0823 02:32:45.133618 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0281063 (* 1 = 0.0281063 loss)
I0823 02:32:45.133628 13823 sgd_solver.cpp:112] Iteration 347000, lr = 1e-06
I0823 02:32:54.891988 13823 solver.cpp:239] Iteration 347100 (10.2476 iter/s, 9.75842s/100 iters), loss = 0.0289016
I0823 02:32:54.892041 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0289007 (* 1 = 0.0289007 loss)
I0823 02:32:54.892051 13823 sgd_solver.cpp:112] Iteration 347100, lr = 1e-06
I0823 02:33:04.456981 13823 solver.cpp:239] Iteration 347200 (10.4548 iter/s, 9.56499s/100 iters), loss = 0.0371112
I0823 02:33:04.457043 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0371103 (* 1 = 0.0371103 loss)
I0823 02:33:04.457056 13823 sgd_solver.cpp:112] Iteration 347200, lr = 1e-06
I0823 02:33:14.301316 13823 solver.cpp:239] Iteration 347300 (10.1581 iter/s, 9.84433s/100 iters), loss = 0.0244262
I0823 02:33:14.301373 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0244253 (* 1 = 0.0244253 loss)
I0823 02:33:14.301385 13823 sgd_solver.cpp:112] Iteration 347300, lr = 1e-06
I0823 02:33:24.071703 13823 solver.cpp:239] Iteration 347400 (10.235 iter/s, 9.77039s/100 iters), loss = 0.0273046
I0823 02:33:24.071753 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0273037 (* 1 = 0.0273037 loss)
I0823 02:33:24.071763 13823 sgd_solver.cpp:112] Iteration 347400, lr = 1e-06
I0823 02:33:33.760885 13823 solver.cpp:239] Iteration 347500 (10.3208 iter/s, 9.68918s/100 iters), loss = 0.0337543
I0823 02:33:33.760941 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0337534 (* 1 = 0.0337534 loss)
I0823 02:33:33.760951 13823 sgd_solver.cpp:112] Iteration 347500, lr = 1e-06
I0823 02:33:43.566004 13823 solver.cpp:239] Iteration 347600 (10.1988 iter/s, 9.80511s/100 iters), loss = 0.0236075
I0823 02:33:43.566054 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0236066 (* 1 = 0.0236066 loss)
I0823 02:33:43.566064 13823 sgd_solver.cpp:112] Iteration 347600, lr = 1e-06
I0823 02:33:53.387353 13823 solver.cpp:239] Iteration 347700 (10.1819 iter/s, 9.82135s/100 iters), loss = 0.0285678
I0823 02:33:53.387403 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0285669 (* 1 = 0.0285669 loss)
I0823 02:33:53.387413 13823 sgd_solver.cpp:112] Iteration 347700, lr = 1e-06
I0823 02:34:03.121167 13823 solver.cpp:239] Iteration 347800 (10.2735 iter/s, 9.73381s/100 iters), loss = 0.028104
I0823 02:34:03.121222 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.028103 (* 1 = 0.028103 loss)
I0823 02:34:03.121232 13823 sgd_solver.cpp:112] Iteration 347800, lr = 1e-06
I0823 02:34:12.546872 13823 solver.cpp:239] Iteration 347900 (10.6093 iter/s, 9.4257s/100 iters), loss = 0.0251051
I0823 02:34:12.546914 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0251042 (* 1 = 0.0251042 loss)
I0823 02:34:12.546922 13823 sgd_solver.cpp:112] Iteration 347900, lr = 1e-06
I0823 02:34:22.064810 13823 solver.cpp:239] Iteration 348000 (10.5065 iter/s, 9.51794s/100 iters), loss = 0.030086
I0823 02:34:22.064859 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.030085 (* 1 = 0.030085 loss)
I0823 02:34:22.064869 13823 sgd_solver.cpp:112] Iteration 348000, lr = 1e-06
I0823 02:34:31.774000 13823 solver.cpp:239] Iteration 348100 (10.2995 iter/s, 9.70918s/100 iters), loss = 0.0299298
I0823 02:34:31.774060 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0299289 (* 1 = 0.0299289 loss)
I0823 02:34:31.774072 13823 sgd_solver.cpp:112] Iteration 348100, lr = 1e-06
I0823 02:34:41.742589 13823 solver.cpp:239] Iteration 348200 (10.0315 iter/s, 9.96858s/100 iters), loss = 0.0238547
I0823 02:34:41.742641 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0238538 (* 1 = 0.0238538 loss)
I0823 02:34:41.742651 13823 sgd_solver.cpp:112] Iteration 348200, lr = 1e-06
I0823 02:34:51.338760 13823 solver.cpp:239] Iteration 348300 (10.4208 iter/s, 9.59617s/100 iters), loss = 0.0251582
I0823 02:34:51.338804 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0251573 (* 1 = 0.0251573 loss)
I0823 02:34:51.338811 13823 sgd_solver.cpp:112] Iteration 348300, lr = 1e-06
I0823 02:35:00.830332 13823 solver.cpp:239] Iteration 348400 (10.5357 iter/s, 9.49157s/100 iters), loss = 0.0254506
I0823 02:35:00.830384 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0254497 (* 1 = 0.0254497 loss)
I0823 02:35:00.830392 13823 sgd_solver.cpp:112] Iteration 348400, lr = 1e-06
I0823 02:35:10.574872 13823 solver.cpp:239] Iteration 348500 (10.2622 iter/s, 9.74453s/100 iters), loss = 0.0287063
I0823 02:35:10.574921 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0287054 (* 1 = 0.0287054 loss)
I0823 02:35:10.574930 13823 sgd_solver.cpp:112] Iteration 348500, lr = 1e-06
I0823 02:35:20.139461 13823 solver.cpp:239] Iteration 348600 (10.4552 iter/s, 9.56458s/100 iters), loss = 0.0260806
I0823 02:35:20.139513 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0260796 (* 1 = 0.0260796 loss)
I0823 02:35:20.139523 13823 sgd_solver.cpp:112] Iteration 348600, lr = 1e-06
I0823 02:35:29.857827 13823 solver.cpp:239] Iteration 348700 (10.2898 iter/s, 9.71836s/100 iters), loss = 0.030043
I0823 02:35:29.857878 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0300421 (* 1 = 0.0300421 loss)
I0823 02:35:29.857887 13823 sgd_solver.cpp:112] Iteration 348700, lr = 1e-06
I0823 02:35:39.625236 13823 solver.cpp:239] Iteration 348800 (10.2381 iter/s, 9.76741s/100 iters), loss = 0.0223223
I0823 02:35:39.625281 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0223214 (* 1 = 0.0223214 loss)
I0823 02:35:39.625291 13823 sgd_solver.cpp:112] Iteration 348800, lr = 1e-06
I0823 02:35:49.429459 13823 solver.cpp:239] Iteration 348900 (10.1997 iter/s, 9.80422s/100 iters), loss = 0.0277723
I0823 02:35:49.429517 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0277714 (* 1 = 0.0277714 loss)
I0823 02:35:49.429530 13823 sgd_solver.cpp:112] Iteration 348900, lr = 1e-06
I0823 02:35:58.980715 13823 solver.cpp:239] Iteration 349000 (10.4698 iter/s, 9.55125s/100 iters), loss = 0.027185
I0823 02:35:58.980757 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0271841 (* 1 = 0.0271841 loss)
I0823 02:35:58.980765 13823 sgd_solver.cpp:112] Iteration 349000, lr = 1e-06
I0823 02:36:08.410483 13823 solver.cpp:239] Iteration 349100 (10.6047 iter/s, 9.42976s/100 iters), loss = 0.0230854
I0823 02:36:08.410534 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0230845 (* 1 = 0.0230845 loss)
I0823 02:36:08.410543 13823 sgd_solver.cpp:112] Iteration 349100, lr = 1e-06
I0823 02:36:17.702015 13823 solver.cpp:239] Iteration 349200 (10.7625 iter/s, 9.29153s/100 iters), loss = 0.0282119
I0823 02:36:17.702059 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.028211 (* 1 = 0.028211 loss)
I0823 02:36:17.702065 13823 sgd_solver.cpp:112] Iteration 349200, lr = 1e-06
I0823 02:36:26.984992 13823 solver.cpp:239] Iteration 349300 (10.7724 iter/s, 9.28298s/100 iters), loss = 0.0378186
I0823 02:36:26.985035 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0378177 (* 1 = 0.0378177 loss)
I0823 02:36:26.985044 13823 sgd_solver.cpp:112] Iteration 349300, lr = 1e-06
I0823 02:36:36.231180 13823 solver.cpp:239] Iteration 349400 (10.8153 iter/s, 9.24619s/100 iters), loss = 0.0260197
I0823 02:36:36.231225 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0260188 (* 1 = 0.0260188 loss)
I0823 02:36:36.231231 13823 sgd_solver.cpp:112] Iteration 349400, lr = 1e-06
I0823 02:36:45.781744 13823 solver.cpp:239] Iteration 349500 (10.4706 iter/s, 9.55056s/100 iters), loss = 0.031767
I0823 02:36:45.781786 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0317661 (* 1 = 0.0317661 loss)
I0823 02:36:45.781793 13823 sgd_solver.cpp:112] Iteration 349500, lr = 1e-06
I0823 02:36:55.162647 13823 solver.cpp:239] Iteration 349600 (10.66 iter/s, 9.3809s/100 iters), loss = 0.0240239
I0823 02:36:55.162688 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.024023 (* 1 = 0.024023 loss)
I0823 02:36:55.162695 13823 sgd_solver.cpp:112] Iteration 349600, lr = 1e-06
I0823 02:37:04.717865 13823 solver.cpp:239] Iteration 349700 (10.4655 iter/s, 9.55522s/100 iters), loss = 0.0273405
I0823 02:37:04.717907 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0273396 (* 1 = 0.0273396 loss)
I0823 02:37:04.717916 13823 sgd_solver.cpp:112] Iteration 349700, lr = 1e-06
I0823 02:37:13.908263 13823 solver.cpp:239] Iteration 349800 (10.8809 iter/s, 9.1904s/100 iters), loss = 0.0239723
I0823 02:37:13.908306 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0239714 (* 1 = 0.0239714 loss)
I0823 02:37:13.908314 13823 sgd_solver.cpp:112] Iteration 349800, lr = 1e-06
I0823 02:37:23.738879 13823 solver.cpp:239] Iteration 349900 (10.1723 iter/s, 9.83061s/100 iters), loss = 0.025491
I0823 02:37:23.738929 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.02549 (* 1 = 0.02549 loss)
I0823 02:37:23.738940 13823 sgd_solver.cpp:112] Iteration 349900, lr = 1e-06
I0823 02:37:33.338567 13823 solver.cpp:239] Iteration 350000 (10.417 iter/s, 9.59968s/100 iters), loss = 0.0256476
I0823 02:37:33.338608 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0256467 (* 1 = 0.0256467 loss)
I0823 02:37:33.338614 13823 sgd_solver.cpp:112] Iteration 350000, lr = 1e-06
I0823 02:37:43.286283 13823 solver.cpp:239] Iteration 350100 (10.0526 iter/s, 9.94771s/100 iters), loss = 0.0254859
I0823 02:37:43.286348 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.025485 (* 1 = 0.025485 loss)
I0823 02:37:43.286363 13823 sgd_solver.cpp:112] Iteration 350100, lr = 1e-06
I0823 02:37:53.116053 13823 solver.cpp:239] Iteration 350200 (10.1732 iter/s, 9.82975s/100 iters), loss = 0.0270197
I0823 02:37:53.116096 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0270188 (* 1 = 0.0270188 loss)
I0823 02:37:53.116102 13823 sgd_solver.cpp:112] Iteration 350200, lr = 1e-06
I0823 02:38:02.577394 13823 solver.cpp:239] Iteration 350300 (10.5693 iter/s, 9.46134s/100 iters), loss = 0.0270494
I0823 02:38:02.577435 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0270485 (* 1 = 0.0270485 loss)
I0823 02:38:02.577442 13823 sgd_solver.cpp:112] Iteration 350300, lr = 1e-06
I0823 02:38:11.899523 13823 solver.cpp:239] Iteration 350400 (10.7272 iter/s, 9.32213s/100 iters), loss = 0.0341315
I0823 02:38:11.899569 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0341306 (* 1 = 0.0341306 loss)
I0823 02:38:11.899576 13823 sgd_solver.cpp:112] Iteration 350400, lr = 1e-06
I0823 02:38:21.279556 13823 solver.cpp:239] Iteration 350500 (10.6609 iter/s, 9.38003s/100 iters), loss = 0.0259893
I0823 02:38:21.279599 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0259884 (* 1 = 0.0259884 loss)
I0823 02:38:21.279606 13823 sgd_solver.cpp:112] Iteration 350500, lr = 1e-06
I0823 02:38:30.731478 13823 solver.cpp:239] Iteration 350600 (10.5799 iter/s, 9.45191s/100 iters), loss = 0.0279288
I0823 02:38:30.731535 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0279279 (* 1 = 0.0279279 loss)
I0823 02:38:30.731549 13823 sgd_solver.cpp:112] Iteration 350600, lr = 1e-06
I0823 02:38:40.733654 13823 solver.cpp:239] Iteration 350700 (9.99784 iter/s, 10.0022s/100 iters), loss = 0.0253605
I0823 02:38:40.733705 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0253596 (* 1 = 0.0253596 loss)
I0823 02:38:40.733712 13823 sgd_solver.cpp:112] Iteration 350700, lr = 1e-06
I0823 02:38:50.582999 13823 solver.cpp:239] Iteration 350800 (10.153 iter/s, 9.84933s/100 iters), loss = 0.0250064
I0823 02:38:50.583065 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0250055 (* 1 = 0.0250055 loss)
I0823 02:38:50.583077 13823 sgd_solver.cpp:112] Iteration 350800, lr = 1e-06
I0823 02:39:00.212556 13823 solver.cpp:239] Iteration 350900 (10.3847 iter/s, 9.62953s/100 iters), loss = 0.024996
I0823 02:39:00.212607 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0249951 (* 1 = 0.0249951 loss)
I0823 02:39:00.212617 13823 sgd_solver.cpp:112] Iteration 350900, lr = 1e-06
I0823 02:39:09.946395 13823 solver.cpp:239] Iteration 351000 (10.2735 iter/s, 9.73382s/100 iters), loss = 0.0319249
I0823 02:39:09.946445 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.031924 (* 1 = 0.031924 loss)
I0823 02:39:09.946455 13823 sgd_solver.cpp:112] Iteration 351000, lr = 1e-06
I0823 02:39:19.800364 13823 solver.cpp:239] Iteration 351100 (10.1482 iter/s, 9.85396s/100 iters), loss = 0.0234952
I0823 02:39:19.800412 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0234943 (* 1 = 0.0234943 loss)
I0823 02:39:19.800422 13823 sgd_solver.cpp:112] Iteration 351100, lr = 1e-06
I0823 02:39:29.728437 13823 solver.cpp:239] Iteration 351200 (10.0725 iter/s, 9.92806s/100 iters), loss = 0.0246226
I0823 02:39:29.728490 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0246217 (* 1 = 0.0246217 loss)
I0823 02:39:29.728500 13823 sgd_solver.cpp:112] Iteration 351200, lr = 1e-06
I0823 02:39:39.470039 13823 solver.cpp:239] Iteration 351300 (10.2653 iter/s, 9.74159s/100 iters), loss = 0.0384278
I0823 02:39:39.470089 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0384269 (* 1 = 0.0384269 loss)
I0823 02:39:39.470099 13823 sgd_solver.cpp:112] Iteration 351300, lr = 1e-06
I0823 02:39:49.393698 13823 solver.cpp:239] Iteration 351400 (10.0769 iter/s, 9.92365s/100 iters), loss = 0.0337767
I0823 02:39:49.393752 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0337758 (* 1 = 0.0337758 loss)
I0823 02:39:49.393760 13823 sgd_solver.cpp:112] Iteration 351400, lr = 1e-06
I0823 02:39:58.958456 13823 solver.cpp:239] Iteration 351500 (10.4551 iter/s, 9.56474s/100 iters), loss = 0.0248689
I0823 02:39:58.958498 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.024868 (* 1 = 0.024868 loss)
I0823 02:39:58.958504 13823 sgd_solver.cpp:112] Iteration 351500, lr = 1e-06
I0823 02:40:08.451416 13823 solver.cpp:239] Iteration 351600 (10.5341 iter/s, 9.49296s/100 iters), loss = 0.0233036
I0823 02:40:08.451458 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0233027 (* 1 = 0.0233027 loss)
I0823 02:40:08.451467 13823 sgd_solver.cpp:112] Iteration 351600, lr = 1e-06
I0823 02:40:18.342767 13823 solver.cpp:239] Iteration 351700 (10.1099 iter/s, 9.89134s/100 iters), loss = 0.026003
I0823 02:40:18.342824 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0260021 (* 1 = 0.0260021 loss)
I0823 02:40:18.342837 13823 sgd_solver.cpp:112] Iteration 351700, lr = 1e-06
I0823 02:40:28.147054 13823 solver.cpp:239] Iteration 351800 (10.1996 iter/s, 9.80427s/100 iters), loss = 0.0227224
I0823 02:40:28.147119 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0227215 (* 1 = 0.0227215 loss)
I0823 02:40:28.147133 13823 sgd_solver.cpp:112] Iteration 351800, lr = 1e-06
I0823 02:40:37.818310 13823 solver.cpp:239] Iteration 351900 (10.3399 iter/s, 9.67123s/100 iters), loss = 0.0253895
I0823 02:40:37.818374 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0253886 (* 1 = 0.0253886 loss)
I0823 02:40:37.818390 13823 sgd_solver.cpp:112] Iteration 351900, lr = 1e-06
I0823 02:40:47.683923 13823 solver.cpp:239] Iteration 352000 (10.1362 iter/s, 9.86559s/100 iters), loss = 0.0277305
I0823 02:40:47.684000 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0277296 (* 1 = 0.0277296 loss)
I0823 02:40:47.684016 13823 sgd_solver.cpp:112] Iteration 352000, lr = 1e-06
I0823 02:40:57.631232 13823 solver.cpp:239] Iteration 352100 (10.053 iter/s, 9.94728s/100 iters), loss = 0.0283305
I0823 02:40:57.631289 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0283296 (* 1 = 0.0283296 loss)
I0823 02:40:57.631302 13823 sgd_solver.cpp:112] Iteration 352100, lr = 1e-06
I0823 02:41:07.376760 13823 solver.cpp:239] Iteration 352200 (10.2611 iter/s, 9.74551s/100 iters), loss = 0.0232751
I0823 02:41:07.376806 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0232742 (* 1 = 0.0232742 loss)
I0823 02:41:07.376816 13823 sgd_solver.cpp:112] Iteration 352200, lr = 1e-06
I0823 02:41:17.201427 13823 solver.cpp:239] Iteration 352300 (10.1785 iter/s, 9.82466s/100 iters), loss = 0.0282919
I0823 02:41:17.201480 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.028291 (* 1 = 0.028291 loss)
I0823 02:41:17.201490 13823 sgd_solver.cpp:112] Iteration 352300, lr = 1e-06
I0823 02:41:27.015494 13823 solver.cpp:239] Iteration 352400 (10.1895 iter/s, 9.81405s/100 iters), loss = 0.0263347
I0823 02:41:27.015552 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0263338 (* 1 = 0.0263338 loss)
I0823 02:41:27.015565 13823 sgd_solver.cpp:112] Iteration 352400, lr = 1e-06
I0823 02:41:36.874377 13823 solver.cpp:239] Iteration 352500 (10.1432 iter/s, 9.85886s/100 iters), loss = 0.0327705
I0823 02:41:36.874436 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0327696 (* 1 = 0.0327696 loss)
I0823 02:41:36.874449 13823 sgd_solver.cpp:112] Iteration 352500, lr = 1e-06
I0823 02:41:46.849624 13823 solver.cpp:239] Iteration 352600 (10.0248 iter/s, 9.97522s/100 iters), loss = 0.0255688
I0823 02:41:46.849674 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0255679 (* 1 = 0.0255679 loss)
I0823 02:41:46.849684 13823 sgd_solver.cpp:112] Iteration 352600, lr = 1e-06
I0823 02:41:56.867245 13823 solver.cpp:239] Iteration 352700 (9.98242 iter/s, 10.0176s/100 iters), loss = 0.0242165
I0823 02:41:56.867297 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0242156 (* 1 = 0.0242156 loss)
I0823 02:41:56.867307 13823 sgd_solver.cpp:112] Iteration 352700, lr = 1e-06
I0823 02:42:07.024572 13823 solver.cpp:239] Iteration 352800 (9.84513 iter/s, 10.1573s/100 iters), loss = 0.0307729
I0823 02:42:07.024623 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.030772 (* 1 = 0.030772 loss)
I0823 02:42:07.024633 13823 sgd_solver.cpp:112] Iteration 352800, lr = 1e-06
I0823 02:42:17.244633 13823 solver.cpp:239] Iteration 352900 (9.78469 iter/s, 10.22s/100 iters), loss = 0.0275679
I0823 02:42:17.244694 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.027567 (* 1 = 0.027567 loss)
I0823 02:42:17.244709 13823 sgd_solver.cpp:112] Iteration 352900, lr = 1e-06
I0823 02:42:27.151088 13823 solver.cpp:239] Iteration 353000 (10.0945 iter/s, 9.90643s/100 iters), loss = 0.0237778
I0823 02:42:27.151150 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.023777 (* 1 = 0.023777 loss)
I0823 02:42:27.151165 13823 sgd_solver.cpp:112] Iteration 353000, lr = 1e-06
I0823 02:42:37.427772 13823 solver.cpp:239] Iteration 353100 (9.73079 iter/s, 10.2767s/100 iters), loss = 0.0271392
I0823 02:42:37.427822 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0271383 (* 1 = 0.0271383 loss)
I0823 02:42:37.427832 13823 sgd_solver.cpp:112] Iteration 353100, lr = 1e-06
I0823 02:42:47.710281 13823 solver.cpp:239] Iteration 353200 (9.72527 iter/s, 10.2825s/100 iters), loss = 0.0274838
I0823 02:42:47.710331 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0274829 (* 1 = 0.0274829 loss)
I0823 02:42:47.710341 13823 sgd_solver.cpp:112] Iteration 353200, lr = 1e-06
I0823 02:42:57.742817 13823 solver.cpp:239] Iteration 353300 (9.96759 iter/s, 10.0325s/100 iters), loss = 0.0278718
I0823 02:42:57.742868 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0278709 (* 1 = 0.0278709 loss)
I0823 02:42:57.742877 13823 sgd_solver.cpp:112] Iteration 353300, lr = 1e-06
I0823 02:43:07.888065 13823 solver.cpp:239] Iteration 353400 (9.85685 iter/s, 10.1452s/100 iters), loss = 0.0261846
I0823 02:43:07.888114 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0261837 (* 1 = 0.0261837 loss)
I0823 02:43:07.888123 13823 sgd_solver.cpp:112] Iteration 353400, lr = 1e-06
I0823 02:43:17.900483 13823 solver.cpp:239] Iteration 353500 (9.98761 iter/s, 10.0124s/100 iters), loss = 0.0224237
I0823 02:43:17.900535 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0224228 (* 1 = 0.0224228 loss)
I0823 02:43:17.900544 13823 sgd_solver.cpp:112] Iteration 353500, lr = 1e-06
I0823 02:43:27.981411 13823 solver.cpp:239] Iteration 353600 (9.91974 iter/s, 10.0809s/100 iters), loss = 0.0281623
I0823 02:43:27.981473 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0281614 (* 1 = 0.0281614 loss)
I0823 02:43:27.981482 13823 sgd_solver.cpp:112] Iteration 353600, lr = 1e-06
I0823 02:43:38.346232 13823 solver.cpp:239] Iteration 353700 (9.64805 iter/s, 10.3648s/100 iters), loss = 0.0234429
I0823 02:43:38.346282 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.023442 (* 1 = 0.023442 loss)
I0823 02:43:38.346290 13823 sgd_solver.cpp:112] Iteration 353700, lr = 1e-06
I0823 02:43:48.385299 13823 solver.cpp:239] Iteration 353800 (9.9611 iter/s, 10.039s/100 iters), loss = 0.0238755
I0823 02:43:48.385366 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0238746 (* 1 = 0.0238746 loss)
I0823 02:43:48.385378 13823 sgd_solver.cpp:112] Iteration 353800, lr = 1e-06
I0823 02:43:58.115972 13823 solver.cpp:239] Iteration 353900 (10.2768 iter/s, 9.73064s/100 iters), loss = 0.024362
I0823 02:43:58.116021 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0243611 (* 1 = 0.0243611 loss)
I0823 02:43:58.116031 13823 sgd_solver.cpp:112] Iteration 353900, lr = 1e-06
I0823 02:44:08.085880 13823 solver.cpp:239] Iteration 354000 (10.0302 iter/s, 9.96989s/100 iters), loss = 0.0253991
I0823 02:44:08.085928 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0253982 (* 1 = 0.0253982 loss)
I0823 02:44:08.085937 13823 sgd_solver.cpp:112] Iteration 354000, lr = 1e-06
I0823 02:44:18.054471 13823 solver.cpp:239] Iteration 354100 (10.0315 iter/s, 9.96857s/100 iters), loss = 0.0268858
I0823 02:44:18.054522 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0268849 (* 1 = 0.0268849 loss)
I0823 02:44:18.054530 13823 sgd_solver.cpp:112] Iteration 354100, lr = 1e-06
I0823 02:44:27.824736 13823 solver.cpp:239] Iteration 354200 (10.2352 iter/s, 9.77024s/100 iters), loss = 0.0228864
I0823 02:44:27.824796 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0228855 (* 1 = 0.0228855 loss)
I0823 02:44:27.824808 13823 sgd_solver.cpp:112] Iteration 354200, lr = 1e-06
I0823 02:44:37.567977 13823 solver.cpp:239] Iteration 354300 (10.2636 iter/s, 9.74321s/100 iters), loss = 0.0409609
I0823 02:44:37.568039 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.04096 (* 1 = 0.04096 loss)
I0823 02:44:37.568050 13823 sgd_solver.cpp:112] Iteration 354300, lr = 1e-06
I0823 02:44:47.687520 13823 solver.cpp:239] Iteration 354400 (9.8819 iter/s, 10.1195s/100 iters), loss = 0.0286305
I0823 02:44:47.687579 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0286296 (* 1 = 0.0286296 loss)
I0823 02:44:47.687592 13823 sgd_solver.cpp:112] Iteration 354400, lr = 1e-06
I0823 02:44:57.823868 13823 solver.cpp:239] Iteration 354500 (9.86551 iter/s, 10.1363s/100 iters), loss = 0.030766
I0823 02:44:57.823917 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0307651 (* 1 = 0.0307651 loss)
I0823 02:44:57.823926 13823 sgd_solver.cpp:112] Iteration 354500, lr = 1e-06
I0823 02:45:07.923123 13823 solver.cpp:239] Iteration 354600 (9.90174 iter/s, 10.0992s/100 iters), loss = 0.026192
I0823 02:45:07.923184 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0261911 (* 1 = 0.0261911 loss)
I0823 02:45:07.923195 13823 sgd_solver.cpp:112] Iteration 354600, lr = 1e-06
I0823 02:45:18.258605 13823 solver.cpp:239] Iteration 354700 (9.67543 iter/s, 10.3355s/100 iters), loss = 0.0246781
I0823 02:45:18.258656 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0246772 (* 1 = 0.0246772 loss)
I0823 02:45:18.258666 13823 sgd_solver.cpp:112] Iteration 354700, lr = 1e-06
I0823 02:45:28.532986 13823 solver.cpp:239] Iteration 354800 (9.73296 iter/s, 10.2744s/100 iters), loss = 0.0265673
I0823 02:45:28.533037 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0265665 (* 1 = 0.0265665 loss)
I0823 02:45:28.533047 13823 sgd_solver.cpp:112] Iteration 354800, lr = 1e-06
I0823 02:45:38.777930 13823 solver.cpp:239] Iteration 354900 (9.76093 iter/s, 10.2449s/100 iters), loss = 0.0315149
I0823 02:45:38.777982 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.031514 (* 1 = 0.031514 loss)
I0823 02:45:38.777993 13823 sgd_solver.cpp:112] Iteration 354900, lr = 1e-06
I0823 02:45:48.959390 13823 solver.cpp:239] Iteration 355000 (9.82179 iter/s, 10.1814s/100 iters), loss = 0.0268038
I0823 02:45:48.959450 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.026803 (* 1 = 0.026803 loss)
I0823 02:45:48.959462 13823 sgd_solver.cpp:112] Iteration 355000, lr = 1e-06
I0823 02:45:59.140373 13823 solver.cpp:239] Iteration 355100 (9.82226 iter/s, 10.181s/100 iters), loss = 0.0239826
I0823 02:45:59.140422 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0239818 (* 1 = 0.0239818 loss)
I0823 02:45:59.140431 13823 sgd_solver.cpp:112] Iteration 355100, lr = 1e-06
I0823 02:46:09.285956 13823 solver.cpp:239] Iteration 355200 (9.85652 iter/s, 10.1456s/100 iters), loss = 0.0269088
I0823 02:46:09.286007 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.026908 (* 1 = 0.026908 loss)
I0823 02:46:09.286016 13823 sgd_solver.cpp:112] Iteration 355200, lr = 1e-06
I0823 02:46:19.392066 13823 solver.cpp:239] Iteration 355300 (9.89502 iter/s, 10.1061s/100 iters), loss = 0.0269799
I0823 02:46:19.392117 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.026979 (* 1 = 0.026979 loss)
I0823 02:46:19.392125 13823 sgd_solver.cpp:112] Iteration 355300, lr = 1e-06
I0823 02:46:29.507158 13823 solver.cpp:239] Iteration 355400 (9.88624 iter/s, 10.1151s/100 iters), loss = 0.0227502
I0823 02:46:29.507210 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0227493 (* 1 = 0.0227493 loss)
I0823 02:46:29.507220 13823 sgd_solver.cpp:112] Iteration 355400, lr = 1e-06
I0823 02:46:39.546864 13823 solver.cpp:239] Iteration 355500 (9.96047 iter/s, 10.0397s/100 iters), loss = 0.0285248
I0823 02:46:39.546914 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0285239 (* 1 = 0.0285239 loss)
I0823 02:46:39.546923 13823 sgd_solver.cpp:112] Iteration 355500, lr = 1e-06
I0823 02:46:49.681016 13823 solver.cpp:239] Iteration 355600 (9.86764 iter/s, 10.1341s/100 iters), loss = 0.0272365
I0823 02:46:49.681066 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0272356 (* 1 = 0.0272356 loss)
I0823 02:46:49.681075 13823 sgd_solver.cpp:112] Iteration 355600, lr = 1e-06
I0823 02:46:59.478996 13823 solver.cpp:239] Iteration 355700 (10.2062 iter/s, 9.79797s/100 iters), loss = 0.0274123
I0823 02:46:59.479050 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0274115 (* 1 = 0.0274115 loss)
I0823 02:46:59.479058 13823 sgd_solver.cpp:112] Iteration 355700, lr = 1e-06
I0823 02:47:09.782992 13823 solver.cpp:239] Iteration 355800 (9.70498 iter/s, 10.304s/100 iters), loss = 0.0333875
I0823 02:47:09.783041 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0333866 (* 1 = 0.0333866 loss)
I0823 02:47:09.783051 13823 sgd_solver.cpp:112] Iteration 355800, lr = 1e-06
I0823 02:47:19.836300 13823 solver.cpp:239] Iteration 355900 (9.94699 iter/s, 10.0533s/100 iters), loss = 0.0266791
I0823 02:47:19.836349 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0266783 (* 1 = 0.0266783 loss)
I0823 02:47:19.836359 13823 sgd_solver.cpp:112] Iteration 355900, lr = 1e-06
I0823 02:47:29.833148 13823 solver.cpp:239] Iteration 356000 (10.0032 iter/s, 9.99683s/100 iters), loss = 0.0249166
I0823 02:47:29.833199 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0249157 (* 1 = 0.0249157 loss)
I0823 02:47:29.833207 13823 sgd_solver.cpp:112] Iteration 356000, lr = 1e-06
I0823 02:47:40.042044 13823 solver.cpp:239] Iteration 356100 (9.7954 iter/s, 10.2089s/100 iters), loss = 0.0300107
I0823 02:47:40.042096 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0300099 (* 1 = 0.0300099 loss)
I0823 02:47:40.042106 13823 sgd_solver.cpp:112] Iteration 356100, lr = 1e-06
I0823 02:47:50.289885 13823 solver.cpp:239] Iteration 356200 (9.75817 iter/s, 10.2478s/100 iters), loss = 0.0278592
I0823 02:47:50.289934 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0278584 (* 1 = 0.0278584 loss)
I0823 02:47:50.289943 13823 sgd_solver.cpp:112] Iteration 356200, lr = 1e-06
I0823 02:48:00.720643 13823 solver.cpp:239] Iteration 356300 (9.58705 iter/s, 10.4307s/100 iters), loss = 0.0262501
I0823 02:48:00.720693 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0262493 (* 1 = 0.0262493 loss)
I0823 02:48:00.720702 13823 sgd_solver.cpp:112] Iteration 356300, lr = 1e-06
I0823 02:48:11.203560 13823 solver.cpp:239] Iteration 356400 (9.53935 iter/s, 10.4829s/100 iters), loss = 0.0301811
I0823 02:48:11.203609 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0301802 (* 1 = 0.0301802 loss)
I0823 02:48:11.203619 13823 sgd_solver.cpp:112] Iteration 356400, lr = 1e-06
I0823 02:48:21.641600 13823 solver.cpp:239] Iteration 356500 (9.58036 iter/s, 10.438s/100 iters), loss = 0.0280468
I0823 02:48:21.641652 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.028046 (* 1 = 0.028046 loss)
I0823 02:48:21.641662 13823 sgd_solver.cpp:112] Iteration 356500, lr = 1e-06
I0823 02:48:31.866219 13823 solver.cpp:239] Iteration 356600 (9.78033 iter/s, 10.2246s/100 iters), loss = 0.0288404
I0823 02:48:31.866259 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0288396 (* 1 = 0.0288396 loss)
I0823 02:48:31.866267 13823 sgd_solver.cpp:112] Iteration 356600, lr = 1e-06
I0823 02:48:42.324069 13823 solver.cpp:239] Iteration 356700 (9.56221 iter/s, 10.4578s/100 iters), loss = 0.0278434
I0823 02:48:42.324126 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0278426 (* 1 = 0.0278426 loss)
I0823 02:48:42.324143 13823 sgd_solver.cpp:112] Iteration 356700, lr = 1e-06
I0823 02:48:52.757465 13823 solver.cpp:239] Iteration 356800 (9.58463 iter/s, 10.4334s/100 iters), loss = 0.0249676
I0823 02:48:52.757519 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0249667 (* 1 = 0.0249667 loss)
I0823 02:48:52.757529 13823 sgd_solver.cpp:112] Iteration 356800, lr = 1e-06
I0823 02:49:03.401302 13823 solver.cpp:239] Iteration 356900 (9.39513 iter/s, 10.6438s/100 iters), loss = 0.0260922
I0823 02:49:03.401353 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0260913 (* 1 = 0.0260913 loss)
I0823 02:49:03.401363 13823 sgd_solver.cpp:112] Iteration 356900, lr = 1e-06
I0823 02:49:13.623291 13823 solver.cpp:239] Iteration 357000 (9.78285 iter/s, 10.222s/100 iters), loss = 0.0248937
I0823 02:49:13.623340 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0248928 (* 1 = 0.0248928 loss)
I0823 02:49:13.623350 13823 sgd_solver.cpp:112] Iteration 357000, lr = 1e-06
I0823 02:49:23.912464 13823 solver.cpp:239] Iteration 357100 (9.71897 iter/s, 10.2892s/100 iters), loss = 0.0265225
I0823 02:49:23.912513 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0265217 (* 1 = 0.0265217 loss)
I0823 02:49:23.912523 13823 sgd_solver.cpp:112] Iteration 357100, lr = 1e-06
I0823 02:49:34.091953 13823 solver.cpp:239] Iteration 357200 (9.8237 iter/s, 10.1795s/100 iters), loss = 0.0270889
I0823 02:49:34.092015 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.027088 (* 1 = 0.027088 loss)
I0823 02:49:34.092026 13823 sgd_solver.cpp:112] Iteration 357200, lr = 1e-06
I0823 02:49:44.569502 13823 solver.cpp:239] Iteration 357300 (9.54424 iter/s, 10.4775s/100 iters), loss = 0.0280183
I0823 02:49:44.569551 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0280174 (* 1 = 0.0280174 loss)
I0823 02:49:44.569561 13823 sgd_solver.cpp:112] Iteration 357300, lr = 1e-06
I0823 02:49:55.098860 13823 solver.cpp:239] Iteration 357400 (9.49727 iter/s, 10.5293s/100 iters), loss = 0.0267477
I0823 02:49:55.098909 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0267468 (* 1 = 0.0267468 loss)
I0823 02:49:55.098918 13823 sgd_solver.cpp:112] Iteration 357400, lr = 1e-06
I0823 02:50:05.691592 13823 solver.cpp:239] Iteration 357500 (9.44045 iter/s, 10.5927s/100 iters), loss = 0.0288979
I0823 02:50:05.691642 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.028897 (* 1 = 0.028897 loss)
I0823 02:50:05.691651 13823 sgd_solver.cpp:112] Iteration 357500, lr = 1e-06
I0823 02:50:16.110683 13823 solver.cpp:239] Iteration 357600 (9.59778 iter/s, 10.4191s/100 iters), loss = 0.0260343
I0823 02:50:16.110728 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0260334 (* 1 = 0.0260334 loss)
I0823 02:50:16.110736 13823 sgd_solver.cpp:112] Iteration 357600, lr = 1e-06
I0823 02:50:26.643498 13823 solver.cpp:239] Iteration 357700 (9.49415 iter/s, 10.5328s/100 iters), loss = 0.0307295
I0823 02:50:26.643548 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0307287 (* 1 = 0.0307287 loss)
I0823 02:50:26.643558 13823 sgd_solver.cpp:112] Iteration 357700, lr = 1e-06
I0823 02:50:37.314177 13823 solver.cpp:239] Iteration 357800 (9.37149 iter/s, 10.6707s/100 iters), loss = 0.0252724
I0823 02:50:37.314225 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0252715 (* 1 = 0.0252715 loss)
I0823 02:50:37.314235 13823 sgd_solver.cpp:112] Iteration 357800, lr = 1e-06
I0823 02:50:47.539232 13823 solver.cpp:239] Iteration 357900 (9.77992 iter/s, 10.225s/100 iters), loss = 0.0275621
I0823 02:50:47.539281 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0275613 (* 1 = 0.0275613 loss)
I0823 02:50:47.539290 13823 sgd_solver.cpp:112] Iteration 357900, lr = 1e-06
I0823 02:50:58.005555 13823 solver.cpp:239] Iteration 358000 (9.55447 iter/s, 10.4663s/100 iters), loss = 0.0272805
I0823 02:50:58.005607 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0272796 (* 1 = 0.0272796 loss)
I0823 02:50:58.005616 13823 sgd_solver.cpp:112] Iteration 358000, lr = 1e-06
I0823 02:51:08.989486 13823 solver.cpp:239] Iteration 358100 (9.10422 iter/s, 10.9839s/100 iters), loss = 0.0252163
I0823 02:51:08.989537 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0252155 (* 1 = 0.0252155 loss)
I0823 02:51:08.989547 13823 sgd_solver.cpp:112] Iteration 358100, lr = 1e-06
I0823 02:51:19.697659 13823 solver.cpp:239] Iteration 358200 (9.33868 iter/s, 10.7082s/100 iters), loss = 0.0271135
I0823 02:51:19.697716 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0271127 (* 1 = 0.0271127 loss)
I0823 02:51:19.697727 13823 sgd_solver.cpp:112] Iteration 358200, lr = 1e-06
I0823 02:51:30.681437 13823 solver.cpp:239] Iteration 358300 (9.10435 iter/s, 10.9838s/100 iters), loss = 0.0254736
I0823 02:51:30.681489 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0254728 (* 1 = 0.0254728 loss)
I0823 02:51:30.681499 13823 sgd_solver.cpp:112] Iteration 358300, lr = 1e-06
I0823 02:51:41.487243 13823 solver.cpp:239] Iteration 358400 (9.25441 iter/s, 10.8057s/100 iters), loss = 0.0278289
I0823 02:51:41.487294 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.027828 (* 1 = 0.027828 loss)
I0823 02:51:41.487303 13823 sgd_solver.cpp:112] Iteration 358400, lr = 1e-06
I0823 02:51:52.448174 13823 solver.cpp:239] Iteration 358500 (9.12347 iter/s, 10.9607s/100 iters), loss = 0.0274052
I0823 02:51:52.448230 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0274043 (* 1 = 0.0274043 loss)
I0823 02:51:52.448241 13823 sgd_solver.cpp:112] Iteration 358500, lr = 1e-06
I0823 02:52:03.314118 13823 solver.cpp:239] Iteration 358600 (9.20322 iter/s, 10.8658s/100 iters), loss = 0.0271268
I0823 02:52:03.314169 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.027126 (* 1 = 0.027126 loss)
I0823 02:52:03.314179 13823 sgd_solver.cpp:112] Iteration 358600, lr = 1e-06
I0823 02:52:13.731313 13823 solver.cpp:239] Iteration 358700 (9.59967 iter/s, 10.417s/100 iters), loss = 0.0286748
I0823 02:52:13.731364 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.028674 (* 1 = 0.028674 loss)
I0823 02:52:13.731374 13823 sgd_solver.cpp:112] Iteration 358700, lr = 1e-06
I0823 02:52:24.496635 13823 solver.cpp:239] Iteration 358800 (9.28924 iter/s, 10.7651s/100 iters), loss = 0.0295774
I0823 02:52:24.496686 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0295765 (* 1 = 0.0295765 loss)
I0823 02:52:24.496695 13823 sgd_solver.cpp:112] Iteration 358800, lr = 1e-06
I0823 02:52:35.513988 13823 solver.cpp:239] Iteration 358900 (9.07673 iter/s, 11.0172s/100 iters), loss = 0.037053
I0823 02:52:35.514040 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0370522 (* 1 = 0.0370522 loss)
I0823 02:52:35.514050 13823 sgd_solver.cpp:112] Iteration 358900, lr = 1e-06
I0823 02:52:46.277696 13823 solver.cpp:239] Iteration 359000 (9.29062 iter/s, 10.7635s/100 iters), loss = 0.0346017
I0823 02:52:46.277746 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0346009 (* 1 = 0.0346009 loss)
I0823 02:52:46.277755 13823 sgd_solver.cpp:112] Iteration 359000, lr = 1e-06
I0823 02:52:57.002071 13823 solver.cpp:239] Iteration 359100 (9.3247 iter/s, 10.7242s/100 iters), loss = 0.0251406
I0823 02:52:57.002126 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0251397 (* 1 = 0.0251397 loss)
I0823 02:52:57.002137 13823 sgd_solver.cpp:112] Iteration 359100, lr = 1e-06
I0823 02:53:07.801738 13823 solver.cpp:239] Iteration 359200 (9.25969 iter/s, 10.7995s/100 iters), loss = 0.0264697
I0823 02:53:07.801787 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0264688 (* 1 = 0.0264688 loss)
I0823 02:53:07.801797 13823 sgd_solver.cpp:112] Iteration 359200, lr = 1e-06
I0823 02:53:18.621595 13823 solver.cpp:239] Iteration 359300 (9.2424 iter/s, 10.8197s/100 iters), loss = 0.0403517
I0823 02:53:18.621652 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0403508 (* 1 = 0.0403508 loss)
I0823 02:53:18.621664 13823 sgd_solver.cpp:112] Iteration 359300, lr = 1e-06
I0823 02:53:29.871389 13823 solver.cpp:239] Iteration 359400 (8.88918 iter/s, 11.2496s/100 iters), loss = 0.0269198
I0823 02:53:29.871443 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.026919 (* 1 = 0.026919 loss)
I0823 02:53:29.871454 13823 sgd_solver.cpp:112] Iteration 359400, lr = 1e-06
I0823 02:53:40.933342 13823 solver.cpp:239] Iteration 359500 (9.04013 iter/s, 11.0618s/100 iters), loss = 0.0289494
I0823 02:53:40.933393 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0289485 (* 1 = 0.0289485 loss)
I0823 02:53:40.933401 13823 sgd_solver.cpp:112] Iteration 359500, lr = 1e-06
I0823 02:53:51.698479 13823 solver.cpp:239] Iteration 359600 (9.28938 iter/s, 10.765s/100 iters), loss = 0.0235921
I0823 02:53:51.698534 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0235913 (* 1 = 0.0235913 loss)
I0823 02:53:51.698544 13823 sgd_solver.cpp:112] Iteration 359600, lr = 1e-06
I0823 02:54:02.650979 13823 solver.cpp:239] Iteration 359700 (9.13047 iter/s, 10.9523s/100 iters), loss = 0.0284328
I0823 02:54:02.651036 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0284319 (* 1 = 0.0284319 loss)
I0823 02:54:02.651048 13823 sgd_solver.cpp:112] Iteration 359700, lr = 1e-06
I0823 02:54:13.636953 13823 solver.cpp:239] Iteration 359800 (9.10265 iter/s, 10.9858s/100 iters), loss = 0.0290187
I0823 02:54:13.637017 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0290178 (* 1 = 0.0290178 loss)
I0823 02:54:13.637032 13823 sgd_solver.cpp:112] Iteration 359800, lr = 1e-06
I0823 02:54:24.376127 13823 solver.cpp:239] Iteration 359900 (9.31184 iter/s, 10.739s/100 iters), loss = 0.0276071
I0823 02:54:24.376186 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0276063 (* 1 = 0.0276063 loss)
I0823 02:54:24.376197 13823 sgd_solver.cpp:112] Iteration 359900, lr = 1e-06
I0823 02:54:35.173625 13823 solver.cpp:464] Snapshotting to binary proto file ./model_112/cascade_mobilenet_112_iter_360000.caffemodel
I0823 02:54:35.216550 13823 sgd_solver.cpp:284] Snapshotting solver state to binary proto file ./model_112/cascade_mobilenet_112_iter_360000.solverstate
I0823 02:54:35.287461 13823 solver.cpp:347] Iteration 360000, Testing net (#0)
I0823 02:55:43.579903 13823 solver.cpp:414]     Test net output #0: landmark_loss = 0.0219068 (* 1 = 0.0219068 loss)
I0823 02:55:43.703469 13823 solver.cpp:239] Iteration 360000 (1.26061 iter/s, 79.3267s/100 iters), loss = 0.0305594
I0823 02:55:43.703521 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0305585 (* 1 = 0.0305585 loss)
I0823 02:55:43.703536 13823 sgd_solver.cpp:112] Iteration 360000, lr = 1e-06
I0823 02:55:54.855082 13823 solver.cpp:239] Iteration 360100 (8.96741 iter/s, 11.1515s/100 iters), loss = 0.029656
I0823 02:55:54.855136 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0296551 (* 1 = 0.0296551 loss)
I0823 02:55:54.855146 13823 sgd_solver.cpp:112] Iteration 360100, lr = 1e-06
I0823 02:56:06.138736 13823 solver.cpp:239] Iteration 360200 (8.86248 iter/s, 11.2835s/100 iters), loss = 0.0277488
I0823 02:56:06.138792 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0277479 (* 1 = 0.0277479 loss)
I0823 02:56:06.138801 13823 sgd_solver.cpp:112] Iteration 360200, lr = 1e-06
I0823 02:56:17.199241 13823 solver.cpp:239] Iteration 360300 (9.04128 iter/s, 11.0604s/100 iters), loss = 0.0294926
I0823 02:56:17.199303 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0294917 (* 1 = 0.0294917 loss)
I0823 02:56:17.199316 13823 sgd_solver.cpp:112] Iteration 360300, lr = 1e-06
I0823 02:56:28.504796 13823 solver.cpp:239] Iteration 360400 (8.84531 iter/s, 11.3054s/100 iters), loss = 0.0257517
I0823 02:56:28.504846 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0257509 (* 1 = 0.0257509 loss)
I0823 02:56:28.504855 13823 sgd_solver.cpp:112] Iteration 360400, lr = 1e-06
I0823 02:56:39.865937 13823 solver.cpp:239] Iteration 360500 (8.80202 iter/s, 11.361s/100 iters), loss = 0.0288921
I0823 02:56:39.865999 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0288913 (* 1 = 0.0288913 loss)
I0823 02:56:39.866010 13823 sgd_solver.cpp:112] Iteration 360500, lr = 1e-06
I0823 02:56:51.436798 13823 solver.cpp:239] Iteration 360600 (8.64249 iter/s, 11.5707s/100 iters), loss = 0.0333624
I0823 02:56:51.436853 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0333616 (* 1 = 0.0333616 loss)
I0823 02:56:51.436864 13823 sgd_solver.cpp:112] Iteration 360600, lr = 1e-06
I0823 02:57:02.828459 13823 solver.cpp:239] Iteration 360700 (8.77844 iter/s, 11.3915s/100 iters), loss = 0.024673
I0823 02:57:02.828516 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0246722 (* 1 = 0.0246722 loss)
I0823 02:57:02.828527 13823 sgd_solver.cpp:112] Iteration 360700, lr = 1e-06
I0823 02:57:13.957887 13823 solver.cpp:239] Iteration 360800 (8.98528 iter/s, 11.1293s/100 iters), loss = 0.0238679
I0823 02:57:13.957945 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0238671 (* 1 = 0.0238671 loss)
I0823 02:57:13.957957 13823 sgd_solver.cpp:112] Iteration 360800, lr = 1e-06
I0823 02:57:25.076833 13823 solver.cpp:239] Iteration 360900 (8.99375 iter/s, 11.1188s/100 iters), loss = 0.025442
I0823 02:57:25.076884 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0254412 (* 1 = 0.0254412 loss)
I0823 02:57:25.076894 13823 sgd_solver.cpp:112] Iteration 360900, lr = 1e-06
I0823 02:57:36.251761 13823 solver.cpp:239] Iteration 361000 (8.94869 iter/s, 11.1748s/100 iters), loss = 0.0252142
I0823 02:57:36.251821 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0252134 (* 1 = 0.0252134 loss)
I0823 02:57:36.251830 13823 sgd_solver.cpp:112] Iteration 361000, lr = 1e-06
I0823 02:57:47.467067 13823 solver.cpp:239] Iteration 361100 (8.91648 iter/s, 11.2152s/100 iters), loss = 0.0225495
I0823 02:57:47.467124 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0225486 (* 1 = 0.0225486 loss)
I0823 02:57:47.467134 13823 sgd_solver.cpp:112] Iteration 361100, lr = 1e-06
I0823 02:57:58.789372 13823 solver.cpp:239] Iteration 361200 (8.83221 iter/s, 11.3222s/100 iters), loss = 0.027378
I0823 02:57:58.789438 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0273771 (* 1 = 0.0273771 loss)
I0823 02:57:58.789450 13823 sgd_solver.cpp:112] Iteration 361200, lr = 1e-06
I0823 02:58:10.149174 13823 solver.cpp:239] Iteration 361300 (8.80306 iter/s, 11.3597s/100 iters), loss = 0.0292925
I0823 02:58:10.149225 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0292916 (* 1 = 0.0292916 loss)
I0823 02:58:10.149235 13823 sgd_solver.cpp:112] Iteration 361300, lr = 1e-06
I0823 02:58:21.289425 13823 solver.cpp:239] Iteration 361400 (8.97654 iter/s, 11.1401s/100 iters), loss = 0.0294331
I0823 02:58:21.289477 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0294323 (* 1 = 0.0294323 loss)
I0823 02:58:21.289487 13823 sgd_solver.cpp:112] Iteration 361400, lr = 1e-06
I0823 02:58:32.404268 13823 solver.cpp:239] Iteration 361500 (8.99706 iter/s, 11.1147s/100 iters), loss = 0.0263924
I0823 02:58:32.404325 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0263915 (* 1 = 0.0263915 loss)
I0823 02:58:32.404336 13823 sgd_solver.cpp:112] Iteration 361500, lr = 1e-06
I0823 02:58:43.544584 13823 solver.cpp:239] Iteration 361600 (8.97649 iter/s, 11.1402s/100 iters), loss = 0.0242533
I0823 02:58:43.544641 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0242525 (* 1 = 0.0242525 loss)
I0823 02:58:43.544651 13823 sgd_solver.cpp:112] Iteration 361600, lr = 1e-06
I0823 02:58:54.752306 13823 solver.cpp:239] Iteration 361700 (8.9225 iter/s, 11.2076s/100 iters), loss = 0.0248458
I0823 02:58:54.752365 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0248449 (* 1 = 0.0248449 loss)
I0823 02:58:54.752377 13823 sgd_solver.cpp:112] Iteration 361700, lr = 1e-06
I0823 02:59:05.963977 13823 solver.cpp:239] Iteration 361800 (8.91936 iter/s, 11.2116s/100 iters), loss = 0.0248357
I0823 02:59:05.964032 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0248348 (* 1 = 0.0248348 loss)
I0823 02:59:05.964042 13823 sgd_solver.cpp:112] Iteration 361800, lr = 1e-06
I0823 02:59:17.402012 13823 solver.cpp:239] Iteration 361900 (8.74284 iter/s, 11.4379s/100 iters), loss = 0.0293372
I0823 02:59:17.402063 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0293364 (* 1 = 0.0293364 loss)
I0823 02:59:17.402072 13823 sgd_solver.cpp:112] Iteration 361900, lr = 1e-06
I0823 02:59:29.035042 13823 solver.cpp:239] Iteration 362000 (8.59629 iter/s, 11.6329s/100 iters), loss = 0.0276723
I0823 02:59:29.035102 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0276715 (* 1 = 0.0276715 loss)
I0823 02:59:29.035115 13823 sgd_solver.cpp:112] Iteration 362000, lr = 1e-06
I0823 02:59:40.575359 13823 solver.cpp:239] Iteration 362100 (8.66535 iter/s, 11.5402s/100 iters), loss = 0.0223432
I0823 02:59:40.575413 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0223423 (* 1 = 0.0223423 loss)
I0823 02:59:40.575423 13823 sgd_solver.cpp:112] Iteration 362100, lr = 1e-06
I0823 02:59:51.706795 13823 solver.cpp:239] Iteration 362200 (8.98365 iter/s, 11.1313s/100 iters), loss = 0.0283289
I0823 02:59:51.706856 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.028328 (* 1 = 0.028328 loss)
I0823 02:59:51.706867 13823 sgd_solver.cpp:112] Iteration 362200, lr = 1e-06
I0823 03:00:03.033612 13823 solver.cpp:239] Iteration 362300 (8.82868 iter/s, 11.3267s/100 iters), loss = 0.0383285
I0823 03:00:03.033665 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0383277 (* 1 = 0.0383277 loss)
I0823 03:00:03.033675 13823 sgd_solver.cpp:112] Iteration 362300, lr = 1e-06
I0823 03:00:14.446635 13823 solver.cpp:239] Iteration 362400 (8.76199 iter/s, 11.4129s/100 iters), loss = 0.0285476
I0823 03:00:14.446696 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0285467 (* 1 = 0.0285467 loss)
I0823 03:00:14.446707 13823 sgd_solver.cpp:112] Iteration 362400, lr = 1e-06
I0823 03:00:25.787133 13823 solver.cpp:239] Iteration 362500 (8.81803 iter/s, 11.3404s/100 iters), loss = 0.0478198
I0823 03:00:25.787195 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0478189 (* 1 = 0.0478189 loss)
I0823 03:00:25.787207 13823 sgd_solver.cpp:112] Iteration 362500, lr = 1e-06
I0823 03:00:37.040292 13823 solver.cpp:239] Iteration 362600 (8.88647 iter/s, 11.2531s/100 iters), loss = 0.0259468
I0823 03:00:37.040343 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0259459 (* 1 = 0.0259459 loss)
I0823 03:00:37.040351 13823 sgd_solver.cpp:112] Iteration 362600, lr = 1e-06
I0823 03:00:47.960753 13823 solver.cpp:239] Iteration 362700 (9.1572 iter/s, 10.9204s/100 iters), loss = 0.0290752
I0823 03:00:47.960805 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0290743 (* 1 = 0.0290743 loss)
I0823 03:00:47.960814 13823 sgd_solver.cpp:112] Iteration 362700, lr = 1e-06
I0823 03:00:59.377773 13823 solver.cpp:239] Iteration 362800 (8.75892 iter/s, 11.4169s/100 iters), loss = 0.0237825
I0823 03:00:59.377835 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0237817 (* 1 = 0.0237817 loss)
I0823 03:00:59.377848 13823 sgd_solver.cpp:112] Iteration 362800, lr = 1e-06
I0823 03:01:10.924309 13823 solver.cpp:239] Iteration 362900 (8.66068 iter/s, 11.5464s/100 iters), loss = 0.0353194
I0823 03:01:10.924362 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0353186 (* 1 = 0.0353186 loss)
I0823 03:01:10.924372 13823 sgd_solver.cpp:112] Iteration 362900, lr = 1e-06
I0823 03:01:22.316226 13823 solver.cpp:239] Iteration 363000 (8.77822 iter/s, 11.3918s/100 iters), loss = 0.0237056
I0823 03:01:22.316273 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0237048 (* 1 = 0.0237048 loss)
I0823 03:01:22.316283 13823 sgd_solver.cpp:112] Iteration 363000, lr = 1e-06
I0823 03:01:33.764048 13823 solver.cpp:239] Iteration 363100 (8.73535 iter/s, 11.4477s/100 iters), loss = 0.0239096
I0823 03:01:33.764109 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0239088 (* 1 = 0.0239088 loss)
I0823 03:01:33.764122 13823 sgd_solver.cpp:112] Iteration 363100, lr = 1e-06
I0823 03:01:45.282160 13823 solver.cpp:239] Iteration 363200 (8.68205 iter/s, 11.518s/100 iters), loss = 0.0244104
I0823 03:01:45.282210 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0244095 (* 1 = 0.0244095 loss)
I0823 03:01:45.282220 13823 sgd_solver.cpp:112] Iteration 363200, lr = 1e-06
I0823 03:01:56.767370 13823 solver.cpp:239] Iteration 363300 (8.70691 iter/s, 11.4851s/100 iters), loss = 0.0258186
I0823 03:01:56.767428 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0258178 (* 1 = 0.0258178 loss)
I0823 03:01:56.767439 13823 sgd_solver.cpp:112] Iteration 363300, lr = 1e-06
I0823 03:02:08.302295 13823 solver.cpp:239] Iteration 363400 (8.66939 iter/s, 11.5348s/100 iters), loss = 0.0258371
I0823 03:02:08.302350 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0258363 (* 1 = 0.0258363 loss)
I0823 03:02:08.302359 13823 sgd_solver.cpp:112] Iteration 363400, lr = 1e-06
I0823 03:02:19.871191 13823 solver.cpp:239] Iteration 363500 (8.64393 iter/s, 11.5688s/100 iters), loss = 0.0298084
I0823 03:02:19.871256 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0298075 (* 1 = 0.0298075 loss)
I0823 03:02:19.871271 13823 sgd_solver.cpp:112] Iteration 363500, lr = 1e-06
I0823 03:02:31.501994 13823 solver.cpp:239] Iteration 363600 (8.59792 iter/s, 11.6307s/100 iters), loss = 0.0307688
I0823 03:02:31.502045 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.030768 (* 1 = 0.030768 loss)
I0823 03:02:31.502054 13823 sgd_solver.cpp:112] Iteration 363600, lr = 1e-06
I0823 03:02:42.387616 13823 solver.cpp:239] Iteration 363700 (9.18649 iter/s, 10.8856s/100 iters), loss = 0.0314184
I0823 03:02:42.387656 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0314176 (* 1 = 0.0314176 loss)
I0823 03:02:42.387663 13823 sgd_solver.cpp:112] Iteration 363700, lr = 1e-06
I0823 03:02:53.462873 13823 solver.cpp:239] Iteration 363800 (9.02919 iter/s, 11.0752s/100 iters), loss = 0.0359417
I0823 03:02:53.462925 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0359409 (* 1 = 0.0359409 loss)
I0823 03:02:53.462935 13823 sgd_solver.cpp:112] Iteration 363800, lr = 1e-06
I0823 03:03:04.777037 13823 solver.cpp:239] Iteration 363900 (8.83854 iter/s, 11.3141s/100 iters), loss = 0.227673
I0823 03:03:04.777088 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.227672 (* 1 = 0.227672 loss)
I0823 03:03:04.777097 13823 sgd_solver.cpp:112] Iteration 363900, lr = 1e-06
I0823 03:03:15.960995 13823 solver.cpp:239] Iteration 364000 (8.94144 iter/s, 11.1839s/100 iters), loss = 0.0252451
I0823 03:03:15.961045 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0252443 (* 1 = 0.0252443 loss)
I0823 03:03:15.961055 13823 sgd_solver.cpp:112] Iteration 364000, lr = 1e-06
I0823 03:03:27.040230 13823 solver.cpp:239] Iteration 364100 (9.02595 iter/s, 11.0792s/100 iters), loss = 0.0324806
I0823 03:03:27.040279 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0324797 (* 1 = 0.0324797 loss)
I0823 03:03:27.040289 13823 sgd_solver.cpp:112] Iteration 364100, lr = 1e-06
I0823 03:03:37.963327 13823 solver.cpp:239] Iteration 364200 (9.15497 iter/s, 10.923s/100 iters), loss = 0.0276054
I0823 03:03:37.963372 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0276045 (* 1 = 0.0276045 loss)
I0823 03:03:37.963380 13823 sgd_solver.cpp:112] Iteration 364200, lr = 1e-06
I0823 03:03:49.577190 13823 solver.cpp:239] Iteration 364300 (8.61045 iter/s, 11.6138s/100 iters), loss = 0.0250525
I0823 03:03:49.577250 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0250516 (* 1 = 0.0250516 loss)
I0823 03:03:49.577265 13823 sgd_solver.cpp:112] Iteration 364300, lr = 1e-06
I0823 03:04:01.074026 13823 solver.cpp:239] Iteration 364400 (8.6981 iter/s, 11.4968s/100 iters), loss = 0.0262197
I0823 03:04:01.074084 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0262189 (* 1 = 0.0262189 loss)
I0823 03:04:01.074096 13823 sgd_solver.cpp:112] Iteration 364400, lr = 1e-06
I0823 03:04:12.501545 13823 solver.cpp:239] Iteration 364500 (8.75086 iter/s, 11.4274s/100 iters), loss = 0.0268393
I0823 03:04:12.501602 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0268385 (* 1 = 0.0268385 loss)
I0823 03:04:12.501616 13823 sgd_solver.cpp:112] Iteration 364500, lr = 1e-06
I0823 03:04:24.027899 13823 solver.cpp:239] Iteration 364600 (8.67582 iter/s, 11.5263s/100 iters), loss = 0.0292417
I0823 03:04:24.027958 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0292409 (* 1 = 0.0292409 loss)
I0823 03:04:24.027969 13823 sgd_solver.cpp:112] Iteration 364600, lr = 1e-06
I0823 03:04:35.004391 13823 solver.cpp:239] Iteration 364700 (9.11044 iter/s, 10.9764s/100 iters), loss = 0.0260377
I0823 03:04:35.004433 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0260369 (* 1 = 0.0260369 loss)
I0823 03:04:35.004441 13823 sgd_solver.cpp:112] Iteration 364700, lr = 1e-06
I0823 03:04:46.395728 13823 solver.cpp:239] Iteration 364800 (8.77865 iter/s, 11.3913s/100 iters), loss = 0.0266369
I0823 03:04:46.395778 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.026636 (* 1 = 0.026636 loss)
I0823 03:04:46.395788 13823 sgd_solver.cpp:112] Iteration 364800, lr = 1e-06
I0823 03:04:57.566447 13823 solver.cpp:239] Iteration 364900 (8.95202 iter/s, 11.1707s/100 iters), loss = 0.0268144
I0823 03:04:57.566488 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0268136 (* 1 = 0.0268136 loss)
I0823 03:04:57.566494 13823 sgd_solver.cpp:112] Iteration 364900, lr = 1e-06
I0823 03:05:08.886929 13823 solver.cpp:239] Iteration 365000 (8.83359 iter/s, 11.3204s/100 iters), loss = 0.0244579
I0823 03:05:08.886981 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.024457 (* 1 = 0.024457 loss)
I0823 03:05:08.886989 13823 sgd_solver.cpp:112] Iteration 365000, lr = 1e-06
I0823 03:05:20.697446 13823 solver.cpp:239] Iteration 365100 (8.46708 iter/s, 11.8105s/100 iters), loss = 0.0251446
I0823 03:05:20.697499 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0251437 (* 1 = 0.0251437 loss)
I0823 03:05:20.697508 13823 sgd_solver.cpp:112] Iteration 365100, lr = 1e-06
I0823 03:05:32.288580 13823 solver.cpp:239] Iteration 365200 (8.62733 iter/s, 11.5911s/100 iters), loss = 0.0289147
I0823 03:05:32.288637 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0289139 (* 1 = 0.0289139 loss)
I0823 03:05:32.288650 13823 sgd_solver.cpp:112] Iteration 365200, lr = 1e-06
I0823 03:05:42.233189 13823 solver.cpp:239] Iteration 365300 (10.0558 iter/s, 9.94454s/100 iters), loss = 0.0233344
I0823 03:05:42.233242 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0233336 (* 1 = 0.0233336 loss)
I0823 03:05:42.233251 13823 sgd_solver.cpp:112] Iteration 365300, lr = 1e-06
I0823 03:05:51.964427 13823 solver.cpp:239] Iteration 365400 (10.2763 iter/s, 9.73117s/100 iters), loss = 0.0260287
I0823 03:05:51.964481 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0260279 (* 1 = 0.0260279 loss)
I0823 03:05:51.964491 13823 sgd_solver.cpp:112] Iteration 365400, lr = 1e-06
I0823 03:06:01.763660 13823 solver.cpp:239] Iteration 365500 (10.2049 iter/s, 9.79917s/100 iters), loss = 0.0288086
I0823 03:06:01.763710 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0288077 (* 1 = 0.0288077 loss)
I0823 03:06:01.763718 13823 sgd_solver.cpp:112] Iteration 365500, lr = 1e-06
I0823 03:06:11.420341 13823 solver.cpp:239] Iteration 365600 (10.3556 iter/s, 9.65662s/100 iters), loss = 0.0294884
I0823 03:06:11.420390 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0294875 (* 1 = 0.0294875 loss)
I0823 03:06:11.420399 13823 sgd_solver.cpp:112] Iteration 365600, lr = 1e-06
I0823 03:06:21.066079 13823 solver.cpp:239] Iteration 365700 (10.3673 iter/s, 9.64568s/100 iters), loss = 0.0248848
I0823 03:06:21.066133 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.024884 (* 1 = 0.024884 loss)
I0823 03:06:21.066141 13823 sgd_solver.cpp:112] Iteration 365700, lr = 1e-06
I0823 03:06:30.538280 13823 solver.cpp:239] Iteration 365800 (10.5573 iter/s, 9.47214s/100 iters), loss = 0.0289417
I0823 03:06:30.538345 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0289409 (* 1 = 0.0289409 loss)
I0823 03:06:30.538362 13823 sgd_solver.cpp:112] Iteration 365800, lr = 1e-06
I0823 03:06:40.477586 13823 solver.cpp:239] Iteration 365900 (10.0611 iter/s, 9.93923s/100 iters), loss = 0.023204
I0823 03:06:40.477641 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0232032 (* 1 = 0.0232032 loss)
I0823 03:06:40.477654 13823 sgd_solver.cpp:112] Iteration 365900, lr = 1e-06
I0823 03:06:50.104017 13823 solver.cpp:239] Iteration 366000 (10.3881 iter/s, 9.62637s/100 iters), loss = 0.0328939
I0823 03:06:50.104064 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.032893 (* 1 = 0.032893 loss)
I0823 03:06:50.104075 13823 sgd_solver.cpp:112] Iteration 366000, lr = 1e-06
I0823 03:06:59.510771 13823 solver.cpp:239] Iteration 366100 (10.6307 iter/s, 9.4067s/100 iters), loss = 0.0255309
I0823 03:06:59.510814 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0255301 (* 1 = 0.0255301 loss)
I0823 03:06:59.510823 13823 sgd_solver.cpp:112] Iteration 366100, lr = 1e-06
I0823 03:07:09.103927 13823 solver.cpp:239] Iteration 366200 (10.4242 iter/s, 9.5931s/100 iters), loss = 0.0299368
I0823 03:07:09.103981 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.029936 (* 1 = 0.029936 loss)
I0823 03:07:09.103989 13823 sgd_solver.cpp:112] Iteration 366200, lr = 1e-06
I0823 03:07:18.657646 13823 solver.cpp:239] Iteration 366300 (10.4672 iter/s, 9.55366s/100 iters), loss = 0.0309357
I0823 03:07:18.657697 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0309348 (* 1 = 0.0309348 loss)
I0823 03:07:18.657706 13823 sgd_solver.cpp:112] Iteration 366300, lr = 1e-06
I0823 03:07:28.594663 13823 solver.cpp:239] Iteration 366400 (10.0634 iter/s, 9.93696s/100 iters), loss = 0.0444577
I0823 03:07:28.594714 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0444568 (* 1 = 0.0444568 loss)
I0823 03:07:28.594723 13823 sgd_solver.cpp:112] Iteration 366400, lr = 1e-06
I0823 03:07:38.596588 13823 solver.cpp:239] Iteration 366500 (9.99813 iter/s, 10.0019s/100 iters), loss = 0.0341454
I0823 03:07:38.596639 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0341446 (* 1 = 0.0341446 loss)
I0823 03:07:38.596648 13823 sgd_solver.cpp:112] Iteration 366500, lr = 1e-06
I0823 03:07:48.210377 13823 solver.cpp:239] Iteration 366600 (10.4018 iter/s, 9.61373s/100 iters), loss = 0.0257741
I0823 03:07:48.210428 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0257732 (* 1 = 0.0257732 loss)
I0823 03:07:48.210438 13823 sgd_solver.cpp:112] Iteration 366600, lr = 1e-06
I0823 03:07:57.712273 13823 solver.cpp:239] Iteration 366700 (10.5243 iter/s, 9.50183s/100 iters), loss = 0.0278971
I0823 03:07:57.712322 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0278963 (* 1 = 0.0278963 loss)
I0823 03:07:57.712332 13823 sgd_solver.cpp:112] Iteration 366700, lr = 1e-06
I0823 03:08:07.353178 13823 solver.cpp:239] Iteration 366800 (10.3725 iter/s, 9.64085s/100 iters), loss = 0.0263134
I0823 03:08:07.353229 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0263126 (* 1 = 0.0263126 loss)
I0823 03:08:07.353238 13823 sgd_solver.cpp:112] Iteration 366800, lr = 1e-06
I0823 03:08:17.132511 13823 solver.cpp:239] Iteration 366900 (10.2257 iter/s, 9.77927s/100 iters), loss = 0.027941
I0823 03:08:17.132563 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0279401 (* 1 = 0.0279401 loss)
I0823 03:08:17.132572 13823 sgd_solver.cpp:112] Iteration 366900, lr = 1e-06
I0823 03:08:26.925531 13823 solver.cpp:239] Iteration 367000 (10.2114 iter/s, 9.79296s/100 iters), loss = 0.0257385
I0823 03:08:26.925597 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0257377 (* 1 = 0.0257377 loss)
I0823 03:08:26.925611 13823 sgd_solver.cpp:112] Iteration 367000, lr = 1e-06
I0823 03:08:36.614897 13823 solver.cpp:239] Iteration 367100 (10.3207 iter/s, 9.6893s/100 iters), loss = 0.0250464
I0823 03:08:36.614938 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0250456 (* 1 = 0.0250456 loss)
I0823 03:08:36.614945 13823 sgd_solver.cpp:112] Iteration 367100, lr = 1e-06
I0823 03:08:46.213459 13823 solver.cpp:239] Iteration 367200 (10.4183 iter/s, 9.59851s/100 iters), loss = 0.0271995
I0823 03:08:46.213510 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0271987 (* 1 = 0.0271987 loss)
I0823 03:08:46.213518 13823 sgd_solver.cpp:112] Iteration 367200, lr = 1e-06
I0823 03:08:56.099411 13823 solver.cpp:239] Iteration 367300 (10.1154 iter/s, 9.88589s/100 iters), loss = 0.0290874
I0823 03:08:56.099462 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0290866 (* 1 = 0.0290866 loss)
I0823 03:08:56.099472 13823 sgd_solver.cpp:112] Iteration 367300, lr = 1e-06
I0823 03:09:06.029966 13823 solver.cpp:239] Iteration 367400 (10.07 iter/s, 9.9305s/100 iters), loss = 0.0385933
I0823 03:09:06.030017 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0385925 (* 1 = 0.0385925 loss)
I0823 03:09:06.030027 13823 sgd_solver.cpp:112] Iteration 367400, lr = 1e-06
I0823 03:09:15.870527 13823 solver.cpp:239] Iteration 367500 (10.1621 iter/s, 9.8405s/100 iters), loss = 0.0263398
I0823 03:09:15.870576 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0263389 (* 1 = 0.0263389 loss)
I0823 03:09:15.870585 13823 sgd_solver.cpp:112] Iteration 367500, lr = 1e-06
I0823 03:09:25.650629 13823 solver.cpp:239] Iteration 367600 (10.2249 iter/s, 9.78004s/100 iters), loss = 0.0362676
I0823 03:09:25.650681 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0362667 (* 1 = 0.0362667 loss)
I0823 03:09:25.650691 13823 sgd_solver.cpp:112] Iteration 367600, lr = 1e-06
I0823 03:09:35.426370 13823 solver.cpp:239] Iteration 367700 (10.2295 iter/s, 9.77568s/100 iters), loss = 0.0272402
I0823 03:09:35.426421 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0272394 (* 1 = 0.0272394 loss)
I0823 03:09:35.426431 13823 sgd_solver.cpp:112] Iteration 367700, lr = 1e-06
I0823 03:09:45.282467 13823 solver.cpp:239] Iteration 367800 (10.1461 iter/s, 9.85604s/100 iters), loss = 0.0266586
I0823 03:09:45.282518 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0266578 (* 1 = 0.0266578 loss)
I0823 03:09:45.282527 13823 sgd_solver.cpp:112] Iteration 367800, lr = 1e-06
I0823 03:09:55.014552 13823 solver.cpp:239] Iteration 367900 (10.2754 iter/s, 9.73203s/100 iters), loss = 0.0283708
I0823 03:09:55.014609 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0283699 (* 1 = 0.0283699 loss)
I0823 03:09:55.014621 13823 sgd_solver.cpp:112] Iteration 367900, lr = 1e-06
I0823 03:10:04.947639 13823 solver.cpp:239] Iteration 368000 (10.0674 iter/s, 9.93302s/100 iters), loss = 0.0276477
I0823 03:10:04.947691 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0276469 (* 1 = 0.0276469 loss)
I0823 03:10:04.947700 13823 sgd_solver.cpp:112] Iteration 368000, lr = 1e-06
I0823 03:10:14.676450 13823 solver.cpp:239] Iteration 368100 (10.2788 iter/s, 9.72875s/100 iters), loss = 0.0275299
I0823 03:10:14.676501 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.027529 (* 1 = 0.027529 loss)
I0823 03:10:14.676510 13823 sgd_solver.cpp:112] Iteration 368100, lr = 1e-06
I0823 03:10:24.798648 13823 solver.cpp:239] Iteration 368200 (9.87933 iter/s, 10.1221s/100 iters), loss = 0.0227853
I0823 03:10:24.798708 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0227844 (* 1 = 0.0227844 loss)
I0823 03:10:24.798719 13823 sgd_solver.cpp:112] Iteration 368200, lr = 1e-06
I0823 03:10:34.837232 13823 solver.cpp:239] Iteration 368300 (9.96163 iter/s, 10.0385s/100 iters), loss = 0.03085
I0823 03:10:34.837283 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0308492 (* 1 = 0.0308492 loss)
I0823 03:10:34.837293 13823 sgd_solver.cpp:112] Iteration 368300, lr = 1e-06
I0823 03:10:45.062840 13823 solver.cpp:239] Iteration 368400 (9.77942 iter/s, 10.2256s/100 iters), loss = 0.0253814
I0823 03:10:45.062892 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0253806 (* 1 = 0.0253806 loss)
I0823 03:10:45.062901 13823 sgd_solver.cpp:112] Iteration 368400, lr = 1e-06
I0823 03:10:54.734899 13823 solver.cpp:239] Iteration 368500 (10.3391 iter/s, 9.672s/100 iters), loss = 0.0239362
I0823 03:10:54.734951 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0239354 (* 1 = 0.0239354 loss)
I0823 03:10:54.734959 13823 sgd_solver.cpp:112] Iteration 368500, lr = 1e-06
I0823 03:11:04.910405 13823 solver.cpp:239] Iteration 368600 (9.82758 iter/s, 10.1754s/100 iters), loss = 0.134803
I0823 03:11:04.910470 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.134802 (* 1 = 0.134802 loss)
I0823 03:11:04.910483 13823 sgd_solver.cpp:112] Iteration 368600, lr = 1e-06
I0823 03:11:14.754247 13823 solver.cpp:239] Iteration 368700 (10.1587 iter/s, 9.84378s/100 iters), loss = 0.0256045
I0823 03:11:14.754299 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0256037 (* 1 = 0.0256037 loss)
I0823 03:11:14.754309 13823 sgd_solver.cpp:112] Iteration 368700, lr = 1e-06
I0823 03:11:24.741613 13823 solver.cpp:239] Iteration 368800 (10.0127 iter/s, 9.98731s/100 iters), loss = 0.0288577
I0823 03:11:24.741663 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0288568 (* 1 = 0.0288568 loss)
I0823 03:11:24.741673 13823 sgd_solver.cpp:112] Iteration 368800, lr = 1e-06
I0823 03:11:34.778436 13823 solver.cpp:239] Iteration 368900 (9.96336 iter/s, 10.0368s/100 iters), loss = 0.0327255
I0823 03:11:34.778487 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0327247 (* 1 = 0.0327247 loss)
I0823 03:11:34.778496 13823 sgd_solver.cpp:112] Iteration 368900, lr = 1e-06
I0823 03:11:44.772102 13823 solver.cpp:239] Iteration 369000 (10.0064 iter/s, 9.99361s/100 iters), loss = 0.0267681
I0823 03:11:44.772156 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0267672 (* 1 = 0.0267672 loss)
I0823 03:11:44.772164 13823 sgd_solver.cpp:112] Iteration 369000, lr = 1e-06
I0823 03:11:54.474936 13823 solver.cpp:239] Iteration 369100 (10.3063 iter/s, 9.70278s/100 iters), loss = 0.0311054
I0823 03:11:54.474987 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0311045 (* 1 = 0.0311045 loss)
I0823 03:11:54.474997 13823 sgd_solver.cpp:112] Iteration 369100, lr = 1e-06
I0823 03:12:04.095069 13823 solver.cpp:239] Iteration 369200 (10.3949 iter/s, 9.62008s/100 iters), loss = 0.0335481
I0823 03:12:04.095134 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0335473 (* 1 = 0.0335473 loss)
I0823 03:12:04.095146 13823 sgd_solver.cpp:112] Iteration 369200, lr = 1e-06
I0823 03:12:13.895210 13823 solver.cpp:239] Iteration 369300 (10.204 iter/s, 9.80008s/100 iters), loss = 0.0256236
I0823 03:12:13.895259 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0256228 (* 1 = 0.0256228 loss)
I0823 03:12:13.895268 13823 sgd_solver.cpp:112] Iteration 369300, lr = 1e-06
I0823 03:12:24.066520 13823 solver.cpp:239] Iteration 369400 (9.83162 iter/s, 10.1713s/100 iters), loss = 0.026224
I0823 03:12:24.066570 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0262232 (* 1 = 0.0262232 loss)
I0823 03:12:24.066578 13823 sgd_solver.cpp:112] Iteration 369400, lr = 1e-06
I0823 03:12:34.071705 13823 solver.cpp:239] Iteration 369500 (9.99487 iter/s, 10.0051s/100 iters), loss = 0.0345681
I0823 03:12:34.071759 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0345672 (* 1 = 0.0345672 loss)
I0823 03:12:34.071769 13823 sgd_solver.cpp:112] Iteration 369500, lr = 1e-06
I0823 03:12:43.970160 13823 solver.cpp:239] Iteration 369600 (10.1026 iter/s, 9.8984s/100 iters), loss = 0.0262183
I0823 03:12:43.970218 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0262175 (* 1 = 0.0262175 loss)
I0823 03:12:43.970229 13823 sgd_solver.cpp:112] Iteration 369600, lr = 1e-06
I0823 03:12:53.902052 13823 solver.cpp:239] Iteration 369700 (10.0686 iter/s, 9.93183s/100 iters), loss = 0.0307422
I0823 03:12:53.902101 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0307414 (* 1 = 0.0307414 loss)
I0823 03:12:53.902110 13823 sgd_solver.cpp:112] Iteration 369700, lr = 1e-06
I0823 03:13:03.636683 13823 solver.cpp:239] Iteration 369800 (10.2727 iter/s, 9.73458s/100 iters), loss = 0.0274166
I0823 03:13:03.636729 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0274158 (* 1 = 0.0274158 loss)
I0823 03:13:03.636736 13823 sgd_solver.cpp:112] Iteration 369800, lr = 1e-06
I0823 03:13:12.954974 13823 solver.cpp:239] Iteration 369900 (10.7316 iter/s, 9.31825s/100 iters), loss = 0.0263054
I0823 03:13:12.955015 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0263046 (* 1 = 0.0263046 loss)
I0823 03:13:12.955024 13823 sgd_solver.cpp:112] Iteration 369900, lr = 1e-06
I0823 03:13:22.793913 13823 solver.cpp:239] Iteration 370000 (10.1637 iter/s, 9.83889s/100 iters), loss = 0.0250832
I0823 03:13:22.793963 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0250823 (* 1 = 0.0250823 loss)
I0823 03:13:22.793973 13823 sgd_solver.cpp:112] Iteration 370000, lr = 1e-06
I0823 03:13:32.737226 13823 solver.cpp:239] Iteration 370100 (10.0571 iter/s, 9.94326s/100 iters), loss = 0.029585
I0823 03:13:32.737277 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0295842 (* 1 = 0.0295842 loss)
I0823 03:13:32.737285 13823 sgd_solver.cpp:112] Iteration 370100, lr = 1e-06
I0823 03:13:42.690119 13823 solver.cpp:239] Iteration 370200 (10.0474 iter/s, 9.95284s/100 iters), loss = 0.0267279
I0823 03:13:42.690171 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0267271 (* 1 = 0.0267271 loss)
I0823 03:13:42.690179 13823 sgd_solver.cpp:112] Iteration 370200, lr = 1e-06
I0823 03:13:52.739171 13823 solver.cpp:239] Iteration 370300 (9.95124 iter/s, 10.049s/100 iters), loss = 0.0266385
I0823 03:13:52.739224 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0266376 (* 1 = 0.0266376 loss)
I0823 03:13:52.739235 13823 sgd_solver.cpp:112] Iteration 370300, lr = 1e-06
I0823 03:14:02.490276 13823 solver.cpp:239] Iteration 370400 (10.2553 iter/s, 9.75105s/100 iters), loss = 0.0383254
I0823 03:14:02.490326 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0383246 (* 1 = 0.0383246 loss)
I0823 03:14:02.490336 13823 sgd_solver.cpp:112] Iteration 370400, lr = 1e-06
I0823 03:14:12.500586 13823 solver.cpp:239] Iteration 370500 (9.98976 iter/s, 10.0103s/100 iters), loss = 0.0248723
I0823 03:14:12.500654 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0248715 (* 1 = 0.0248715 loss)
I0823 03:14:12.500664 13823 sgd_solver.cpp:112] Iteration 370500, lr = 1e-06
I0823 03:14:22.412233 13823 solver.cpp:239] Iteration 370600 (10.0892 iter/s, 9.91158s/100 iters), loss = 0.0256727
I0823 03:14:22.412297 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0256718 (* 1 = 0.0256718 loss)
I0823 03:14:22.412308 13823 sgd_solver.cpp:112] Iteration 370600, lr = 1e-06
I0823 03:14:32.279269 13823 solver.cpp:239] Iteration 370700 (10.1348 iter/s, 9.86698s/100 iters), loss = 0.0264116
I0823 03:14:32.279325 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0264107 (* 1 = 0.0264107 loss)
I0823 03:14:32.279335 13823 sgd_solver.cpp:112] Iteration 370700, lr = 1e-06
I0823 03:14:42.174409 13823 solver.cpp:239] Iteration 370800 (10.106 iter/s, 9.89508s/100 iters), loss = 0.0268165
I0823 03:14:42.174475 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0268157 (* 1 = 0.0268157 loss)
I0823 03:14:42.174489 13823 sgd_solver.cpp:112] Iteration 370800, lr = 1e-06
I0823 03:14:52.019985 13823 solver.cpp:239] Iteration 370900 (10.1569 iter/s, 9.84551s/100 iters), loss = 0.0277231
I0823 03:14:52.020031 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0277222 (* 1 = 0.0277222 loss)
I0823 03:14:52.020041 13823 sgd_solver.cpp:112] Iteration 370900, lr = 1e-06
I0823 03:15:02.178236 13823 solver.cpp:239] Iteration 371000 (9.84426 iter/s, 10.1582s/100 iters), loss = 0.0292678
I0823 03:15:02.178292 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.029267 (* 1 = 0.029267 loss)
I0823 03:15:02.178303 13823 sgd_solver.cpp:112] Iteration 371000, lr = 1e-06
I0823 03:15:12.344921 13823 solver.cpp:239] Iteration 371100 (9.8361 iter/s, 10.1666s/100 iters), loss = 0.0277084
I0823 03:15:12.344981 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0277075 (* 1 = 0.0277075 loss)
I0823 03:15:12.344993 13823 sgd_solver.cpp:112] Iteration 371100, lr = 1e-06
I0823 03:15:22.318038 13823 solver.cpp:239] Iteration 371200 (10.027 iter/s, 9.97306s/100 iters), loss = 0.0283576
I0823 03:15:22.318091 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0283567 (* 1 = 0.0283567 loss)
I0823 03:15:22.318101 13823 sgd_solver.cpp:112] Iteration 371200, lr = 1e-06
I0823 03:15:32.168354 13823 solver.cpp:239] Iteration 371300 (10.152 iter/s, 9.85026s/100 iters), loss = 0.0310979
I0823 03:15:32.168406 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0310971 (* 1 = 0.0310971 loss)
I0823 03:15:32.168414 13823 sgd_solver.cpp:112] Iteration 371300, lr = 1e-06
I0823 03:15:42.309522 13823 solver.cpp:239] Iteration 371400 (9.86084 iter/s, 10.1411s/100 iters), loss = 0.0249693
I0823 03:15:42.309573 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0249685 (* 1 = 0.0249685 loss)
I0823 03:15:42.309583 13823 sgd_solver.cpp:112] Iteration 371400, lr = 1e-06
I0823 03:15:52.445921 13823 solver.cpp:239] Iteration 371500 (9.86549 iter/s, 10.1363s/100 iters), loss = 0.0231536
I0823 03:15:52.445977 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0231528 (* 1 = 0.0231528 loss)
I0823 03:15:52.445988 13823 sgd_solver.cpp:112] Iteration 371500, lr = 1e-06
I0823 03:16:02.825906 13823 solver.cpp:239] Iteration 371600 (9.63398 iter/s, 10.3799s/100 iters), loss = 0.0342227
I0823 03:16:02.825960 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0342219 (* 1 = 0.0342219 loss)
I0823 03:16:02.825970 13823 sgd_solver.cpp:112] Iteration 371600, lr = 1e-06
I0823 03:16:13.071311 13823 solver.cpp:239] Iteration 371700 (9.76052 iter/s, 10.2454s/100 iters), loss = 0.0263943
I0823 03:16:13.071365 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0263935 (* 1 = 0.0263935 loss)
I0823 03:16:13.071375 13823 sgd_solver.cpp:112] Iteration 371700, lr = 1e-06
I0823 03:16:22.927999 13823 solver.cpp:239] Iteration 371800 (10.1454 iter/s, 9.85664s/100 iters), loss = 0.0379009
I0823 03:16:22.928050 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0379 (* 1 = 0.0379 loss)
I0823 03:16:22.928059 13823 sgd_solver.cpp:112] Iteration 371800, lr = 1e-06
I0823 03:16:33.053158 13823 solver.cpp:239] Iteration 371900 (9.87644 iter/s, 10.1251s/100 iters), loss = 0.0285877
I0823 03:16:33.053207 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0285869 (* 1 = 0.0285869 loss)
I0823 03:16:33.053216 13823 sgd_solver.cpp:112] Iteration 371900, lr = 1e-06
I0823 03:16:42.982187 13823 solver.cpp:239] Iteration 372000 (10.0715 iter/s, 9.92899s/100 iters), loss = 0.0254406
I0823 03:16:42.982228 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0254398 (* 1 = 0.0254398 loss)
I0823 03:16:42.982235 13823 sgd_solver.cpp:112] Iteration 372000, lr = 1e-06
I0823 03:16:53.105585 13823 solver.cpp:239] Iteration 372100 (9.87815 iter/s, 10.1234s/100 iters), loss = 0.0358593
I0823 03:16:53.105645 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0358584 (* 1 = 0.0358584 loss)
I0823 03:16:53.105657 13823 sgd_solver.cpp:112] Iteration 372100, lr = 1e-06
I0823 03:17:03.264111 13823 solver.cpp:239] Iteration 372200 (9.844 iter/s, 10.1585s/100 iters), loss = 0.0255594
I0823 03:17:03.264165 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0255585 (* 1 = 0.0255585 loss)
I0823 03:17:03.264175 13823 sgd_solver.cpp:112] Iteration 372200, lr = 1e-06
I0823 03:17:13.542682 13823 solver.cpp:239] Iteration 372300 (9.72903 iter/s, 10.2785s/100 iters), loss = 0.0264654
I0823 03:17:13.542732 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0264645 (* 1 = 0.0264645 loss)
I0823 03:17:13.542742 13823 sgd_solver.cpp:112] Iteration 372300, lr = 1e-06
I0823 03:17:23.455447 13823 solver.cpp:239] Iteration 372400 (10.088 iter/s, 9.91272s/100 iters), loss = 0.0297295
I0823 03:17:23.455499 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0297286 (* 1 = 0.0297286 loss)
I0823 03:17:23.455508 13823 sgd_solver.cpp:112] Iteration 372400, lr = 1e-06
I0823 03:17:33.471702 13823 solver.cpp:239] Iteration 372500 (9.98382 iter/s, 10.0162s/100 iters), loss = 0.0260129
I0823 03:17:33.471753 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.026012 (* 1 = 0.026012 loss)
I0823 03:17:33.471762 13823 sgd_solver.cpp:112] Iteration 372500, lr = 1e-06
I0823 03:17:43.676473 13823 solver.cpp:239] Iteration 372600 (9.79938 iter/s, 10.2047s/100 iters), loss = 0.0249984
I0823 03:17:43.676523 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0249976 (* 1 = 0.0249976 loss)
I0823 03:17:43.676532 13823 sgd_solver.cpp:112] Iteration 372600, lr = 1e-06
I0823 03:17:53.938927 13823 solver.cpp:239] Iteration 372700 (9.7443 iter/s, 10.2624s/100 iters), loss = 0.0227627
I0823 03:17:53.938977 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0227618 (* 1 = 0.0227618 loss)
I0823 03:17:53.938987 13823 sgd_solver.cpp:112] Iteration 372700, lr = 1e-06
I0823 03:18:04.488785 13823 solver.cpp:239] Iteration 372800 (9.47884 iter/s, 10.5498s/100 iters), loss = 0.0303077
I0823 03:18:04.488839 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0303068 (* 1 = 0.0303068 loss)
I0823 03:18:04.488849 13823 sgd_solver.cpp:112] Iteration 372800, lr = 1e-06
I0823 03:18:14.905400 13823 solver.cpp:239] Iteration 372900 (9.6001 iter/s, 10.4166s/100 iters), loss = 0.0249657
I0823 03:18:14.905460 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0249649 (* 1 = 0.0249649 loss)
I0823 03:18:14.905472 13823 sgd_solver.cpp:112] Iteration 372900, lr = 1e-06
I0823 03:18:25.287300 13823 solver.cpp:239] Iteration 373000 (9.6322 iter/s, 10.3818s/100 iters), loss = 0.0352283
I0823 03:18:25.287349 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0352274 (* 1 = 0.0352274 loss)
I0823 03:18:25.287359 13823 sgd_solver.cpp:112] Iteration 373000, lr = 1e-06
I0823 03:18:35.618432 13823 solver.cpp:239] Iteration 373100 (9.67953 iter/s, 10.3311s/100 iters), loss = 0.0261051
I0823 03:18:35.618480 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0261042 (* 1 = 0.0261042 loss)
I0823 03:18:35.618489 13823 sgd_solver.cpp:112] Iteration 373100, lr = 1e-06
I0823 03:18:45.832592 13823 solver.cpp:239] Iteration 373200 (9.79037 iter/s, 10.2141s/100 iters), loss = 0.0291789
I0823 03:18:45.832645 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0291781 (* 1 = 0.0291781 loss)
I0823 03:18:45.832655 13823 sgd_solver.cpp:112] Iteration 373200, lr = 1e-06
I0823 03:18:56.087600 13823 solver.cpp:239] Iteration 373300 (9.75138 iter/s, 10.255s/100 iters), loss = 0.0250595
I0823 03:18:56.087653 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0250587 (* 1 = 0.0250587 loss)
I0823 03:18:56.087662 13823 sgd_solver.cpp:112] Iteration 373300, lr = 1e-06
I0823 03:19:06.227020 13823 solver.cpp:239] Iteration 373400 (9.86255 iter/s, 10.1394s/100 iters), loss = 0.0224394
I0823 03:19:06.227072 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0224386 (* 1 = 0.0224386 loss)
I0823 03:19:06.227082 13823 sgd_solver.cpp:112] Iteration 373400, lr = 1e-06
I0823 03:19:16.542115 13823 solver.cpp:239] Iteration 373500 (9.69457 iter/s, 10.315s/100 iters), loss = 0.0280812
I0823 03:19:16.542165 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0280804 (* 1 = 0.0280804 loss)
I0823 03:19:16.542174 13823 sgd_solver.cpp:112] Iteration 373500, lr = 1e-06
I0823 03:19:26.871955 13823 solver.cpp:239] Iteration 373600 (9.68074 iter/s, 10.3298s/100 iters), loss = 0.0278667
I0823 03:19:26.872007 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0278659 (* 1 = 0.0278659 loss)
I0823 03:19:26.872017 13823 sgd_solver.cpp:112] Iteration 373600, lr = 1e-06
I0823 03:19:37.304700 13823 solver.cpp:239] Iteration 373700 (9.58525 iter/s, 10.4327s/100 iters), loss = 0.0271113
I0823 03:19:37.304751 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0271105 (* 1 = 0.0271105 loss)
I0823 03:19:37.304760 13823 sgd_solver.cpp:112] Iteration 373700, lr = 1e-06
I0823 03:19:47.631436 13823 solver.cpp:239] Iteration 373800 (9.68365 iter/s, 10.3267s/100 iters), loss = 0.0259311
I0823 03:19:47.631496 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0259303 (* 1 = 0.0259303 loss)
I0823 03:19:47.631507 13823 sgd_solver.cpp:112] Iteration 373800, lr = 1e-06
I0823 03:19:57.912814 13823 solver.cpp:239] Iteration 373900 (9.72638 iter/s, 10.2813s/100 iters), loss = 0.029713
I0823 03:19:57.912869 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0297122 (* 1 = 0.0297122 loss)
I0823 03:19:57.912879 13823 sgd_solver.cpp:112] Iteration 373900, lr = 1e-06
I0823 03:20:08.370918 13823 solver.cpp:239] Iteration 374000 (9.56201 iter/s, 10.4581s/100 iters), loss = 0.0258057
I0823 03:20:08.370970 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0258049 (* 1 = 0.0258049 loss)
I0823 03:20:08.370980 13823 sgd_solver.cpp:112] Iteration 374000, lr = 1e-06
I0823 03:20:18.676520 13823 solver.cpp:239] Iteration 374100 (9.70351 iter/s, 10.3056s/100 iters), loss = 0.0243758
I0823 03:20:18.676573 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.024375 (* 1 = 0.024375 loss)
I0823 03:20:18.676582 13823 sgd_solver.cpp:112] Iteration 374100, lr = 1e-06
I0823 03:20:29.067582 13823 solver.cpp:239] Iteration 374200 (9.6237 iter/s, 10.391s/100 iters), loss = 0.0284421
I0823 03:20:29.067646 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0284413 (* 1 = 0.0284413 loss)
I0823 03:20:29.067657 13823 sgd_solver.cpp:112] Iteration 374200, lr = 1e-06
I0823 03:20:39.747643 13823 solver.cpp:239] Iteration 374300 (9.36329 iter/s, 10.68s/100 iters), loss = 0.0250356
I0823 03:20:39.747699 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0250347 (* 1 = 0.0250347 loss)
I0823 03:20:39.747709 13823 sgd_solver.cpp:112] Iteration 374300, lr = 1e-06
I0823 03:20:50.251176 13823 solver.cpp:239] Iteration 374400 (9.52065 iter/s, 10.5035s/100 iters), loss = 0.0263617
I0823 03:20:50.251240 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0263609 (* 1 = 0.0263609 loss)
I0823 03:20:50.251252 13823 sgd_solver.cpp:112] Iteration 374400, lr = 1e-06
I0823 03:21:00.734298 13823 solver.cpp:239] Iteration 374500 (9.5392 iter/s, 10.4831s/100 iters), loss = 0.0249184
I0823 03:21:00.734357 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0249176 (* 1 = 0.0249176 loss)
I0823 03:21:00.734369 13823 sgd_solver.cpp:112] Iteration 374500, lr = 1e-06
I0823 03:21:11.120414 13823 solver.cpp:239] Iteration 374600 (9.62829 iter/s, 10.3861s/100 iters), loss = 0.0292743
I0823 03:21:11.120463 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0292735 (* 1 = 0.0292735 loss)
I0823 03:21:11.120473 13823 sgd_solver.cpp:112] Iteration 374600, lr = 1e-06
I0823 03:21:21.609760 13823 solver.cpp:239] Iteration 374700 (9.53352 iter/s, 10.4893s/100 iters), loss = 0.0247257
I0823 03:21:21.609812 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0247249 (* 1 = 0.0247249 loss)
I0823 03:21:21.609822 13823 sgd_solver.cpp:112] Iteration 374700, lr = 1e-06
I0823 03:21:32.107628 13823 solver.cpp:239] Iteration 374800 (9.52578 iter/s, 10.4978s/100 iters), loss = 0.024265
I0823 03:21:32.107681 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0242642 (* 1 = 0.0242642 loss)
I0823 03:21:32.107692 13823 sgd_solver.cpp:112] Iteration 374800, lr = 1e-06
I0823 03:21:42.665997 13823 solver.cpp:239] Iteration 374900 (9.4712 iter/s, 10.5583s/100 iters), loss = 0.0251364
I0823 03:21:42.666054 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0251356 (* 1 = 0.0251356 loss)
I0823 03:21:42.666064 13823 sgd_solver.cpp:112] Iteration 374900, lr = 1e-06
I0823 03:21:53.052552 13823 solver.cpp:239] Iteration 375000 (9.62788 iter/s, 10.3865s/100 iters), loss = 0.046016
I0823 03:21:53.052601 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0460152 (* 1 = 0.0460152 loss)
I0823 03:21:53.052610 13823 sgd_solver.cpp:112] Iteration 375000, lr = 1e-06
I0823 03:22:03.641680 13823 solver.cpp:239] Iteration 375100 (9.44369 iter/s, 10.5891s/100 iters), loss = 0.0333114
I0823 03:22:03.641736 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0333106 (* 1 = 0.0333106 loss)
I0823 03:22:03.641746 13823 sgd_solver.cpp:112] Iteration 375100, lr = 1e-06
I0823 03:22:13.913960 13823 solver.cpp:239] Iteration 375200 (9.73498 iter/s, 10.2722s/100 iters), loss = 0.0415106
I0823 03:22:13.914013 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0415097 (* 1 = 0.0415097 loss)
I0823 03:22:13.914022 13823 sgd_solver.cpp:112] Iteration 375200, lr = 1e-06
I0823 03:22:24.521512 13823 solver.cpp:239] Iteration 375300 (9.42729 iter/s, 10.6075s/100 iters), loss = 0.028994
I0823 03:22:24.521564 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0289931 (* 1 = 0.0289931 loss)
I0823 03:22:24.521572 13823 sgd_solver.cpp:112] Iteration 375300, lr = 1e-06
I0823 03:22:34.953218 13823 solver.cpp:239] Iteration 375400 (9.5862 iter/s, 10.4317s/100 iters), loss = 0.030985
I0823 03:22:34.953266 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0309842 (* 1 = 0.0309842 loss)
I0823 03:22:34.953276 13823 sgd_solver.cpp:112] Iteration 375400, lr = 1e-06
I0823 03:22:45.514294 13823 solver.cpp:239] Iteration 375500 (9.46877 iter/s, 10.561s/100 iters), loss = 0.0316937
I0823 03:22:45.514345 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0316929 (* 1 = 0.0316929 loss)
I0823 03:22:45.514354 13823 sgd_solver.cpp:112] Iteration 375500, lr = 1e-06
I0823 03:22:55.976969 13823 solver.cpp:239] Iteration 375600 (9.55783 iter/s, 10.4626s/100 iters), loss = 0.0311786
I0823 03:22:55.977018 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0311778 (* 1 = 0.0311778 loss)
I0823 03:22:55.977027 13823 sgd_solver.cpp:112] Iteration 375600, lr = 1e-06
I0823 03:23:06.435745 13823 solver.cpp:239] Iteration 375700 (9.56139 iter/s, 10.4587s/100 iters), loss = 0.0248247
I0823 03:23:06.435796 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0248239 (* 1 = 0.0248239 loss)
I0823 03:23:06.435804 13823 sgd_solver.cpp:112] Iteration 375700, lr = 1e-06
I0823 03:23:17.209538 13823 solver.cpp:239] Iteration 375800 (9.28182 iter/s, 10.7738s/100 iters), loss = 0.0291478
I0823 03:23:17.209591 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0291469 (* 1 = 0.0291469 loss)
I0823 03:23:17.209602 13823 sgd_solver.cpp:112] Iteration 375800, lr = 1e-06
I0823 03:23:27.867121 13823 solver.cpp:239] Iteration 375900 (9.38303 iter/s, 10.6575s/100 iters), loss = 0.0234274
I0823 03:23:27.867172 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0234266 (* 1 = 0.0234266 loss)
I0823 03:23:27.867182 13823 sgd_solver.cpp:112] Iteration 375900, lr = 1e-06
I0823 03:23:38.534142 13823 solver.cpp:239] Iteration 376000 (9.37473 iter/s, 10.667s/100 iters), loss = 0.0269117
I0823 03:23:38.534196 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0269109 (* 1 = 0.0269109 loss)
I0823 03:23:38.534206 13823 sgd_solver.cpp:112] Iteration 376000, lr = 1e-06
I0823 03:23:49.227120 13823 solver.cpp:239] Iteration 376100 (9.35197 iter/s, 10.6929s/100 iters), loss = 0.0250905
I0823 03:23:49.227170 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0250897 (* 1 = 0.0250897 loss)
I0823 03:23:49.227180 13823 sgd_solver.cpp:112] Iteration 376100, lr = 1e-06
I0823 03:23:59.739495 13823 solver.cpp:239] Iteration 376200 (9.51264 iter/s, 10.5123s/100 iters), loss = 0.026196
I0823 03:23:59.739553 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0261951 (* 1 = 0.0261951 loss)
I0823 03:23:59.739564 13823 sgd_solver.cpp:112] Iteration 376200, lr = 1e-06
I0823 03:24:10.028764 13823 solver.cpp:239] Iteration 376300 (9.71891 iter/s, 10.2892s/100 iters), loss = 0.0252898
I0823 03:24:10.028821 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.025289 (* 1 = 0.025289 loss)
I0823 03:24:10.028832 13823 sgd_solver.cpp:112] Iteration 376300, lr = 1e-06
I0823 03:24:20.856570 13823 solver.cpp:239] Iteration 376400 (9.23552 iter/s, 10.8278s/100 iters), loss = 0.0289166
I0823 03:24:20.856618 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0289158 (* 1 = 0.0289158 loss)
I0823 03:24:20.856628 13823 sgd_solver.cpp:112] Iteration 376400, lr = 1e-06
I0823 03:24:31.536685 13823 solver.cpp:239] Iteration 376500 (9.36323 iter/s, 10.6801s/100 iters), loss = 0.0298269
I0823 03:24:31.536744 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0298261 (* 1 = 0.0298261 loss)
I0823 03:24:31.536756 13823 sgd_solver.cpp:112] Iteration 376500, lr = 1e-06
I0823 03:24:42.429417 13823 solver.cpp:239] Iteration 376600 (9.18048 iter/s, 10.8927s/100 iters), loss = 0.0271216
I0823 03:24:42.429484 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0271207 (* 1 = 0.0271207 loss)
I0823 03:24:42.429497 13823 sgd_solver.cpp:112] Iteration 376600, lr = 1e-06
I0823 03:24:53.128221 13823 solver.cpp:239] Iteration 376700 (9.34689 iter/s, 10.6987s/100 iters), loss = 0.0285468
I0823 03:24:53.128280 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0285459 (* 1 = 0.0285459 loss)
I0823 03:24:53.128291 13823 sgd_solver.cpp:112] Iteration 376700, lr = 1e-06
I0823 03:25:03.831009 13823 solver.cpp:239] Iteration 376800 (9.34341 iter/s, 10.7027s/100 iters), loss = 0.0264157
I0823 03:25:03.831073 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0264148 (* 1 = 0.0264148 loss)
I0823 03:25:03.831085 13823 sgd_solver.cpp:112] Iteration 376800, lr = 1e-06
I0823 03:25:14.689899 13823 solver.cpp:239] Iteration 376900 (9.20909 iter/s, 10.8588s/100 iters), loss = 0.0266735
I0823 03:25:14.689947 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0266726 (* 1 = 0.0266726 loss)
I0823 03:25:14.689956 13823 sgd_solver.cpp:112] Iteration 376900, lr = 1e-06
I0823 03:25:25.826570 13823 solver.cpp:239] Iteration 377000 (8.97938 iter/s, 11.1366s/100 iters), loss = 0.0235633
I0823 03:25:25.826632 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0235624 (* 1 = 0.0235624 loss)
I0823 03:25:25.826643 13823 sgd_solver.cpp:112] Iteration 377000, lr = 1e-06
I0823 03:25:36.721618 13823 solver.cpp:239] Iteration 377100 (9.17853 iter/s, 10.895s/100 iters), loss = 0.0257373
I0823 03:25:36.721680 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0257364 (* 1 = 0.0257364 loss)
I0823 03:25:36.721693 13823 sgd_solver.cpp:112] Iteration 377100, lr = 1e-06
I0823 03:25:47.417497 13823 solver.cpp:239] Iteration 377200 (9.34937 iter/s, 10.6959s/100 iters), loss = 0.026592
I0823 03:25:47.417552 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0265912 (* 1 = 0.0265912 loss)
I0823 03:25:47.417565 13823 sgd_solver.cpp:112] Iteration 377200, lr = 1e-06
I0823 03:25:58.677750 13823 solver.cpp:239] Iteration 377300 (8.88072 iter/s, 11.2604s/100 iters), loss = 0.0286318
I0823 03:25:58.677815 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.028631 (* 1 = 0.028631 loss)
I0823 03:25:58.677829 13823 sgd_solver.cpp:112] Iteration 377300, lr = 1e-06
I0823 03:26:09.375536 13823 solver.cpp:239] Iteration 377400 (9.34766 iter/s, 10.6979s/100 iters), loss = 0.0282806
I0823 03:26:09.375600 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0282798 (* 1 = 0.0282798 loss)
I0823 03:26:09.375612 13823 sgd_solver.cpp:112] Iteration 377400, lr = 1e-06
I0823 03:26:20.126076 13823 solver.cpp:239] Iteration 377500 (9.30179 iter/s, 10.7506s/100 iters), loss = 0.0249032
I0823 03:26:20.126132 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0249024 (* 1 = 0.0249024 loss)
I0823 03:26:20.126142 13823 sgd_solver.cpp:112] Iteration 377500, lr = 1e-06
I0823 03:26:31.267978 13823 solver.cpp:239] Iteration 377600 (8.97505 iter/s, 11.142s/100 iters), loss = 0.0255249
I0823 03:26:31.268028 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.025524 (* 1 = 0.025524 loss)
I0823 03:26:31.268038 13823 sgd_solver.cpp:112] Iteration 377600, lr = 1e-06
I0823 03:26:41.922049 13823 solver.cpp:239] Iteration 377700 (9.38601 iter/s, 10.6542s/100 iters), loss = 0.0256556
I0823 03:26:41.922114 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0256548 (* 1 = 0.0256548 loss)
I0823 03:26:41.922128 13823 sgd_solver.cpp:112] Iteration 377700, lr = 1e-06
I0823 03:26:52.684556 13823 solver.cpp:239] Iteration 377800 (9.29145 iter/s, 10.7626s/100 iters), loss = 0.0257336
I0823 03:26:52.684613 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0257328 (* 1 = 0.0257328 loss)
I0823 03:26:52.684624 13823 sgd_solver.cpp:112] Iteration 377800, lr = 1e-06
I0823 03:27:03.663415 13823 solver.cpp:239] Iteration 377900 (9.10835 iter/s, 10.9789s/100 iters), loss = 0.0289064
I0823 03:27:03.663475 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0289056 (* 1 = 0.0289056 loss)
I0823 03:27:03.663486 13823 sgd_solver.cpp:112] Iteration 377900, lr = 1e-06
I0823 03:27:14.787545 13823 solver.cpp:239] Iteration 378000 (8.9894 iter/s, 11.1242s/100 iters), loss = 0.0259481
I0823 03:27:14.787601 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0259473 (* 1 = 0.0259473 loss)
I0823 03:27:14.787614 13823 sgd_solver.cpp:112] Iteration 378000, lr = 1e-06
I0823 03:27:25.397080 13823 solver.cpp:239] Iteration 378100 (9.42541 iter/s, 10.6096s/100 iters), loss = 0.0333694
I0823 03:27:25.397123 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0333686 (* 1 = 0.0333686 loss)
I0823 03:27:25.397130 13823 sgd_solver.cpp:112] Iteration 378100, lr = 1e-06
I0823 03:27:36.018805 13823 solver.cpp:239] Iteration 378200 (9.41459 iter/s, 10.6218s/100 iters), loss = 0.0259006
I0823 03:27:36.018848 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0258997 (* 1 = 0.0258997 loss)
I0823 03:27:36.018855 13823 sgd_solver.cpp:112] Iteration 378200, lr = 1e-06
I0823 03:27:47.138854 13823 solver.cpp:239] Iteration 378300 (8.9927 iter/s, 11.1201s/100 iters), loss = 0.0213437
I0823 03:27:47.138907 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0213429 (* 1 = 0.0213429 loss)
I0823 03:27:47.138917 13823 sgd_solver.cpp:112] Iteration 378300, lr = 1e-06
I0823 03:27:57.830448 13823 solver.cpp:239] Iteration 378400 (9.35308 iter/s, 10.6917s/100 iters), loss = 0.0276187
I0823 03:27:57.830504 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0276179 (* 1 = 0.0276179 loss)
I0823 03:27:57.830515 13823 sgd_solver.cpp:112] Iteration 378400, lr = 1e-06
I0823 03:28:08.757196 13823 solver.cpp:239] Iteration 378500 (9.1518 iter/s, 10.9268s/100 iters), loss = 0.0270071
I0823 03:28:08.757254 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0270063 (* 1 = 0.0270063 loss)
I0823 03:28:08.757266 13823 sgd_solver.cpp:112] Iteration 378500, lr = 1e-06
I0823 03:28:19.923215 13823 solver.cpp:239] Iteration 378600 (8.95569 iter/s, 11.1661s/100 iters), loss = 0.0345744
I0823 03:28:19.923274 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0345735 (* 1 = 0.0345735 loss)
I0823 03:28:19.923286 13823 sgd_solver.cpp:112] Iteration 378600, lr = 1e-06
I0823 03:28:30.874774 13823 solver.cpp:239] Iteration 378700 (9.13107 iter/s, 10.9516s/100 iters), loss = 0.0260534
I0823 03:28:30.874824 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0260525 (* 1 = 0.0260525 loss)
I0823 03:28:30.874832 13823 sgd_solver.cpp:112] Iteration 378700, lr = 1e-06
I0823 03:28:41.816175 13823 solver.cpp:239] Iteration 378800 (9.13954 iter/s, 10.9415s/100 iters), loss = 0.0293904
I0823 03:28:41.816241 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0293895 (* 1 = 0.0293895 loss)
I0823 03:28:41.816253 13823 sgd_solver.cpp:112] Iteration 378800, lr = 1e-06
I0823 03:28:52.657824 13823 solver.cpp:239] Iteration 378900 (9.22364 iter/s, 10.8417s/100 iters), loss = 0.0239347
I0823 03:28:52.657872 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0239338 (* 1 = 0.0239338 loss)
I0823 03:28:52.657882 13823 sgd_solver.cpp:112] Iteration 378900, lr = 1e-06
I0823 03:29:03.501987 13823 solver.cpp:239] Iteration 379000 (9.22149 iter/s, 10.8442s/100 iters), loss = 0.0253326
I0823 03:29:03.502038 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0253318 (* 1 = 0.0253318 loss)
I0823 03:29:03.502046 13823 sgd_solver.cpp:112] Iteration 379000, lr = 1e-06
I0823 03:29:14.467962 13823 solver.cpp:239] Iteration 379100 (9.11906 iter/s, 10.966s/100 iters), loss = 0.0346061
I0823 03:29:14.468015 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0346052 (* 1 = 0.0346052 loss)
I0823 03:29:14.468025 13823 sgd_solver.cpp:112] Iteration 379100, lr = 1e-06
I0823 03:29:25.755156 13823 solver.cpp:239] Iteration 379200 (8.85955 iter/s, 11.2873s/100 iters), loss = 0.0263815
I0823 03:29:25.755213 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0263807 (* 1 = 0.0263807 loss)
I0823 03:29:25.755223 13823 sgd_solver.cpp:112] Iteration 379200, lr = 1e-06
I0823 03:29:36.931877 13823 solver.cpp:239] Iteration 379300 (8.94712 iter/s, 11.1768s/100 iters), loss = 0.0282289
I0823 03:29:36.931938 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0282281 (* 1 = 0.0282281 loss)
I0823 03:29:36.931951 13823 sgd_solver.cpp:112] Iteration 379300, lr = 1e-06
I0823 03:29:47.925894 13823 solver.cpp:239] Iteration 379400 (9.09581 iter/s, 10.9941s/100 iters), loss = 0.0388943
I0823 03:29:47.925943 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0388935 (* 1 = 0.0388935 loss)
I0823 03:29:47.925953 13823 sgd_solver.cpp:112] Iteration 379400, lr = 1e-06
I0823 03:29:58.865600 13823 solver.cpp:239] Iteration 379500 (9.14097 iter/s, 10.9398s/100 iters), loss = 0.0257629
I0823 03:29:58.865660 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0257621 (* 1 = 0.0257621 loss)
I0823 03:29:58.865671 13823 sgd_solver.cpp:112] Iteration 379500, lr = 1e-06
I0823 03:30:09.861218 13823 solver.cpp:239] Iteration 379600 (9.09449 iter/s, 10.9957s/100 iters), loss = 0.0294583
I0823 03:30:09.861281 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0294575 (* 1 = 0.0294575 loss)
I0823 03:30:09.861294 13823 sgd_solver.cpp:112] Iteration 379600, lr = 1e-06
I0823 03:30:21.014823 13823 solver.cpp:239] Iteration 379700 (8.96568 iter/s, 11.1536s/100 iters), loss = 0.0277766
I0823 03:30:21.014878 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0277758 (* 1 = 0.0277758 loss)
I0823 03:30:21.014890 13823 sgd_solver.cpp:112] Iteration 379700, lr = 1e-06
I0823 03:30:32.040509 13823 solver.cpp:239] Iteration 379800 (9.06969 iter/s, 11.0257s/100 iters), loss = 0.0325773
I0823 03:30:32.040567 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0325765 (* 1 = 0.0325765 loss)
I0823 03:30:32.040578 13823 sgd_solver.cpp:112] Iteration 379800, lr = 1e-06
I0823 03:30:43.324451 13823 solver.cpp:239] Iteration 379900 (8.86211 iter/s, 11.284s/100 iters), loss = 0.024405
I0823 03:30:43.324501 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0244042 (* 1 = 0.0244042 loss)
I0823 03:30:43.324508 13823 sgd_solver.cpp:112] Iteration 379900, lr = 1e-06
I0823 03:30:54.402719 13823 solver.cpp:464] Snapshotting to binary proto file ./model_112/cascade_mobilenet_112_iter_380000.caffemodel
I0823 03:30:54.451601 13823 sgd_solver.cpp:284] Snapshotting solver state to binary proto file ./model_112/cascade_mobilenet_112_iter_380000.solverstate
I0823 03:30:54.483094 13823 solver.cpp:347] Iteration 380000, Testing net (#0)
I0823 03:32:00.299155 13823 solver.cpp:414]     Test net output #0: landmark_loss = 0.0220515 (* 1 = 0.0220515 loss)
I0823 03:32:00.415295 13823 solver.cpp:239] Iteration 380000 (1.29716 iter/s, 77.0915s/100 iters), loss = 0.0365397
I0823 03:32:00.415346 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0365389 (* 1 = 0.0365389 loss)
I0823 03:32:00.415360 13823 sgd_solver.cpp:112] Iteration 380000, lr = 1e-06
I0823 03:32:11.769218 13823 solver.cpp:239] Iteration 380100 (8.80749 iter/s, 11.354s/100 iters), loss = 0.0272788
I0823 03:32:11.769279 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.027278 (* 1 = 0.027278 loss)
I0823 03:32:11.769290 13823 sgd_solver.cpp:112] Iteration 380100, lr = 1e-06
I0823 03:32:22.931078 13823 solver.cpp:239] Iteration 380200 (8.95905 iter/s, 11.1619s/100 iters), loss = 0.0283652
I0823 03:32:22.931128 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0283644 (* 1 = 0.0283644 loss)
I0823 03:32:22.931138 13823 sgd_solver.cpp:112] Iteration 380200, lr = 1e-06
I0823 03:32:34.046528 13823 solver.cpp:239] Iteration 380300 (8.99645 iter/s, 11.1155s/100 iters), loss = 0.0268653
I0823 03:32:34.046588 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0268645 (* 1 = 0.0268645 loss)
I0823 03:32:34.046599 13823 sgd_solver.cpp:112] Iteration 380300, lr = 1e-06
I0823 03:32:45.295234 13823 solver.cpp:239] Iteration 380400 (8.88988 iter/s, 11.2487s/100 iters), loss = 0.0320102
I0823 03:32:45.295296 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0320094 (* 1 = 0.0320094 loss)
I0823 03:32:45.295308 13823 sgd_solver.cpp:112] Iteration 380400, lr = 1e-06
I0823 03:32:56.494298 13823 solver.cpp:239] Iteration 380500 (8.92929 iter/s, 11.1991s/100 iters), loss = 0.0874926
I0823 03:32:56.494354 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0874918 (* 1 = 0.0874918 loss)
I0823 03:32:56.494365 13823 sgd_solver.cpp:112] Iteration 380500, lr = 1e-06
I0823 03:33:07.540884 13823 solver.cpp:239] Iteration 380600 (9.05254 iter/s, 11.0466s/100 iters), loss = 0.0257406
I0823 03:33:07.540940 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0257398 (* 1 = 0.0257398 loss)
I0823 03:33:07.540949 13823 sgd_solver.cpp:112] Iteration 380600, lr = 1e-06
I0823 03:33:18.634964 13823 solver.cpp:239] Iteration 380700 (9.01379 iter/s, 11.0941s/100 iters), loss = 0.0283694
I0823 03:33:18.635015 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0283686 (* 1 = 0.0283686 loss)
I0823 03:33:18.635026 13823 sgd_solver.cpp:112] Iteration 380700, lr = 1e-06
I0823 03:33:29.853924 13823 solver.cpp:239] Iteration 380800 (8.91345 iter/s, 11.219s/100 iters), loss = 0.0366432
I0823 03:33:29.853977 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0366424 (* 1 = 0.0366424 loss)
I0823 03:33:29.853987 13823 sgd_solver.cpp:112] Iteration 380800, lr = 1e-06
I0823 03:33:41.195688 13823 solver.cpp:239] Iteration 380900 (8.81694 iter/s, 11.3418s/100 iters), loss = 0.0266977
I0823 03:33:41.195739 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0266969 (* 1 = 0.0266969 loss)
I0823 03:33:41.195749 13823 sgd_solver.cpp:112] Iteration 380900, lr = 1e-06
I0823 03:33:52.366457 13823 solver.cpp:239] Iteration 381000 (8.95191 iter/s, 11.1708s/100 iters), loss = 0.0273507
I0823 03:33:52.366509 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0273499 (* 1 = 0.0273499 loss)
I0823 03:33:52.366519 13823 sgd_solver.cpp:112] Iteration 381000, lr = 1e-06
I0823 03:34:03.927564 13823 solver.cpp:239] Iteration 381100 (8.64966 iter/s, 11.5611s/100 iters), loss = 0.0274525
I0823 03:34:03.927621 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0274517 (* 1 = 0.0274517 loss)
I0823 03:34:03.927633 13823 sgd_solver.cpp:112] Iteration 381100, lr = 1e-06
I0823 03:34:15.534811 13823 solver.cpp:239] Iteration 381200 (8.61528 iter/s, 11.6073s/100 iters), loss = 0.0259614
I0823 03:34:15.534865 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0259606 (* 1 = 0.0259606 loss)
I0823 03:34:15.534876 13823 sgd_solver.cpp:112] Iteration 381200, lr = 1e-06
I0823 03:34:27.069320 13823 solver.cpp:239] Iteration 381300 (8.66961 iter/s, 11.5345s/100 iters), loss = 0.0335142
I0823 03:34:27.069376 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0335134 (* 1 = 0.0335134 loss)
I0823 03:34:27.069387 13823 sgd_solver.cpp:112] Iteration 381300, lr = 1e-06
I0823 03:34:38.761881 13823 solver.cpp:239] Iteration 381400 (8.55242 iter/s, 11.6926s/100 iters), loss = 0.0260226
I0823 03:34:38.761934 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0260218 (* 1 = 0.0260218 loss)
I0823 03:34:38.761945 13823 sgd_solver.cpp:112] Iteration 381400, lr = 1e-06
I0823 03:34:50.391769 13823 solver.cpp:239] Iteration 381500 (8.59851 iter/s, 11.6299s/100 iters), loss = 0.0268637
I0823 03:34:50.391829 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0268629 (* 1 = 0.0268629 loss)
I0823 03:34:50.391839 13823 sgd_solver.cpp:112] Iteration 381500, lr = 1e-06
I0823 03:35:02.105098 13823 solver.cpp:239] Iteration 381600 (8.53726 iter/s, 11.7134s/100 iters), loss = 0.025451
I0823 03:35:02.105151 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0254502 (* 1 = 0.0254502 loss)
I0823 03:35:02.105162 13823 sgd_solver.cpp:112] Iteration 381600, lr = 1e-06
I0823 03:35:13.368111 13823 solver.cpp:239] Iteration 381700 (8.8786 iter/s, 11.263s/100 iters), loss = 0.0248861
I0823 03:35:13.368165 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0248852 (* 1 = 0.0248852 loss)
I0823 03:35:13.368175 13823 sgd_solver.cpp:112] Iteration 381700, lr = 1e-06
I0823 03:35:24.630412 13823 solver.cpp:239] Iteration 381800 (8.87916 iter/s, 11.2623s/100 iters), loss = 0.0220765
I0823 03:35:24.630470 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0220756 (* 1 = 0.0220756 loss)
I0823 03:35:24.630481 13823 sgd_solver.cpp:112] Iteration 381800, lr = 1e-06
I0823 03:35:35.810678 13823 solver.cpp:239] Iteration 381900 (8.94431 iter/s, 11.1803s/100 iters), loss = 0.0231806
I0823 03:35:35.810734 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0231798 (* 1 = 0.0231798 loss)
I0823 03:35:35.810745 13823 sgd_solver.cpp:112] Iteration 381900, lr = 1e-06
I0823 03:35:47.281877 13823 solver.cpp:239] Iteration 382000 (8.71747 iter/s, 11.4712s/100 iters), loss = 0.0287328
I0823 03:35:47.281939 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.028732 (* 1 = 0.028732 loss)
I0823 03:35:47.281951 13823 sgd_solver.cpp:112] Iteration 382000, lr = 1e-06
I0823 03:35:58.800407 13823 solver.cpp:239] Iteration 382100 (8.68165 iter/s, 11.5185s/100 iters), loss = 0.0269588
I0823 03:35:58.800458 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.026958 (* 1 = 0.026958 loss)
I0823 03:35:58.800468 13823 sgd_solver.cpp:112] Iteration 382100, lr = 1e-06
I0823 03:36:10.565541 13823 solver.cpp:239] Iteration 382200 (8.49967 iter/s, 11.7652s/100 iters), loss = 0.0318766
I0823 03:36:10.565591 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0318758 (* 1 = 0.0318758 loss)
I0823 03:36:10.565600 13823 sgd_solver.cpp:112] Iteration 382200, lr = 1e-06
I0823 03:36:22.027123 13823 solver.cpp:239] Iteration 382300 (8.72478 iter/s, 11.4616s/100 iters), loss = 0.0233889
I0823 03:36:22.027173 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0233881 (* 1 = 0.0233881 loss)
I0823 03:36:22.027182 13823 sgd_solver.cpp:112] Iteration 382300, lr = 1e-06
I0823 03:36:33.565963 13823 solver.cpp:239] Iteration 382400 (8.66636 iter/s, 11.5389s/100 iters), loss = 0.0402467
I0823 03:36:33.566026 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0402459 (* 1 = 0.0402459 loss)
I0823 03:36:33.566040 13823 sgd_solver.cpp:112] Iteration 382400, lr = 1e-06
I0823 03:36:45.137784 13823 solver.cpp:239] Iteration 382500 (8.64167 iter/s, 11.5718s/100 iters), loss = 0.0248384
I0823 03:36:45.137840 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0248375 (* 1 = 0.0248375 loss)
I0823 03:36:45.137850 13823 sgd_solver.cpp:112] Iteration 382500, lr = 1e-06
I0823 03:36:56.495992 13823 solver.cpp:239] Iteration 382600 (8.80419 iter/s, 11.3582s/100 iters), loss = 0.0266434
I0823 03:36:56.496048 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0266426 (* 1 = 0.0266426 loss)
I0823 03:36:56.496058 13823 sgd_solver.cpp:112] Iteration 382600, lr = 1e-06
I0823 03:37:07.911034 13823 solver.cpp:239] Iteration 382700 (8.76036 iter/s, 11.4151s/100 iters), loss = 0.0211531
I0823 03:37:07.911087 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0211522 (* 1 = 0.0211522 loss)
I0823 03:37:07.911096 13823 sgd_solver.cpp:112] Iteration 382700, lr = 1e-06
I0823 03:37:19.347295 13823 solver.cpp:239] Iteration 382800 (8.7441 iter/s, 11.4363s/100 iters), loss = 0.0264735
I0823 03:37:19.347355 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0264727 (* 1 = 0.0264727 loss)
I0823 03:37:19.347368 13823 sgd_solver.cpp:112] Iteration 382800, lr = 1e-06
I0823 03:37:31.084381 13823 solver.cpp:239] Iteration 382900 (8.51999 iter/s, 11.7371s/100 iters), loss = 0.0260681
I0823 03:37:31.084434 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0260673 (* 1 = 0.0260673 loss)
I0823 03:37:31.084444 13823 sgd_solver.cpp:112] Iteration 382900, lr = 1e-06
I0823 03:37:42.534198 13823 solver.cpp:239] Iteration 383000 (8.73375 iter/s, 11.4498s/100 iters), loss = 0.0236296
I0823 03:37:42.534251 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0236288 (* 1 = 0.0236288 loss)
I0823 03:37:42.534261 13823 sgd_solver.cpp:112] Iteration 383000, lr = 1e-06
I0823 03:37:54.124693 13823 solver.cpp:239] Iteration 383100 (8.62774 iter/s, 11.5905s/100 iters), loss = 0.0224608
I0823 03:37:54.124742 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0224599 (* 1 = 0.0224599 loss)
I0823 03:37:54.124752 13823 sgd_solver.cpp:112] Iteration 383100, lr = 1e-06
I0823 03:38:05.648941 13823 solver.cpp:239] Iteration 383200 (8.67734 iter/s, 11.5243s/100 iters), loss = 0.0291285
I0823 03:38:05.649008 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0291277 (* 1 = 0.0291277 loss)
I0823 03:38:05.649021 13823 sgd_solver.cpp:112] Iteration 383200, lr = 1e-06
I0823 03:38:17.305730 13823 solver.cpp:239] Iteration 383300 (8.57869 iter/s, 11.6568s/100 iters), loss = 0.0262428
I0823 03:38:17.305794 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0262419 (* 1 = 0.0262419 loss)
I0823 03:38:17.305806 13823 sgd_solver.cpp:112] Iteration 383300, lr = 1e-06
I0823 03:38:28.881325 13823 solver.cpp:239] Iteration 383400 (8.63886 iter/s, 11.5756s/100 iters), loss = 0.0277795
I0823 03:38:28.881374 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0277787 (* 1 = 0.0277787 loss)
I0823 03:38:28.881384 13823 sgd_solver.cpp:112] Iteration 383400, lr = 1e-06
I0823 03:38:39.473007 13823 solver.cpp:239] Iteration 383500 (9.44135 iter/s, 10.5917s/100 iters), loss = 0.0245125
I0823 03:38:39.473065 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0245117 (* 1 = 0.0245117 loss)
I0823 03:38:39.473073 13823 sgd_solver.cpp:112] Iteration 383500, lr = 1e-06
I0823 03:38:48.966572 13823 solver.cpp:239] Iteration 383600 (10.5335 iter/s, 9.49356s/100 iters), loss = 0.0249462
I0823 03:38:48.966624 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0249454 (* 1 = 0.0249454 loss)
I0823 03:38:48.966634 13823 sgd_solver.cpp:112] Iteration 383600, lr = 1e-06
I0823 03:38:58.389940 13823 solver.cpp:239] Iteration 383700 (10.6119 iter/s, 9.42337s/100 iters), loss = 0.0373483
I0823 03:38:58.389989 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0373475 (* 1 = 0.0373475 loss)
I0823 03:38:58.389998 13823 sgd_solver.cpp:112] Iteration 383700, lr = 1e-06
I0823 03:39:07.920146 13823 solver.cpp:239] Iteration 383800 (10.4929 iter/s, 9.53022s/100 iters), loss = 0.0296184
I0823 03:39:07.920192 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0296176 (* 1 = 0.0296176 loss)
I0823 03:39:07.920199 13823 sgd_solver.cpp:112] Iteration 383800, lr = 1e-06
I0823 03:39:17.310727 13823 solver.cpp:239] Iteration 383900 (10.649 iter/s, 9.39059s/100 iters), loss = 0.0362235
I0823 03:39:17.310770 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0362227 (* 1 = 0.0362227 loss)
I0823 03:39:17.310776 13823 sgd_solver.cpp:112] Iteration 383900, lr = 1e-06
I0823 03:39:26.698930 13823 solver.cpp:239] Iteration 384000 (10.6517 iter/s, 9.38822s/100 iters), loss = 0.0221357
I0823 03:39:26.698971 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0221349 (* 1 = 0.0221349 loss)
I0823 03:39:26.698979 13823 sgd_solver.cpp:112] Iteration 384000, lr = 1e-06
I0823 03:39:35.937165 13823 solver.cpp:239] Iteration 384100 (10.8246 iter/s, 9.23825s/100 iters), loss = 0.0421259
I0823 03:39:35.937206 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0421251 (* 1 = 0.0421251 loss)
I0823 03:39:35.937213 13823 sgd_solver.cpp:112] Iteration 384100, lr = 1e-06
I0823 03:39:45.442028 13823 solver.cpp:239] Iteration 384200 (10.5209 iter/s, 9.50487s/100 iters), loss = 0.0262695
I0823 03:39:45.442080 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0262687 (* 1 = 0.0262687 loss)
I0823 03:39:45.442088 13823 sgd_solver.cpp:112] Iteration 384200, lr = 1e-06
I0823 03:39:55.618192 13823 solver.cpp:239] Iteration 384300 (9.82688 iter/s, 10.1762s/100 iters), loss = 0.0330645
I0823 03:39:55.618244 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0330637 (* 1 = 0.0330637 loss)
I0823 03:39:55.618254 13823 sgd_solver.cpp:112] Iteration 384300, lr = 1e-06
I0823 03:40:05.202402 13823 solver.cpp:239] Iteration 384400 (10.4338 iter/s, 9.58421s/100 iters), loss = 0.0271313
I0823 03:40:05.202455 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0271305 (* 1 = 0.0271305 loss)
I0823 03:40:05.202464 13823 sgd_solver.cpp:112] Iteration 384400, lr = 1e-06
I0823 03:40:15.090584 13823 solver.cpp:239] Iteration 384500 (10.1131 iter/s, 9.88818s/100 iters), loss = 0.0334138
I0823 03:40:15.090636 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.033413 (* 1 = 0.033413 loss)
I0823 03:40:15.090644 13823 sgd_solver.cpp:112] Iteration 384500, lr = 1e-06
I0823 03:40:24.813328 13823 solver.cpp:239] Iteration 384600 (10.2852 iter/s, 9.72274s/100 iters), loss = 0.0276854
I0823 03:40:24.813380 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0276845 (* 1 = 0.0276845 loss)
I0823 03:40:24.813390 13823 sgd_solver.cpp:112] Iteration 384600, lr = 1e-06
I0823 03:40:34.705770 13823 solver.cpp:239] Iteration 384700 (10.1087 iter/s, 9.89244s/100 iters), loss = 0.0276203
I0823 03:40:34.705826 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0276195 (* 1 = 0.0276195 loss)
I0823 03:40:34.705837 13823 sgd_solver.cpp:112] Iteration 384700, lr = 1e-06
I0823 03:40:44.092479 13823 solver.cpp:239] Iteration 384800 (10.6534 iter/s, 9.3867s/100 iters), loss = 0.028364
I0823 03:40:44.092535 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0283631 (* 1 = 0.0283631 loss)
I0823 03:40:44.092548 13823 sgd_solver.cpp:112] Iteration 384800, lr = 1e-06
I0823 03:40:53.796196 13823 solver.cpp:239] Iteration 384900 (10.3053 iter/s, 9.70371s/100 iters), loss = 0.0294271
I0823 03:40:53.796255 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0294262 (* 1 = 0.0294262 loss)
I0823 03:40:53.796268 13823 sgd_solver.cpp:112] Iteration 384900, lr = 1e-06
I0823 03:41:03.707254 13823 solver.cpp:239] Iteration 385000 (10.0897 iter/s, 9.91105s/100 iters), loss = 0.0254857
I0823 03:41:03.707314 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0254849 (* 1 = 0.0254849 loss)
I0823 03:41:03.707325 13823 sgd_solver.cpp:112] Iteration 385000, lr = 1e-06
I0823 03:41:13.653703 13823 solver.cpp:239] Iteration 385100 (10.0538 iter/s, 9.94644s/100 iters), loss = 0.0315511
I0823 03:41:13.653770 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0315503 (* 1 = 0.0315503 loss)
I0823 03:41:13.653785 13823 sgd_solver.cpp:112] Iteration 385100, lr = 1e-06
I0823 03:41:23.395851 13823 solver.cpp:239] Iteration 385200 (10.2647 iter/s, 9.74214s/100 iters), loss = 0.0382981
I0823 03:41:23.395908 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0382972 (* 1 = 0.0382972 loss)
I0823 03:41:23.395921 13823 sgd_solver.cpp:112] Iteration 385200, lr = 1e-06
I0823 03:41:33.126940 13823 solver.cpp:239] Iteration 385300 (10.2764 iter/s, 9.73108s/100 iters), loss = 0.0296132
I0823 03:41:33.126997 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0296123 (* 1 = 0.0296123 loss)
I0823 03:41:33.127010 13823 sgd_solver.cpp:112] Iteration 385300, lr = 1e-06
I0823 03:41:43.241799 13823 solver.cpp:239] Iteration 385400 (9.88645 iter/s, 10.1149s/100 iters), loss = 0.026472
I0823 03:41:43.241852 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0264711 (* 1 = 0.0264711 loss)
I0823 03:41:43.241863 13823 sgd_solver.cpp:112] Iteration 385400, lr = 1e-06
I0823 03:41:53.062058 13823 solver.cpp:239] Iteration 385500 (10.183 iter/s, 9.82025s/100 iters), loss = 0.0251087
I0823 03:41:53.062110 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0251078 (* 1 = 0.0251078 loss)
I0823 03:41:53.062120 13823 sgd_solver.cpp:112] Iteration 385500, lr = 1e-06
I0823 03:42:02.882190 13823 solver.cpp:239] Iteration 385600 (10.1832 iter/s, 9.82013s/100 iters), loss = 0.275292
I0823 03:42:02.882241 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.275291 (* 1 = 0.275291 loss)
I0823 03:42:02.882251 13823 sgd_solver.cpp:112] Iteration 385600, lr = 1e-06
I0823 03:42:13.014264 13823 solver.cpp:239] Iteration 385700 (9.86965 iter/s, 10.1321s/100 iters), loss = 0.0252064
I0823 03:42:13.014329 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0252056 (* 1 = 0.0252056 loss)
I0823 03:42:13.014345 13823 sgd_solver.cpp:112] Iteration 385700, lr = 1e-06
I0823 03:42:22.823062 13823 solver.cpp:239] Iteration 385800 (10.1949 iter/s, 9.80878s/100 iters), loss = 0.026704
I0823 03:42:22.823115 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0267031 (* 1 = 0.0267031 loss)
I0823 03:42:22.823124 13823 sgd_solver.cpp:112] Iteration 385800, lr = 1e-06
I0823 03:42:32.711436 13823 solver.cpp:239] Iteration 385900 (10.1129 iter/s, 9.88837s/100 iters), loss = 0.0255922
I0823 03:42:32.711488 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0255913 (* 1 = 0.0255913 loss)
I0823 03:42:32.711496 13823 sgd_solver.cpp:112] Iteration 385900, lr = 1e-06
I0823 03:42:42.210132 13823 solver.cpp:239] Iteration 386000 (10.5278 iter/s, 9.49869s/100 iters), loss = 0.0261649
I0823 03:42:42.210173 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.026164 (* 1 = 0.026164 loss)
I0823 03:42:42.210181 13823 sgd_solver.cpp:112] Iteration 386000, lr = 1e-06
I0823 03:42:51.981163 13823 solver.cpp:239] Iteration 386100 (10.2343 iter/s, 9.77103s/100 iters), loss = 0.0390588
I0823 03:42:51.981212 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0390579 (* 1 = 0.0390579 loss)
I0823 03:42:51.981221 13823 sgd_solver.cpp:112] Iteration 386100, lr = 1e-06
I0823 03:43:01.725196 13823 solver.cpp:239] Iteration 386200 (10.2627 iter/s, 9.74403s/100 iters), loss = 0.0278115
I0823 03:43:01.725247 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0278106 (* 1 = 0.0278106 loss)
I0823 03:43:01.725258 13823 sgd_solver.cpp:112] Iteration 386200, lr = 1e-06
I0823 03:43:11.482861 13823 solver.cpp:239] Iteration 386300 (10.2484 iter/s, 9.75765s/100 iters), loss = 0.0248
I0823 03:43:11.482918 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0247991 (* 1 = 0.0247991 loss)
I0823 03:43:11.482929 13823 sgd_solver.cpp:112] Iteration 386300, lr = 1e-06
I0823 03:43:21.422415 13823 solver.cpp:239] Iteration 386400 (10.0608 iter/s, 9.93954s/100 iters), loss = 0.0289744
I0823 03:43:21.422468 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0289735 (* 1 = 0.0289735 loss)
I0823 03:43:21.422478 13823 sgd_solver.cpp:112] Iteration 386400, lr = 1e-06
I0823 03:43:31.108551 13823 solver.cpp:239] Iteration 386500 (10.324 iter/s, 9.68613s/100 iters), loss = 0.0277496
I0823 03:43:31.108592 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0277486 (* 1 = 0.0277486 loss)
I0823 03:43:31.108599 13823 sgd_solver.cpp:112] Iteration 386500, lr = 1e-06
I0823 03:43:41.142160 13823 solver.cpp:239] Iteration 386600 (9.96651 iter/s, 10.0336s/100 iters), loss = 0.0266551
I0823 03:43:41.142238 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0266542 (* 1 = 0.0266542 loss)
I0823 03:43:41.142256 13823 sgd_solver.cpp:112] Iteration 386600, lr = 1e-06
I0823 03:43:51.073042 13823 solver.cpp:239] Iteration 386700 (10.0696 iter/s, 9.93085s/100 iters), loss = 0.0246374
I0823 03:43:51.073093 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0246364 (* 1 = 0.0246364 loss)
I0823 03:43:51.073103 13823 sgd_solver.cpp:112] Iteration 386700, lr = 1e-06
I0823 03:44:00.747846 13823 solver.cpp:239] Iteration 386800 (10.3361 iter/s, 9.6748s/100 iters), loss = 0.0253081
I0823 03:44:00.747896 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0253071 (* 1 = 0.0253071 loss)
I0823 03:44:00.747905 13823 sgd_solver.cpp:112] Iteration 386800, lr = 1e-06
I0823 03:44:10.644929 13823 solver.cpp:239] Iteration 386900 (10.104 iter/s, 9.89708s/100 iters), loss = 0.0242187
I0823 03:44:10.644980 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0242178 (* 1 = 0.0242178 loss)
I0823 03:44:10.644990 13823 sgd_solver.cpp:112] Iteration 386900, lr = 1e-06
I0823 03:44:20.429467 13823 solver.cpp:239] Iteration 387000 (10.2202 iter/s, 9.78453s/100 iters), loss = 0.0278519
I0823 03:44:20.429510 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0278509 (* 1 = 0.0278509 loss)
I0823 03:44:20.429518 13823 sgd_solver.cpp:112] Iteration 387000, lr = 1e-06
I0823 03:44:29.940582 13823 solver.cpp:239] Iteration 387100 (10.514 iter/s, 9.51112s/100 iters), loss = 0.0535045
I0823 03:44:29.940623 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0535036 (* 1 = 0.0535036 loss)
I0823 03:44:29.940631 13823 sgd_solver.cpp:112] Iteration 387100, lr = 1e-06
I0823 03:44:39.841591 13823 solver.cpp:239] Iteration 387200 (10.1 iter/s, 9.901s/100 iters), loss = 0.026779
I0823 03:44:39.841661 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0267781 (* 1 = 0.0267781 loss)
I0823 03:44:39.841678 13823 sgd_solver.cpp:112] Iteration 387200, lr = 1e-06
I0823 03:44:49.492203 13823 solver.cpp:239] Iteration 387300 (10.3621 iter/s, 9.65059s/100 iters), loss = 0.0270112
I0823 03:44:49.492265 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0270103 (* 1 = 0.0270103 loss)
I0823 03:44:49.492280 13823 sgd_solver.cpp:112] Iteration 387300, lr = 1e-06
I0823 03:44:59.230585 13823 solver.cpp:239] Iteration 387400 (10.2687 iter/s, 9.73836s/100 iters), loss = 0.0307413
I0823 03:44:59.230644 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0307404 (* 1 = 0.0307404 loss)
I0823 03:44:59.230655 13823 sgd_solver.cpp:112] Iteration 387400, lr = 1e-06
I0823 03:45:09.146570 13823 solver.cpp:239] Iteration 387500 (10.0847 iter/s, 9.91597s/100 iters), loss = 0.0249717
I0823 03:45:09.146627 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0249707 (* 1 = 0.0249707 loss)
I0823 03:45:09.146638 13823 sgd_solver.cpp:112] Iteration 387500, lr = 1e-06
I0823 03:45:19.167062 13823 solver.cpp:239] Iteration 387600 (9.97957 iter/s, 10.0205s/100 iters), loss = 0.0277363
I0823 03:45:19.167129 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0277353 (* 1 = 0.0277353 loss)
I0823 03:45:19.167138 13823 sgd_solver.cpp:112] Iteration 387600, lr = 1e-06
I0823 03:45:29.224763 13823 solver.cpp:239] Iteration 387700 (9.94265 iter/s, 10.0577s/100 iters), loss = 0.0272946
I0823 03:45:29.224815 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0272936 (* 1 = 0.0272936 loss)
I0823 03:45:29.224825 13823 sgd_solver.cpp:112] Iteration 387700, lr = 1e-06
I0823 03:45:39.139742 13823 solver.cpp:239] Iteration 387800 (10.0858 iter/s, 9.91497s/100 iters), loss = 0.027525
I0823 03:45:39.139794 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0275241 (* 1 = 0.0275241 loss)
I0823 03:45:39.139804 13823 sgd_solver.cpp:112] Iteration 387800, lr = 1e-06
I0823 03:45:49.242740 13823 solver.cpp:239] Iteration 387900 (9.89806 iter/s, 10.103s/100 iters), loss = 0.0468378
I0823 03:45:49.242790 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0468369 (* 1 = 0.0468369 loss)
I0823 03:45:49.242800 13823 sgd_solver.cpp:112] Iteration 387900, lr = 1e-06
I0823 03:45:59.202889 13823 solver.cpp:239] Iteration 388000 (10.04 iter/s, 9.96014s/100 iters), loss = 0.0249533
I0823 03:45:59.202939 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0249523 (* 1 = 0.0249523 loss)
I0823 03:45:59.202950 13823 sgd_solver.cpp:112] Iteration 388000, lr = 1e-06
I0823 03:46:09.437657 13823 solver.cpp:239] Iteration 388100 (9.77062 iter/s, 10.2348s/100 iters), loss = 0.0296766
I0823 03:46:09.437700 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0296757 (* 1 = 0.0296757 loss)
I0823 03:46:09.437707 13823 sgd_solver.cpp:112] Iteration 388100, lr = 1e-06
I0823 03:46:19.331794 13823 solver.cpp:239] Iteration 388200 (10.107 iter/s, 9.89413s/100 iters), loss = 0.0281082
I0823 03:46:19.331848 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0281072 (* 1 = 0.0281072 loss)
I0823 03:46:19.331859 13823 sgd_solver.cpp:112] Iteration 388200, lr = 1e-06
I0823 03:46:29.351496 13823 solver.cpp:239] Iteration 388300 (9.98035 iter/s, 10.0197s/100 iters), loss = 0.0232788
I0823 03:46:29.351547 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0232779 (* 1 = 0.0232779 loss)
I0823 03:46:29.351557 13823 sgd_solver.cpp:112] Iteration 388300, lr = 1e-06
I0823 03:46:39.392760 13823 solver.cpp:239] Iteration 388400 (9.95892 iter/s, 10.0413s/100 iters), loss = 0.0224991
I0823 03:46:39.392812 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0224982 (* 1 = 0.0224982 loss)
I0823 03:46:39.392822 13823 sgd_solver.cpp:112] Iteration 388400, lr = 1e-06
I0823 03:46:49.625874 13823 solver.cpp:239] Iteration 388500 (9.77221 iter/s, 10.2331s/100 iters), loss = 0.0274551
I0823 03:46:49.625936 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0274542 (* 1 = 0.0274542 loss)
I0823 03:46:49.625948 13823 sgd_solver.cpp:112] Iteration 388500, lr = 1e-06
I0823 03:46:59.634193 13823 solver.cpp:239] Iteration 388600 (9.99171 iter/s, 10.0083s/100 iters), loss = 0.0244209
I0823 03:46:59.634248 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0244199 (* 1 = 0.0244199 loss)
I0823 03:46:59.634258 13823 sgd_solver.cpp:112] Iteration 388600, lr = 1e-06
I0823 03:47:09.963472 13823 solver.cpp:239] Iteration 388700 (9.68123 iter/s, 10.3293s/100 iters), loss = 0.025156
I0823 03:47:09.963523 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.025155 (* 1 = 0.025155 loss)
I0823 03:47:09.963533 13823 sgd_solver.cpp:112] Iteration 388700, lr = 1e-06
I0823 03:47:20.297183 13823 solver.cpp:239] Iteration 388800 (9.67708 iter/s, 10.3337s/100 iters), loss = 0.0371599
I0823 03:47:20.297236 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.037159 (* 1 = 0.037159 loss)
I0823 03:47:20.297247 13823 sgd_solver.cpp:112] Iteration 388800, lr = 1e-06
I0823 03:47:30.667009 13823 solver.cpp:239] Iteration 388900 (9.64338 iter/s, 10.3698s/100 iters), loss = 0.0286484
I0823 03:47:30.667068 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0286474 (* 1 = 0.0286474 loss)
I0823 03:47:30.667078 13823 sgd_solver.cpp:112] Iteration 388900, lr = 1e-06
I0823 03:47:40.956142 13823 solver.cpp:239] Iteration 389000 (9.71901 iter/s, 10.2891s/100 iters), loss = 0.0348877
I0823 03:47:40.956193 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0348868 (* 1 = 0.0348868 loss)
I0823 03:47:40.956203 13823 sgd_solver.cpp:112] Iteration 389000, lr = 1e-06
I0823 03:47:51.197561 13823 solver.cpp:239] Iteration 389100 (9.76428 iter/s, 10.2414s/100 iters), loss = 0.0282446
I0823 03:47:51.197610 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0282437 (* 1 = 0.0282437 loss)
I0823 03:47:51.197619 13823 sgd_solver.cpp:112] Iteration 389100, lr = 1e-06
I0823 03:48:01.575750 13823 solver.cpp:239] Iteration 389200 (9.6356 iter/s, 10.3782s/100 iters), loss = 0.0245011
I0823 03:48:01.575803 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0245001 (* 1 = 0.0245001 loss)
I0823 03:48:01.575814 13823 sgd_solver.cpp:112] Iteration 389200, lr = 1e-06
I0823 03:48:11.736148 13823 solver.cpp:239] Iteration 389300 (9.84215 iter/s, 10.1604s/100 iters), loss = 0.0297826
I0823 03:48:11.736210 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0297816 (* 1 = 0.0297816 loss)
I0823 03:48:11.736222 13823 sgd_solver.cpp:112] Iteration 389300, lr = 1e-06
I0823 03:48:22.019042 13823 solver.cpp:239] Iteration 389400 (9.72491 iter/s, 10.2829s/100 iters), loss = 0.0281054
I0823 03:48:22.019091 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0281045 (* 1 = 0.0281045 loss)
I0823 03:48:22.019100 13823 sgd_solver.cpp:112] Iteration 389400, lr = 1e-06
I0823 03:48:32.263185 13823 solver.cpp:239] Iteration 389500 (9.76169 iter/s, 10.2441s/100 iters), loss = 0.0340327
I0823 03:48:32.263236 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0340317 (* 1 = 0.0340317 loss)
I0823 03:48:32.263244 13823 sgd_solver.cpp:112] Iteration 389500, lr = 1e-06
I0823 03:48:42.404860 13823 solver.cpp:239] Iteration 389600 (9.86032 iter/s, 10.1417s/100 iters), loss = 0.0349565
I0823 03:48:42.404911 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0349555 (* 1 = 0.0349555 loss)
I0823 03:48:42.404920 13823 sgd_solver.cpp:112] Iteration 389600, lr = 1e-06
I0823 03:48:52.524900 13823 solver.cpp:239] Iteration 389700 (9.8814 iter/s, 10.12s/100 iters), loss = 0.0244298
I0823 03:48:52.524955 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0244289 (* 1 = 0.0244289 loss)
I0823 03:48:52.524966 13823 sgd_solver.cpp:112] Iteration 389700, lr = 1e-06
I0823 03:49:02.614312 13823 solver.cpp:239] Iteration 389800 (9.9114 iter/s, 10.0894s/100 iters), loss = 0.0290666
I0823 03:49:02.614362 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0290656 (* 1 = 0.0290656 loss)
I0823 03:49:02.614372 13823 sgd_solver.cpp:112] Iteration 389800, lr = 1e-06
I0823 03:49:12.516964 13823 solver.cpp:239] Iteration 389900 (10.0983 iter/s, 9.90264s/100 iters), loss = 0.0244428
I0823 03:49:12.517015 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0244419 (* 1 = 0.0244419 loss)
I0823 03:49:12.517025 13823 sgd_solver.cpp:112] Iteration 389900, lr = 1e-06
I0823 03:49:22.543802 13823 solver.cpp:239] Iteration 390000 (9.97325 iter/s, 10.0268s/100 iters), loss = 0.0252776
I0823 03:49:22.543851 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0252766 (* 1 = 0.0252766 loss)
I0823 03:49:22.543860 13823 sgd_solver.cpp:112] Iteration 390000, lr = 1e-06
I0823 03:49:32.913970 13823 solver.cpp:239] Iteration 390100 (9.64306 iter/s, 10.3702s/100 iters), loss = 0.0292934
I0823 03:49:32.914023 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0292924 (* 1 = 0.0292924 loss)
I0823 03:49:32.914033 13823 sgd_solver.cpp:112] Iteration 390100, lr = 1e-06
I0823 03:49:43.007589 13823 solver.cpp:239] Iteration 390200 (9.90726 iter/s, 10.0936s/100 iters), loss = 0.0229357
I0823 03:49:43.007639 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0229348 (* 1 = 0.0229348 loss)
I0823 03:49:43.007648 13823 sgd_solver.cpp:112] Iteration 390200, lr = 1e-06
I0823 03:49:53.239915 13823 solver.cpp:239] Iteration 390300 (9.77296 iter/s, 10.2323s/100 iters), loss = 0.0225384
I0823 03:49:53.239967 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0225375 (* 1 = 0.0225375 loss)
I0823 03:49:53.239976 13823 sgd_solver.cpp:112] Iteration 390300, lr = 1e-06
I0823 03:50:03.479131 13823 solver.cpp:239] Iteration 390400 (9.76639 iter/s, 10.2392s/100 iters), loss = 0.0342488
I0823 03:50:03.479183 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0342479 (* 1 = 0.0342479 loss)
I0823 03:50:03.479193 13823 sgd_solver.cpp:112] Iteration 390400, lr = 1e-06
I0823 03:50:13.625416 13823 solver.cpp:239] Iteration 390500 (9.85584 iter/s, 10.1463s/100 iters), loss = 0.0368676
I0823 03:50:13.625468 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0368666 (* 1 = 0.0368666 loss)
I0823 03:50:13.625478 13823 sgd_solver.cpp:112] Iteration 390500, lr = 1e-06
I0823 03:50:23.607550 13823 solver.cpp:239] Iteration 390600 (10.0179 iter/s, 9.98212s/100 iters), loss = 0.0308846
I0823 03:50:23.607599 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0308836 (* 1 = 0.0308836 loss)
I0823 03:50:23.607609 13823 sgd_solver.cpp:112] Iteration 390600, lr = 1e-06
I0823 03:50:33.676803 13823 solver.cpp:239] Iteration 390700 (9.93123 iter/s, 10.0692s/100 iters), loss = 0.0258581
I0823 03:50:33.676854 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0258572 (* 1 = 0.0258572 loss)
I0823 03:50:33.676864 13823 sgd_solver.cpp:112] Iteration 390700, lr = 1e-06
I0823 03:50:43.737427 13823 solver.cpp:239] Iteration 390800 (9.93976 iter/s, 10.0606s/100 iters), loss = 0.0315578
I0823 03:50:43.737491 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0315568 (* 1 = 0.0315568 loss)
I0823 03:50:43.737504 13823 sgd_solver.cpp:112] Iteration 390800, lr = 1e-06
I0823 03:50:53.676007 13823 solver.cpp:239] Iteration 390900 (10.0618 iter/s, 9.93856s/100 iters), loss = 0.0253662
I0823 03:50:53.676059 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0253652 (* 1 = 0.0253652 loss)
I0823 03:50:53.676066 13823 sgd_solver.cpp:112] Iteration 390900, lr = 1e-06
I0823 03:51:03.362234 13823 solver.cpp:239] Iteration 391000 (10.324 iter/s, 9.68621s/100 iters), loss = 0.0288491
I0823 03:51:03.362282 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0288481 (* 1 = 0.0288481 loss)
I0823 03:51:03.362291 13823 sgd_solver.cpp:112] Iteration 391000, lr = 1e-06
I0823 03:51:13.836366 13823 solver.cpp:239] Iteration 391100 (9.54734 iter/s, 10.4741s/100 iters), loss = 0.0346047
I0823 03:51:13.836419 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0346038 (* 1 = 0.0346038 loss)
I0823 03:51:13.836429 13823 sgd_solver.cpp:112] Iteration 391100, lr = 1e-06
I0823 03:51:24.092233 13823 solver.cpp:239] Iteration 391200 (9.75053 iter/s, 10.2559s/100 iters), loss = 0.027592
I0823 03:51:24.092288 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.027591 (* 1 = 0.027591 loss)
I0823 03:51:24.092298 13823 sgd_solver.cpp:112] Iteration 391200, lr = 1e-06
I0823 03:51:34.187747 13823 solver.cpp:239] Iteration 391300 (9.90541 iter/s, 10.0955s/100 iters), loss = 0.0252968
I0823 03:51:34.187795 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0252959 (* 1 = 0.0252959 loss)
I0823 03:51:34.187805 13823 sgd_solver.cpp:112] Iteration 391300, lr = 1e-06
I0823 03:51:44.566537 13823 solver.cpp:239] Iteration 391400 (9.63504 iter/s, 10.3788s/100 iters), loss = 0.027882
I0823 03:51:44.566588 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0278811 (* 1 = 0.0278811 loss)
I0823 03:51:44.566597 13823 sgd_solver.cpp:112] Iteration 391400, lr = 1e-06
I0823 03:51:54.916642 13823 solver.cpp:239] Iteration 391500 (9.66175 iter/s, 10.3501s/100 iters), loss = 0.0325652
I0823 03:51:54.916692 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0325643 (* 1 = 0.0325643 loss)
I0823 03:51:54.916702 13823 sgd_solver.cpp:112] Iteration 391500, lr = 1e-06
I0823 03:52:05.371126 13823 solver.cpp:239] Iteration 391600 (9.56528 iter/s, 10.4545s/100 iters), loss = 0.0264717
I0823 03:52:05.371178 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0264707 (* 1 = 0.0264707 loss)
I0823 03:52:05.371187 13823 sgd_solver.cpp:112] Iteration 391600, lr = 1e-06
I0823 03:52:15.782755 13823 solver.cpp:239] Iteration 391700 (9.60466 iter/s, 10.4116s/100 iters), loss = 0.0297999
I0823 03:52:15.782805 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.029799 (* 1 = 0.029799 loss)
I0823 03:52:15.782814 13823 sgd_solver.cpp:112] Iteration 391700, lr = 1e-06
I0823 03:52:26.301419 13823 solver.cpp:239] Iteration 391800 (9.50692 iter/s, 10.5187s/100 iters), loss = 0.027071
I0823 03:52:26.301473 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0270701 (* 1 = 0.0270701 loss)
I0823 03:52:26.301484 13823 sgd_solver.cpp:112] Iteration 391800, lr = 1e-06
I0823 03:52:36.637811 13823 solver.cpp:239] Iteration 391900 (9.67457 iter/s, 10.3364s/100 iters), loss = 0.0274707
I0823 03:52:36.637863 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0274698 (* 1 = 0.0274698 loss)
I0823 03:52:36.637873 13823 sgd_solver.cpp:112] Iteration 391900, lr = 1e-06
I0823 03:52:46.853135 13823 solver.cpp:239] Iteration 392000 (9.78923 iter/s, 10.2153s/100 iters), loss = 0.0304586
I0823 03:52:46.853186 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0304576 (* 1 = 0.0304576 loss)
I0823 03:52:46.853196 13823 sgd_solver.cpp:112] Iteration 392000, lr = 1e-06
I0823 03:52:57.001761 13823 solver.cpp:239] Iteration 392100 (9.85357 iter/s, 10.1486s/100 iters), loss = 0.0281906
I0823 03:52:57.001811 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0281897 (* 1 = 0.0281897 loss)
I0823 03:52:57.001819 13823 sgd_solver.cpp:112] Iteration 392100, lr = 1e-06
I0823 03:53:07.199399 13823 solver.cpp:239] Iteration 392200 (9.80621 iter/s, 10.1976s/100 iters), loss = 0.0232926
I0823 03:53:07.199450 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0232917 (* 1 = 0.0232917 loss)
I0823 03:53:07.199460 13823 sgd_solver.cpp:112] Iteration 392200, lr = 1e-06
I0823 03:53:17.483894 13823 solver.cpp:239] Iteration 392300 (9.72339 iter/s, 10.2845s/100 iters), loss = 0.0272141
I0823 03:53:17.483945 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0272132 (* 1 = 0.0272132 loss)
I0823 03:53:17.483955 13823 sgd_solver.cpp:112] Iteration 392300, lr = 1e-06
I0823 03:53:27.792795 13823 solver.cpp:239] Iteration 392400 (9.70037 iter/s, 10.3089s/100 iters), loss = 0.0267479
I0823 03:53:27.792850 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.026747 (* 1 = 0.026747 loss)
I0823 03:53:27.792860 13823 sgd_solver.cpp:112] Iteration 392400, lr = 1e-06
I0823 03:53:38.230798 13823 solver.cpp:239] Iteration 392500 (9.58039 iter/s, 10.438s/100 iters), loss = 0.0233409
I0823 03:53:38.230845 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.02334 (* 1 = 0.02334 loss)
I0823 03:53:38.230854 13823 sgd_solver.cpp:112] Iteration 392500, lr = 1e-06
I0823 03:53:48.345645 13823 solver.cpp:239] Iteration 392600 (9.88647 iter/s, 10.1148s/100 iters), loss = 0.0251971
I0823 03:53:48.345696 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0251962 (* 1 = 0.0251962 loss)
I0823 03:53:48.345706 13823 sgd_solver.cpp:112] Iteration 392600, lr = 1e-06
I0823 03:53:58.358000 13823 solver.cpp:239] Iteration 392700 (9.98768 iter/s, 10.0123s/100 iters), loss = 0.0247758
I0823 03:53:58.358052 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0247748 (* 1 = 0.0247748 loss)
I0823 03:53:58.358060 13823 sgd_solver.cpp:112] Iteration 392700, lr = 1e-06
I0823 03:54:08.733158 13823 solver.cpp:239] Iteration 392800 (9.63842 iter/s, 10.3751s/100 iters), loss = 0.029398
I0823 03:54:08.733211 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.029397 (* 1 = 0.029397 loss)
I0823 03:54:08.733219 13823 sgd_solver.cpp:112] Iteration 392800, lr = 1e-06
I0823 03:54:18.939368 13823 solver.cpp:239] Iteration 392900 (9.79797 iter/s, 10.2062s/100 iters), loss = 0.0252649
I0823 03:54:18.939419 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0252639 (* 1 = 0.0252639 loss)
I0823 03:54:18.939429 13823 sgd_solver.cpp:112] Iteration 392900, lr = 1e-06
I0823 03:54:29.425942 13823 solver.cpp:239] Iteration 393000 (9.53601 iter/s, 10.4866s/100 iters), loss = 0.0224107
I0823 03:54:29.425993 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0224097 (* 1 = 0.0224097 loss)
I0823 03:54:29.426003 13823 sgd_solver.cpp:112] Iteration 393000, lr = 1e-06
I0823 03:54:40.053779 13823 solver.cpp:239] Iteration 393100 (9.40927 iter/s, 10.6278s/100 iters), loss = 0.0261952
I0823 03:54:40.053839 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0261942 (* 1 = 0.0261942 loss)
I0823 03:54:40.053851 13823 sgd_solver.cpp:112] Iteration 393100, lr = 1e-06
I0823 03:54:50.464852 13823 solver.cpp:239] Iteration 393200 (9.60518 iter/s, 10.411s/100 iters), loss = 0.0267751
I0823 03:54:50.464903 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0267741 (* 1 = 0.0267741 loss)
I0823 03:54:50.464913 13823 sgd_solver.cpp:112] Iteration 393200, lr = 1e-06
I0823 03:55:00.940906 13823 solver.cpp:239] Iteration 393300 (9.54559 iter/s, 10.476s/100 iters), loss = 0.0308456
I0823 03:55:00.940964 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0308447 (* 1 = 0.0308447 loss)
I0823 03:55:00.940975 13823 sgd_solver.cpp:112] Iteration 393300, lr = 1e-06
I0823 03:55:11.421747 13823 solver.cpp:239] Iteration 393400 (9.54124 iter/s, 10.4808s/100 iters), loss = 0.0260314
I0823 03:55:11.421802 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0260304 (* 1 = 0.0260304 loss)
I0823 03:55:11.421811 13823 sgd_solver.cpp:112] Iteration 393400, lr = 1e-06
I0823 03:55:21.886713 13823 solver.cpp:239] Iteration 393500 (9.55571 iter/s, 10.4649s/100 iters), loss = 0.0276173
I0823 03:55:21.886763 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0276163 (* 1 = 0.0276163 loss)
I0823 03:55:21.886773 13823 sgd_solver.cpp:112] Iteration 393500, lr = 1e-06
I0823 03:55:32.266130 13823 solver.cpp:239] Iteration 393600 (9.63447 iter/s, 10.3794s/100 iters), loss = 0.0239904
I0823 03:55:32.266183 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0239894 (* 1 = 0.0239894 loss)
I0823 03:55:32.266193 13823 sgd_solver.cpp:112] Iteration 393600, lr = 1e-06
I0823 03:55:42.573855 13823 solver.cpp:239] Iteration 393700 (9.70148 iter/s, 10.3077s/100 iters), loss = 0.0309439
I0823 03:55:42.573909 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0309429 (* 1 = 0.0309429 loss)
I0823 03:55:42.573920 13823 sgd_solver.cpp:112] Iteration 393700, lr = 1e-06
I0823 03:55:53.348044 13823 solver.cpp:239] Iteration 393800 (9.28146 iter/s, 10.7742s/100 iters), loss = 0.028992
I0823 03:55:53.348094 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.028991 (* 1 = 0.028991 loss)
I0823 03:55:53.348104 13823 sgd_solver.cpp:112] Iteration 393800, lr = 1e-06
I0823 03:56:03.810920 13823 solver.cpp:239] Iteration 393900 (9.55762 iter/s, 10.4629s/100 iters), loss = 0.0255288
I0823 03:56:03.810971 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0255279 (* 1 = 0.0255279 loss)
I0823 03:56:03.810979 13823 sgd_solver.cpp:112] Iteration 393900, lr = 1e-06
I0823 03:56:14.320399 13823 solver.cpp:239] Iteration 394000 (9.51523 iter/s, 10.5095s/100 iters), loss = 0.0275423
I0823 03:56:14.320447 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0275413 (* 1 = 0.0275413 loss)
I0823 03:56:14.320456 13823 sgd_solver.cpp:112] Iteration 394000, lr = 1e-06
I0823 03:56:24.958415 13823 solver.cpp:239] Iteration 394100 (9.40026 iter/s, 10.638s/100 iters), loss = 0.0268154
I0823 03:56:24.958465 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0268144 (* 1 = 0.0268144 loss)
I0823 03:56:24.958475 13823 sgd_solver.cpp:112] Iteration 394100, lr = 1e-06
I0823 03:56:35.450736 13823 solver.cpp:239] Iteration 394200 (9.53079 iter/s, 10.4923s/100 iters), loss = 0.026769
I0823 03:56:35.450785 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0267681 (* 1 = 0.0267681 loss)
I0823 03:56:35.450794 13823 sgd_solver.cpp:112] Iteration 394200, lr = 1e-06
I0823 03:56:46.099268 13823 solver.cpp:239] Iteration 394300 (9.39098 iter/s, 10.6485s/100 iters), loss = 0.0259568
I0823 03:56:46.099318 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0259558 (* 1 = 0.0259558 loss)
I0823 03:56:46.099326 13823 sgd_solver.cpp:112] Iteration 394300, lr = 1e-06
I0823 03:56:56.445713 13823 solver.cpp:239] Iteration 394400 (9.66517 iter/s, 10.3464s/100 iters), loss = 0.0247378
I0823 03:56:56.445768 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0247369 (* 1 = 0.0247369 loss)
I0823 03:56:56.445780 13823 sgd_solver.cpp:112] Iteration 394400, lr = 1e-06
I0823 03:57:06.782209 13823 solver.cpp:239] Iteration 394500 (9.67448 iter/s, 10.3365s/100 iters), loss = 0.0262504
I0823 03:57:06.782265 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0262494 (* 1 = 0.0262494 loss)
I0823 03:57:06.782276 13823 sgd_solver.cpp:112] Iteration 394500, lr = 1e-06
I0823 03:57:17.268015 13823 solver.cpp:239] Iteration 394600 (9.53672 iter/s, 10.4858s/100 iters), loss = 0.0296019
I0823 03:57:17.268067 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0296009 (* 1 = 0.0296009 loss)
I0823 03:57:17.268077 13823 sgd_solver.cpp:112] Iteration 394600, lr = 1e-06
I0823 03:57:27.832800 13823 solver.cpp:239] Iteration 394700 (9.46542 iter/s, 10.5648s/100 iters), loss = 0.030401
I0823 03:57:27.832850 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0304 (* 1 = 0.0304 loss)
I0823 03:57:27.832859 13823 sgd_solver.cpp:112] Iteration 394700, lr = 1e-06
I0823 03:57:38.505492 13823 solver.cpp:239] Iteration 394800 (9.36972 iter/s, 10.6727s/100 iters), loss = 0.0255963
I0823 03:57:38.505549 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0255954 (* 1 = 0.0255954 loss)
I0823 03:57:38.505560 13823 sgd_solver.cpp:112] Iteration 394800, lr = 1e-06
I0823 03:57:49.494520 13823 solver.cpp:239] Iteration 394900 (9.1 iter/s, 10.989s/100 iters), loss = 0.027233
I0823 03:57:49.494572 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0272321 (* 1 = 0.0272321 loss)
I0823 03:57:49.494581 13823 sgd_solver.cpp:112] Iteration 394900, lr = 1e-06
I0823 03:58:00.635385 13823 solver.cpp:239] Iteration 395000 (8.97598 iter/s, 11.1409s/100 iters), loss = 0.0283456
I0823 03:58:00.635450 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0283446 (* 1 = 0.0283446 loss)
I0823 03:58:00.635462 13823 sgd_solver.cpp:112] Iteration 395000, lr = 1e-06
I0823 03:58:11.530745 13823 solver.cpp:239] Iteration 395100 (9.17824 iter/s, 10.8953s/100 iters), loss = 0.0249406
I0823 03:58:11.530805 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0249396 (* 1 = 0.0249396 loss)
I0823 03:58:11.530817 13823 sgd_solver.cpp:112] Iteration 395100, lr = 1e-06
I0823 03:58:22.386610 13823 solver.cpp:239] Iteration 395200 (9.21163 iter/s, 10.8558s/100 iters), loss = 0.025528
I0823 03:58:22.386665 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0255271 (* 1 = 0.0255271 loss)
I0823 03:58:22.386675 13823 sgd_solver.cpp:112] Iteration 395200, lr = 1e-06
I0823 03:58:33.009971 13823 solver.cpp:239] Iteration 395300 (9.41323 iter/s, 10.6233s/100 iters), loss = 0.0330788
I0823 03:58:33.010022 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0330778 (* 1 = 0.0330778 loss)
I0823 03:58:33.010031 13823 sgd_solver.cpp:112] Iteration 395300, lr = 1e-06
I0823 03:58:43.827224 13823 solver.cpp:239] Iteration 395400 (9.2445 iter/s, 10.8172s/100 iters), loss = 0.0291297
I0823 03:58:43.827275 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0291287 (* 1 = 0.0291287 loss)
I0823 03:58:43.827283 13823 sgd_solver.cpp:112] Iteration 395400, lr = 1e-06
I0823 03:58:54.649494 13823 solver.cpp:239] Iteration 395500 (9.24022 iter/s, 10.8223s/100 iters), loss = 0.025881
I0823 03:58:54.649544 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0258801 (* 1 = 0.0258801 loss)
I0823 03:58:54.649552 13823 sgd_solver.cpp:112] Iteration 395500, lr = 1e-06
I0823 03:59:05.336339 13823 solver.cpp:239] Iteration 395600 (9.35731 iter/s, 10.6868s/100 iters), loss = 0.021667
I0823 03:59:05.336390 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0216661 (* 1 = 0.0216661 loss)
I0823 03:59:05.336400 13823 sgd_solver.cpp:112] Iteration 395600, lr = 1e-06
I0823 03:59:16.217669 13823 solver.cpp:239] Iteration 395700 (9.19007 iter/s, 10.8813s/100 iters), loss = 0.0278233
I0823 03:59:16.217730 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0278224 (* 1 = 0.0278224 loss)
I0823 03:59:16.217741 13823 sgd_solver.cpp:112] Iteration 395700, lr = 1e-06
I0823 03:59:26.797504 13823 solver.cpp:239] Iteration 395800 (9.45196 iter/s, 10.5798s/100 iters), loss = 0.0217297
I0823 03:59:26.797551 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0217288 (* 1 = 0.0217288 loss)
I0823 03:59:26.797561 13823 sgd_solver.cpp:112] Iteration 395800, lr = 1e-06
I0823 03:59:37.725376 13823 solver.cpp:239] Iteration 395900 (9.15092 iter/s, 10.9279s/100 iters), loss = 0.0279993
I0823 03:59:37.725431 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0279983 (* 1 = 0.0279983 loss)
I0823 03:59:37.725441 13823 sgd_solver.cpp:112] Iteration 395900, lr = 1e-06
I0823 03:59:48.711313 13823 solver.cpp:239] Iteration 396000 (9.10256 iter/s, 10.9859s/100 iters), loss = 0.0328917
I0823 03:59:48.711374 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0328907 (* 1 = 0.0328907 loss)
I0823 03:59:48.711385 13823 sgd_solver.cpp:112] Iteration 396000, lr = 1e-06
I0823 03:59:59.477104 13823 solver.cpp:239] Iteration 396100 (9.28877 iter/s, 10.7657s/100 iters), loss = 0.0221049
I0823 03:59:59.477155 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0221039 (* 1 = 0.0221039 loss)
I0823 03:59:59.477165 13823 sgd_solver.cpp:112] Iteration 396100, lr = 1e-06
I0823 04:00:10.523645 13823 solver.cpp:239] Iteration 396200 (9.0527 iter/s, 11.0464s/100 iters), loss = 0.0292184
I0823 04:00:10.523708 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0292175 (* 1 = 0.0292175 loss)
I0823 04:00:10.523721 13823 sgd_solver.cpp:112] Iteration 396200, lr = 1e-06
I0823 04:00:21.695327 13823 solver.cpp:239] Iteration 396300 (8.9513 iter/s, 11.1716s/100 iters), loss = 0.0247378
I0823 04:00:21.695389 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0247368 (* 1 = 0.0247368 loss)
I0823 04:00:21.695401 13823 sgd_solver.cpp:112] Iteration 396300, lr = 1e-06
I0823 04:00:32.576587 13823 solver.cpp:239] Iteration 396400 (9.19021 iter/s, 10.8811s/100 iters), loss = 0.0289087
I0823 04:00:32.576650 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0289078 (* 1 = 0.0289078 loss)
I0823 04:00:32.576663 13823 sgd_solver.cpp:112] Iteration 396400, lr = 1e-06
I0823 04:00:43.432014 13823 solver.cpp:239] Iteration 396500 (9.21207 iter/s, 10.8553s/100 iters), loss = 0.0313404
I0823 04:00:43.432065 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0313394 (* 1 = 0.0313394 loss)
I0823 04:00:43.432075 13823 sgd_solver.cpp:112] Iteration 396500, lr = 1e-06
I0823 04:00:54.501206 13823 solver.cpp:239] Iteration 396600 (9.03416 iter/s, 11.0691s/100 iters), loss = 0.0247949
I0823 04:00:54.501257 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0247939 (* 1 = 0.0247939 loss)
I0823 04:00:54.501266 13823 sgd_solver.cpp:112] Iteration 396600, lr = 1e-06
I0823 04:01:05.613126 13823 solver.cpp:239] Iteration 396700 (8.99942 iter/s, 11.1118s/100 iters), loss = 0.0358926
I0823 04:01:05.613180 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0358916 (* 1 = 0.0358916 loss)
I0823 04:01:05.613190 13823 sgd_solver.cpp:112] Iteration 396700, lr = 1e-06
I0823 04:01:16.926725 13823 solver.cpp:239] Iteration 396800 (8.839 iter/s, 11.3135s/100 iters), loss = 0.0242122
I0823 04:01:16.926782 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0242112 (* 1 = 0.0242112 loss)
I0823 04:01:16.926792 13823 sgd_solver.cpp:112] Iteration 396800, lr = 1e-06
I0823 04:01:28.149912 13823 solver.cpp:239] Iteration 396900 (8.9102 iter/s, 11.2231s/100 iters), loss = 0.0263177
I0823 04:01:28.149967 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0263167 (* 1 = 0.0263167 loss)
I0823 04:01:28.149977 13823 sgd_solver.cpp:112] Iteration 396900, lr = 1e-06
I0823 04:01:39.217919 13823 solver.cpp:239] Iteration 397000 (9.03513 iter/s, 11.0679s/100 iters), loss = 0.0272623
I0823 04:01:39.217974 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0272613 (* 1 = 0.0272613 loss)
I0823 04:01:39.217985 13823 sgd_solver.cpp:112] Iteration 397000, lr = 1e-06
I0823 04:01:50.372324 13823 solver.cpp:239] Iteration 397100 (8.96515 iter/s, 11.1543s/100 iters), loss = 0.0252516
I0823 04:01:50.372381 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0252506 (* 1 = 0.0252506 loss)
I0823 04:01:50.372392 13823 sgd_solver.cpp:112] Iteration 397100, lr = 1e-06
I0823 04:02:01.573056 13823 solver.cpp:239] Iteration 397200 (8.92807 iter/s, 11.2006s/100 iters), loss = 0.0352882
I0823 04:02:01.573118 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0352872 (* 1 = 0.0352872 loss)
I0823 04:02:01.573132 13823 sgd_solver.cpp:112] Iteration 397200, lr = 1e-06
I0823 04:02:12.934876 13823 solver.cpp:239] Iteration 397300 (8.80148 iter/s, 11.3617s/100 iters), loss = 0.0245398
I0823 04:02:12.934938 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0245388 (* 1 = 0.0245388 loss)
I0823 04:02:12.934952 13823 sgd_solver.cpp:112] Iteration 397300, lr = 1e-06
I0823 04:02:24.066753 13823 solver.cpp:239] Iteration 397400 (8.98329 iter/s, 11.1318s/100 iters), loss = 0.0272122
I0823 04:02:24.066805 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0272112 (* 1 = 0.0272112 loss)
I0823 04:02:24.066815 13823 sgd_solver.cpp:112] Iteration 397400, lr = 1e-06
I0823 04:02:35.353590 13823 solver.cpp:239] Iteration 397500 (8.85995 iter/s, 11.2867s/100 iters), loss = 0.0292778
I0823 04:02:35.353642 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0292768 (* 1 = 0.0292768 loss)
I0823 04:02:35.353653 13823 sgd_solver.cpp:112] Iteration 397500, lr = 1e-06
I0823 04:02:46.556391 13823 solver.cpp:239] Iteration 397600 (8.92641 iter/s, 11.2027s/100 iters), loss = 0.0311808
I0823 04:02:46.556452 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0311797 (* 1 = 0.0311797 loss)
I0823 04:02:46.556463 13823 sgd_solver.cpp:112] Iteration 397600, lr = 1e-06
I0823 04:02:57.727032 13823 solver.cpp:239] Iteration 397700 (8.95211 iter/s, 11.1705s/100 iters), loss = 0.0250273
I0823 04:02:57.727082 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0250263 (* 1 = 0.0250263 loss)
I0823 04:02:57.727092 13823 sgd_solver.cpp:112] Iteration 397700, lr = 1e-06
I0823 04:03:08.872098 13823 solver.cpp:239] Iteration 397800 (8.97264 iter/s, 11.145s/100 iters), loss = 0.0358149
I0823 04:03:08.872153 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0358139 (* 1 = 0.0358139 loss)
I0823 04:03:08.872164 13823 sgd_solver.cpp:112] Iteration 397800, lr = 1e-06
I0823 04:03:19.747738 13823 solver.cpp:239] Iteration 397900 (9.19493 iter/s, 10.8756s/100 iters), loss = 0.0268087
I0823 04:03:19.747808 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0268077 (* 1 = 0.0268077 loss)
I0823 04:03:19.747825 13823 sgd_solver.cpp:112] Iteration 397900, lr = 1e-06
I0823 04:03:30.621727 13823 solver.cpp:239] Iteration 398000 (9.19633 iter/s, 10.8739s/100 iters), loss = 0.0239842
I0823 04:03:30.621768 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0239832 (* 1 = 0.0239832 loss)
I0823 04:03:30.621776 13823 sgd_solver.cpp:112] Iteration 398000, lr = 1e-06
I0823 04:03:41.284924 13823 solver.cpp:239] Iteration 398100 (9.37811 iter/s, 10.6631s/100 iters), loss = 0.0262345
I0823 04:03:41.284978 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0262335 (* 1 = 0.0262335 loss)
I0823 04:03:41.284989 13823 sgd_solver.cpp:112] Iteration 398100, lr = 1e-06
I0823 04:03:51.945210 13823 solver.cpp:239] Iteration 398200 (9.38068 iter/s, 10.6602s/100 iters), loss = 0.0269135
I0823 04:03:51.945255 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0269125 (* 1 = 0.0269125 loss)
I0823 04:03:51.945263 13823 sgd_solver.cpp:112] Iteration 398200, lr = 1e-06
I0823 04:04:03.013945 13823 solver.cpp:239] Iteration 398300 (9.03451 iter/s, 11.0687s/100 iters), loss = 0.0332237
I0823 04:04:03.013996 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0332227 (* 1 = 0.0332227 loss)
I0823 04:04:03.014005 13823 sgd_solver.cpp:112] Iteration 398300, lr = 1e-06
I0823 04:04:14.367473 13823 solver.cpp:239] Iteration 398400 (8.80789 iter/s, 11.3535s/100 iters), loss = 0.025516
I0823 04:04:14.367532 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0255149 (* 1 = 0.0255149 loss)
I0823 04:04:14.367542 13823 sgd_solver.cpp:112] Iteration 398400, lr = 1e-06
I0823 04:04:25.741951 13823 solver.cpp:239] Iteration 398500 (8.79167 iter/s, 11.3744s/100 iters), loss = 0.0280893
I0823 04:04:25.742005 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0280883 (* 1 = 0.0280883 loss)
I0823 04:04:25.742015 13823 sgd_solver.cpp:112] Iteration 398500, lr = 1e-06
I0823 04:04:37.219405 13823 solver.cpp:239] Iteration 398600 (8.71279 iter/s, 11.4774s/100 iters), loss = 0.0252789
I0823 04:04:37.219470 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0252779 (* 1 = 0.0252779 loss)
I0823 04:04:37.219482 13823 sgd_solver.cpp:112] Iteration 398600, lr = 1e-06
I0823 04:04:48.456923 13823 solver.cpp:239] Iteration 398700 (8.89883 iter/s, 11.2374s/100 iters), loss = 0.025558
I0823 04:04:48.456982 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.025557 (* 1 = 0.025557 loss)
I0823 04:04:48.456993 13823 sgd_solver.cpp:112] Iteration 398700, lr = 1e-06
I0823 04:04:59.896481 13823 solver.cpp:239] Iteration 398800 (8.74166 iter/s, 11.4395s/100 iters), loss = 0.0280741
I0823 04:04:59.896548 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0280731 (* 1 = 0.0280731 loss)
I0823 04:04:59.896561 13823 sgd_solver.cpp:112] Iteration 398800, lr = 1e-06
I0823 04:05:11.159355 13823 solver.cpp:239] Iteration 398900 (8.87879 iter/s, 11.2628s/100 iters), loss = 0.0285655
I0823 04:05:11.159411 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0285645 (* 1 = 0.0285645 loss)
I0823 04:05:11.159422 13823 sgd_solver.cpp:112] Iteration 398900, lr = 1e-06
I0823 04:05:22.558233 13823 solver.cpp:239] Iteration 399000 (8.77285 iter/s, 11.3988s/100 iters), loss = 0.025528
I0823 04:05:22.558291 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0255269 (* 1 = 0.0255269 loss)
I0823 04:05:22.558302 13823 sgd_solver.cpp:112] Iteration 399000, lr = 1e-06
I0823 04:05:33.918120 13823 solver.cpp:239] Iteration 399100 (8.80296 iter/s, 11.3598s/100 iters), loss = 0.0278926
I0823 04:05:33.918175 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0278916 (* 1 = 0.0278916 loss)
I0823 04:05:33.918185 13823 sgd_solver.cpp:112] Iteration 399100, lr = 1e-06
I0823 04:05:45.316512 13823 solver.cpp:239] Iteration 399200 (8.77322 iter/s, 11.3983s/100 iters), loss = 0.0266987
I0823 04:05:45.316570 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0266977 (* 1 = 0.0266977 loss)
I0823 04:05:45.316581 13823 sgd_solver.cpp:112] Iteration 399200, lr = 1e-06
I0823 04:05:56.672040 13823 solver.cpp:239] Iteration 399300 (8.80634 iter/s, 11.3555s/100 iters), loss = 0.0266934
I0823 04:05:56.672099 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0266924 (* 1 = 0.0266924 loss)
I0823 04:05:56.672109 13823 sgd_solver.cpp:112] Iteration 399300, lr = 1e-06
I0823 04:06:07.971868 13823 solver.cpp:239] Iteration 399400 (8.84975 iter/s, 11.2998s/100 iters), loss = 0.0268613
I0823 04:06:07.971927 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0268603 (* 1 = 0.0268603 loss)
I0823 04:06:07.971940 13823 sgd_solver.cpp:112] Iteration 399400, lr = 1e-06
I0823 04:06:19.297149 13823 solver.cpp:239] Iteration 399500 (8.82986 iter/s, 11.3252s/100 iters), loss = 0.0251792
I0823 04:06:19.297207 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0251782 (* 1 = 0.0251782 loss)
I0823 04:06:19.297219 13823 sgd_solver.cpp:112] Iteration 399500, lr = 1e-06
I0823 04:06:30.649291 13823 solver.cpp:239] Iteration 399600 (8.80897 iter/s, 11.3521s/100 iters), loss = 0.0273077
I0823 04:06:30.649345 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0273066 (* 1 = 0.0273066 loss)
I0823 04:06:30.649356 13823 sgd_solver.cpp:112] Iteration 399600, lr = 1e-06
I0823 04:06:41.996946 13823 solver.cpp:239] Iteration 399700 (8.81245 iter/s, 11.3476s/100 iters), loss = 0.0273133
I0823 04:06:41.997009 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0273123 (* 1 = 0.0273123 loss)
I0823 04:06:41.997021 13823 sgd_solver.cpp:112] Iteration 399700, lr = 1e-06
I0823 04:06:53.486513 13823 solver.cpp:239] Iteration 399800 (8.7036 iter/s, 11.4895s/100 iters), loss = 0.0237406
I0823 04:06:53.486567 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0237395 (* 1 = 0.0237395 loss)
I0823 04:06:53.486575 13823 sgd_solver.cpp:112] Iteration 399800, lr = 1e-06
I0823 04:07:05.034117 13823 solver.cpp:239] Iteration 399900 (8.65985 iter/s, 11.5475s/100 iters), loss = 0.0263711
I0823 04:07:05.034176 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0263701 (* 1 = 0.0263701 loss)
I0823 04:07:05.034188 13823 sgd_solver.cpp:112] Iteration 399900, lr = 1e-06
I0823 04:07:16.108167 13823 solver.cpp:464] Snapshotting to binary proto file ./model_112/cascade_mobilenet_112_iter_400000.caffemodel
I0823 04:07:16.151501 13823 sgd_solver.cpp:284] Snapshotting solver state to binary proto file ./model_112/cascade_mobilenet_112_iter_400000.solverstate
I0823 04:07:16.182597 13823 solver.cpp:347] Iteration 400000, Testing net (#0)
I0823 04:08:20.579629 13823 solver.cpp:414]     Test net output #0: landmark_loss = 0.0219692 (* 1 = 0.0219692 loss)
I0823 04:08:20.702225 13823 solver.cpp:239] Iteration 400000 (1.32156 iter/s, 75.6681s/100 iters), loss = 0.0233325
I0823 04:08:20.702283 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0233314 (* 1 = 0.0233314 loss)
I0823 04:08:20.702298 13823 sgd_solver.cpp:112] Iteration 400000, lr = 1e-06
I0823 04:08:32.297626 13823 solver.cpp:239] Iteration 400100 (8.62415 iter/s, 11.5953s/100 iters), loss = 0.0289545
I0823 04:08:32.297683 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0289534 (* 1 = 0.0289534 loss)
I0823 04:08:32.297693 13823 sgd_solver.cpp:112] Iteration 400100, lr = 1e-06
I0823 04:08:43.733443 13823 solver.cpp:239] Iteration 400200 (8.7445 iter/s, 11.4358s/100 iters), loss = 0.024679
I0823 04:08:43.733503 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0246779 (* 1 = 0.0246779 loss)
I0823 04:08:43.733515 13823 sgd_solver.cpp:112] Iteration 400200, lr = 1e-06
I0823 04:08:55.245645 13823 solver.cpp:239] Iteration 400300 (8.68648 iter/s, 11.5121s/100 iters), loss = 0.0270555
I0823 04:08:55.245702 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0270545 (* 1 = 0.0270545 loss)
I0823 04:08:55.245712 13823 sgd_solver.cpp:112] Iteration 400300, lr = 1e-06
I0823 04:09:07.062121 13823 solver.cpp:239] Iteration 400400 (8.4628 iter/s, 11.8164s/100 iters), loss = 0.0257728
I0823 04:09:07.062183 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0257718 (* 1 = 0.0257718 loss)
I0823 04:09:07.062196 13823 sgd_solver.cpp:112] Iteration 400400, lr = 1e-06
I0823 04:09:18.622648 13823 solver.cpp:239] Iteration 400500 (8.65017 iter/s, 11.5605s/100 iters), loss = 0.0275289
I0823 04:09:18.622709 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0275278 (* 1 = 0.0275278 loss)
I0823 04:09:18.622720 13823 sgd_solver.cpp:112] Iteration 400500, lr = 1e-06
I0823 04:09:30.021152 13823 solver.cpp:239] Iteration 400600 (8.77312 iter/s, 11.3984s/100 iters), loss = 0.0452161
I0823 04:09:30.021209 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.045215 (* 1 = 0.045215 loss)
I0823 04:09:30.021221 13823 sgd_solver.cpp:112] Iteration 400600, lr = 1e-06
I0823 04:09:41.607139 13823 solver.cpp:239] Iteration 400700 (8.63115 iter/s, 11.5859s/100 iters), loss = 0.0591586
I0823 04:09:41.607193 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0591575 (* 1 = 0.0591575 loss)
I0823 04:09:41.607203 13823 sgd_solver.cpp:112] Iteration 400700, lr = 1e-06
I0823 04:09:53.288960 13823 solver.cpp:239] Iteration 400800 (8.56034 iter/s, 11.6818s/100 iters), loss = 0.028232
I0823 04:09:53.289012 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0282309 (* 1 = 0.0282309 loss)
I0823 04:09:53.289022 13823 sgd_solver.cpp:112] Iteration 400800, lr = 1e-06
I0823 04:10:04.861528 13823 solver.cpp:239] Iteration 400900 (8.64116 iter/s, 11.5725s/100 iters), loss = 0.025422
I0823 04:10:04.861588 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.025421 (* 1 = 0.025421 loss)
I0823 04:10:04.861598 13823 sgd_solver.cpp:112] Iteration 400900, lr = 1e-06
I0823 04:10:16.478735 13823 solver.cpp:239] Iteration 401000 (8.60796 iter/s, 11.6172s/100 iters), loss = 0.0343085
I0823 04:10:16.478797 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0343075 (* 1 = 0.0343075 loss)
I0823 04:10:16.478809 13823 sgd_solver.cpp:112] Iteration 401000, lr = 1e-06
I0823 04:10:28.234979 13823 solver.cpp:239] Iteration 401100 (8.50616 iter/s, 11.7562s/100 iters), loss = 0.0213917
I0823 04:10:28.235038 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0213906 (* 1 = 0.0213906 loss)
I0823 04:10:28.235049 13823 sgd_solver.cpp:112] Iteration 401100, lr = 1e-06
I0823 04:10:40.103081 13823 solver.cpp:239] Iteration 401200 (8.42598 iter/s, 11.8681s/100 iters), loss = 0.0250809
I0823 04:10:40.103138 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0250799 (* 1 = 0.0250799 loss)
I0823 04:10:40.103149 13823 sgd_solver.cpp:112] Iteration 401200, lr = 1e-06
I0823 04:10:51.908102 13823 solver.cpp:239] Iteration 401300 (8.47101 iter/s, 11.805s/100 iters), loss = 0.0277716
I0823 04:10:51.908155 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0277706 (* 1 = 0.0277706 loss)
I0823 04:10:51.908165 13823 sgd_solver.cpp:112] Iteration 401300, lr = 1e-06
I0823 04:11:03.467378 13823 solver.cpp:239] Iteration 401400 (8.6511 iter/s, 11.5592s/100 iters), loss = 0.0276045
I0823 04:11:03.467438 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0276034 (* 1 = 0.0276034 loss)
I0823 04:11:03.467450 13823 sgd_solver.cpp:112] Iteration 401400, lr = 1e-06
I0823 04:11:15.172297 13823 solver.cpp:239] Iteration 401500 (8.54345 iter/s, 11.7049s/100 iters), loss = 0.0421244
I0823 04:11:15.172358 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0421233 (* 1 = 0.0421233 loss)
I0823 04:11:15.172370 13823 sgd_solver.cpp:112] Iteration 401500, lr = 1e-06
I0823 04:11:26.916476 13823 solver.cpp:239] Iteration 401600 (8.51489 iter/s, 11.7441s/100 iters), loss = 0.0294169
I0823 04:11:26.916529 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0294158 (* 1 = 0.0294158 loss)
I0823 04:11:26.916539 13823 sgd_solver.cpp:112] Iteration 401600, lr = 1e-06
I0823 04:11:38.455574 13823 solver.cpp:239] Iteration 401700 (8.66622 iter/s, 11.5391s/100 iters), loss = 0.0255035
I0823 04:11:38.455631 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0255024 (* 1 = 0.0255024 loss)
I0823 04:11:38.455643 13823 sgd_solver.cpp:112] Iteration 401700, lr = 1e-06
I0823 04:11:48.743835 13823 solver.cpp:239] Iteration 401800 (9.71986 iter/s, 10.2882s/100 iters), loss = 0.0283971
I0823 04:11:48.743886 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.028396 (* 1 = 0.028396 loss)
I0823 04:11:48.743896 13823 sgd_solver.cpp:112] Iteration 401800, lr = 1e-06
I0823 04:11:58.688591 13823 solver.cpp:239] Iteration 401900 (10.0556 iter/s, 9.94471s/100 iters), loss = 0.0276853
I0823 04:11:58.688642 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0276842 (* 1 = 0.0276842 loss)
I0823 04:11:58.688650 13823 sgd_solver.cpp:112] Iteration 401900, lr = 1e-06
I0823 04:12:08.495705 13823 solver.cpp:239] Iteration 402000 (10.1967 iter/s, 9.80707s/100 iters), loss = 0.0353853
I0823 04:12:08.495764 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0353843 (* 1 = 0.0353843 loss)
I0823 04:12:08.495775 13823 sgd_solver.cpp:112] Iteration 402000, lr = 1e-06
I0823 04:12:18.323839 13823 solver.cpp:239] Iteration 402100 (10.1749 iter/s, 9.82808s/100 iters), loss = 0.0289976
I0823 04:12:18.323889 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0289965 (* 1 = 0.0289965 loss)
I0823 04:12:18.323897 13823 sgd_solver.cpp:112] Iteration 402100, lr = 1e-06
I0823 04:12:28.069715 13823 solver.cpp:239] Iteration 402200 (10.2608 iter/s, 9.74584s/100 iters), loss = 0.0262909
I0823 04:12:28.069766 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0262898 (* 1 = 0.0262898 loss)
I0823 04:12:28.069775 13823 sgd_solver.cpp:112] Iteration 402200, lr = 1e-06
I0823 04:12:37.818948 13823 solver.cpp:239] Iteration 402300 (10.2573 iter/s, 9.74919s/100 iters), loss = 0.0274185
I0823 04:12:37.818997 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0274174 (* 1 = 0.0274174 loss)
I0823 04:12:37.819006 13823 sgd_solver.cpp:112] Iteration 402300, lr = 1e-06
I0823 04:12:47.759846 13823 solver.cpp:239] Iteration 402400 (10.0595 iter/s, 9.94086s/100 iters), loss = 0.0225414
I0823 04:12:47.759896 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0225403 (* 1 = 0.0225403 loss)
I0823 04:12:47.759904 13823 sgd_solver.cpp:112] Iteration 402400, lr = 1e-06
I0823 04:12:57.262372 13823 solver.cpp:239] Iteration 402500 (10.5236 iter/s, 9.50248s/100 iters), loss = 0.0262815
I0823 04:12:57.262424 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0262804 (* 1 = 0.0262804 loss)
I0823 04:12:57.262434 13823 sgd_solver.cpp:112] Iteration 402500, lr = 1e-06
I0823 04:13:07.197847 13823 solver.cpp:239] Iteration 402600 (10.065 iter/s, 9.93543s/100 iters), loss = 0.0359726
I0823 04:13:07.197899 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0359715 (* 1 = 0.0359715 loss)
I0823 04:13:07.197908 13823 sgd_solver.cpp:112] Iteration 402600, lr = 1e-06
I0823 04:13:16.678944 13823 solver.cpp:239] Iteration 402700 (10.5473 iter/s, 9.48106s/100 iters), loss = 0.0256984
I0823 04:13:16.678985 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0256973 (* 1 = 0.0256973 loss)
I0823 04:13:16.678992 13823 sgd_solver.cpp:112] Iteration 402700, lr = 1e-06
I0823 04:13:25.910131 13823 solver.cpp:239] Iteration 402800 (10.8329 iter/s, 9.23116s/100 iters), loss = 0.0255743
I0823 04:13:25.910172 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0255732 (* 1 = 0.0255732 loss)
I0823 04:13:25.910179 13823 sgd_solver.cpp:112] Iteration 402800, lr = 1e-06
I0823 04:13:35.529139 13823 solver.cpp:239] Iteration 402900 (10.3961 iter/s, 9.61897s/100 iters), loss = 0.0413091
I0823 04:13:35.529189 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.041308 (* 1 = 0.041308 loss)
I0823 04:13:35.529199 13823 sgd_solver.cpp:112] Iteration 402900, lr = 1e-06
I0823 04:13:45.657893 13823 solver.cpp:239] Iteration 403000 (9.87292 iter/s, 10.1287s/100 iters), loss = 0.0403842
I0823 04:13:45.657945 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0403831 (* 1 = 0.0403831 loss)
I0823 04:13:45.657954 13823 sgd_solver.cpp:112] Iteration 403000, lr = 1e-06
I0823 04:13:55.386960 13823 solver.cpp:239] Iteration 403100 (10.2785 iter/s, 9.72903s/100 iters), loss = 0.0263111
I0823 04:13:55.387012 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.02631 (* 1 = 0.02631 loss)
I0823 04:13:55.387019 13823 sgd_solver.cpp:112] Iteration 403100, lr = 1e-06
I0823 04:14:05.320292 13823 solver.cpp:239] Iteration 403200 (10.0672 iter/s, 9.93329s/100 iters), loss = 0.0270459
I0823 04:14:05.320350 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0270448 (* 1 = 0.0270448 loss)
I0823 04:14:05.320361 13823 sgd_solver.cpp:112] Iteration 403200, lr = 1e-06
I0823 04:14:15.089515 13823 solver.cpp:239] Iteration 403300 (10.2363 iter/s, 9.76917s/100 iters), loss = 0.0274568
I0823 04:14:15.089567 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0274558 (* 1 = 0.0274558 loss)
I0823 04:14:15.089577 13823 sgd_solver.cpp:112] Iteration 403300, lr = 1e-06
I0823 04:14:24.987432 13823 solver.cpp:239] Iteration 403400 (10.1032 iter/s, 9.89787s/100 iters), loss = 0.02779
I0823 04:14:24.987493 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0277889 (* 1 = 0.0277889 loss)
I0823 04:14:24.987504 13823 sgd_solver.cpp:112] Iteration 403400, lr = 1e-06
I0823 04:14:34.787093 13823 solver.cpp:239] Iteration 403500 (10.2045 iter/s, 9.79961s/100 iters), loss = 0.0247748
I0823 04:14:34.787142 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0247738 (* 1 = 0.0247738 loss)
I0823 04:14:34.787153 13823 sgd_solver.cpp:112] Iteration 403500, lr = 1e-06
I0823 04:14:44.490396 13823 solver.cpp:239] Iteration 403600 (10.3058 iter/s, 9.70326s/100 iters), loss = 0.0226804
I0823 04:14:44.490456 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0226793 (* 1 = 0.0226793 loss)
I0823 04:14:44.490468 13823 sgd_solver.cpp:112] Iteration 403600, lr = 1e-06
I0823 04:14:54.449283 13823 solver.cpp:239] Iteration 403700 (10.0413 iter/s, 9.95884s/100 iters), loss = 0.036411
I0823 04:14:54.449347 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0364099 (* 1 = 0.0364099 loss)
I0823 04:14:54.449358 13823 sgd_solver.cpp:112] Iteration 403700, lr = 1e-06
I0823 04:15:04.272222 13823 solver.cpp:239] Iteration 403800 (10.1803 iter/s, 9.82289s/100 iters), loss = 0.0334542
I0823 04:15:04.272274 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0334532 (* 1 = 0.0334532 loss)
I0823 04:15:04.272284 13823 sgd_solver.cpp:112] Iteration 403800, lr = 1e-06
I0823 04:15:13.964648 13823 solver.cpp:239] Iteration 403900 (10.3174 iter/s, 9.69238s/100 iters), loss = 0.0293453
I0823 04:15:13.964697 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0293442 (* 1 = 0.0293442 loss)
I0823 04:15:13.964707 13823 sgd_solver.cpp:112] Iteration 403900, lr = 1e-06
I0823 04:15:24.009191 13823 solver.cpp:239] Iteration 404000 (9.9557 iter/s, 10.0445s/100 iters), loss = 0.0271712
I0823 04:15:24.009241 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0271701 (* 1 = 0.0271701 loss)
I0823 04:15:24.009250 13823 sgd_solver.cpp:112] Iteration 404000, lr = 1e-06
I0823 04:15:33.725905 13823 solver.cpp:239] Iteration 404100 (10.2916 iter/s, 9.71667s/100 iters), loss = 0.0275094
I0823 04:15:33.725956 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0275083 (* 1 = 0.0275083 loss)
I0823 04:15:33.725965 13823 sgd_solver.cpp:112] Iteration 404100, lr = 1e-06
I0823 04:15:43.669262 13823 solver.cpp:239] Iteration 404200 (10.057 iter/s, 9.94331s/100 iters), loss = 0.0285102
I0823 04:15:43.669317 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0285091 (* 1 = 0.0285091 loss)
I0823 04:15:43.669327 13823 sgd_solver.cpp:112] Iteration 404200, lr = 1e-06
I0823 04:15:53.299228 13823 solver.cpp:239] Iteration 404300 (10.3843 iter/s, 9.62992s/100 iters), loss = 0.0269143
I0823 04:15:53.299289 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0269132 (* 1 = 0.0269132 loss)
I0823 04:15:53.299299 13823 sgd_solver.cpp:112] Iteration 404300, lr = 1e-06
I0823 04:16:03.110533 13823 solver.cpp:239] Iteration 404400 (10.1924 iter/s, 9.81126s/100 iters), loss = 0.0290482
I0823 04:16:03.110587 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0290472 (* 1 = 0.0290472 loss)
I0823 04:16:03.110597 13823 sgd_solver.cpp:112] Iteration 404400, lr = 1e-06
I0823 04:16:12.545975 13823 solver.cpp:239] Iteration 404500 (10.5984 iter/s, 9.4354s/100 iters), loss = 0.0276718
I0823 04:16:12.546017 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0276707 (* 1 = 0.0276707 loss)
I0823 04:16:12.546025 13823 sgd_solver.cpp:112] Iteration 404500, lr = 1e-06
I0823 04:16:22.415035 13823 solver.cpp:239] Iteration 404600 (10.1327 iter/s, 9.86903s/100 iters), loss = 0.0262624
I0823 04:16:22.415087 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0262613 (* 1 = 0.0262613 loss)
I0823 04:16:22.415096 13823 sgd_solver.cpp:112] Iteration 404600, lr = 1e-06
I0823 04:16:32.185477 13823 solver.cpp:239] Iteration 404700 (10.235 iter/s, 9.7704s/100 iters), loss = 0.0273769
I0823 04:16:32.185526 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0273758 (* 1 = 0.0273758 loss)
I0823 04:16:32.185536 13823 sgd_solver.cpp:112] Iteration 404700, lr = 1e-06
I0823 04:16:41.750439 13823 solver.cpp:239] Iteration 404800 (10.4549 iter/s, 9.56492s/100 iters), loss = 0.0213796
I0823 04:16:41.750492 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0213785 (* 1 = 0.0213785 loss)
I0823 04:16:41.750502 13823 sgd_solver.cpp:112] Iteration 404800, lr = 1e-06
I0823 04:16:51.701285 13823 solver.cpp:239] Iteration 404900 (10.0494 iter/s, 9.9508s/100 iters), loss = 0.0239445
I0823 04:16:51.701336 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0239435 (* 1 = 0.0239435 loss)
I0823 04:16:51.701345 13823 sgd_solver.cpp:112] Iteration 404900, lr = 1e-06
I0823 04:17:01.388847 13823 solver.cpp:239] Iteration 405000 (10.3226 iter/s, 9.68753s/100 iters), loss = 0.0229655
I0823 04:17:01.388885 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0229644 (* 1 = 0.0229644 loss)
I0823 04:17:01.388893 13823 sgd_solver.cpp:112] Iteration 405000, lr = 1e-06
I0823 04:17:10.786115 13823 solver.cpp:239] Iteration 405100 (10.6414 iter/s, 9.39724s/100 iters), loss = 0.0241961
I0823 04:17:10.786155 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0241951 (* 1 = 0.0241951 loss)
I0823 04:17:10.786162 13823 sgd_solver.cpp:112] Iteration 405100, lr = 1e-06
I0823 04:17:20.683445 13823 solver.cpp:239] Iteration 405200 (10.1038 iter/s, 9.8973s/100 iters), loss = 0.0239924
I0823 04:17:20.683497 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0239913 (* 1 = 0.0239913 loss)
I0823 04:17:20.683506 13823 sgd_solver.cpp:112] Iteration 405200, lr = 1e-06
I0823 04:17:30.428093 13823 solver.cpp:239] Iteration 405300 (10.2621 iter/s, 9.74461s/100 iters), loss = 0.0440161
I0823 04:17:30.428138 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0440151 (* 1 = 0.0440151 loss)
I0823 04:17:30.428146 13823 sgd_solver.cpp:112] Iteration 405300, lr = 1e-06
I0823 04:17:40.119632 13823 solver.cpp:239] Iteration 405400 (10.3183 iter/s, 9.69151s/100 iters), loss = 0.0225515
I0823 04:17:40.119683 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0225505 (* 1 = 0.0225505 loss)
I0823 04:17:40.119693 13823 sgd_solver.cpp:112] Iteration 405400, lr = 1e-06
I0823 04:17:49.936185 13823 solver.cpp:239] Iteration 405500 (10.1869 iter/s, 9.81651s/100 iters), loss = 0.0269262
I0823 04:17:49.936233 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0269251 (* 1 = 0.0269251 loss)
I0823 04:17:49.936241 13823 sgd_solver.cpp:112] Iteration 405500, lr = 1e-06
I0823 04:17:59.645927 13823 solver.cpp:239] Iteration 405600 (10.299 iter/s, 9.70971s/100 iters), loss = 0.0258622
I0823 04:17:59.645978 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0258612 (* 1 = 0.0258612 loss)
I0823 04:17:59.645987 13823 sgd_solver.cpp:112] Iteration 405600, lr = 1e-06
I0823 04:18:09.073475 13823 solver.cpp:239] Iteration 405700 (10.6072 iter/s, 9.42752s/100 iters), loss = 0.0344867
I0823 04:18:09.073518 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0344856 (* 1 = 0.0344856 loss)
I0823 04:18:09.073524 13823 sgd_solver.cpp:112] Iteration 405700, lr = 1e-06
I0823 04:18:18.909562 13823 solver.cpp:239] Iteration 405800 (10.1667 iter/s, 9.83605s/100 iters), loss = 0.0233549
I0823 04:18:18.909620 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0233538 (* 1 = 0.0233538 loss)
I0823 04:18:18.909631 13823 sgd_solver.cpp:112] Iteration 405800, lr = 1e-06
I0823 04:18:28.922570 13823 solver.cpp:239] Iteration 405900 (9.98705 iter/s, 10.013s/100 iters), loss = 0.0232386
I0823 04:18:28.922621 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0232376 (* 1 = 0.0232376 loss)
I0823 04:18:28.922631 13823 sgd_solver.cpp:112] Iteration 405900, lr = 1e-06
I0823 04:18:39.214938 13823 solver.cpp:239] Iteration 406000 (9.71597 iter/s, 10.2923s/100 iters), loss = 0.0269884
I0823 04:18:39.214992 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0269873 (* 1 = 0.0269873 loss)
I0823 04:18:39.215000 13823 sgd_solver.cpp:112] Iteration 406000, lr = 1e-06
I0823 04:18:49.213258 13823 solver.cpp:239] Iteration 406100 (10.0017 iter/s, 9.99828s/100 iters), loss = 0.0350468
I0823 04:18:49.213313 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0350457 (* 1 = 0.0350457 loss)
I0823 04:18:49.213323 13823 sgd_solver.cpp:112] Iteration 406100, lr = 1e-06
I0823 04:18:59.213495 13823 solver.cpp:239] Iteration 406200 (9.9998 iter/s, 10.0002s/100 iters), loss = 0.0251809
I0823 04:18:59.213546 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0251798 (* 1 = 0.0251798 loss)
I0823 04:18:59.213555 13823 sgd_solver.cpp:112] Iteration 406200, lr = 1e-06
I0823 04:19:08.957597 13823 solver.cpp:239] Iteration 406300 (10.2627 iter/s, 9.74406s/100 iters), loss = 0.0332212
I0823 04:19:08.957650 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0332201 (* 1 = 0.0332201 loss)
I0823 04:19:08.957660 13823 sgd_solver.cpp:112] Iteration 406300, lr = 1e-06
I0823 04:19:18.837714 13823 solver.cpp:239] Iteration 406400 (10.1214 iter/s, 9.88008s/100 iters), loss = 0.0286393
I0823 04:19:18.837766 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0286383 (* 1 = 0.0286383 loss)
I0823 04:19:18.837775 13823 sgd_solver.cpp:112] Iteration 406400, lr = 1e-06
I0823 04:19:28.607832 13823 solver.cpp:239] Iteration 406500 (10.2353 iter/s, 9.77008s/100 iters), loss = 0.0276703
I0823 04:19:28.607882 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0276692 (* 1 = 0.0276692 loss)
I0823 04:19:28.607890 13823 sgd_solver.cpp:112] Iteration 406500, lr = 1e-06
I0823 04:19:38.546800 13823 solver.cpp:239] Iteration 406600 (10.0614 iter/s, 9.93893s/100 iters), loss = 0.0238374
I0823 04:19:38.546847 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0238363 (* 1 = 0.0238363 loss)
I0823 04:19:38.546856 13823 sgd_solver.cpp:112] Iteration 406600, lr = 1e-06
I0823 04:19:48.354506 13823 solver.cpp:239] Iteration 406700 (10.1961 iter/s, 9.80767s/100 iters), loss = 0.023858
I0823 04:19:48.354557 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0238569 (* 1 = 0.0238569 loss)
I0823 04:19:48.354568 13823 sgd_solver.cpp:112] Iteration 406700, lr = 1e-06
I0823 04:19:58.424221 13823 solver.cpp:239] Iteration 406800 (9.93081 iter/s, 10.0697s/100 iters), loss = 0.0242533
I0823 04:19:58.424276 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0242522 (* 1 = 0.0242522 loss)
I0823 04:19:58.424288 13823 sgd_solver.cpp:112] Iteration 406800, lr = 1e-06
I0823 04:20:08.180992 13823 solver.cpp:239] Iteration 406900 (10.2493 iter/s, 9.75673s/100 iters), loss = 0.0241302
I0823 04:20:08.181042 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0241292 (* 1 = 0.0241292 loss)
I0823 04:20:08.181051 13823 sgd_solver.cpp:112] Iteration 406900, lr = 1e-06
I0823 04:20:18.267096 13823 solver.cpp:239] Iteration 407000 (9.91467 iter/s, 10.0861s/100 iters), loss = 0.031387
I0823 04:20:18.267145 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0313859 (* 1 = 0.0313859 loss)
I0823 04:20:18.267154 13823 sgd_solver.cpp:112] Iteration 407000, lr = 1e-06
I0823 04:20:28.324308 13823 solver.cpp:239] Iteration 407100 (9.94315 iter/s, 10.0572s/100 iters), loss = 0.0238535
I0823 04:20:28.324360 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0238524 (* 1 = 0.0238524 loss)
I0823 04:20:28.324369 13823 sgd_solver.cpp:112] Iteration 407100, lr = 1e-06
I0823 04:20:38.408155 13823 solver.cpp:239] Iteration 407200 (9.91689 iter/s, 10.0838s/100 iters), loss = 0.0286664
I0823 04:20:38.408216 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0286654 (* 1 = 0.0286654 loss)
I0823 04:20:38.408229 13823 sgd_solver.cpp:112] Iteration 407200, lr = 1e-06
I0823 04:20:48.546085 13823 solver.cpp:239] Iteration 407300 (9.86399 iter/s, 10.1379s/100 iters), loss = 0.0265974
I0823 04:20:48.546135 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0265963 (* 1 = 0.0265963 loss)
I0823 04:20:48.546145 13823 sgd_solver.cpp:112] Iteration 407300, lr = 1e-06
I0823 04:20:58.641155 13823 solver.cpp:239] Iteration 407400 (9.90586 iter/s, 10.095s/100 iters), loss = 0.0246661
I0823 04:20:58.641206 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0246651 (* 1 = 0.0246651 loss)
I0823 04:20:58.641216 13823 sgd_solver.cpp:112] Iteration 407400, lr = 1e-06
I0823 04:21:08.548401 13823 solver.cpp:239] Iteration 407500 (10.0937 iter/s, 9.90721s/100 iters), loss = 0.0238758
I0823 04:21:08.548452 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0238748 (* 1 = 0.0238748 loss)
I0823 04:21:08.548462 13823 sgd_solver.cpp:112] Iteration 407500, lr = 1e-06
I0823 04:21:18.456007 13823 solver.cpp:239] Iteration 407600 (10.0933 iter/s, 9.90757s/100 iters), loss = 0.0249319
I0823 04:21:18.456073 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0249308 (* 1 = 0.0249308 loss)
I0823 04:21:18.456085 13823 sgd_solver.cpp:112] Iteration 407600, lr = 1e-06
I0823 04:21:28.332479 13823 solver.cpp:239] Iteration 407700 (10.1251 iter/s, 9.87642s/100 iters), loss = 0.0275923
I0823 04:21:28.332535 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0275913 (* 1 = 0.0275913 loss)
I0823 04:21:28.332545 13823 sgd_solver.cpp:112] Iteration 407700, lr = 1e-06
I0823 04:21:38.586670 13823 solver.cpp:239] Iteration 407800 (9.75215 iter/s, 10.2542s/100 iters), loss = 0.0243655
I0823 04:21:38.586724 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0243644 (* 1 = 0.0243644 loss)
I0823 04:21:38.586735 13823 sgd_solver.cpp:112] Iteration 407800, lr = 1e-06
I0823 04:21:48.516363 13823 solver.cpp:239] Iteration 407900 (10.0708 iter/s, 9.92966s/100 iters), loss = 0.0244381
I0823 04:21:48.516413 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0244371 (* 1 = 0.0244371 loss)
I0823 04:21:48.516422 13823 sgd_solver.cpp:112] Iteration 407900, lr = 1e-06
I0823 04:21:58.679425 13823 solver.cpp:239] Iteration 408000 (9.83959 iter/s, 10.163s/100 iters), loss = 0.0247697
I0823 04:21:58.679474 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0247687 (* 1 = 0.0247687 loss)
I0823 04:21:58.679483 13823 sgd_solver.cpp:112] Iteration 408000, lr = 1e-06
I0823 04:22:09.122753 13823 solver.cpp:239] Iteration 408100 (9.57552 iter/s, 10.4433s/100 iters), loss = 0.0243989
I0823 04:22:09.122809 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0243979 (* 1 = 0.0243979 loss)
I0823 04:22:09.122820 13823 sgd_solver.cpp:112] Iteration 408100, lr = 1e-06
I0823 04:22:19.437867 13823 solver.cpp:239] Iteration 408200 (9.69455 iter/s, 10.3151s/100 iters), loss = 0.0238863
I0823 04:22:19.437921 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0238852 (* 1 = 0.0238852 loss)
I0823 04:22:19.437930 13823 sgd_solver.cpp:112] Iteration 408200, lr = 1e-06
I0823 04:22:29.739455 13823 solver.cpp:239] Iteration 408300 (9.70728 iter/s, 10.3015s/100 iters), loss = 0.0247653
I0823 04:22:29.739517 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0247642 (* 1 = 0.0247642 loss)
I0823 04:22:29.739531 13823 sgd_solver.cpp:112] Iteration 408300, lr = 1e-06
I0823 04:22:40.236415 13823 solver.cpp:239] Iteration 408400 (9.52661 iter/s, 10.4969s/100 iters), loss = 0.0757522
I0823 04:22:40.236465 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0757512 (* 1 = 0.0757512 loss)
I0823 04:22:40.236474 13823 sgd_solver.cpp:112] Iteration 408400, lr = 1e-06
I0823 04:22:50.614742 13823 solver.cpp:239] Iteration 408500 (9.6355 iter/s, 10.3783s/100 iters), loss = 0.0261378
I0823 04:22:50.614792 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0261368 (* 1 = 0.0261368 loss)
I0823 04:22:50.614801 13823 sgd_solver.cpp:112] Iteration 408500, lr = 1e-06
I0823 04:23:00.676443 13823 solver.cpp:239] Iteration 408600 (9.93871 iter/s, 10.0617s/100 iters), loss = 0.0265869
I0823 04:23:00.676493 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0265858 (* 1 = 0.0265858 loss)
I0823 04:23:00.676503 13823 sgd_solver.cpp:112] Iteration 408600, lr = 1e-06
I0823 04:23:10.704246 13823 solver.cpp:239] Iteration 408700 (9.97231 iter/s, 10.0278s/100 iters), loss = 0.0251414
I0823 04:23:10.704299 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0251404 (* 1 = 0.0251404 loss)
I0823 04:23:10.704309 13823 sgd_solver.cpp:112] Iteration 408700, lr = 1e-06
I0823 04:23:20.882644 13823 solver.cpp:239] Iteration 408800 (9.82476 iter/s, 10.1784s/100 iters), loss = 0.0305755
I0823 04:23:20.882694 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0305745 (* 1 = 0.0305745 loss)
I0823 04:23:20.882702 13823 sgd_solver.cpp:112] Iteration 408800, lr = 1e-06
I0823 04:23:31.147560 13823 solver.cpp:239] Iteration 408900 (9.74195 iter/s, 10.2649s/100 iters), loss = 0.0298817
I0823 04:23:31.147612 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0298806 (* 1 = 0.0298806 loss)
I0823 04:23:31.147622 13823 sgd_solver.cpp:112] Iteration 408900, lr = 1e-06
I0823 04:23:41.095410 13823 solver.cpp:239] Iteration 409000 (10.0525 iter/s, 9.94781s/100 iters), loss = 0.0331985
I0823 04:23:41.095463 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0331975 (* 1 = 0.0331975 loss)
I0823 04:23:41.095471 13823 sgd_solver.cpp:112] Iteration 409000, lr = 1e-06
I0823 04:23:51.318061 13823 solver.cpp:239] Iteration 409100 (9.78223 iter/s, 10.2226s/100 iters), loss = 0.0242384
I0823 04:23:51.318112 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0242373 (* 1 = 0.0242373 loss)
I0823 04:23:51.318122 13823 sgd_solver.cpp:112] Iteration 409100, lr = 1e-06
I0823 04:24:01.996297 13823 solver.cpp:239] Iteration 409200 (9.36487 iter/s, 10.6782s/100 iters), loss = 0.0268007
I0823 04:24:01.996346 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0267997 (* 1 = 0.0267997 loss)
I0823 04:24:01.996356 13823 sgd_solver.cpp:112] Iteration 409200, lr = 1e-06
I0823 04:24:12.197831 13823 solver.cpp:239] Iteration 409300 (9.80248 iter/s, 10.2015s/100 iters), loss = 0.027179
I0823 04:24:12.197885 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.027178 (* 1 = 0.027178 loss)
I0823 04:24:12.197894 13823 sgd_solver.cpp:112] Iteration 409300, lr = 1e-06
I0823 04:24:22.626425 13823 solver.cpp:239] Iteration 409400 (9.58905 iter/s, 10.4286s/100 iters), loss = 0.0236908
I0823 04:24:22.626474 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0236897 (* 1 = 0.0236897 loss)
I0823 04:24:22.626484 13823 sgd_solver.cpp:112] Iteration 409400, lr = 1e-06
I0823 04:24:33.212118 13823 solver.cpp:239] Iteration 409500 (9.44674 iter/s, 10.5857s/100 iters), loss = 0.0267824
I0823 04:24:33.212177 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0267814 (* 1 = 0.0267814 loss)
I0823 04:24:33.212188 13823 sgd_solver.cpp:112] Iteration 409500, lr = 1e-06
I0823 04:24:43.414281 13823 solver.cpp:239] Iteration 409600 (9.80188 iter/s, 10.2021s/100 iters), loss = 0.0251174
I0823 04:24:43.414331 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0251164 (* 1 = 0.0251164 loss)
I0823 04:24:43.414340 13823 sgd_solver.cpp:112] Iteration 409600, lr = 1e-06
I0823 04:24:53.915664 13823 solver.cpp:239] Iteration 409700 (9.52259 iter/s, 10.5013s/100 iters), loss = 0.0248825
I0823 04:24:53.915717 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0248815 (* 1 = 0.0248815 loss)
I0823 04:24:53.915727 13823 sgd_solver.cpp:112] Iteration 409700, lr = 1e-06
I0823 04:25:03.954712 13823 solver.cpp:239] Iteration 409800 (9.96114 iter/s, 10.039s/100 iters), loss = 0.0277822
I0823 04:25:03.954764 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0277811 (* 1 = 0.0277811 loss)
I0823 04:25:03.954773 13823 sgd_solver.cpp:112] Iteration 409800, lr = 1e-06
I0823 04:25:14.389226 13823 solver.cpp:239] Iteration 409900 (9.58361 iter/s, 10.4345s/100 iters), loss = 0.0296037
I0823 04:25:14.389279 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0296027 (* 1 = 0.0296027 loss)
I0823 04:25:14.389289 13823 sgd_solver.cpp:112] Iteration 409900, lr = 1e-06
I0823 04:25:24.957197 13823 solver.cpp:239] Iteration 410000 (9.46258 iter/s, 10.5679s/100 iters), loss = 0.0250862
I0823 04:25:24.957247 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0250851 (* 1 = 0.0250851 loss)
I0823 04:25:24.957255 13823 sgd_solver.cpp:112] Iteration 410000, lr = 1e-06
I0823 04:25:35.197712 13823 solver.cpp:239] Iteration 410100 (9.76516 iter/s, 10.2405s/100 iters), loss = 0.0265053
I0823 04:25:35.197763 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0265043 (* 1 = 0.0265043 loss)
I0823 04:25:35.197773 13823 sgd_solver.cpp:112] Iteration 410100, lr = 1e-06
I0823 04:25:45.571271 13823 solver.cpp:239] Iteration 410200 (9.63992 iter/s, 10.3735s/100 iters), loss = 0.0317845
I0823 04:25:45.571331 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0317835 (* 1 = 0.0317835 loss)
I0823 04:25:45.571342 13823 sgd_solver.cpp:112] Iteration 410200, lr = 1e-06
I0823 04:25:56.081543 13823 solver.cpp:239] Iteration 410300 (9.51454 iter/s, 10.5102s/100 iters), loss = 0.0275932
I0823 04:25:56.081594 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0275921 (* 1 = 0.0275921 loss)
I0823 04:25:56.081604 13823 sgd_solver.cpp:112] Iteration 410300, lr = 1e-06
I0823 04:26:06.554613 13823 solver.cpp:239] Iteration 410400 (9.54833 iter/s, 10.473s/100 iters), loss = 0.0280717
I0823 04:26:06.554666 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0280707 (* 1 = 0.0280707 loss)
I0823 04:26:06.554674 13823 sgd_solver.cpp:112] Iteration 410400, lr = 1e-06
I0823 04:26:16.663776 13823 solver.cpp:239] Iteration 410500 (9.89205 iter/s, 10.1091s/100 iters), loss = 0.0271853
I0823 04:26:16.663830 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0271843 (* 1 = 0.0271843 loss)
I0823 04:26:16.663841 13823 sgd_solver.cpp:112] Iteration 410500, lr = 1e-06
I0823 04:26:27.423583 13823 solver.cpp:239] Iteration 410600 (9.29388 iter/s, 10.7598s/100 iters), loss = 0.0281373
I0823 04:26:27.423635 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0281363 (* 1 = 0.0281363 loss)
I0823 04:26:27.423643 13823 sgd_solver.cpp:112] Iteration 410600, lr = 1e-06
I0823 04:26:37.572894 13823 solver.cpp:239] Iteration 410700 (9.85292 iter/s, 10.1493s/100 iters), loss = 0.0305123
I0823 04:26:37.572943 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0305113 (* 1 = 0.0305113 loss)
I0823 04:26:37.572952 13823 sgd_solver.cpp:112] Iteration 410700, lr = 1e-06
I0823 04:26:48.023978 13823 solver.cpp:239] Iteration 410800 (9.56841 iter/s, 10.4511s/100 iters), loss = 0.0285524
I0823 04:26:48.024030 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0285514 (* 1 = 0.0285514 loss)
I0823 04:26:48.024039 13823 sgd_solver.cpp:112] Iteration 410800, lr = 1e-06
I0823 04:26:58.540186 13823 solver.cpp:239] Iteration 410900 (9.50916 iter/s, 10.5162s/100 iters), loss = 0.0273359
I0823 04:26:58.540238 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0273349 (* 1 = 0.0273349 loss)
I0823 04:26:58.540248 13823 sgd_solver.cpp:112] Iteration 410900, lr = 1e-06
I0823 04:27:08.887202 13823 solver.cpp:239] Iteration 411000 (9.66465 iter/s, 10.347s/100 iters), loss = 0.0250146
I0823 04:27:08.887253 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0250135 (* 1 = 0.0250135 loss)
I0823 04:27:08.887262 13823 sgd_solver.cpp:112] Iteration 411000, lr = 1e-06
I0823 04:27:19.434350 13823 solver.cpp:239] Iteration 411100 (9.48126 iter/s, 10.5471s/100 iters), loss = 0.0245556
I0823 04:27:19.434402 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0245545 (* 1 = 0.0245545 loss)
I0823 04:27:19.434412 13823 sgd_solver.cpp:112] Iteration 411100, lr = 1e-06
I0823 04:27:30.013346 13823 solver.cpp:239] Iteration 411200 (9.45272 iter/s, 10.579s/100 iters), loss = 0.0277165
I0823 04:27:30.013398 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0277155 (* 1 = 0.0277155 loss)
I0823 04:27:30.013408 13823 sgd_solver.cpp:112] Iteration 411200, lr = 1e-06
I0823 04:27:40.394119 13823 solver.cpp:239] Iteration 411300 (9.63323 iter/s, 10.3807s/100 iters), loss = 0.0274286
I0823 04:27:40.394176 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0274275 (* 1 = 0.0274275 loss)
I0823 04:27:40.394188 13823 sgd_solver.cpp:112] Iteration 411300, lr = 1e-06
I0823 04:27:51.188138 13823 solver.cpp:239] Iteration 411400 (9.26442 iter/s, 10.794s/100 iters), loss = 0.0270346
I0823 04:27:51.188189 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0270335 (* 1 = 0.0270335 loss)
I0823 04:27:51.188199 13823 sgd_solver.cpp:112] Iteration 411400, lr = 1e-06
I0823 04:28:01.845708 13823 solver.cpp:239] Iteration 411500 (9.38303 iter/s, 10.6575s/100 iters), loss = 0.0273863
I0823 04:28:01.845757 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0273852 (* 1 = 0.0273852 loss)
I0823 04:28:01.845767 13823 sgd_solver.cpp:112] Iteration 411500, lr = 1e-06
I0823 04:28:12.485824 13823 solver.cpp:239] Iteration 411600 (9.39842 iter/s, 10.6401s/100 iters), loss = 0.027113
I0823 04:28:12.485888 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0271119 (* 1 = 0.0271119 loss)
I0823 04:28:12.485900 13823 sgd_solver.cpp:112] Iteration 411600, lr = 1e-06
I0823 04:28:22.931648 13823 solver.cpp:239] Iteration 411700 (9.57324 iter/s, 10.4458s/100 iters), loss = 0.0252483
I0823 04:28:22.931701 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0252472 (* 1 = 0.0252472 loss)
I0823 04:28:22.931710 13823 sgd_solver.cpp:112] Iteration 411700, lr = 1e-06
I0823 04:28:33.512411 13823 solver.cpp:239] Iteration 411800 (9.45114 iter/s, 10.5807s/100 iters), loss = 0.0277397
I0823 04:28:33.512465 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0277387 (* 1 = 0.0277387 loss)
I0823 04:28:33.512475 13823 sgd_solver.cpp:112] Iteration 411800, lr = 1e-06
I0823 04:28:44.087397 13823 solver.cpp:239] Iteration 411900 (9.45631 iter/s, 10.575s/100 iters), loss = 0.0381493
I0823 04:28:44.087463 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0381482 (* 1 = 0.0381482 loss)
I0823 04:28:44.087476 13823 sgd_solver.cpp:112] Iteration 411900, lr = 1e-06
I0823 04:28:54.743122 13823 solver.cpp:239] Iteration 412000 (9.38466 iter/s, 10.6557s/100 iters), loss = 0.0235947
I0823 04:28:54.743173 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0235936 (* 1 = 0.0235936 loss)
I0823 04:28:54.743183 13823 sgd_solver.cpp:112] Iteration 412000, lr = 1e-06
I0823 04:29:05.432343 13823 solver.cpp:239] Iteration 412100 (9.35525 iter/s, 10.6892s/100 iters), loss = 0.0277976
I0823 04:29:05.432394 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0277965 (* 1 = 0.0277965 loss)
I0823 04:29:05.432402 13823 sgd_solver.cpp:112] Iteration 412100, lr = 1e-06
I0823 04:29:16.056156 13823 solver.cpp:239] Iteration 412200 (9.41284 iter/s, 10.6238s/100 iters), loss = 0.0302448
I0823 04:29:16.056206 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0302438 (* 1 = 0.0302438 loss)
I0823 04:29:16.056216 13823 sgd_solver.cpp:112] Iteration 412200, lr = 1e-06
I0823 04:29:26.540729 13823 solver.cpp:239] Iteration 412300 (9.53785 iter/s, 10.4845s/100 iters), loss = 0.0931263
I0823 04:29:26.540783 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0931253 (* 1 = 0.0931253 loss)
I0823 04:29:26.540793 13823 sgd_solver.cpp:112] Iteration 412300, lr = 1e-06
I0823 04:29:37.485018 13823 solver.cpp:239] Iteration 412400 (9.13721 iter/s, 10.9443s/100 iters), loss = 0.0244508
I0823 04:29:37.485078 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0244498 (* 1 = 0.0244498 loss)
I0823 04:29:37.485090 13823 sgd_solver.cpp:112] Iteration 412400, lr = 1e-06
I0823 04:29:48.263964 13823 solver.cpp:239] Iteration 412500 (9.27738 iter/s, 10.7789s/100 iters), loss = 0.0307269
I0823 04:29:48.264024 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0307259 (* 1 = 0.0307259 loss)
I0823 04:29:48.264036 13823 sgd_solver.cpp:112] Iteration 412500, lr = 1e-06
I0823 04:29:59.010334 13823 solver.cpp:239] Iteration 412600 (9.3055 iter/s, 10.7463s/100 iters), loss = 0.028992
I0823 04:29:59.010383 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.028991 (* 1 = 0.028991 loss)
I0823 04:29:59.010392 13823 sgd_solver.cpp:112] Iteration 412600, lr = 1e-06
I0823 04:30:09.808611 13823 solver.cpp:239] Iteration 412700 (9.26076 iter/s, 10.7982s/100 iters), loss = 0.0281384
I0823 04:30:09.808665 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0281374 (* 1 = 0.0281374 loss)
I0823 04:30:09.808674 13823 sgd_solver.cpp:112] Iteration 412700, lr = 1e-06
I0823 04:30:20.736397 13823 solver.cpp:239] Iteration 412800 (9.15101 iter/s, 10.9278s/100 iters), loss = 0.0397337
I0823 04:30:20.736456 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0397326 (* 1 = 0.0397326 loss)
I0823 04:30:20.736467 13823 sgd_solver.cpp:112] Iteration 412800, lr = 1e-06
I0823 04:30:31.227277 13823 solver.cpp:239] Iteration 412900 (9.53212 iter/s, 10.4908s/100 iters), loss = 0.0274131
I0823 04:30:31.227325 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0274121 (* 1 = 0.0274121 loss)
I0823 04:30:31.227335 13823 sgd_solver.cpp:112] Iteration 412900, lr = 1e-06
I0823 04:30:41.970786 13823 solver.cpp:239] Iteration 413000 (9.30797 iter/s, 10.7435s/100 iters), loss = 0.024111
I0823 04:30:41.970842 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.02411 (* 1 = 0.02411 loss)
I0823 04:30:41.970854 13823 sgd_solver.cpp:112] Iteration 413000, lr = 1e-06
I0823 04:30:52.858438 13823 solver.cpp:239] Iteration 413100 (9.18475 iter/s, 10.8876s/100 iters), loss = 0.0252128
I0823 04:30:52.858489 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0252117 (* 1 = 0.0252117 loss)
I0823 04:30:52.858498 13823 sgd_solver.cpp:112] Iteration 413100, lr = 1e-06
I0823 04:31:03.737218 13823 solver.cpp:239] Iteration 413200 (9.19223 iter/s, 10.8787s/100 iters), loss = 0.0263411
I0823 04:31:03.737282 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.02634 (* 1 = 0.02634 loss)
I0823 04:31:03.737294 13823 sgd_solver.cpp:112] Iteration 413200, lr = 1e-06
I0823 04:31:14.640897 13823 solver.cpp:239] Iteration 413300 (9.17125 iter/s, 10.9036s/100 iters), loss = 0.027064
I0823 04:31:14.640947 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0270629 (* 1 = 0.0270629 loss)
I0823 04:31:14.640957 13823 sgd_solver.cpp:112] Iteration 413300, lr = 1e-06
I0823 04:31:25.260108 13823 solver.cpp:239] Iteration 413400 (9.41692 iter/s, 10.6192s/100 iters), loss = 0.0276533
I0823 04:31:25.260162 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0276523 (* 1 = 0.0276523 loss)
I0823 04:31:25.260172 13823 sgd_solver.cpp:112] Iteration 413400, lr = 1e-06
I0823 04:31:36.058878 13823 solver.cpp:239] Iteration 413500 (9.26034 iter/s, 10.7987s/100 iters), loss = 0.0286154
I0823 04:31:36.058933 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0286143 (* 1 = 0.0286143 loss)
I0823 04:31:36.058943 13823 sgd_solver.cpp:112] Iteration 413500, lr = 1e-06
I0823 04:31:46.720146 13823 solver.cpp:239] Iteration 413600 (9.37978 iter/s, 10.6612s/100 iters), loss = 0.0274982
I0823 04:31:46.720201 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0274971 (* 1 = 0.0274971 loss)
I0823 04:31:46.720211 13823 sgd_solver.cpp:112] Iteration 413600, lr = 1e-06
I0823 04:31:57.504108 13823 solver.cpp:239] Iteration 413700 (9.27306 iter/s, 10.7839s/100 iters), loss = 0.0274079
I0823 04:31:57.504160 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0274068 (* 1 = 0.0274068 loss)
I0823 04:31:57.504170 13823 sgd_solver.cpp:112] Iteration 413700, lr = 1e-06
I0823 04:32:08.588069 13823 solver.cpp:239] Iteration 413800 (9.02207 iter/s, 11.0839s/100 iters), loss = 0.0245146
I0823 04:32:08.588120 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0245135 (* 1 = 0.0245135 loss)
I0823 04:32:08.588135 13823 sgd_solver.cpp:112] Iteration 413800, lr = 1e-06
I0823 04:32:19.317452 13823 solver.cpp:239] Iteration 413900 (9.32023 iter/s, 10.7294s/100 iters), loss = 0.0299841
I0823 04:32:19.317514 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.029983 (* 1 = 0.029983 loss)
I0823 04:32:19.317526 13823 sgd_solver.cpp:112] Iteration 413900, lr = 1e-06
I0823 04:32:30.331761 13823 solver.cpp:239] Iteration 414000 (9.07913 iter/s, 11.0143s/100 iters), loss = 0.0271427
I0823 04:32:30.331820 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0271416 (* 1 = 0.0271416 loss)
I0823 04:32:30.331830 13823 sgd_solver.cpp:112] Iteration 414000, lr = 1e-06
I0823 04:32:41.069124 13823 solver.cpp:239] Iteration 414100 (9.3133 iter/s, 10.7373s/100 iters), loss = 0.0249432
I0823 04:32:41.069175 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0249421 (* 1 = 0.0249421 loss)
I0823 04:32:41.069183 13823 sgd_solver.cpp:112] Iteration 414100, lr = 1e-06
I0823 04:32:51.632210 13823 solver.cpp:239] Iteration 414200 (9.46696 iter/s, 10.5631s/100 iters), loss = 0.0285866
I0823 04:32:51.632261 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0285855 (* 1 = 0.0285855 loss)
I0823 04:32:51.632270 13823 sgd_solver.cpp:112] Iteration 414200, lr = 1e-06
I0823 04:33:02.274149 13823 solver.cpp:239] Iteration 414300 (9.39681 iter/s, 10.6419s/100 iters), loss = 0.0241704
I0823 04:33:02.274200 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0241694 (* 1 = 0.0241694 loss)
I0823 04:33:02.274209 13823 sgd_solver.cpp:112] Iteration 414300, lr = 1e-06
I0823 04:33:13.146719 13823 solver.cpp:239] Iteration 414400 (9.19748 iter/s, 10.8725s/100 iters), loss = 0.0256219
I0823 04:33:13.146775 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0256208 (* 1 = 0.0256208 loss)
I0823 04:33:13.146785 13823 sgd_solver.cpp:112] Iteration 414400, lr = 1e-06
I0823 04:33:23.967227 13823 solver.cpp:239] Iteration 414500 (9.24174 iter/s, 10.8205s/100 iters), loss = 0.0441075
I0823 04:33:23.967278 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0441064 (* 1 = 0.0441064 loss)
I0823 04:33:23.967288 13823 sgd_solver.cpp:112] Iteration 414500, lr = 1e-06
I0823 04:33:34.798084 13823 solver.cpp:239] Iteration 414600 (9.23291 iter/s, 10.8308s/100 iters), loss = 0.0243927
I0823 04:33:34.798133 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0243917 (* 1 = 0.0243917 loss)
I0823 04:33:34.798142 13823 sgd_solver.cpp:112] Iteration 414600, lr = 1e-06
I0823 04:33:45.716388 13823 solver.cpp:239] Iteration 414700 (9.15895 iter/s, 10.9183s/100 iters), loss = 0.0274537
I0823 04:33:45.716439 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0274526 (* 1 = 0.0274526 loss)
I0823 04:33:45.716447 13823 sgd_solver.cpp:112] Iteration 414700, lr = 1e-06
I0823 04:33:56.722677 13823 solver.cpp:239] Iteration 414800 (9.08574 iter/s, 11.0063s/100 iters), loss = 0.0252418
I0823 04:33:56.722726 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0252407 (* 1 = 0.0252407 loss)
I0823 04:33:56.722735 13823 sgd_solver.cpp:112] Iteration 414800, lr = 1e-06
I0823 04:34:07.627497 13823 solver.cpp:239] Iteration 414900 (9.17029 iter/s, 10.9048s/100 iters), loss = 0.0347028
I0823 04:34:07.627560 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0347017 (* 1 = 0.0347017 loss)
I0823 04:34:07.627573 13823 sgd_solver.cpp:112] Iteration 414900, lr = 1e-06
I0823 04:34:18.875670 13823 solver.cpp:239] Iteration 415000 (8.89038 iter/s, 11.2481s/100 iters), loss = 0.0247386
I0823 04:34:18.875731 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0247375 (* 1 = 0.0247375 loss)
I0823 04:34:18.875743 13823 sgd_solver.cpp:112] Iteration 415000, lr = 1e-06
I0823 04:34:29.853070 13823 solver.cpp:239] Iteration 415100 (9.10967 iter/s, 10.9773s/100 iters), loss = 0.0312138
I0823 04:34:29.853125 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0312127 (* 1 = 0.0312127 loss)
I0823 04:34:29.853135 13823 sgd_solver.cpp:112] Iteration 415100, lr = 1e-06
I0823 04:34:41.236469 13823 solver.cpp:239] Iteration 415200 (8.78476 iter/s, 11.3833s/100 iters), loss = 0.0298443
I0823 04:34:41.236519 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0298433 (* 1 = 0.0298433 loss)
I0823 04:34:41.236528 13823 sgd_solver.cpp:112] Iteration 415200, lr = 1e-06
I0823 04:34:52.305593 13823 solver.cpp:239] Iteration 415300 (9.03418 iter/s, 11.0691s/100 iters), loss = 0.0386257
I0823 04:34:52.305652 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0386246 (* 1 = 0.0386246 loss)
I0823 04:34:52.305665 13823 sgd_solver.cpp:112] Iteration 415300, lr = 1e-06
I0823 04:35:03.306860 13823 solver.cpp:239] Iteration 415400 (9.08991 iter/s, 11.0012s/100 iters), loss = 0.0240831
I0823 04:35:03.306921 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.024082 (* 1 = 0.024082 loss)
I0823 04:35:03.306931 13823 sgd_solver.cpp:112] Iteration 415400, lr = 1e-06
I0823 04:35:14.165282 13823 solver.cpp:239] Iteration 415500 (9.20949 iter/s, 10.8584s/100 iters), loss = 0.0397337
I0823 04:35:14.165330 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0397326 (* 1 = 0.0397326 loss)
I0823 04:35:14.165340 13823 sgd_solver.cpp:112] Iteration 415500, lr = 1e-06
I0823 04:35:25.377970 13823 solver.cpp:239] Iteration 415600 (8.9185 iter/s, 11.2126s/100 iters), loss = 0.0261977
I0823 04:35:25.378028 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0261967 (* 1 = 0.0261967 loss)
I0823 04:35:25.378039 13823 sgd_solver.cpp:112] Iteration 415600, lr = 1e-06
I0823 04:35:36.597570 13823 solver.cpp:239] Iteration 415700 (8.91302 iter/s, 11.2195s/100 iters), loss = 0.0238869
I0823 04:35:36.597635 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0238859 (* 1 = 0.0238859 loss)
I0823 04:35:36.597648 13823 sgd_solver.cpp:112] Iteration 415700, lr = 1e-06
I0823 04:35:47.942788 13823 solver.cpp:239] Iteration 415800 (8.81433 iter/s, 11.3452s/100 iters), loss = 0.0233807
I0823 04:35:47.942847 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0233796 (* 1 = 0.0233796 loss)
I0823 04:35:47.942859 13823 sgd_solver.cpp:112] Iteration 415800, lr = 1e-06
I0823 04:35:59.350070 13823 solver.cpp:239] Iteration 415900 (8.76637 iter/s, 11.4072s/100 iters), loss = 0.0303148
I0823 04:35:59.350131 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0303137 (* 1 = 0.0303137 loss)
I0823 04:35:59.350143 13823 sgd_solver.cpp:112] Iteration 415900, lr = 1e-06
I0823 04:36:10.709412 13823 solver.cpp:239] Iteration 416000 (8.80337 iter/s, 11.3593s/100 iters), loss = 0.0307619
I0823 04:36:10.709471 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0307609 (* 1 = 0.0307609 loss)
I0823 04:36:10.709482 13823 sgd_solver.cpp:112] Iteration 416000, lr = 1e-06
I0823 04:36:21.833485 13823 solver.cpp:239] Iteration 416100 (8.98956 iter/s, 11.124s/100 iters), loss = 0.0284705
I0823 04:36:21.833542 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0284695 (* 1 = 0.0284695 loss)
I0823 04:36:21.833554 13823 sgd_solver.cpp:112] Iteration 416100, lr = 1e-06
I0823 04:36:32.815915 13823 solver.cpp:239] Iteration 416200 (9.10549 iter/s, 10.9824s/100 iters), loss = 0.0310863
I0823 04:36:32.815966 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0310852 (* 1 = 0.0310852 loss)
I0823 04:36:32.815975 13823 sgd_solver.cpp:112] Iteration 416200, lr = 1e-06
I0823 04:36:44.242883 13823 solver.cpp:239] Iteration 416300 (8.75126 iter/s, 11.4269s/100 iters), loss = 0.0260911
I0823 04:36:44.242939 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.02609 (* 1 = 0.02609 loss)
I0823 04:36:44.242950 13823 sgd_solver.cpp:112] Iteration 416300, lr = 1e-06
I0823 04:36:55.368715 13823 solver.cpp:239] Iteration 416400 (8.98813 iter/s, 11.1258s/100 iters), loss = 0.0344568
I0823 04:36:55.368765 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0344557 (* 1 = 0.0344557 loss)
I0823 04:36:55.368774 13823 sgd_solver.cpp:112] Iteration 416400, lr = 1e-06
I0823 04:37:06.398582 13823 solver.cpp:239] Iteration 416500 (9.06633 iter/s, 11.0298s/100 iters), loss = 0.0228839
I0823 04:37:06.398646 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0228829 (* 1 = 0.0228829 loss)
I0823 04:37:06.398658 13823 sgd_solver.cpp:112] Iteration 416500, lr = 1e-06
I0823 04:37:17.744047 13823 solver.cpp:239] Iteration 416600 (8.81414 iter/s, 11.3454s/100 iters), loss = 0.0287421
I0823 04:37:17.744107 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.028741 (* 1 = 0.028741 loss)
I0823 04:37:17.744117 13823 sgd_solver.cpp:112] Iteration 416600, lr = 1e-06
I0823 04:37:29.091958 13823 solver.cpp:239] Iteration 416700 (8.81223 iter/s, 11.3479s/100 iters), loss = 0.025169
I0823 04:37:29.092015 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0251679 (* 1 = 0.0251679 loss)
I0823 04:37:29.092026 13823 sgd_solver.cpp:112] Iteration 416700, lr = 1e-06
I0823 04:37:40.585094 13823 solver.cpp:239] Iteration 416800 (8.70088 iter/s, 11.4931s/100 iters), loss = 0.0270568
I0823 04:37:40.585151 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0270557 (* 1 = 0.0270557 loss)
I0823 04:37:40.585162 13823 sgd_solver.cpp:112] Iteration 416800, lr = 1e-06
I0823 04:37:51.857587 13823 solver.cpp:239] Iteration 416900 (8.87119 iter/s, 11.2724s/100 iters), loss = 0.023628
I0823 04:37:51.857651 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0236269 (* 1 = 0.0236269 loss)
I0823 04:37:51.857663 13823 sgd_solver.cpp:112] Iteration 416900, lr = 1e-06
I0823 04:38:03.354370 13823 solver.cpp:239] Iteration 417000 (8.69812 iter/s, 11.4967s/100 iters), loss = 0.0254362
I0823 04:38:03.354421 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0254351 (* 1 = 0.0254351 loss)
I0823 04:38:03.354430 13823 sgd_solver.cpp:112] Iteration 417000, lr = 1e-06
I0823 04:38:14.558439 13823 solver.cpp:239] Iteration 417100 (8.92536 iter/s, 11.204s/100 iters), loss = 0.0263756
I0823 04:38:14.558493 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0263745 (* 1 = 0.0263745 loss)
I0823 04:38:14.558503 13823 sgd_solver.cpp:112] Iteration 417100, lr = 1e-06
I0823 04:38:25.681176 13823 solver.cpp:239] Iteration 417200 (8.99063 iter/s, 11.1227s/100 iters), loss = 0.0321664
I0823 04:38:25.681236 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0321653 (* 1 = 0.0321653 loss)
I0823 04:38:25.681246 13823 sgd_solver.cpp:112] Iteration 417200, lr = 1e-06
I0823 04:38:36.898458 13823 solver.cpp:239] Iteration 417300 (8.91486 iter/s, 11.2172s/100 iters), loss = 0.0551417
I0823 04:38:36.898515 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0551406 (* 1 = 0.0551406 loss)
I0823 04:38:36.898526 13823 sgd_solver.cpp:112] Iteration 417300, lr = 1e-06
I0823 04:38:48.262307 13823 solver.cpp:239] Iteration 417400 (8.79987 iter/s, 11.3638s/100 iters), loss = 0.0298726
I0823 04:38:48.262370 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0298715 (* 1 = 0.0298715 loss)
I0823 04:38:48.262382 13823 sgd_solver.cpp:112] Iteration 417400, lr = 1e-06
I0823 04:38:59.640151 13823 solver.cpp:239] Iteration 417500 (8.78905 iter/s, 11.3778s/100 iters), loss = 0.0229668
I0823 04:38:59.640213 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0229656 (* 1 = 0.0229656 loss)
I0823 04:38:59.640224 13823 sgd_solver.cpp:112] Iteration 417500, lr = 1e-06
I0823 04:39:10.874183 13823 solver.cpp:239] Iteration 417600 (8.90156 iter/s, 11.234s/100 iters), loss = 0.0248333
I0823 04:39:10.874248 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0248322 (* 1 = 0.0248322 loss)
I0823 04:39:10.874260 13823 sgd_solver.cpp:112] Iteration 417600, lr = 1e-06
I0823 04:39:22.219022 13823 solver.cpp:239] Iteration 417700 (8.81462 iter/s, 11.3448s/100 iters), loss = 0.0276103
I0823 04:39:22.219081 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0276092 (* 1 = 0.0276092 loss)
I0823 04:39:22.219094 13823 sgd_solver.cpp:112] Iteration 417700, lr = 1e-06
I0823 04:39:33.586498 13823 solver.cpp:239] Iteration 417800 (8.79706 iter/s, 11.3674s/100 iters), loss = 0.0304466
I0823 04:39:33.586560 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0304455 (* 1 = 0.0304455 loss)
I0823 04:39:33.586572 13823 sgd_solver.cpp:112] Iteration 417800, lr = 1e-06
I0823 04:39:44.948951 13823 solver.cpp:239] Iteration 417900 (8.80095 iter/s, 11.3624s/100 iters), loss = 0.0888602
I0823 04:39:44.949004 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0888591 (* 1 = 0.0888591 loss)
I0823 04:39:44.949013 13823 sgd_solver.cpp:112] Iteration 417900, lr = 1e-06
I0823 04:39:56.296118 13823 solver.cpp:239] Iteration 418000 (8.8128 iter/s, 11.3471s/100 iters), loss = 0.0235422
I0823 04:39:56.296180 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0235411 (* 1 = 0.0235411 loss)
I0823 04:39:56.296191 13823 sgd_solver.cpp:112] Iteration 418000, lr = 1e-06
I0823 04:40:07.989959 13823 solver.cpp:239] Iteration 418100 (8.55155 iter/s, 11.6938s/100 iters), loss = 0.0244862
I0823 04:40:07.990016 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0244851 (* 1 = 0.0244851 loss)
I0823 04:40:07.990027 13823 sgd_solver.cpp:112] Iteration 418100, lr = 1e-06
I0823 04:40:19.561084 13823 solver.cpp:239] Iteration 418200 (8.64223 iter/s, 11.5711s/100 iters), loss = 0.042023
I0823 04:40:19.561137 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0420218 (* 1 = 0.0420218 loss)
I0823 04:40:19.561147 13823 sgd_solver.cpp:112] Iteration 418200, lr = 1e-06
I0823 04:40:31.147395 13823 solver.cpp:239] Iteration 418300 (8.63091 iter/s, 11.5863s/100 iters), loss = 0.0353109
I0823 04:40:31.147460 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0353097 (* 1 = 0.0353097 loss)
I0823 04:40:31.147475 13823 sgd_solver.cpp:112] Iteration 418300, lr = 1e-06
I0823 04:40:42.324487 13823 solver.cpp:239] Iteration 418400 (8.94691 iter/s, 11.177s/100 iters), loss = 0.0287592
I0823 04:40:42.324539 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0287581 (* 1 = 0.0287581 loss)
I0823 04:40:42.324549 13823 sgd_solver.cpp:112] Iteration 418400, lr = 1e-06
I0823 04:40:53.526789 13823 solver.cpp:239] Iteration 418500 (8.92677 iter/s, 11.2023s/100 iters), loss = 0.0272916
I0823 04:40:53.526840 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0272905 (* 1 = 0.0272905 loss)
I0823 04:40:53.526849 13823 sgd_solver.cpp:112] Iteration 418500, lr = 1e-06
I0823 04:41:04.632100 13823 solver.cpp:239] Iteration 418600 (9.00473 iter/s, 11.1053s/100 iters), loss = 0.0250358
I0823 04:41:04.632172 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0250347 (* 1 = 0.0250347 loss)
I0823 04:41:04.632189 13823 sgd_solver.cpp:112] Iteration 418600, lr = 1e-06
I0823 04:41:16.279963 13823 solver.cpp:239] Iteration 418700 (8.5853 iter/s, 11.6478s/100 iters), loss = 0.0257323
I0823 04:41:16.280014 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0257312 (* 1 = 0.0257312 loss)
I0823 04:41:16.280023 13823 sgd_solver.cpp:112] Iteration 418700, lr = 1e-06
I0823 04:41:27.775296 13823 solver.cpp:239] Iteration 418800 (8.69921 iter/s, 11.4953s/100 iters), loss = 0.0321183
I0823 04:41:27.775347 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0321172 (* 1 = 0.0321172 loss)
I0823 04:41:27.775357 13823 sgd_solver.cpp:112] Iteration 418800, lr = 1e-06
I0823 04:41:39.370329 13823 solver.cpp:239] Iteration 418900 (8.62441 iter/s, 11.595s/100 iters), loss = 0.027908
I0823 04:41:39.370384 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0279069 (* 1 = 0.0279069 loss)
I0823 04:41:39.370394 13823 sgd_solver.cpp:112] Iteration 418900, lr = 1e-06
I0823 04:41:50.842453 13823 solver.cpp:239] Iteration 419000 (8.71681 iter/s, 11.4721s/100 iters), loss = 0.0337447
I0823 04:41:50.842511 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0337436 (* 1 = 0.0337436 loss)
I0823 04:41:50.842523 13823 sgd_solver.cpp:112] Iteration 419000, lr = 1e-06
I0823 04:42:02.289175 13823 solver.cpp:239] Iteration 419100 (8.73616 iter/s, 11.4467s/100 iters), loss = 0.0284796
I0823 04:42:02.289232 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0284785 (* 1 = 0.0284785 loss)
I0823 04:42:02.289242 13823 sgd_solver.cpp:112] Iteration 419100, lr = 1e-06
I0823 04:42:13.717700 13823 solver.cpp:239] Iteration 419200 (8.75007 iter/s, 11.4285s/100 iters), loss = 0.0320462
I0823 04:42:13.717752 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0320451 (* 1 = 0.0320451 loss)
I0823 04:42:13.717762 13823 sgd_solver.cpp:112] Iteration 419200, lr = 1e-06
I0823 04:42:25.209370 13823 solver.cpp:239] Iteration 419300 (8.70198 iter/s, 11.4916s/100 iters), loss = 0.0274069
I0823 04:42:25.209430 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0274058 (* 1 = 0.0274058 loss)
I0823 04:42:25.209444 13823 sgd_solver.cpp:112] Iteration 419300, lr = 1e-06
I0823 04:42:36.342803 13823 solver.cpp:239] Iteration 419400 (8.98199 iter/s, 11.1334s/100 iters), loss = 0.0242788
I0823 04:42:36.342850 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0242777 (* 1 = 0.0242777 loss)
I0823 04:42:36.342859 13823 sgd_solver.cpp:112] Iteration 419400, lr = 1e-06
I0823 04:42:47.243033 13823 solver.cpp:239] Iteration 419500 (9.17415 iter/s, 10.9002s/100 iters), loss = 0.0272614
I0823 04:42:47.243085 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0272603 (* 1 = 0.0272603 loss)
I0823 04:42:47.243094 13823 sgd_solver.cpp:112] Iteration 419500, lr = 1e-06
I0823 04:42:58.694624 13823 solver.cpp:239] Iteration 419600 (8.73244 iter/s, 11.4516s/100 iters), loss = 0.0243938
I0823 04:42:58.694674 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0243927 (* 1 = 0.0243927 loss)
I0823 04:42:58.694684 13823 sgd_solver.cpp:112] Iteration 419600, lr = 1e-06
I0823 04:43:09.883280 13823 solver.cpp:239] Iteration 419700 (8.93765 iter/s, 11.1886s/100 iters), loss = 0.0358057
I0823 04:43:09.883337 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0358046 (* 1 = 0.0358046 loss)
I0823 04:43:09.883347 13823 sgd_solver.cpp:112] Iteration 419700, lr = 1e-06
I0823 04:43:21.567006 13823 solver.cpp:239] Iteration 419800 (8.55894 iter/s, 11.6837s/100 iters), loss = 0.0253428
I0823 04:43:21.567059 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0253417 (* 1 = 0.0253417 loss)
I0823 04:43:21.567070 13823 sgd_solver.cpp:112] Iteration 419800, lr = 1e-06
I0823 04:43:33.159945 13823 solver.cpp:239] Iteration 419900 (8.62597 iter/s, 11.5929s/100 iters), loss = 0.0419498
I0823 04:43:33.160003 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0419487 (* 1 = 0.0419487 loss)
I0823 04:43:33.160017 13823 sgd_solver.cpp:112] Iteration 419900, lr = 1e-06
I0823 04:43:44.550750 13823 solver.cpp:464] Snapshotting to binary proto file ./model_112/cascade_mobilenet_112_iter_420000.caffemodel
I0823 04:43:44.593962 13823 sgd_solver.cpp:284] Snapshotting solver state to binary proto file ./model_112/cascade_mobilenet_112_iter_420000.solverstate
I0823 04:43:44.625041 13823 solver.cpp:347] Iteration 420000, Testing net (#0)
I0823 04:44:45.375149 13823 solver.cpp:414]     Test net output #0: landmark_loss = 0.0218666 (* 1 = 0.0218666 loss)
I0823 04:44:45.460418 13823 solver.cpp:239] Iteration 420000 (1.38311 iter/s, 72.3006s/100 iters), loss = 0.0252056
I0823 04:44:45.460448 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0252045 (* 1 = 0.0252045 loss)
I0823 04:44:45.460458 13823 sgd_solver.cpp:112] Iteration 420000, lr = 1e-06
I0823 04:44:54.929659 13823 solver.cpp:239] Iteration 420100 (10.5605 iter/s, 9.46923s/100 iters), loss = 0.0253819
I0823 04:44:54.929702 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0253808 (* 1 = 0.0253808 loss)
I0823 04:44:54.929709 13823 sgd_solver.cpp:112] Iteration 420100, lr = 1e-06
I0823 04:45:04.526126 13823 solver.cpp:239] Iteration 420200 (10.4205 iter/s, 9.59645s/100 iters), loss = 0.022681
I0823 04:45:04.526168 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0226798 (* 1 = 0.0226798 loss)
I0823 04:45:04.526175 13823 sgd_solver.cpp:112] Iteration 420200, lr = 1e-06
I0823 04:45:14.135910 13823 solver.cpp:239] Iteration 420300 (10.4061 iter/s, 9.60976s/100 iters), loss = 0.0254288
I0823 04:45:14.135955 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0254277 (* 1 = 0.0254277 loss)
I0823 04:45:14.135965 13823 sgd_solver.cpp:112] Iteration 420300, lr = 1e-06
I0823 04:45:23.649180 13823 solver.cpp:239] Iteration 420400 (10.5117 iter/s, 9.51325s/100 iters), loss = 0.0267734
I0823 04:45:23.649224 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0267723 (* 1 = 0.0267723 loss)
I0823 04:45:23.649232 13823 sgd_solver.cpp:112] Iteration 420400, lr = 1e-06
I0823 04:45:33.719686 13823 solver.cpp:239] Iteration 420500 (9.93001 iter/s, 10.0705s/100 iters), loss = 0.0244649
I0823 04:45:33.719729 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0244637 (* 1 = 0.0244637 loss)
I0823 04:45:33.719738 13823 sgd_solver.cpp:112] Iteration 420500, lr = 1e-06
I0823 04:45:43.589656 13823 solver.cpp:239] Iteration 420600 (10.1318 iter/s, 9.86995s/100 iters), loss = 0.0272126
I0823 04:45:43.589715 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0272115 (* 1 = 0.0272115 loss)
I0823 04:45:43.589727 13823 sgd_solver.cpp:112] Iteration 420600, lr = 1e-06
I0823 04:45:53.501713 13823 solver.cpp:239] Iteration 420700 (10.0888 iter/s, 9.91202s/100 iters), loss = 0.0312108
I0823 04:45:53.501768 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0312097 (* 1 = 0.0312097 loss)
I0823 04:45:53.501781 13823 sgd_solver.cpp:112] Iteration 420700, lr = 1e-06
I0823 04:46:03.458834 13823 solver.cpp:239] Iteration 420800 (10.0431 iter/s, 9.95709s/100 iters), loss = 0.022162
I0823 04:46:03.458892 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0221609 (* 1 = 0.0221609 loss)
I0823 04:46:03.458905 13823 sgd_solver.cpp:112] Iteration 420800, lr = 1e-06
I0823 04:46:13.246419 13823 solver.cpp:239] Iteration 420900 (10.2171 iter/s, 9.78755s/100 iters), loss = 0.0259819
I0823 04:46:13.246476 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0259808 (* 1 = 0.0259808 loss)
I0823 04:46:13.246490 13823 sgd_solver.cpp:112] Iteration 420900, lr = 1e-06
I0823 04:46:22.893424 13823 solver.cpp:239] Iteration 421000 (10.366 iter/s, 9.64697s/100 iters), loss = 0.0267264
I0823 04:46:22.893481 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0267253 (* 1 = 0.0267253 loss)
I0823 04:46:22.893493 13823 sgd_solver.cpp:112] Iteration 421000, lr = 1e-06
I0823 04:46:32.517838 13823 solver.cpp:239] Iteration 421100 (10.3903 iter/s, 9.62437s/100 iters), loss = 0.0261025
I0823 04:46:32.517910 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0261014 (* 1 = 0.0261014 loss)
I0823 04:46:32.517925 13823 sgd_solver.cpp:112] Iteration 421100, lr = 1e-06
I0823 04:46:42.389842 13823 solver.cpp:239] Iteration 421200 (10.1297 iter/s, 9.87195s/100 iters), loss = 0.0249823
I0823 04:46:42.389899 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0249811 (* 1 = 0.0249811 loss)
I0823 04:46:42.389912 13823 sgd_solver.cpp:112] Iteration 421200, lr = 1e-06
I0823 04:46:52.127761 13823 solver.cpp:239] Iteration 421300 (10.2692 iter/s, 9.73788s/100 iters), loss = 0.0277683
I0823 04:46:52.127825 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0277671 (* 1 = 0.0277671 loss)
I0823 04:46:52.127840 13823 sgd_solver.cpp:112] Iteration 421300, lr = 1e-06
I0823 04:47:01.799856 13823 solver.cpp:239] Iteration 421400 (10.3391 iter/s, 9.67205s/100 iters), loss = 0.0358405
I0823 04:47:01.799912 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0358393 (* 1 = 0.0358393 loss)
I0823 04:47:01.799926 13823 sgd_solver.cpp:112] Iteration 421400, lr = 1e-06
I0823 04:47:11.648680 13823 solver.cpp:239] Iteration 421500 (10.1535 iter/s, 9.84879s/100 iters), loss = 0.0281705
I0823 04:47:11.648732 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0281693 (* 1 = 0.0281693 loss)
I0823 04:47:11.648741 13823 sgd_solver.cpp:112] Iteration 421500, lr = 1e-06
I0823 04:47:21.440209 13823 solver.cpp:239] Iteration 421600 (10.2129 iter/s, 9.79149s/100 iters), loss = 0.0261927
I0823 04:47:21.440263 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0261915 (* 1 = 0.0261915 loss)
I0823 04:47:21.440271 13823 sgd_solver.cpp:112] Iteration 421600, lr = 1e-06
I0823 04:47:31.273494 13823 solver.cpp:239] Iteration 421700 (10.1696 iter/s, 9.83325s/100 iters), loss = 0.028451
I0823 04:47:31.273545 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0284498 (* 1 = 0.0284498 loss)
I0823 04:47:31.273555 13823 sgd_solver.cpp:112] Iteration 421700, lr = 1e-06
I0823 04:47:41.196827 13823 solver.cpp:239] Iteration 421800 (10.0773 iter/s, 9.9233s/100 iters), loss = 0.0262281
I0823 04:47:41.196879 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.026227 (* 1 = 0.026227 loss)
I0823 04:47:41.196888 13823 sgd_solver.cpp:112] Iteration 421800, lr = 1e-06
I0823 04:47:51.029743 13823 solver.cpp:239] Iteration 421900 (10.17 iter/s, 9.83288s/100 iters), loss = 0.0245303
I0823 04:47:51.029811 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0245292 (* 1 = 0.0245292 loss)
I0823 04:47:51.029826 13823 sgd_solver.cpp:112] Iteration 421900, lr = 1e-06
I0823 04:48:01.071251 13823 solver.cpp:239] Iteration 422000 (9.95871 iter/s, 10.0415s/100 iters), loss = 0.0286711
I0823 04:48:01.071305 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.02867 (* 1 = 0.02867 loss)
I0823 04:48:01.071313 13823 sgd_solver.cpp:112] Iteration 422000, lr = 1e-06
I0823 04:48:10.539103 13823 solver.cpp:239] Iteration 422100 (10.5621 iter/s, 9.46782s/100 iters), loss = 0.0282384
I0823 04:48:10.539145 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0282373 (* 1 = 0.0282373 loss)
I0823 04:48:10.539153 13823 sgd_solver.cpp:112] Iteration 422100, lr = 1e-06
I0823 04:48:20.366130 13823 solver.cpp:239] Iteration 422200 (10.176 iter/s, 9.827s/100 iters), loss = 0.0265942
I0823 04:48:20.366171 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.026593 (* 1 = 0.026593 loss)
I0823 04:48:20.366179 13823 sgd_solver.cpp:112] Iteration 422200, lr = 1e-06
I0823 04:48:30.014210 13823 solver.cpp:239] Iteration 422300 (10.3648 iter/s, 9.64806s/100 iters), loss = 0.025411
I0823 04:48:30.014253 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0254098 (* 1 = 0.0254098 loss)
I0823 04:48:30.014261 13823 sgd_solver.cpp:112] Iteration 422300, lr = 1e-06
I0823 04:48:39.876179 13823 solver.cpp:239] Iteration 422400 (10.14 iter/s, 9.86195s/100 iters), loss = 0.032494
I0823 04:48:39.876221 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0324928 (* 1 = 0.0324928 loss)
I0823 04:48:39.876230 13823 sgd_solver.cpp:112] Iteration 422400, lr = 1e-06
I0823 04:48:49.510288 13823 solver.cpp:239] Iteration 422500 (10.3798 iter/s, 9.63408s/100 iters), loss = 0.0239869
I0823 04:48:49.510344 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0239857 (* 1 = 0.0239857 loss)
I0823 04:48:49.510356 13823 sgd_solver.cpp:112] Iteration 422500, lr = 1e-06
I0823 04:48:59.205219 13823 solver.cpp:239] Iteration 422600 (10.3147 iter/s, 9.69489s/100 iters), loss = 0.0304666
I0823 04:48:59.205274 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0304654 (* 1 = 0.0304654 loss)
I0823 04:48:59.205286 13823 sgd_solver.cpp:112] Iteration 422600, lr = 1e-06
I0823 04:49:09.358717 13823 solver.cpp:239] Iteration 422700 (9.84886 iter/s, 10.1535s/100 iters), loss = 0.0271572
I0823 04:49:09.358788 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.027156 (* 1 = 0.027156 loss)
I0823 04:49:09.358804 13823 sgd_solver.cpp:112] Iteration 422700, lr = 1e-06
I0823 04:49:19.312144 13823 solver.cpp:239] Iteration 422800 (10.0468 iter/s, 9.95337s/100 iters), loss = 0.0288782
I0823 04:49:19.312199 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.028877 (* 1 = 0.028877 loss)
I0823 04:49:19.312212 13823 sgd_solver.cpp:112] Iteration 422800, lr = 1e-06
I0823 04:49:28.826534 13823 solver.cpp:239] Iteration 422900 (10.5104 iter/s, 9.51435s/100 iters), loss = 0.0254609
I0823 04:49:28.826586 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0254598 (* 1 = 0.0254598 loss)
I0823 04:49:28.826594 13823 sgd_solver.cpp:112] Iteration 422900, lr = 1e-06
I0823 04:49:38.616370 13823 solver.cpp:239] Iteration 423000 (10.2147 iter/s, 9.7898s/100 iters), loss = 0.0395768
I0823 04:49:38.616430 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0395756 (* 1 = 0.0395756 loss)
I0823 04:49:38.616443 13823 sgd_solver.cpp:112] Iteration 423000, lr = 1e-06
I0823 04:49:48.418247 13823 solver.cpp:239] Iteration 423100 (10.2022 iter/s, 9.80184s/100 iters), loss = 0.0289529
I0823 04:49:48.418298 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0289517 (* 1 = 0.0289517 loss)
I0823 04:49:48.418308 13823 sgd_solver.cpp:112] Iteration 423100, lr = 1e-06
I0823 04:49:58.547797 13823 solver.cpp:239] Iteration 423200 (9.87214 iter/s, 10.1295s/100 iters), loss = 0.0255488
I0823 04:49:58.547855 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0255476 (* 1 = 0.0255476 loss)
I0823 04:49:58.547868 13823 sgd_solver.cpp:112] Iteration 423200, lr = 1e-06
I0823 04:50:08.262048 13823 solver.cpp:239] Iteration 423300 (10.2942 iter/s, 9.71421s/100 iters), loss = 0.0356569
I0823 04:50:08.262111 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0356558 (* 1 = 0.0356558 loss)
I0823 04:50:08.262123 13823 sgd_solver.cpp:112] Iteration 423300, lr = 1e-06
I0823 04:50:18.397186 13823 solver.cpp:239] Iteration 423400 (9.86671 iter/s, 10.1351s/100 iters), loss = 0.0316297
I0823 04:50:18.397248 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0316285 (* 1 = 0.0316285 loss)
I0823 04:50:18.397259 13823 sgd_solver.cpp:112] Iteration 423400, lr = 1e-06
I0823 04:50:28.543576 13823 solver.cpp:239] Iteration 423500 (9.85576 iter/s, 10.1463s/100 iters), loss = 0.0278605
I0823 04:50:28.543628 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0278594 (* 1 = 0.0278594 loss)
I0823 04:50:28.543638 13823 sgd_solver.cpp:112] Iteration 423500, lr = 1e-06
I0823 04:50:38.657465 13823 solver.cpp:239] Iteration 423600 (9.88743 iter/s, 10.1139s/100 iters), loss = 0.0222314
I0823 04:50:38.657516 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0222302 (* 1 = 0.0222302 loss)
I0823 04:50:38.657526 13823 sgd_solver.cpp:112] Iteration 423600, lr = 1e-06
I0823 04:50:48.732936 13823 solver.cpp:239] Iteration 423700 (9.92513 iter/s, 10.0754s/100 iters), loss = 0.0247034
I0823 04:50:48.732987 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0247022 (* 1 = 0.0247022 loss)
I0823 04:50:48.732996 13823 sgd_solver.cpp:112] Iteration 423700, lr = 1e-06
I0823 04:50:58.544226 13823 solver.cpp:239] Iteration 423800 (10.1924 iter/s, 9.81126s/100 iters), loss = 0.033501
I0823 04:50:58.544278 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0334998 (* 1 = 0.0334998 loss)
I0823 04:50:58.544291 13823 sgd_solver.cpp:112] Iteration 423800, lr = 1e-06
I0823 04:51:08.331135 13823 solver.cpp:239] Iteration 423900 (10.2178 iter/s, 9.78687s/100 iters), loss = 0.0255319
I0823 04:51:08.331198 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0255307 (* 1 = 0.0255307 loss)
I0823 04:51:08.331210 13823 sgd_solver.cpp:112] Iteration 423900, lr = 1e-06
I0823 04:51:18.716310 13823 solver.cpp:239] Iteration 424000 (9.62915 iter/s, 10.3851s/100 iters), loss = 0.0288336
I0823 04:51:18.716369 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0288325 (* 1 = 0.0288325 loss)
I0823 04:51:18.716382 13823 sgd_solver.cpp:112] Iteration 424000, lr = 1e-06
I0823 04:51:29.007153 13823 solver.cpp:239] Iteration 424100 (9.71741 iter/s, 10.2908s/100 iters), loss = 0.0261093
I0823 04:51:29.007203 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0261081 (* 1 = 0.0261081 loss)
I0823 04:51:29.007213 13823 sgd_solver.cpp:112] Iteration 424100, lr = 1e-06
I0823 04:51:39.253104 13823 solver.cpp:239] Iteration 424200 (9.75998 iter/s, 10.2459s/100 iters), loss = 0.0364491
I0823 04:51:39.253165 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0364479 (* 1 = 0.0364479 loss)
I0823 04:51:39.253176 13823 sgd_solver.cpp:112] Iteration 424200, lr = 1e-06
I0823 04:51:49.646116 13823 solver.cpp:239] Iteration 424300 (9.62189 iter/s, 10.393s/100 iters), loss = 0.027275
I0823 04:51:49.646180 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0272738 (* 1 = 0.0272738 loss)
I0823 04:51:49.646191 13823 sgd_solver.cpp:112] Iteration 424300, lr = 1e-06
I0823 04:51:59.582819 13823 solver.cpp:239] Iteration 424400 (10.0637 iter/s, 9.93666s/100 iters), loss = 0.0253469
I0823 04:51:59.582870 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0253458 (* 1 = 0.0253458 loss)
I0823 04:51:59.582880 13823 sgd_solver.cpp:112] Iteration 424400, lr = 1e-06
I0823 04:52:09.753355 13823 solver.cpp:239] Iteration 424500 (9.83236 iter/s, 10.1705s/100 iters), loss = 0.0241347
I0823 04:52:09.753417 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0241336 (* 1 = 0.0241336 loss)
I0823 04:52:09.753427 13823 sgd_solver.cpp:112] Iteration 424500, lr = 1e-06
I0823 04:52:19.923084 13823 solver.cpp:239] Iteration 424600 (9.83314 iter/s, 10.1697s/100 iters), loss = 0.0243486
I0823 04:52:19.923135 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0243474 (* 1 = 0.0243474 loss)
I0823 04:52:19.923146 13823 sgd_solver.cpp:112] Iteration 424600, lr = 1e-06
I0823 04:52:30.188944 13823 solver.cpp:239] Iteration 424700 (9.74106 iter/s, 10.2658s/100 iters), loss = 0.0245443
I0823 04:52:30.188994 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0245431 (* 1 = 0.0245431 loss)
I0823 04:52:30.189004 13823 sgd_solver.cpp:112] Iteration 424700, lr = 1e-06
I0823 04:52:40.396097 13823 solver.cpp:239] Iteration 424800 (9.79708 iter/s, 10.2071s/100 iters), loss = 0.0305873
I0823 04:52:40.396155 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0305861 (* 1 = 0.0305861 loss)
I0823 04:52:40.396165 13823 sgd_solver.cpp:112] Iteration 424800, lr = 1e-06
I0823 04:52:50.573828 13823 solver.cpp:239] Iteration 424900 (9.82541 iter/s, 10.1777s/100 iters), loss = 0.0266631
I0823 04:52:50.573894 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0266619 (* 1 = 0.0266619 loss)
I0823 04:52:50.573906 13823 sgd_solver.cpp:112] Iteration 424900, lr = 1e-06
I0823 04:53:01.213515 13823 solver.cpp:239] Iteration 425000 (9.39881 iter/s, 10.6396s/100 iters), loss = 0.0246197
I0823 04:53:01.213587 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0246185 (* 1 = 0.0246185 loss)
I0823 04:53:01.213603 13823 sgd_solver.cpp:112] Iteration 425000, lr = 1e-06
I0823 04:53:11.277683 13823 solver.cpp:239] Iteration 425100 (9.93629 iter/s, 10.0641s/100 iters), loss = 0.0323451
I0823 04:53:11.277757 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0323439 (* 1 = 0.0323439 loss)
I0823 04:53:11.277776 13823 sgd_solver.cpp:112] Iteration 425100, lr = 1e-06
I0823 04:53:21.353225 13823 solver.cpp:239] Iteration 425200 (9.92507 iter/s, 10.0755s/100 iters), loss = 0.0245829
I0823 04:53:21.353281 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0245818 (* 1 = 0.0245818 loss)
I0823 04:53:21.353294 13823 sgd_solver.cpp:112] Iteration 425200, lr = 1e-06
I0823 04:53:31.412387 13823 solver.cpp:239] Iteration 425300 (9.94122 iter/s, 10.0591s/100 iters), loss = 0.0324787
I0823 04:53:31.412442 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0324775 (* 1 = 0.0324775 loss)
I0823 04:53:31.412453 13823 sgd_solver.cpp:112] Iteration 425300, lr = 1e-06
I0823 04:53:41.418776 13823 solver.cpp:239] Iteration 425400 (9.99365 iter/s, 10.0064s/100 iters), loss = 0.0266109
I0823 04:53:41.418833 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0266097 (* 1 = 0.0266097 loss)
I0823 04:53:41.418846 13823 sgd_solver.cpp:112] Iteration 425400, lr = 1e-06
I0823 04:53:51.729382 13823 solver.cpp:239] Iteration 425500 (9.69879 iter/s, 10.3106s/100 iters), loss = 0.0361707
I0823 04:53:51.729432 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0361695 (* 1 = 0.0361695 loss)
I0823 04:53:51.729442 13823 sgd_solver.cpp:112] Iteration 425500, lr = 1e-06
I0823 04:54:01.933604 13823 solver.cpp:239] Iteration 425600 (9.7999 iter/s, 10.2042s/100 iters), loss = 0.0259739
I0823 04:54:01.933671 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0259727 (* 1 = 0.0259727 loss)
I0823 04:54:01.933688 13823 sgd_solver.cpp:112] Iteration 425600, lr = 1e-06
I0823 04:54:12.212267 13823 solver.cpp:239] Iteration 425700 (9.72893 iter/s, 10.2786s/100 iters), loss = 0.0257414
I0823 04:54:12.212327 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0257402 (* 1 = 0.0257402 loss)
I0823 04:54:12.212340 13823 sgd_solver.cpp:112] Iteration 425700, lr = 1e-06
I0823 04:54:22.157409 13823 solver.cpp:239] Iteration 425800 (10.0552 iter/s, 9.9451s/100 iters), loss = 0.0267624
I0823 04:54:22.157465 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0267612 (* 1 = 0.0267612 loss)
I0823 04:54:22.157479 13823 sgd_solver.cpp:112] Iteration 425800, lr = 1e-06
I0823 04:54:31.967721 13823 solver.cpp:239] Iteration 425900 (10.1934 iter/s, 9.81028s/100 iters), loss = 0.0267302
I0823 04:54:31.967777 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.026729 (* 1 = 0.026729 loss)
I0823 04:54:31.967788 13823 sgd_solver.cpp:112] Iteration 425900, lr = 1e-06
I0823 04:54:41.952214 13823 solver.cpp:239] Iteration 426000 (10.0156 iter/s, 9.98446s/100 iters), loss = 0.0270327
I0823 04:54:41.952265 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0270315 (* 1 = 0.0270315 loss)
I0823 04:54:41.952273 13823 sgd_solver.cpp:112] Iteration 426000, lr = 1e-06
I0823 04:54:52.051893 13823 solver.cpp:239] Iteration 426100 (9.90134 iter/s, 10.0996s/100 iters), loss = 0.026971
I0823 04:54:52.051944 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0269698 (* 1 = 0.0269698 loss)
I0823 04:54:52.051952 13823 sgd_solver.cpp:112] Iteration 426100, lr = 1e-06
I0823 04:55:01.994071 13823 solver.cpp:239] Iteration 426200 (10.0582 iter/s, 9.94215s/100 iters), loss = 0.0395067
I0823 04:55:01.994124 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0395055 (* 1 = 0.0395055 loss)
I0823 04:55:01.994132 13823 sgd_solver.cpp:112] Iteration 426200, lr = 1e-06
I0823 04:55:11.903357 13823 solver.cpp:239] Iteration 426300 (10.0916 iter/s, 9.90925s/100 iters), loss = 0.0233843
I0823 04:55:11.903407 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0233831 (* 1 = 0.0233831 loss)
I0823 04:55:11.903416 13823 sgd_solver.cpp:112] Iteration 426300, lr = 1e-06
I0823 04:55:22.202951 13823 solver.cpp:239] Iteration 426400 (9.70915 iter/s, 10.2996s/100 iters), loss = 0.0298132
I0823 04:55:22.203004 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.029812 (* 1 = 0.029812 loss)
I0823 04:55:22.203014 13823 sgd_solver.cpp:112] Iteration 426400, lr = 1e-06
I0823 04:55:32.220042 13823 solver.cpp:239] Iteration 426500 (9.98297 iter/s, 10.0171s/100 iters), loss = 0.026217
I0823 04:55:32.220106 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0262158 (* 1 = 0.0262158 loss)
I0823 04:55:32.220119 13823 sgd_solver.cpp:112] Iteration 426500, lr = 1e-06
I0823 04:55:42.894955 13823 solver.cpp:239] Iteration 426600 (9.36779 iter/s, 10.6749s/100 iters), loss = 0.0248144
I0823 04:55:42.895012 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0248132 (* 1 = 0.0248132 loss)
I0823 04:55:42.895023 13823 sgd_solver.cpp:112] Iteration 426600, lr = 1e-06
I0823 04:55:53.175535 13823 solver.cpp:239] Iteration 426700 (9.72711 iter/s, 10.2805s/100 iters), loss = 0.0278248
I0823 04:55:53.175593 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0278236 (* 1 = 0.0278236 loss)
I0823 04:55:53.175604 13823 sgd_solver.cpp:112] Iteration 426700, lr = 1e-06
I0823 04:56:03.501840 13823 solver.cpp:239] Iteration 426800 (9.68404 iter/s, 10.3263s/100 iters), loss = 0.0273365
I0823 04:56:03.501893 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0273353 (* 1 = 0.0273353 loss)
I0823 04:56:03.501904 13823 sgd_solver.cpp:112] Iteration 426800, lr = 1e-06
I0823 04:56:14.045681 13823 solver.cpp:239] Iteration 426900 (9.48424 iter/s, 10.5438s/100 iters), loss = 0.0276828
I0823 04:56:14.045739 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0276816 (* 1 = 0.0276816 loss)
I0823 04:56:14.045753 13823 sgd_solver.cpp:112] Iteration 426900, lr = 1e-06
I0823 04:56:24.554960 13823 solver.cpp:239] Iteration 427000 (9.51543 iter/s, 10.5092s/100 iters), loss = 0.0304637
I0823 04:56:24.555016 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0304625 (* 1 = 0.0304625 loss)
I0823 04:56:24.555028 13823 sgd_solver.cpp:112] Iteration 427000, lr = 1e-06
I0823 04:56:34.860656 13823 solver.cpp:239] Iteration 427100 (9.7034 iter/s, 10.3057s/100 iters), loss = 0.0265804
I0823 04:56:34.860718 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0265792 (* 1 = 0.0265792 loss)
I0823 04:56:34.860728 13823 sgd_solver.cpp:112] Iteration 427100, lr = 1e-06
I0823 04:56:45.291025 13823 solver.cpp:239] Iteration 427200 (9.58743 iter/s, 10.4303s/100 iters), loss = 0.0329088
I0823 04:56:45.291076 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0329076 (* 1 = 0.0329076 loss)
I0823 04:56:45.291087 13823 sgd_solver.cpp:112] Iteration 427200, lr = 1e-06
I0823 04:56:55.560650 13823 solver.cpp:239] Iteration 427300 (9.73749 iter/s, 10.2696s/100 iters), loss = 0.0234788
I0823 04:56:55.560710 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0234776 (* 1 = 0.0234776 loss)
I0823 04:56:55.560722 13823 sgd_solver.cpp:112] Iteration 427300, lr = 1e-06
I0823 04:57:05.922677 13823 solver.cpp:239] Iteration 427400 (9.65066 iter/s, 10.362s/100 iters), loss = 0.0255429
I0823 04:57:05.922737 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0255417 (* 1 = 0.0255417 loss)
I0823 04:57:05.922751 13823 sgd_solver.cpp:112] Iteration 427400, lr = 1e-06
I0823 04:57:16.329306 13823 solver.cpp:239] Iteration 427500 (9.6093 iter/s, 10.4066s/100 iters), loss = 0.0266689
I0823 04:57:16.329371 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0266677 (* 1 = 0.0266677 loss)
I0823 04:57:16.329387 13823 sgd_solver.cpp:112] Iteration 427500, lr = 1e-06
I0823 04:57:26.419948 13823 solver.cpp:239] Iteration 427600 (9.91021 iter/s, 10.0906s/100 iters), loss = 0.0251855
I0823 04:57:26.420009 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0251843 (* 1 = 0.0251843 loss)
I0823 04:57:26.420022 13823 sgd_solver.cpp:112] Iteration 427600, lr = 1e-06
I0823 04:57:36.795140 13823 solver.cpp:239] Iteration 427700 (9.63841 iter/s, 10.3752s/100 iters), loss = 0.0266421
I0823 04:57:36.795195 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0266409 (* 1 = 0.0266409 loss)
I0823 04:57:36.795205 13823 sgd_solver.cpp:112] Iteration 427700, lr = 1e-06
I0823 04:57:47.028976 13823 solver.cpp:239] Iteration 427800 (9.77154 iter/s, 10.2338s/100 iters), loss = 0.0376409
I0823 04:57:47.029027 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0376397 (* 1 = 0.0376397 loss)
I0823 04:57:47.029037 13823 sgd_solver.cpp:112] Iteration 427800, lr = 1e-06
I0823 04:57:57.742416 13823 solver.cpp:239] Iteration 427900 (9.3341 iter/s, 10.7134s/100 iters), loss = 0.0235088
I0823 04:57:57.742473 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0235076 (* 1 = 0.0235076 loss)
I0823 04:57:57.742483 13823 sgd_solver.cpp:112] Iteration 427900, lr = 1e-06
I0823 04:58:08.145635 13823 solver.cpp:239] Iteration 428000 (9.61244 iter/s, 10.4032s/100 iters), loss = 0.0278202
I0823 04:58:08.145687 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.027819 (* 1 = 0.027819 loss)
I0823 04:58:08.145697 13823 sgd_solver.cpp:112] Iteration 428000, lr = 1e-06
I0823 04:58:18.613656 13823 solver.cpp:239] Iteration 428100 (9.55293 iter/s, 10.468s/100 iters), loss = 0.0244077
I0823 04:58:18.613706 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0244065 (* 1 = 0.0244065 loss)
I0823 04:58:18.613716 13823 sgd_solver.cpp:112] Iteration 428100, lr = 1e-06
I0823 04:58:29.074014 13823 solver.cpp:239] Iteration 428200 (9.55993 iter/s, 10.4603s/100 iters), loss = 0.0260983
I0823 04:58:29.074074 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0260971 (* 1 = 0.0260971 loss)
I0823 04:58:29.074087 13823 sgd_solver.cpp:112] Iteration 428200, lr = 1e-06
I0823 04:58:39.695231 13823 solver.cpp:239] Iteration 428300 (9.41515 iter/s, 10.6212s/100 iters), loss = 0.0272684
I0823 04:58:39.695292 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0272672 (* 1 = 0.0272672 loss)
I0823 04:58:39.695303 13823 sgd_solver.cpp:112] Iteration 428300, lr = 1e-06
I0823 04:58:50.192701 13823 solver.cpp:239] Iteration 428400 (9.52614 iter/s, 10.4974s/100 iters), loss = 0.0240262
I0823 04:58:50.192777 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.024025 (* 1 = 0.024025 loss)
I0823 04:58:50.192795 13823 sgd_solver.cpp:112] Iteration 428400, lr = 1e-06
I0823 04:59:00.685802 13823 solver.cpp:239] Iteration 428500 (9.53011 iter/s, 10.4931s/100 iters), loss = 0.0275712
I0823 04:59:00.685855 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.02757 (* 1 = 0.02757 loss)
I0823 04:59:00.685865 13823 sgd_solver.cpp:112] Iteration 428500, lr = 1e-06
I0823 04:59:10.890488 13823 solver.cpp:239] Iteration 428600 (9.79945 iter/s, 10.2047s/100 iters), loss = 0.0284896
I0823 04:59:10.890537 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0284884 (* 1 = 0.0284884 loss)
I0823 04:59:10.890547 13823 sgd_solver.cpp:112] Iteration 428600, lr = 1e-06
I0823 04:59:21.266131 13823 solver.cpp:239] Iteration 428700 (9.63798 iter/s, 10.3756s/100 iters), loss = 0.0257009
I0823 04:59:21.266183 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0256997 (* 1 = 0.0256997 loss)
I0823 04:59:21.266193 13823 sgd_solver.cpp:112] Iteration 428700, lr = 1e-06
I0823 04:59:31.510071 13823 solver.cpp:239] Iteration 428800 (9.7619 iter/s, 10.2439s/100 iters), loss = 0.0335363
I0823 04:59:31.510112 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0335351 (* 1 = 0.0335351 loss)
I0823 04:59:31.510119 13823 sgd_solver.cpp:112] Iteration 428800, lr = 1e-06
I0823 04:59:42.118870 13823 solver.cpp:239] Iteration 428900 (9.42616 iter/s, 10.6088s/100 iters), loss = 0.028792
I0823 04:59:42.118926 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0287909 (* 1 = 0.0287909 loss)
I0823 04:59:42.118938 13823 sgd_solver.cpp:112] Iteration 428900, lr = 1e-06
I0823 04:59:52.803110 13823 solver.cpp:239] Iteration 429000 (9.35961 iter/s, 10.6842s/100 iters), loss = 0.0233463
I0823 04:59:52.803169 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0233451 (* 1 = 0.0233451 loss)
I0823 04:59:52.803184 13823 sgd_solver.cpp:112] Iteration 429000, lr = 1e-06
I0823 05:00:03.570881 13823 solver.cpp:239] Iteration 429100 (9.287 iter/s, 10.7677s/100 iters), loss = 0.0242957
I0823 05:00:03.570932 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0242945 (* 1 = 0.0242945 loss)
I0823 05:00:03.570941 13823 sgd_solver.cpp:112] Iteration 429100, lr = 1e-06
I0823 05:00:13.989372 13823 solver.cpp:239] Iteration 429200 (9.59835 iter/s, 10.4185s/100 iters), loss = 0.0288909
I0823 05:00:13.989421 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0288897 (* 1 = 0.0288897 loss)
I0823 05:00:13.989430 13823 sgd_solver.cpp:112] Iteration 429200, lr = 1e-06
I0823 05:00:24.462080 13823 solver.cpp:239] Iteration 429300 (9.54865 iter/s, 10.4727s/100 iters), loss = 0.0270323
I0823 05:00:24.462131 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0270312 (* 1 = 0.0270312 loss)
I0823 05:00:24.462139 13823 sgd_solver.cpp:112] Iteration 429300, lr = 1e-06
I0823 05:00:34.989125 13823 solver.cpp:239] Iteration 429400 (9.49937 iter/s, 10.527s/100 iters), loss = 0.0274422
I0823 05:00:34.989176 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0274411 (* 1 = 0.0274411 loss)
I0823 05:00:34.989184 13823 sgd_solver.cpp:112] Iteration 429400, lr = 1e-06
I0823 05:00:45.415323 13823 solver.cpp:239] Iteration 429500 (9.59125 iter/s, 10.4262s/100 iters), loss = 0.0272191
I0823 05:00:45.415374 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.027218 (* 1 = 0.027218 loss)
I0823 05:00:45.415382 13823 sgd_solver.cpp:112] Iteration 429500, lr = 1e-06
I0823 05:00:56.036715 13823 solver.cpp:239] Iteration 429600 (9.41499 iter/s, 10.6214s/100 iters), loss = 0.02791
I0823 05:00:56.036770 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0279088 (* 1 = 0.0279088 loss)
I0823 05:00:56.036779 13823 sgd_solver.cpp:112] Iteration 429600, lr = 1e-06
I0823 05:01:07.179935 13823 solver.cpp:239] Iteration 429700 (8.97409 iter/s, 11.1432s/100 iters), loss = 0.0283889
I0823 05:01:07.179985 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0283878 (* 1 = 0.0283878 loss)
I0823 05:01:07.179994 13823 sgd_solver.cpp:112] Iteration 429700, lr = 1e-06
I0823 05:01:17.890028 13823 solver.cpp:239] Iteration 429800 (9.33701 iter/s, 10.7101s/100 iters), loss = 0.0276398
I0823 05:01:17.890084 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0276387 (* 1 = 0.0276387 loss)
I0823 05:01:17.890094 13823 sgd_solver.cpp:112] Iteration 429800, lr = 1e-06
I0823 05:01:28.554859 13823 solver.cpp:239] Iteration 429900 (9.37664 iter/s, 10.6648s/100 iters), loss = 0.038036
I0823 05:01:28.554910 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0380348 (* 1 = 0.0380348 loss)
I0823 05:01:28.554920 13823 sgd_solver.cpp:112] Iteration 429900, lr = 1e-06
I0823 05:01:39.301942 13823 solver.cpp:239] Iteration 430000 (9.30488 iter/s, 10.7471s/100 iters), loss = 0.0237382
I0823 05:01:39.301996 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.023737 (* 1 = 0.023737 loss)
I0823 05:01:39.302007 13823 sgd_solver.cpp:112] Iteration 430000, lr = 1e-06
I0823 05:01:50.376876 13823 solver.cpp:239] Iteration 430100 (9.02942 iter/s, 11.0749s/100 iters), loss = 0.0265835
I0823 05:01:50.376932 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0265823 (* 1 = 0.0265823 loss)
I0823 05:01:50.376943 13823 sgd_solver.cpp:112] Iteration 430100, lr = 1e-06
I0823 05:02:01.236891 13823 solver.cpp:239] Iteration 430200 (9.20812 iter/s, 10.86s/100 iters), loss = 0.0287986
I0823 05:02:01.236943 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0287974 (* 1 = 0.0287974 loss)
I0823 05:02:01.236953 13823 sgd_solver.cpp:112] Iteration 430200, lr = 1e-06
I0823 05:02:11.726313 13823 solver.cpp:239] Iteration 430300 (9.53344 iter/s, 10.4894s/100 iters), loss = 0.0279885
I0823 05:02:11.726366 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0279873 (* 1 = 0.0279873 loss)
I0823 05:02:11.726377 13823 sgd_solver.cpp:112] Iteration 430300, lr = 1e-06
I0823 05:02:22.227681 13823 solver.cpp:239] Iteration 430400 (9.5226 iter/s, 10.5013s/100 iters), loss = 0.0305544
I0823 05:02:22.227730 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0305532 (* 1 = 0.0305532 loss)
I0823 05:02:22.227741 13823 sgd_solver.cpp:112] Iteration 430400, lr = 1e-06
I0823 05:02:32.956142 13823 solver.cpp:239] Iteration 430500 (9.32103 iter/s, 10.7284s/100 iters), loss = 0.0251529
I0823 05:02:32.956193 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0251518 (* 1 = 0.0251518 loss)
I0823 05:02:32.956202 13823 sgd_solver.cpp:112] Iteration 430500, lr = 1e-06
I0823 05:02:43.598098 13823 solver.cpp:239] Iteration 430600 (9.39679 iter/s, 10.6419s/100 iters), loss = 0.025219
I0823 05:02:43.598153 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0252178 (* 1 = 0.0252178 loss)
I0823 05:02:43.598163 13823 sgd_solver.cpp:112] Iteration 430600, lr = 1e-06
I0823 05:02:54.166975 13823 solver.cpp:239] Iteration 430700 (9.46177 iter/s, 10.5688s/100 iters), loss = 0.0256831
I0823 05:02:54.167026 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.025682 (* 1 = 0.025682 loss)
I0823 05:02:54.167035 13823 sgd_solver.cpp:112] Iteration 430700, lr = 1e-06
I0823 05:03:04.857268 13823 solver.cpp:239] Iteration 430800 (9.35431 iter/s, 10.6903s/100 iters), loss = 0.0271365
I0823 05:03:04.857326 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0271354 (* 1 = 0.0271354 loss)
I0823 05:03:04.857336 13823 sgd_solver.cpp:112] Iteration 430800, lr = 1e-06
I0823 05:03:15.744154 13823 solver.cpp:239] Iteration 430900 (9.18539 iter/s, 10.8868s/100 iters), loss = 0.0257519
I0823 05:03:15.744217 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0257508 (* 1 = 0.0257508 loss)
I0823 05:03:15.744230 13823 sgd_solver.cpp:112] Iteration 430900, lr = 1e-06
I0823 05:03:26.461027 13823 solver.cpp:239] Iteration 431000 (9.33112 iter/s, 10.7168s/100 iters), loss = 0.0287415
I0823 05:03:26.461082 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0287403 (* 1 = 0.0287403 loss)
I0823 05:03:26.461092 13823 sgd_solver.cpp:112] Iteration 431000, lr = 1e-06
I0823 05:03:37.123699 13823 solver.cpp:239] Iteration 431100 (9.37854 iter/s, 10.6626s/100 iters), loss = 0.0263692
I0823 05:03:37.123752 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.026368 (* 1 = 0.026368 loss)
I0823 05:03:37.123762 13823 sgd_solver.cpp:112] Iteration 431100, lr = 1e-06
I0823 05:03:47.976375 13823 solver.cpp:239] Iteration 431200 (9.21434 iter/s, 10.8526s/100 iters), loss = 0.0240962
I0823 05:03:47.976424 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0240951 (* 1 = 0.0240951 loss)
I0823 05:03:47.976434 13823 sgd_solver.cpp:112] Iteration 431200, lr = 1e-06
I0823 05:03:58.815451 13823 solver.cpp:239] Iteration 431300 (9.2259 iter/s, 10.839s/100 iters), loss = 0.0235819
I0823 05:03:58.815503 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0235807 (* 1 = 0.0235807 loss)
I0823 05:03:58.815513 13823 sgd_solver.cpp:112] Iteration 431300, lr = 1e-06
I0823 05:04:09.637336 13823 solver.cpp:239] Iteration 431400 (9.24056 iter/s, 10.8219s/100 iters), loss = 0.0245567
I0823 05:04:09.637387 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0245555 (* 1 = 0.0245555 loss)
I0823 05:04:09.637398 13823 sgd_solver.cpp:112] Iteration 431400, lr = 1e-06
I0823 05:04:20.529073 13823 solver.cpp:239] Iteration 431500 (9.1813 iter/s, 10.8917s/100 iters), loss = 0.0245955
I0823 05:04:20.529132 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0245943 (* 1 = 0.0245943 loss)
I0823 05:04:20.529143 13823 sgd_solver.cpp:112] Iteration 431500, lr = 1e-06
I0823 05:04:31.646852 13823 solver.cpp:239] Iteration 431600 (8.99463 iter/s, 11.1177s/100 iters), loss = 0.0274057
I0823 05:04:31.646908 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0274045 (* 1 = 0.0274045 loss)
I0823 05:04:31.646919 13823 sgd_solver.cpp:112] Iteration 431600, lr = 1e-06
I0823 05:04:42.068087 13823 solver.cpp:239] Iteration 431700 (9.59582 iter/s, 10.4212s/100 iters), loss = 0.038723
I0823 05:04:42.068140 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0387218 (* 1 = 0.0387218 loss)
I0823 05:04:42.068151 13823 sgd_solver.cpp:112] Iteration 431700, lr = 1e-06
I0823 05:04:52.657516 13823 solver.cpp:239] Iteration 431800 (9.4434 iter/s, 10.5894s/100 iters), loss = 0.0234067
I0823 05:04:52.657567 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0234056 (* 1 = 0.0234056 loss)
I0823 05:04:52.657577 13823 sgd_solver.cpp:112] Iteration 431800, lr = 1e-06
I0823 05:05:03.362299 13823 solver.cpp:239] Iteration 431900 (9.34164 iter/s, 10.7048s/100 iters), loss = 0.0288548
I0823 05:05:03.362351 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0288536 (* 1 = 0.0288536 loss)
I0823 05:05:03.362361 13823 sgd_solver.cpp:112] Iteration 431900, lr = 1e-06
I0823 05:05:13.854981 13823 solver.cpp:239] Iteration 432000 (9.53048 iter/s, 10.4927s/100 iters), loss = 0.0218953
I0823 05:05:13.855031 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0218942 (* 1 = 0.0218942 loss)
I0823 05:05:13.855041 13823 sgd_solver.cpp:112] Iteration 432000, lr = 1e-06
I0823 05:05:24.559048 13823 solver.cpp:239] Iteration 432100 (9.34227 iter/s, 10.704s/100 iters), loss = 0.0312818
I0823 05:05:24.559098 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0312807 (* 1 = 0.0312807 loss)
I0823 05:05:24.559108 13823 sgd_solver.cpp:112] Iteration 432100, lr = 1e-06
I0823 05:05:35.107268 13823 solver.cpp:239] Iteration 432200 (9.4803 iter/s, 10.5482s/100 iters), loss = 0.0245284
I0823 05:05:35.107318 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0245272 (* 1 = 0.0245272 loss)
I0823 05:05:35.107327 13823 sgd_solver.cpp:112] Iteration 432200, lr = 1e-06
I0823 05:05:46.094622 13823 solver.cpp:239] Iteration 432300 (9.10139 iter/s, 10.9873s/100 iters), loss = 0.0286573
I0823 05:05:46.094677 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0286561 (* 1 = 0.0286561 loss)
I0823 05:05:46.094687 13823 sgd_solver.cpp:112] Iteration 432300, lr = 1e-06
I0823 05:05:57.287742 13823 solver.cpp:239] Iteration 432400 (8.93409 iter/s, 11.1931s/100 iters), loss = 0.0233114
I0823 05:05:57.287804 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0233102 (* 1 = 0.0233102 loss)
I0823 05:05:57.287816 13823 sgd_solver.cpp:112] Iteration 432400, lr = 1e-06
I0823 05:06:08.205824 13823 solver.cpp:239] Iteration 432500 (9.15915 iter/s, 10.918s/100 iters), loss = 0.0243958
I0823 05:06:08.205879 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0243947 (* 1 = 0.0243947 loss)
I0823 05:06:08.205890 13823 sgd_solver.cpp:112] Iteration 432500, lr = 1e-06
I0823 05:06:19.047576 13823 solver.cpp:239] Iteration 432600 (9.22365 iter/s, 10.8417s/100 iters), loss = 0.0381977
I0823 05:06:19.047641 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0381965 (* 1 = 0.0381965 loss)
I0823 05:06:19.047652 13823 sgd_solver.cpp:112] Iteration 432600, lr = 1e-06
I0823 05:06:30.194635 13823 solver.cpp:239] Iteration 432700 (8.97101 iter/s, 11.147s/100 iters), loss = 0.0279705
I0823 05:06:30.194684 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0279693 (* 1 = 0.0279693 loss)
I0823 05:06:30.194692 13823 sgd_solver.cpp:112] Iteration 432700, lr = 1e-06
I0823 05:06:41.187904 13823 solver.cpp:239] Iteration 432800 (9.0965 iter/s, 10.9932s/100 iters), loss = 0.0276477
I0823 05:06:41.187968 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0276465 (* 1 = 0.0276465 loss)
I0823 05:06:41.187980 13823 sgd_solver.cpp:112] Iteration 432800, lr = 1e-06
I0823 05:06:52.184641 13823 solver.cpp:239] Iteration 432900 (9.09364 iter/s, 10.9967s/100 iters), loss = 0.0344715
I0823 05:06:52.184692 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0344703 (* 1 = 0.0344703 loss)
I0823 05:06:52.184701 13823 sgd_solver.cpp:112] Iteration 432900, lr = 1e-06
I0823 05:07:03.207783 13823 solver.cpp:239] Iteration 433000 (9.07184 iter/s, 11.0231s/100 iters), loss = 0.0314958
I0823 05:07:03.207834 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0314946 (* 1 = 0.0314946 loss)
I0823 05:07:03.207842 13823 sgd_solver.cpp:112] Iteration 433000, lr = 1e-06
I0823 05:07:14.396863 13823 solver.cpp:239] Iteration 433100 (8.93731 iter/s, 11.1891s/100 iters), loss = 0.0928559
I0823 05:07:14.396914 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0928547 (* 1 = 0.0928547 loss)
I0823 05:07:14.396924 13823 sgd_solver.cpp:112] Iteration 433100, lr = 1e-06
I0823 05:07:25.562070 13823 solver.cpp:239] Iteration 433200 (8.95642 iter/s, 11.1652s/100 iters), loss = 0.0248401
I0823 05:07:25.562132 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0248389 (* 1 = 0.0248389 loss)
I0823 05:07:25.562144 13823 sgd_solver.cpp:112] Iteration 433200, lr = 1e-06
I0823 05:07:36.260877 13823 solver.cpp:239] Iteration 433300 (9.34687 iter/s, 10.6988s/100 iters), loss = 0.0257322
I0823 05:07:36.260928 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.025731 (* 1 = 0.025731 loss)
I0823 05:07:36.260937 13823 sgd_solver.cpp:112] Iteration 433300, lr = 1e-06
I0823 05:07:47.509299 13823 solver.cpp:239] Iteration 433400 (8.89016 iter/s, 11.2484s/100 iters), loss = 0.0355324
I0823 05:07:47.509348 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0355312 (* 1 = 0.0355312 loss)
I0823 05:07:47.509357 13823 sgd_solver.cpp:112] Iteration 433400, lr = 1e-06
I0823 05:07:58.592300 13823 solver.cpp:239] Iteration 433500 (9.02285 iter/s, 11.083s/100 iters), loss = 0.0237348
I0823 05:07:58.592348 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0237336 (* 1 = 0.0237336 loss)
I0823 05:07:58.592356 13823 sgd_solver.cpp:112] Iteration 433500, lr = 1e-06
I0823 05:08:09.561120 13823 solver.cpp:239] Iteration 433600 (9.11679 iter/s, 10.9688s/100 iters), loss = 0.0265613
I0823 05:08:09.561162 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0265601 (* 1 = 0.0265601 loss)
I0823 05:08:09.561170 13823 sgd_solver.cpp:112] Iteration 433600, lr = 1e-06
I0823 05:08:20.613962 13823 solver.cpp:239] Iteration 433700 (9.04754 iter/s, 11.0527s/100 iters), loss = 0.0261171
I0823 05:08:20.614020 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0261159 (* 1 = 0.0261159 loss)
I0823 05:08:20.614032 13823 sgd_solver.cpp:112] Iteration 433700, lr = 1e-06
I0823 05:08:31.904906 13823 solver.cpp:239] Iteration 433800 (8.85675 iter/s, 11.2908s/100 iters), loss = 0.0270536
I0823 05:08:31.904959 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0270524 (* 1 = 0.0270524 loss)
I0823 05:08:31.904968 13823 sgd_solver.cpp:112] Iteration 433800, lr = 1e-06
I0823 05:08:43.064255 13823 solver.cpp:239] Iteration 433900 (8.96119 iter/s, 11.1592s/100 iters), loss = 0.0313664
I0823 05:08:43.064318 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0313652 (* 1 = 0.0313652 loss)
I0823 05:08:43.064330 13823 sgd_solver.cpp:112] Iteration 433900, lr = 1e-06
I0823 05:08:54.451372 13823 solver.cpp:239] Iteration 434000 (8.78195 iter/s, 11.387s/100 iters), loss = 0.0262055
I0823 05:08:54.451436 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0262043 (* 1 = 0.0262043 loss)
I0823 05:08:54.451448 13823 sgd_solver.cpp:112] Iteration 434000, lr = 1e-06
I0823 05:09:05.886220 13823 solver.cpp:239] Iteration 434100 (8.74529 iter/s, 11.4347s/100 iters), loss = 0.0270809
I0823 05:09:05.886277 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0270797 (* 1 = 0.0270797 loss)
I0823 05:09:05.886291 13823 sgd_solver.cpp:112] Iteration 434100, lr = 1e-06
I0823 05:09:17.285354 13823 solver.cpp:239] Iteration 434200 (8.77269 iter/s, 11.399s/100 iters), loss = 0.0261234
I0823 05:09:17.285403 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0261222 (* 1 = 0.0261222 loss)
I0823 05:09:17.285413 13823 sgd_solver.cpp:112] Iteration 434200, lr = 1e-06
I0823 05:09:28.480340 13823 solver.cpp:239] Iteration 434300 (8.93266 iter/s, 11.1949s/100 iters), loss = 0.0283483
I0823 05:09:28.480392 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0283471 (* 1 = 0.0283471 loss)
I0823 05:09:28.480401 13823 sgd_solver.cpp:112] Iteration 434300, lr = 1e-06
I0823 05:09:39.424463 13823 solver.cpp:239] Iteration 434400 (9.13741 iter/s, 10.944s/100 iters), loss = 0.0293887
I0823 05:09:39.424523 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0293875 (* 1 = 0.0293875 loss)
I0823 05:09:39.424538 13823 sgd_solver.cpp:112] Iteration 434400, lr = 1e-06
I0823 05:09:50.685981 13823 solver.cpp:239] Iteration 434500 (8.87989 iter/s, 11.2614s/100 iters), loss = 0.0286728
I0823 05:09:50.686043 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0286715 (* 1 = 0.0286715 loss)
I0823 05:09:50.686058 13823 sgd_solver.cpp:112] Iteration 434500, lr = 1e-06
I0823 05:10:01.694614 13823 solver.cpp:239] Iteration 434600 (9.08387 iter/s, 11.0085s/100 iters), loss = 0.0238783
I0823 05:10:01.694664 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0238771 (* 1 = 0.0238771 loss)
I0823 05:10:01.694674 13823 sgd_solver.cpp:112] Iteration 434600, lr = 1e-06
I0823 05:10:12.922940 13823 solver.cpp:239] Iteration 434700 (8.90613 iter/s, 11.2282s/100 iters), loss = 0.0299614
I0823 05:10:12.923004 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0299602 (* 1 = 0.0299602 loss)
I0823 05:10:12.923019 13823 sgd_solver.cpp:112] Iteration 434700, lr = 1e-06
I0823 05:10:24.180677 13823 solver.cpp:239] Iteration 434800 (8.88286 iter/s, 11.2576s/100 iters), loss = 0.0244795
I0823 05:10:24.180721 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0244783 (* 1 = 0.0244783 loss)
I0823 05:10:24.180728 13823 sgd_solver.cpp:112] Iteration 434800, lr = 1e-06
I0823 05:10:35.243723 13823 solver.cpp:239] Iteration 434900 (9.03918 iter/s, 11.063s/100 iters), loss = 0.0251791
I0823 05:10:35.243773 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0251779 (* 1 = 0.0251779 loss)
I0823 05:10:35.243782 13823 sgd_solver.cpp:112] Iteration 434900, lr = 1e-06
I0823 05:10:46.146508 13823 solver.cpp:239] Iteration 435000 (9.17205 iter/s, 10.9027s/100 iters), loss = 0.0261568
I0823 05:10:46.146558 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0261556 (* 1 = 0.0261556 loss)
I0823 05:10:46.146566 13823 sgd_solver.cpp:112] Iteration 435000, lr = 1e-06
I0823 05:10:57.397722 13823 solver.cpp:239] Iteration 435100 (8.88801 iter/s, 11.2511s/100 iters), loss = 0.0398225
I0823 05:10:57.397773 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0398213 (* 1 = 0.0398213 loss)
I0823 05:10:57.397783 13823 sgd_solver.cpp:112] Iteration 435100, lr = 1e-06
I0823 05:11:08.904111 13823 solver.cpp:239] Iteration 435200 (8.6909 iter/s, 11.5063s/100 iters), loss = 0.0257831
I0823 05:11:08.904175 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0257819 (* 1 = 0.0257819 loss)
I0823 05:11:08.904186 13823 sgd_solver.cpp:112] Iteration 435200, lr = 1e-06
I0823 05:11:20.359972 13823 solver.cpp:239] Iteration 435300 (8.72924 iter/s, 11.4558s/100 iters), loss = 0.0354254
I0823 05:11:20.360021 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0354242 (* 1 = 0.0354242 loss)
I0823 05:11:20.360030 13823 sgd_solver.cpp:112] Iteration 435300, lr = 1e-06
I0823 05:11:31.716027 13823 solver.cpp:239] Iteration 435400 (8.80595 iter/s, 11.356s/100 iters), loss = 0.0327246
I0823 05:11:31.716087 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0327234 (* 1 = 0.0327234 loss)
I0823 05:11:31.716099 13823 sgd_solver.cpp:112] Iteration 435400, lr = 1e-06
I0823 05:11:43.047693 13823 solver.cpp:239] Iteration 435500 (8.82491 iter/s, 11.3316s/100 iters), loss = 0.0234277
I0823 05:11:43.047756 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0234264 (* 1 = 0.0234264 loss)
I0823 05:11:43.047770 13823 sgd_solver.cpp:112] Iteration 435500, lr = 1e-06
I0823 05:11:54.389179 13823 solver.cpp:239] Iteration 435600 (8.81727 iter/s, 11.3414s/100 iters), loss = 0.0288327
I0823 05:11:54.389228 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0288315 (* 1 = 0.0288315 loss)
I0823 05:11:54.389237 13823 sgd_solver.cpp:112] Iteration 435600, lr = 1e-06
I0823 05:12:05.828652 13823 solver.cpp:239] Iteration 435700 (8.74173 iter/s, 11.4394s/100 iters), loss = 0.0288912
I0823 05:12:05.828706 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.02889 (* 1 = 0.02889 loss)
I0823 05:12:05.828714 13823 sgd_solver.cpp:112] Iteration 435700, lr = 1e-06
I0823 05:12:17.030519 13823 solver.cpp:239] Iteration 435800 (8.92716 iter/s, 11.2018s/100 iters), loss = 0.0282189
I0823 05:12:17.030570 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0282177 (* 1 = 0.0282177 loss)
I0823 05:12:17.030578 13823 sgd_solver.cpp:112] Iteration 435800, lr = 1e-06
I0823 05:12:28.245667 13823 solver.cpp:239] Iteration 435900 (8.91658 iter/s, 11.2151s/100 iters), loss = 0.0279538
I0823 05:12:28.245723 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0279526 (* 1 = 0.0279526 loss)
I0823 05:12:28.245734 13823 sgd_solver.cpp:112] Iteration 435900, lr = 1e-06
I0823 05:12:39.428227 13823 solver.cpp:239] Iteration 436000 (8.94257 iter/s, 11.1825s/100 iters), loss = 0.0268706
I0823 05:12:39.428277 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0268694 (* 1 = 0.0268694 loss)
I0823 05:12:39.428287 13823 sgd_solver.cpp:112] Iteration 436000, lr = 1e-06
I0823 05:12:50.571007 13823 solver.cpp:239] Iteration 436100 (8.97449 iter/s, 11.1427s/100 iters), loss = 0.0313855
I0823 05:12:50.571055 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0313842 (* 1 = 0.0313842 loss)
I0823 05:12:50.571064 13823 sgd_solver.cpp:112] Iteration 436100, lr = 1e-06
I0823 05:13:01.710500 13823 solver.cpp:239] Iteration 436200 (8.97714 iter/s, 11.1394s/100 iters), loss = 0.0252541
I0823 05:13:01.710551 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0252529 (* 1 = 0.0252529 loss)
I0823 05:13:01.710561 13823 sgd_solver.cpp:112] Iteration 436200, lr = 1e-06
I0823 05:13:13.013851 13823 solver.cpp:239] Iteration 436300 (8.847 iter/s, 11.3033s/100 iters), loss = 0.0251192
I0823 05:13:13.013906 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.025118 (* 1 = 0.025118 loss)
I0823 05:13:13.013916 13823 sgd_solver.cpp:112] Iteration 436300, lr = 1e-06
I0823 05:13:24.609097 13823 solver.cpp:239] Iteration 436400 (8.62429 iter/s, 11.5952s/100 iters), loss = 0.0257995
I0823 05:13:24.609149 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0257983 (* 1 = 0.0257983 loss)
I0823 05:13:24.609159 13823 sgd_solver.cpp:112] Iteration 436400, lr = 1e-06
I0823 05:13:36.405799 13823 solver.cpp:239] Iteration 436500 (8.47701 iter/s, 11.7966s/100 iters), loss = 0.0270296
I0823 05:13:36.405859 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0270284 (* 1 = 0.0270284 loss)
I0823 05:13:36.405871 13823 sgd_solver.cpp:112] Iteration 436500, lr = 1e-06
I0823 05:13:47.906018 13823 solver.cpp:239] Iteration 436600 (8.69556 iter/s, 11.5001s/100 iters), loss = 0.0275222
I0823 05:13:47.906083 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.027521 (* 1 = 0.027521 loss)
I0823 05:13:47.906096 13823 sgd_solver.cpp:112] Iteration 436600, lr = 1e-06
I0823 05:13:59.524622 13823 solver.cpp:239] Iteration 436700 (8.60696 iter/s, 11.6185s/100 iters), loss = 0.029675
I0823 05:13:59.524682 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0296738 (* 1 = 0.0296738 loss)
I0823 05:13:59.524694 13823 sgd_solver.cpp:112] Iteration 436700, lr = 1e-06
I0823 05:14:10.837272 13823 solver.cpp:239] Iteration 436800 (8.83973 iter/s, 11.3126s/100 iters), loss = 0.0243319
I0823 05:14:10.837325 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0243307 (* 1 = 0.0243307 loss)
I0823 05:14:10.837337 13823 sgd_solver.cpp:112] Iteration 436800, lr = 1e-06
I0823 05:14:22.441387 13823 solver.cpp:239] Iteration 436900 (8.61769 iter/s, 11.604s/100 iters), loss = 0.0283563
I0823 05:14:22.441447 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0283551 (* 1 = 0.0283551 loss)
I0823 05:14:22.441459 13823 sgd_solver.cpp:112] Iteration 436900, lr = 1e-06
I0823 05:14:33.888459 13823 solver.cpp:239] Iteration 437000 (8.73592 iter/s, 11.447s/100 iters), loss = 0.0264856
I0823 05:14:33.888521 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0264844 (* 1 = 0.0264844 loss)
I0823 05:14:33.888535 13823 sgd_solver.cpp:112] Iteration 437000, lr = 1e-06
I0823 05:14:45.559847 13823 solver.cpp:239] Iteration 437100 (8.56802 iter/s, 11.6713s/100 iters), loss = 0.0236402
I0823 05:14:45.559906 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.023639 (* 1 = 0.023639 loss)
I0823 05:14:45.559916 13823 sgd_solver.cpp:112] Iteration 437100, lr = 1e-06
I0823 05:14:57.194700 13823 solver.cpp:239] Iteration 437200 (8.59493 iter/s, 11.6348s/100 iters), loss = 0.0318577
I0823 05:14:57.194751 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0318565 (* 1 = 0.0318565 loss)
I0823 05:14:57.194759 13823 sgd_solver.cpp:112] Iteration 437200, lr = 1e-06
I0823 05:15:08.330379 13823 solver.cpp:239] Iteration 437300 (8.9802 iter/s, 11.1356s/100 iters), loss = 0.0281534
I0823 05:15:08.330431 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0281522 (* 1 = 0.0281522 loss)
I0823 05:15:08.330441 13823 sgd_solver.cpp:112] Iteration 437300, lr = 1e-06
I0823 05:15:19.667165 13823 solver.cpp:239] Iteration 437400 (8.8209 iter/s, 11.3367s/100 iters), loss = 0.0263329
I0823 05:15:19.667223 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0263317 (* 1 = 0.0263317 loss)
I0823 05:15:19.667237 13823 sgd_solver.cpp:112] Iteration 437400, lr = 1e-06
I0823 05:15:31.268646 13823 solver.cpp:239] Iteration 437500 (8.61965 iter/s, 11.6014s/100 iters), loss = 0.0262339
I0823 05:15:31.268707 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0262327 (* 1 = 0.0262327 loss)
I0823 05:15:31.268716 13823 sgd_solver.cpp:112] Iteration 437500, lr = 1e-06
I0823 05:15:42.756279 13823 solver.cpp:239] Iteration 437600 (8.70508 iter/s, 11.4876s/100 iters), loss = 0.0302497
I0823 05:15:42.756340 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0302485 (* 1 = 0.0302485 loss)
I0823 05:15:42.756355 13823 sgd_solver.cpp:112] Iteration 437600, lr = 1e-06
I0823 05:15:54.290328 13823 solver.cpp:239] Iteration 437700 (8.67004 iter/s, 11.534s/100 iters), loss = 0.0232824
I0823 05:15:54.290381 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0232812 (* 1 = 0.0232812 loss)
I0823 05:15:54.290390 13823 sgd_solver.cpp:112] Iteration 437700, lr = 1e-06
I0823 05:16:05.675897 13823 solver.cpp:239] Iteration 437800 (8.7831 iter/s, 11.3855s/100 iters), loss = 0.0257466
I0823 05:16:05.675958 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0257454 (* 1 = 0.0257454 loss)
I0823 05:16:05.675971 13823 sgd_solver.cpp:112] Iteration 437800, lr = 1e-06
I0823 05:16:17.399590 13823 solver.cpp:239] Iteration 437900 (8.52979 iter/s, 11.7236s/100 iters), loss = 0.0261652
I0823 05:16:17.399643 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.026164 (* 1 = 0.026164 loss)
I0823 05:16:17.399653 13823 sgd_solver.cpp:112] Iteration 437900, lr = 1e-06
I0823 05:16:29.179409 13823 solver.cpp:239] Iteration 438000 (8.48915 iter/s, 11.7797s/100 iters), loss = 0.0272429
I0823 05:16:29.179466 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0272417 (* 1 = 0.0272417 loss)
I0823 05:16:29.179478 13823 sgd_solver.cpp:112] Iteration 438000, lr = 1e-06
I0823 05:16:40.511521 13823 solver.cpp:239] Iteration 438100 (8.82453 iter/s, 11.332s/100 iters), loss = 0.0272104
I0823 05:16:40.511564 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0272092 (* 1 = 0.0272092 loss)
I0823 05:16:40.511571 13823 sgd_solver.cpp:112] Iteration 438100, lr = 1e-06
I0823 05:16:51.922894 13823 solver.cpp:239] Iteration 438200 (8.76324 iter/s, 11.4113s/100 iters), loss = 0.0255033
I0823 05:16:51.922950 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.025502 (* 1 = 0.025502 loss)
I0823 05:16:51.922961 13823 sgd_solver.cpp:112] Iteration 438200, lr = 1e-06
I0823 05:17:02.178400 13823 solver.cpp:239] Iteration 438300 (9.75092 iter/s, 10.2554s/100 iters), loss = 0.0266097
I0823 05:17:02.178445 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0266084 (* 1 = 0.0266084 loss)
I0823 05:17:02.178455 13823 sgd_solver.cpp:112] Iteration 438300, lr = 1e-06
I0823 05:17:11.791501 13823 solver.cpp:239] Iteration 438400 (10.4025 iter/s, 9.61304s/100 iters), loss = 0.0282307
I0823 05:17:11.791560 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0282294 (* 1 = 0.0282294 loss)
I0823 05:17:11.791574 13823 sgd_solver.cpp:112] Iteration 438400, lr = 1e-06
I0823 05:17:21.390709 13823 solver.cpp:239] Iteration 438500 (10.4176 iter/s, 9.59914s/100 iters), loss = 0.0245434
I0823 05:17:21.390761 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0245422 (* 1 = 0.0245422 loss)
I0823 05:17:21.390771 13823 sgd_solver.cpp:112] Iteration 438500, lr = 1e-06
I0823 05:17:30.913646 13823 solver.cpp:239] Iteration 438600 (10.501 iter/s, 9.52287s/100 iters), loss = 0.0258148
I0823 05:17:30.913707 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0258135 (* 1 = 0.0258135 loss)
I0823 05:17:30.913718 13823 sgd_solver.cpp:112] Iteration 438600, lr = 1e-06
I0823 05:17:40.714689 13823 solver.cpp:239] Iteration 438700 (10.2031 iter/s, 9.80097s/100 iters), loss = 0.0284426
I0823 05:17:40.714740 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0284413 (* 1 = 0.0284413 loss)
I0823 05:17:40.714748 13823 sgd_solver.cpp:112] Iteration 438700, lr = 1e-06
I0823 05:17:50.084439 13823 solver.cpp:239] Iteration 438800 (10.6727 iter/s, 9.36968s/100 iters), loss = 0.0241171
I0823 05:17:50.084491 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0241159 (* 1 = 0.0241159 loss)
I0823 05:17:50.084501 13823 sgd_solver.cpp:112] Iteration 438800, lr = 1e-06
I0823 05:17:59.946095 13823 solver.cpp:239] Iteration 438900 (10.1403 iter/s, 9.86159s/100 iters), loss = 0.0297444
I0823 05:17:59.946146 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0297431 (* 1 = 0.0297431 loss)
I0823 05:17:59.946156 13823 sgd_solver.cpp:112] Iteration 438900, lr = 1e-06
I0823 05:18:09.563868 13823 solver.cpp:239] Iteration 439000 (10.3975 iter/s, 9.61771s/100 iters), loss = 0.0279057
I0823 05:18:09.563920 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0279045 (* 1 = 0.0279045 loss)
I0823 05:18:09.563930 13823 sgd_solver.cpp:112] Iteration 439000, lr = 1e-06
I0823 05:18:19.053717 13823 solver.cpp:239] Iteration 439100 (10.5376 iter/s, 9.48979s/100 iters), loss = 0.0290257
I0823 05:18:19.053768 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0290245 (* 1 = 0.0290245 loss)
I0823 05:18:19.053777 13823 sgd_solver.cpp:112] Iteration 439100, lr = 1e-06
I0823 05:18:28.850342 13823 solver.cpp:239] Iteration 439200 (10.2077 iter/s, 9.79656s/100 iters), loss = 0.0322997
I0823 05:18:28.850394 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0322985 (* 1 = 0.0322985 loss)
I0823 05:18:28.850404 13823 sgd_solver.cpp:112] Iteration 439200, lr = 1e-06
I0823 05:18:38.546957 13823 solver.cpp:239] Iteration 439300 (10.3129 iter/s, 9.69655s/100 iters), loss = 0.0296052
I0823 05:18:38.547008 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0296039 (* 1 = 0.0296039 loss)
I0823 05:18:38.547017 13823 sgd_solver.cpp:112] Iteration 439300, lr = 1e-06
I0823 05:18:48.232533 13823 solver.cpp:239] Iteration 439400 (10.3247 iter/s, 9.68551s/100 iters), loss = 0.0271159
I0823 05:18:48.232584 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0271146 (* 1 = 0.0271146 loss)
I0823 05:18:48.232594 13823 sgd_solver.cpp:112] Iteration 439400, lr = 1e-06
I0823 05:18:57.890681 13823 solver.cpp:239] Iteration 439500 (10.354 iter/s, 9.65809s/100 iters), loss = 0.0273199
I0823 05:18:57.890731 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0273187 (* 1 = 0.0273187 loss)
I0823 05:18:57.890740 13823 sgd_solver.cpp:112] Iteration 439500, lr = 1e-06
I0823 05:19:07.817394 13823 solver.cpp:239] Iteration 439600 (10.0739 iter/s, 9.92665s/100 iters), loss = 0.0293184
I0823 05:19:07.817446 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0293172 (* 1 = 0.0293172 loss)
I0823 05:19:07.817456 13823 sgd_solver.cpp:112] Iteration 439600, lr = 1e-06
I0823 05:19:17.679368 13823 solver.cpp:239] Iteration 439700 (10.14 iter/s, 9.86191s/100 iters), loss = 0.028338
I0823 05:19:17.679421 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0283368 (* 1 = 0.0283368 loss)
I0823 05:19:17.679430 13823 sgd_solver.cpp:112] Iteration 439700, lr = 1e-06
I0823 05:19:27.320220 13823 solver.cpp:239] Iteration 439800 (10.3726 iter/s, 9.64079s/100 iters), loss = 0.0272925
I0823 05:19:27.320277 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0272913 (* 1 = 0.0272913 loss)
I0823 05:19:27.320288 13823 sgd_solver.cpp:112] Iteration 439800, lr = 1e-06
I0823 05:19:36.730581 13823 solver.cpp:239] Iteration 439900 (10.6267 iter/s, 9.4103s/100 iters), loss = 0.0250063
I0823 05:19:36.730634 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0250051 (* 1 = 0.0250051 loss)
I0823 05:19:36.730644 13823 sgd_solver.cpp:112] Iteration 439900, lr = 1e-06
I0823 05:19:46.486447 13823 solver.cpp:464] Snapshotting to binary proto file ./model_112/cascade_mobilenet_112_iter_440000.caffemodel
I0823 05:19:46.529345 13823 sgd_solver.cpp:284] Snapshotting solver state to binary proto file ./model_112/cascade_mobilenet_112_iter_440000.solverstate
I0823 05:19:46.560107 13823 solver.cpp:347] Iteration 440000, Testing net (#0)
I0823 05:20:47.354518 13823 solver.cpp:414]     Test net output #0: landmark_loss = 0.0220037 (* 1 = 0.0220037 loss)
I0823 05:20:47.447348 13823 solver.cpp:239] Iteration 440000 (1.41409 iter/s, 70.7167s/100 iters), loss = 0.0240215
I0823 05:20:47.447388 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0240203 (* 1 = 0.0240203 loss)
I0823 05:20:47.447401 13823 sgd_solver.cpp:112] Iteration 440000, lr = 1e-06
I0823 05:20:57.331552 13823 solver.cpp:239] Iteration 440100 (10.1172 iter/s, 9.88416s/100 iters), loss = 0.0264692
I0823 05:20:57.331602 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.026468 (* 1 = 0.026468 loss)
I0823 05:20:57.331612 13823 sgd_solver.cpp:112] Iteration 440100, lr = 1e-06
I0823 05:21:07.357831 13823 solver.cpp:239] Iteration 440200 (9.97384 iter/s, 10.0262s/100 iters), loss = 0.0252405
I0823 05:21:07.357890 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0252393 (* 1 = 0.0252393 loss)
I0823 05:21:07.357903 13823 sgd_solver.cpp:112] Iteration 440200, lr = 1e-06
I0823 05:21:17.233948 13823 solver.cpp:239] Iteration 440300 (10.1255 iter/s, 9.87606s/100 iters), loss = 0.0287396
I0823 05:21:17.234006 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0287383 (* 1 = 0.0287383 loss)
I0823 05:21:17.234016 13823 sgd_solver.cpp:112] Iteration 440300, lr = 1e-06
I0823 05:21:27.184559 13823 solver.cpp:239] Iteration 440400 (10.0497 iter/s, 9.95055s/100 iters), loss = 0.0291355
I0823 05:21:27.184619 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0291342 (* 1 = 0.0291342 loss)
I0823 05:21:27.184631 13823 sgd_solver.cpp:112] Iteration 440400, lr = 1e-06
I0823 05:21:37.234699 13823 solver.cpp:239] Iteration 440500 (9.95017 iter/s, 10.0501s/100 iters), loss = 0.0247557
I0823 05:21:37.234763 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0247544 (* 1 = 0.0247544 loss)
I0823 05:21:37.234777 13823 sgd_solver.cpp:112] Iteration 440500, lr = 1e-06
I0823 05:21:47.097877 13823 solver.cpp:239] Iteration 440600 (10.1388 iter/s, 9.86311s/100 iters), loss = 0.0275925
I0823 05:21:47.097956 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0275913 (* 1 = 0.0275913 loss)
I0823 05:21:47.097975 13823 sgd_solver.cpp:112] Iteration 440600, lr = 1e-06
I0823 05:21:57.081681 13823 solver.cpp:239] Iteration 440700 (10.0163 iter/s, 9.98373s/100 iters), loss = 0.0236588
I0823 05:21:57.081732 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0236576 (* 1 = 0.0236576 loss)
I0823 05:21:57.081743 13823 sgd_solver.cpp:112] Iteration 440700, lr = 1e-06
I0823 05:22:07.041785 13823 solver.cpp:239] Iteration 440800 (10.0401 iter/s, 9.96005s/100 iters), loss = 0.0243239
I0823 05:22:07.041834 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0243226 (* 1 = 0.0243226 loss)
I0823 05:22:07.041843 13823 sgd_solver.cpp:112] Iteration 440800, lr = 1e-06
I0823 05:22:16.808315 13823 solver.cpp:239] Iteration 440900 (10.2391 iter/s, 9.76648s/100 iters), loss = 0.0240403
I0823 05:22:16.808367 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0240391 (* 1 = 0.0240391 loss)
I0823 05:22:16.808377 13823 sgd_solver.cpp:112] Iteration 440900, lr = 1e-06
I0823 05:22:26.607375 13823 solver.cpp:239] Iteration 441000 (10.2051 iter/s, 9.79901s/100 iters), loss = 0.0344685
I0823 05:22:26.607426 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0344672 (* 1 = 0.0344672 loss)
I0823 05:22:26.607436 13823 sgd_solver.cpp:112] Iteration 441000, lr = 1e-06
I0823 05:22:36.462697 13823 solver.cpp:239] Iteration 441100 (10.1469 iter/s, 9.85527s/100 iters), loss = 0.028203
I0823 05:22:36.462749 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0282017 (* 1 = 0.0282017 loss)
I0823 05:22:36.462757 13823 sgd_solver.cpp:112] Iteration 441100, lr = 1e-06
I0823 05:22:45.994333 13823 solver.cpp:239] Iteration 441200 (10.4914 iter/s, 9.53159s/100 iters), loss = 0.0287156
I0823 05:22:45.994372 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0287143 (* 1 = 0.0287143 loss)
I0823 05:22:45.994380 13823 sgd_solver.cpp:112] Iteration 441200, lr = 1e-06
I0823 05:22:55.987722 13823 solver.cpp:239] Iteration 441300 (10.0067 iter/s, 9.99334s/100 iters), loss = 0.0227184
I0823 05:22:55.987782 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0227171 (* 1 = 0.0227171 loss)
I0823 05:22:55.987793 13823 sgd_solver.cpp:112] Iteration 441300, lr = 1e-06
I0823 05:23:05.851435 13823 solver.cpp:239] Iteration 441400 (10.1382 iter/s, 9.86365s/100 iters), loss = 0.0334592
I0823 05:23:05.851487 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0334579 (* 1 = 0.0334579 loss)
I0823 05:23:05.851496 13823 sgd_solver.cpp:112] Iteration 441400, lr = 1e-06
I0823 05:23:15.643760 13823 solver.cpp:239] Iteration 441500 (10.2121 iter/s, 9.79227s/100 iters), loss = 0.0276426
I0823 05:23:15.643818 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0276414 (* 1 = 0.0276414 loss)
I0823 05:23:15.643831 13823 sgd_solver.cpp:112] Iteration 441500, lr = 1e-06
I0823 05:23:25.762964 13823 solver.cpp:239] Iteration 441600 (9.88226 iter/s, 10.1191s/100 iters), loss = 0.0246582
I0823 05:23:25.763020 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.024657 (* 1 = 0.024657 loss)
I0823 05:23:25.763032 13823 sgd_solver.cpp:112] Iteration 441600, lr = 1e-06
I0823 05:23:35.644901 13823 solver.cpp:239] Iteration 441700 (10.1195 iter/s, 9.88188s/100 iters), loss = 0.0274072
I0823 05:23:35.644953 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0274059 (* 1 = 0.0274059 loss)
I0823 05:23:35.644963 13823 sgd_solver.cpp:112] Iteration 441700, lr = 1e-06
I0823 05:23:45.602314 13823 solver.cpp:239] Iteration 441800 (10.0428 iter/s, 9.95736s/100 iters), loss = 0.0280662
I0823 05:23:45.602376 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0280649 (* 1 = 0.0280649 loss)
I0823 05:23:45.602388 13823 sgd_solver.cpp:112] Iteration 441800, lr = 1e-06
I0823 05:23:55.798974 13823 solver.cpp:239] Iteration 441900 (9.80719 iter/s, 10.1966s/100 iters), loss = 0.0298216
I0823 05:23:55.799018 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0298203 (* 1 = 0.0298203 loss)
I0823 05:23:55.799026 13823 sgd_solver.cpp:112] Iteration 441900, lr = 1e-06
I0823 05:24:05.721941 13823 solver.cpp:239] Iteration 442000 (10.0777 iter/s, 9.92293s/100 iters), loss = 0.0252078
I0823 05:24:05.721987 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0252065 (* 1 = 0.0252065 loss)
I0823 05:24:05.721994 13823 sgd_solver.cpp:112] Iteration 442000, lr = 1e-06
I0823 05:24:15.334620 13823 solver.cpp:239] Iteration 442100 (10.403 iter/s, 9.61263s/100 iters), loss = 0.022365
I0823 05:24:15.334676 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0223637 (* 1 = 0.0223637 loss)
I0823 05:24:15.334686 13823 sgd_solver.cpp:112] Iteration 442100, lr = 1e-06
I0823 05:24:25.129891 13823 solver.cpp:239] Iteration 442200 (10.2091 iter/s, 9.79522s/100 iters), loss = 0.0219628
I0823 05:24:25.129933 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0219615 (* 1 = 0.0219615 loss)
I0823 05:24:25.129941 13823 sgd_solver.cpp:112] Iteration 442200, lr = 1e-06
I0823 05:24:34.786476 13823 solver.cpp:239] Iteration 442300 (10.3557 iter/s, 9.65655s/100 iters), loss = 0.0249498
I0823 05:24:34.786517 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0249485 (* 1 = 0.0249485 loss)
I0823 05:24:34.786525 13823 sgd_solver.cpp:112] Iteration 442300, lr = 1e-06
I0823 05:24:44.595818 13823 solver.cpp:239] Iteration 442400 (10.1944 iter/s, 9.8093s/100 iters), loss = 0.0252499
I0823 05:24:44.595880 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0252486 (* 1 = 0.0252486 loss)
I0823 05:24:44.595892 13823 sgd_solver.cpp:112] Iteration 442400, lr = 1e-06
I0823 05:24:54.304613 13823 solver.cpp:239] Iteration 442500 (10.3 iter/s, 9.70874s/100 iters), loss = 0.0280246
I0823 05:24:54.304670 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0280233 (* 1 = 0.0280233 loss)
I0823 05:24:54.304682 13823 sgd_solver.cpp:112] Iteration 442500, lr = 1e-06
I0823 05:25:04.253039 13823 solver.cpp:239] Iteration 442600 (10.0519 iter/s, 9.94837s/100 iters), loss = 0.0312567
I0823 05:25:04.253089 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0312554 (* 1 = 0.0312554 loss)
I0823 05:25:04.253099 13823 sgd_solver.cpp:112] Iteration 442600, lr = 1e-06
I0823 05:25:14.206333 13823 solver.cpp:239] Iteration 442700 (10.047 iter/s, 9.95324s/100 iters), loss = 0.0259583
I0823 05:25:14.206390 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.025957 (* 1 = 0.025957 loss)
I0823 05:25:14.206403 13823 sgd_solver.cpp:112] Iteration 442700, lr = 1e-06
I0823 05:25:24.358521 13823 solver.cpp:239] Iteration 442800 (9.85015 iter/s, 10.1521s/100 iters), loss = 0.0234726
I0823 05:25:24.358579 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0234713 (* 1 = 0.0234713 loss)
I0823 05:25:24.358592 13823 sgd_solver.cpp:112] Iteration 442800, lr = 1e-06
I0823 05:25:34.583215 13823 solver.cpp:239] Iteration 442900 (9.7803 iter/s, 10.2246s/100 iters), loss = 0.0257391
I0823 05:25:34.583267 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0257378 (* 1 = 0.0257378 loss)
I0823 05:25:34.583276 13823 sgd_solver.cpp:112] Iteration 442900, lr = 1e-06
I0823 05:25:44.637203 13823 solver.cpp:239] Iteration 443000 (9.94635 iter/s, 10.0539s/100 iters), loss = 0.0290575
I0823 05:25:44.637267 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0290562 (* 1 = 0.0290562 loss)
I0823 05:25:44.637282 13823 sgd_solver.cpp:112] Iteration 443000, lr = 1e-06
I0823 05:25:54.878706 13823 solver.cpp:239] Iteration 443100 (9.76425 iter/s, 10.2414s/100 iters), loss = 0.0274501
I0823 05:25:54.878762 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0274488 (* 1 = 0.0274488 loss)
I0823 05:25:54.878774 13823 sgd_solver.cpp:112] Iteration 443100, lr = 1e-06
I0823 05:26:05.088598 13823 solver.cpp:239] Iteration 443200 (9.79447 iter/s, 10.2098s/100 iters), loss = 0.0280706
I0823 05:26:05.088655 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0280693 (* 1 = 0.0280693 loss)
I0823 05:26:05.088666 13823 sgd_solver.cpp:112] Iteration 443200, lr = 1e-06
I0823 05:26:15.124251 13823 solver.cpp:239] Iteration 443300 (9.96453 iter/s, 10.0356s/100 iters), loss = 0.029975
I0823 05:26:15.124310 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0299737 (* 1 = 0.0299737 loss)
I0823 05:26:15.124322 13823 sgd_solver.cpp:112] Iteration 443300, lr = 1e-06
I0823 05:26:25.236830 13823 solver.cpp:239] Iteration 443400 (9.88873 iter/s, 10.1125s/100 iters), loss = 0.0260464
I0823 05:26:25.236886 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0260451 (* 1 = 0.0260451 loss)
I0823 05:26:25.236899 13823 sgd_solver.cpp:112] Iteration 443400, lr = 1e-06
I0823 05:26:35.391300 13823 solver.cpp:239] Iteration 443500 (9.84793 iter/s, 10.1544s/100 iters), loss = 0.0244716
I0823 05:26:35.391376 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0244703 (* 1 = 0.0244703 loss)
I0823 05:26:35.391392 13823 sgd_solver.cpp:112] Iteration 443500, lr = 1e-06
I0823 05:26:45.508368 13823 solver.cpp:239] Iteration 443600 (9.88435 iter/s, 10.117s/100 iters), loss = 0.0268734
I0823 05:26:45.508420 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0268721 (* 1 = 0.0268721 loss)
I0823 05:26:45.508430 13823 sgd_solver.cpp:112] Iteration 443600, lr = 1e-06
I0823 05:26:55.662741 13823 solver.cpp:239] Iteration 443700 (9.84802 iter/s, 10.1543s/100 iters), loss = 0.0296082
I0823 05:26:55.662792 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0296069 (* 1 = 0.0296069 loss)
I0823 05:26:55.662802 13823 sgd_solver.cpp:112] Iteration 443700, lr = 1e-06
I0823 05:27:05.886229 13823 solver.cpp:239] Iteration 443800 (9.78144 iter/s, 10.2234s/100 iters), loss = 0.0295862
I0823 05:27:05.886286 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0295849 (* 1 = 0.0295849 loss)
I0823 05:27:05.886298 13823 sgd_solver.cpp:112] Iteration 443800, lr = 1e-06
I0823 05:27:16.199508 13823 solver.cpp:239] Iteration 443900 (9.69628 iter/s, 10.3132s/100 iters), loss = 0.0241526
I0823 05:27:16.199560 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0241513 (* 1 = 0.0241513 loss)
I0823 05:27:16.199570 13823 sgd_solver.cpp:112] Iteration 443900, lr = 1e-06
I0823 05:27:26.228921 13823 solver.cpp:239] Iteration 444000 (9.97072 iter/s, 10.0294s/100 iters), loss = 0.0270605
I0823 05:27:26.228978 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0270592 (* 1 = 0.0270592 loss)
I0823 05:27:26.228992 13823 sgd_solver.cpp:112] Iteration 444000, lr = 1e-06
I0823 05:27:36.089746 13823 solver.cpp:239] Iteration 444100 (10.1412 iter/s, 9.86077s/100 iters), loss = 0.0296056
I0823 05:27:36.089797 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0296043 (* 1 = 0.0296043 loss)
I0823 05:27:36.089807 13823 sgd_solver.cpp:112] Iteration 444100, lr = 1e-06
I0823 05:27:46.465907 13823 solver.cpp:239] Iteration 444200 (9.63752 iter/s, 10.3761s/100 iters), loss = 0.0319998
I0823 05:27:46.465977 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0319985 (* 1 = 0.0319985 loss)
I0823 05:27:46.465994 13823 sgd_solver.cpp:112] Iteration 444200, lr = 1e-06
I0823 05:27:56.770891 13823 solver.cpp:239] Iteration 444300 (9.7041 iter/s, 10.3049s/100 iters), loss = 0.0313828
I0823 05:27:56.770944 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0313815 (* 1 = 0.0313815 loss)
I0823 05:27:56.770954 13823 sgd_solver.cpp:112] Iteration 444300, lr = 1e-06
I0823 05:28:06.866618 13823 solver.cpp:239] Iteration 444400 (9.90523 iter/s, 10.0957s/100 iters), loss = 0.0353079
I0823 05:28:06.866669 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0353066 (* 1 = 0.0353066 loss)
I0823 05:28:06.866679 13823 sgd_solver.cpp:112] Iteration 444400, lr = 1e-06
I0823 05:28:17.261457 13823 solver.cpp:239] Iteration 444500 (9.6202 iter/s, 10.3948s/100 iters), loss = 0.0271413
I0823 05:28:17.261514 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.02714 (* 1 = 0.02714 loss)
I0823 05:28:17.261525 13823 sgd_solver.cpp:112] Iteration 444500, lr = 1e-06
I0823 05:28:27.469053 13823 solver.cpp:239] Iteration 444600 (9.79668 iter/s, 10.2075s/100 iters), loss = 0.0254027
I0823 05:28:27.469111 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0254014 (* 1 = 0.0254014 loss)
I0823 05:28:27.469122 13823 sgd_solver.cpp:112] Iteration 444600, lr = 1e-06
I0823 05:28:37.903209 13823 solver.cpp:239] Iteration 444700 (9.58396 iter/s, 10.4341s/100 iters), loss = 0.0379732
I0823 05:28:37.903265 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0379719 (* 1 = 0.0379719 loss)
I0823 05:28:37.903276 13823 sgd_solver.cpp:112] Iteration 444700, lr = 1e-06
I0823 05:28:48.518939 13823 solver.cpp:239] Iteration 444800 (9.42003 iter/s, 10.6157s/100 iters), loss = 0.0260188
I0823 05:28:48.518990 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0260175 (* 1 = 0.0260175 loss)
I0823 05:28:48.518999 13823 sgd_solver.cpp:112] Iteration 444800, lr = 1e-06
I0823 05:28:58.637228 13823 solver.cpp:239] Iteration 444900 (9.88314 iter/s, 10.1182s/100 iters), loss = 0.0250435
I0823 05:28:58.637279 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0250423 (* 1 = 0.0250423 loss)
I0823 05:28:58.637289 13823 sgd_solver.cpp:112] Iteration 444900, lr = 1e-06
I0823 05:29:08.928009 13823 solver.cpp:239] Iteration 445000 (9.71748 iter/s, 10.2907s/100 iters), loss = 0.0298718
I0823 05:29:08.928062 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0298705 (* 1 = 0.0298705 loss)
I0823 05:29:08.928071 13823 sgd_solver.cpp:112] Iteration 445000, lr = 1e-06
I0823 05:29:19.017288 13823 solver.cpp:239] Iteration 445100 (9.91156 iter/s, 10.0892s/100 iters), loss = 0.0278113
I0823 05:29:19.017340 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.02781 (* 1 = 0.02781 loss)
I0823 05:29:19.017349 13823 sgd_solver.cpp:112] Iteration 445100, lr = 1e-06
I0823 05:29:29.259513 13823 solver.cpp:239] Iteration 445200 (9.76355 iter/s, 10.2422s/100 iters), loss = 0.0248526
I0823 05:29:29.259564 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0248513 (* 1 = 0.0248513 loss)
I0823 05:29:29.259573 13823 sgd_solver.cpp:112] Iteration 445200, lr = 1e-06
I0823 05:29:39.218554 13823 solver.cpp:239] Iteration 445300 (10.0412 iter/s, 9.959s/100 iters), loss = 0.0284953
I0823 05:29:39.218603 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.028494 (* 1 = 0.028494 loss)
I0823 05:29:39.218612 13823 sgd_solver.cpp:112] Iteration 445300, lr = 1e-06
I0823 05:29:49.307914 13823 solver.cpp:239] Iteration 445400 (9.91148 iter/s, 10.0893s/100 iters), loss = 0.0233792
I0823 05:29:49.307971 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.023378 (* 1 = 0.023378 loss)
I0823 05:29:49.307982 13823 sgd_solver.cpp:112] Iteration 445400, lr = 1e-06
I0823 05:29:59.559830 13823 solver.cpp:239] Iteration 445500 (9.75432 iter/s, 10.2519s/100 iters), loss = 0.0274557
I0823 05:29:59.559881 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0274544 (* 1 = 0.0274544 loss)
I0823 05:29:59.559891 13823 sgd_solver.cpp:112] Iteration 445500, lr = 1e-06
I0823 05:30:09.912058 13823 solver.cpp:239] Iteration 445600 (9.6598 iter/s, 10.3522s/100 iters), loss = 0.0256941
I0823 05:30:09.912109 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0256928 (* 1 = 0.0256928 loss)
I0823 05:30:09.912118 13823 sgd_solver.cpp:112] Iteration 445600, lr = 1e-06
I0823 05:30:19.947410 13823 solver.cpp:239] Iteration 445700 (9.96482 iter/s, 10.0353s/100 iters), loss = 0.0313304
I0823 05:30:19.947460 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0313291 (* 1 = 0.0313291 loss)
I0823 05:30:19.947469 13823 sgd_solver.cpp:112] Iteration 445700, lr = 1e-06
I0823 05:30:30.321977 13823 solver.cpp:239] Iteration 445800 (9.639 iter/s, 10.3745s/100 iters), loss = 0.0316694
I0823 05:30:30.322033 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0316681 (* 1 = 0.0316681 loss)
I0823 05:30:30.322044 13823 sgd_solver.cpp:112] Iteration 445800, lr = 1e-06
I0823 05:30:40.726753 13823 solver.cpp:239] Iteration 445900 (9.61102 iter/s, 10.4047s/100 iters), loss = 0.0286653
I0823 05:30:40.726804 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.028664 (* 1 = 0.028664 loss)
I0823 05:30:40.726814 13823 sgd_solver.cpp:112] Iteration 445900, lr = 1e-06
I0823 05:30:50.994712 13823 solver.cpp:239] Iteration 446000 (9.73908 iter/s, 10.2679s/100 iters), loss = 0.0250713
I0823 05:30:50.994763 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.02507 (* 1 = 0.02507 loss)
I0823 05:30:50.994772 13823 sgd_solver.cpp:112] Iteration 446000, lr = 1e-06
I0823 05:31:01.294430 13823 solver.cpp:239] Iteration 446100 (9.70905 iter/s, 10.2997s/100 iters), loss = 0.0256599
I0823 05:31:01.294478 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0256586 (* 1 = 0.0256586 loss)
I0823 05:31:01.294488 13823 sgd_solver.cpp:112] Iteration 446100, lr = 1e-06
I0823 05:31:11.554991 13823 solver.cpp:239] Iteration 446200 (9.7461 iter/s, 10.2605s/100 iters), loss = 0.029187
I0823 05:31:11.555042 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0291858 (* 1 = 0.0291858 loss)
I0823 05:31:11.555052 13823 sgd_solver.cpp:112] Iteration 446200, lr = 1e-06
I0823 05:31:21.898244 13823 solver.cpp:239] Iteration 446300 (9.66818 iter/s, 10.3432s/100 iters), loss = 0.0263031
I0823 05:31:21.898303 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0263018 (* 1 = 0.0263018 loss)
I0823 05:31:21.898314 13823 sgd_solver.cpp:112] Iteration 446300, lr = 1e-06
I0823 05:31:32.199026 13823 solver.cpp:239] Iteration 446400 (9.70805 iter/s, 10.3007s/100 iters), loss = 0.031095
I0823 05:31:32.199075 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0310938 (* 1 = 0.0310938 loss)
I0823 05:31:32.199085 13823 sgd_solver.cpp:112] Iteration 446400, lr = 1e-06
I0823 05:31:42.623392 13823 solver.cpp:239] Iteration 446500 (9.59295 iter/s, 10.4243s/100 iters), loss = 0.0370805
I0823 05:31:42.623455 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0370792 (* 1 = 0.0370792 loss)
I0823 05:31:42.623466 13823 sgd_solver.cpp:112] Iteration 446500, lr = 1e-06
I0823 05:31:53.021503 13823 solver.cpp:239] Iteration 446600 (9.61718 iter/s, 10.3981s/100 iters), loss = 0.026749
I0823 05:31:53.021554 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0267478 (* 1 = 0.0267478 loss)
I0823 05:31:53.021564 13823 sgd_solver.cpp:112] Iteration 446600, lr = 1e-06
I0823 05:32:03.735131 13823 solver.cpp:239] Iteration 446700 (9.33395 iter/s, 10.7136s/100 iters), loss = 0.0260735
I0823 05:32:03.735191 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0260723 (* 1 = 0.0260723 loss)
I0823 05:32:03.735203 13823 sgd_solver.cpp:112] Iteration 446700, lr = 1e-06
I0823 05:32:14.169260 13823 solver.cpp:239] Iteration 446800 (9.58398 iter/s, 10.4341s/100 iters), loss = 0.0355495
I0823 05:32:14.169309 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0355482 (* 1 = 0.0355482 loss)
I0823 05:32:14.169319 13823 sgd_solver.cpp:112] Iteration 446800, lr = 1e-06
I0823 05:32:24.625535 13823 solver.cpp:239] Iteration 446900 (9.56367 iter/s, 10.4562s/100 iters), loss = 0.0260548
I0823 05:32:24.625587 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0260535 (* 1 = 0.0260535 loss)
I0823 05:32:24.625597 13823 sgd_solver.cpp:112] Iteration 446900, lr = 1e-06
I0823 05:32:35.138461 13823 solver.cpp:239] Iteration 447000 (9.51214 iter/s, 10.5129s/100 iters), loss = 0.0274788
I0823 05:32:35.138514 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0274776 (* 1 = 0.0274776 loss)
I0823 05:32:35.138523 13823 sgd_solver.cpp:112] Iteration 447000, lr = 1e-06
I0823 05:32:45.675168 13823 solver.cpp:239] Iteration 447100 (9.49067 iter/s, 10.5367s/100 iters), loss = 0.0254199
I0823 05:32:45.675223 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0254186 (* 1 = 0.0254186 loss)
I0823 05:32:45.675233 13823 sgd_solver.cpp:112] Iteration 447100, lr = 1e-06
I0823 05:32:56.666663 13823 solver.cpp:239] Iteration 447200 (9.09798 iter/s, 10.9914s/100 iters), loss = 0.0271793
I0823 05:32:56.666728 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0271781 (* 1 = 0.0271781 loss)
I0823 05:32:56.666741 13823 sgd_solver.cpp:112] Iteration 447200, lr = 1e-06
I0823 05:33:07.348129 13823 solver.cpp:239] Iteration 447300 (9.36206 iter/s, 10.6814s/100 iters), loss = 0.0291292
I0823 05:33:07.348186 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.029128 (* 1 = 0.029128 loss)
I0823 05:33:07.348196 13823 sgd_solver.cpp:112] Iteration 447300, lr = 1e-06
I0823 05:33:18.083019 13823 solver.cpp:239] Iteration 447400 (9.31546 iter/s, 10.7348s/100 iters), loss = 0.0251441
I0823 05:33:18.083076 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0251429 (* 1 = 0.0251429 loss)
I0823 05:33:18.083086 13823 sgd_solver.cpp:112] Iteration 447400, lr = 1e-06
I0823 05:33:28.772985 13823 solver.cpp:239] Iteration 447500 (9.35461 iter/s, 10.6899s/100 iters), loss = 0.0256835
I0823 05:33:28.773044 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0256822 (* 1 = 0.0256822 loss)
I0823 05:33:28.773056 13823 sgd_solver.cpp:112] Iteration 447500, lr = 1e-06
I0823 05:33:39.220645 13823 solver.cpp:239] Iteration 447600 (9.57157 iter/s, 10.4476s/100 iters), loss = 0.0257863
I0823 05:33:39.220706 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0257851 (* 1 = 0.0257851 loss)
I0823 05:33:39.220718 13823 sgd_solver.cpp:112] Iteration 447600, lr = 1e-06
I0823 05:33:49.625367 13823 solver.cpp:239] Iteration 447700 (9.61107 iter/s, 10.4047s/100 iters), loss = 0.0245949
I0823 05:33:49.625423 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0245937 (* 1 = 0.0245937 loss)
I0823 05:33:49.625433 13823 sgd_solver.cpp:112] Iteration 447700, lr = 1e-06
I0823 05:34:00.228529 13823 solver.cpp:239] Iteration 447800 (9.43119 iter/s, 10.6031s/100 iters), loss = 0.0321891
I0823 05:34:00.228580 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0321879 (* 1 = 0.0321879 loss)
I0823 05:34:00.228590 13823 sgd_solver.cpp:112] Iteration 447800, lr = 1e-06
I0823 05:34:11.194720 13823 solver.cpp:239] Iteration 447900 (9.11897 iter/s, 10.9661s/100 iters), loss = 0.0268591
I0823 05:34:11.194775 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0268578 (* 1 = 0.0268578 loss)
I0823 05:34:11.194787 13823 sgd_solver.cpp:112] Iteration 447900, lr = 1e-06
I0823 05:34:22.252602 13823 solver.cpp:239] Iteration 448000 (9.04336 iter/s, 11.0578s/100 iters), loss = 0.0221927
I0823 05:34:22.252667 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0221915 (* 1 = 0.0221915 loss)
I0823 05:34:22.252681 13823 sgd_solver.cpp:112] Iteration 448000, lr = 1e-06
I0823 05:34:32.860110 13823 solver.cpp:239] Iteration 448100 (9.42733 iter/s, 10.6075s/100 iters), loss = 0.0239745
I0823 05:34:32.860175 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0239733 (* 1 = 0.0239733 loss)
I0823 05:34:32.860188 13823 sgd_solver.cpp:112] Iteration 448100, lr = 1e-06
I0823 05:34:43.669800 13823 solver.cpp:239] Iteration 448200 (9.25101 iter/s, 10.8096s/100 iters), loss = 0.026165
I0823 05:34:43.669862 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0261638 (* 1 = 0.0261638 loss)
I0823 05:34:43.669875 13823 sgd_solver.cpp:112] Iteration 448200, lr = 1e-06
I0823 05:34:54.300107 13823 solver.cpp:239] Iteration 448300 (9.40711 iter/s, 10.6303s/100 iters), loss = 0.024994
I0823 05:34:54.300161 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0249928 (* 1 = 0.0249928 loss)
I0823 05:34:54.300171 13823 sgd_solver.cpp:112] Iteration 448300, lr = 1e-06
I0823 05:35:05.155993 13823 solver.cpp:239] Iteration 448400 (9.21163 iter/s, 10.8558s/100 iters), loss = 0.0322573
I0823 05:35:05.156047 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0322561 (* 1 = 0.0322561 loss)
I0823 05:35:05.156057 13823 sgd_solver.cpp:112] Iteration 448400, lr = 1e-06
I0823 05:35:15.762109 13823 solver.cpp:239] Iteration 448500 (9.42856 iter/s, 10.6061s/100 iters), loss = 0.026181
I0823 05:35:15.762159 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0261798 (* 1 = 0.0261798 loss)
I0823 05:35:15.762169 13823 sgd_solver.cpp:112] Iteration 448500, lr = 1e-06
I0823 05:35:26.533582 13823 solver.cpp:239] Iteration 448600 (9.28382 iter/s, 10.7714s/100 iters), loss = 0.0217203
I0823 05:35:26.533644 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0217191 (* 1 = 0.0217191 loss)
I0823 05:35:26.533658 13823 sgd_solver.cpp:112] Iteration 448600, lr = 1e-06
I0823 05:35:37.659150 13823 solver.cpp:239] Iteration 448700 (8.98835 iter/s, 11.1255s/100 iters), loss = 0.0273861
I0823 05:35:37.659199 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0273849 (* 1 = 0.0273849 loss)
I0823 05:35:37.659209 13823 sgd_solver.cpp:112] Iteration 448700, lr = 1e-06
I0823 05:35:48.282693 13823 solver.cpp:239] Iteration 448800 (9.41309 iter/s, 10.6235s/100 iters), loss = 0.0234577
I0823 05:35:48.282749 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0234565 (* 1 = 0.0234565 loss)
I0823 05:35:48.282760 13823 sgd_solver.cpp:112] Iteration 448800, lr = 1e-06
I0823 05:35:58.809507 13823 solver.cpp:239] Iteration 448900 (9.49959 iter/s, 10.5268s/100 iters), loss = 0.0265733
I0823 05:35:58.809558 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0265721 (* 1 = 0.0265721 loss)
I0823 05:35:58.809568 13823 sgd_solver.cpp:112] Iteration 448900, lr = 1e-06
I0823 05:36:09.718314 13823 solver.cpp:239] Iteration 449000 (9.16694 iter/s, 10.9088s/100 iters), loss = 0.0291392
I0823 05:36:09.718365 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.029138 (* 1 = 0.029138 loss)
I0823 05:36:09.718374 13823 sgd_solver.cpp:112] Iteration 449000, lr = 1e-06
I0823 05:36:20.596530 13823 solver.cpp:239] Iteration 449100 (9.19272 iter/s, 10.8782s/100 iters), loss = 0.0241617
I0823 05:36:20.596590 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0241604 (* 1 = 0.0241604 loss)
I0823 05:36:20.596601 13823 sgd_solver.cpp:112] Iteration 449100, lr = 1e-06
I0823 05:36:31.376247 13823 solver.cpp:239] Iteration 449200 (9.27673 iter/s, 10.7797s/100 iters), loss = 0.025112
I0823 05:36:31.376309 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0251107 (* 1 = 0.0251107 loss)
I0823 05:36:31.376320 13823 sgd_solver.cpp:112] Iteration 449200, lr = 1e-06
I0823 05:36:42.362318 13823 solver.cpp:239] Iteration 449300 (9.10248 iter/s, 10.986s/100 iters), loss = 0.0280069
I0823 05:36:42.362370 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0280057 (* 1 = 0.0280057 loss)
I0823 05:36:42.362380 13823 sgd_solver.cpp:112] Iteration 449300, lr = 1e-06
I0823 05:36:53.162353 13823 solver.cpp:239] Iteration 449400 (9.25926 iter/s, 10.8s/100 iters), loss = 0.0269121
I0823 05:36:53.162402 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0269108 (* 1 = 0.0269108 loss)
I0823 05:36:53.162412 13823 sgd_solver.cpp:112] Iteration 449400, lr = 1e-06
I0823 05:37:04.097347 13823 solver.cpp:239] Iteration 449500 (9.14499 iter/s, 10.935s/100 iters), loss = 0.0283953
I0823 05:37:04.097399 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0283941 (* 1 = 0.0283941 loss)
I0823 05:37:04.097409 13823 sgd_solver.cpp:112] Iteration 449500, lr = 1e-06
I0823 05:37:14.914271 13823 solver.cpp:239] Iteration 449600 (9.24481 iter/s, 10.8169s/100 iters), loss = 0.0300768
I0823 05:37:14.914321 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0300756 (* 1 = 0.0300756 loss)
I0823 05:37:14.914331 13823 sgd_solver.cpp:112] Iteration 449600, lr = 1e-06
I0823 05:37:26.090925 13823 solver.cpp:239] Iteration 449700 (8.94726 iter/s, 11.1766s/100 iters), loss = 0.0257378
I0823 05:37:26.090981 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0257366 (* 1 = 0.0257366 loss)
I0823 05:37:26.090991 13823 sgd_solver.cpp:112] Iteration 449700, lr = 1e-06
I0823 05:37:37.030171 13823 solver.cpp:239] Iteration 449800 (9.14144 iter/s, 10.9392s/100 iters), loss = 0.0264127
I0823 05:37:37.030232 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0264115 (* 1 = 0.0264115 loss)
I0823 05:37:37.030244 13823 sgd_solver.cpp:112] Iteration 449800, lr = 1e-06
I0823 05:37:47.948612 13823 solver.cpp:239] Iteration 449900 (9.15886 iter/s, 10.9184s/100 iters), loss = 0.0413676
I0823 05:37:47.948669 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0413664 (* 1 = 0.0413664 loss)
I0823 05:37:47.948680 13823 sgd_solver.cpp:112] Iteration 449900, lr = 1e-06
I0823 05:37:58.757329 13823 solver.cpp:239] Iteration 450000 (9.25183 iter/s, 10.8087s/100 iters), loss = 0.0283129
I0823 05:37:58.757380 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0283117 (* 1 = 0.0283117 loss)
I0823 05:37:58.757390 13823 sgd_solver.cpp:112] Iteration 450000, lr = 1e-06
I0823 05:38:09.735879 13823 solver.cpp:239] Iteration 450100 (9.10871 iter/s, 10.9785s/100 iters), loss = 0.0266275
I0823 05:38:09.735930 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0266263 (* 1 = 0.0266263 loss)
I0823 05:38:09.735939 13823 sgd_solver.cpp:112] Iteration 450100, lr = 1e-06
I0823 05:38:20.877892 13823 solver.cpp:239] Iteration 450200 (8.97507 iter/s, 11.142s/100 iters), loss = 0.026479
I0823 05:38:20.877952 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0264779 (* 1 = 0.0264779 loss)
I0823 05:38:20.877964 13823 sgd_solver.cpp:112] Iteration 450200, lr = 1e-06
I0823 05:38:31.953169 13823 solver.cpp:239] Iteration 450300 (9.02916 iter/s, 11.0752s/100 iters), loss = 0.0264792
I0823 05:38:31.953227 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0264781 (* 1 = 0.0264781 loss)
I0823 05:38:31.953238 13823 sgd_solver.cpp:112] Iteration 450300, lr = 1e-06
I0823 05:38:42.870471 13823 solver.cpp:239] Iteration 450400 (9.15981 iter/s, 10.9173s/100 iters), loss = 0.026502
I0823 05:38:42.870528 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0265008 (* 1 = 0.0265008 loss)
I0823 05:38:42.870539 13823 sgd_solver.cpp:112] Iteration 450400, lr = 1e-06
I0823 05:38:54.023581 13823 solver.cpp:239] Iteration 450500 (8.96615 iter/s, 11.1531s/100 iters), loss = 0.0260222
I0823 05:38:54.023635 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0260211 (* 1 = 0.0260211 loss)
I0823 05:38:54.023645 13823 sgd_solver.cpp:112] Iteration 450500, lr = 1e-06
I0823 05:39:05.070415 13823 solver.cpp:239] Iteration 450600 (9.0524 iter/s, 11.0468s/100 iters), loss = 0.0261484
I0823 05:39:05.070466 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0261473 (* 1 = 0.0261473 loss)
I0823 05:39:05.070475 13823 sgd_solver.cpp:112] Iteration 450600, lr = 1e-06
I0823 05:39:16.220997 13823 solver.cpp:239] Iteration 450700 (8.96817 iter/s, 11.1505s/100 iters), loss = 0.0393166
I0823 05:39:16.221055 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0393155 (* 1 = 0.0393155 loss)
I0823 05:39:16.221065 13823 sgd_solver.cpp:112] Iteration 450700, lr = 1e-06
I0823 05:39:27.149384 13823 solver.cpp:239] Iteration 450800 (9.15052 iter/s, 10.9283s/100 iters), loss = 0.0265868
I0823 05:39:27.149435 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0265857 (* 1 = 0.0265857 loss)
I0823 05:39:27.149443 13823 sgd_solver.cpp:112] Iteration 450800, lr = 1e-06
I0823 05:39:38.235065 13823 solver.cpp:239] Iteration 450900 (9.02068 iter/s, 11.0856s/100 iters), loss = 0.0253843
I0823 05:39:38.235126 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0253832 (* 1 = 0.0253832 loss)
I0823 05:39:38.235137 13823 sgd_solver.cpp:112] Iteration 450900, lr = 1e-06
I0823 05:39:49.077276 13823 solver.cpp:239] Iteration 451000 (9.22325 iter/s, 10.8422s/100 iters), loss = 0.0263821
I0823 05:39:49.077329 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0263809 (* 1 = 0.0263809 loss)
I0823 05:39:49.077339 13823 sgd_solver.cpp:112] Iteration 451000, lr = 1e-06
I0823 05:40:00.288192 13823 solver.cpp:239] Iteration 451100 (8.91991 iter/s, 11.2109s/100 iters), loss = 0.0265475
I0823 05:40:00.288244 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0265463 (* 1 = 0.0265463 loss)
I0823 05:40:00.288254 13823 sgd_solver.cpp:112] Iteration 451100, lr = 1e-06
I0823 05:40:11.379333 13823 solver.cpp:239] Iteration 451200 (9.01624 iter/s, 11.0911s/100 iters), loss = 0.0364292
I0823 05:40:11.379382 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.036428 (* 1 = 0.036428 loss)
I0823 05:40:11.379392 13823 sgd_solver.cpp:112] Iteration 451200, lr = 1e-06
I0823 05:40:21.882433 13823 solver.cpp:239] Iteration 451300 (9.52103 iter/s, 10.5031s/100 iters), loss = 0.0268131
I0823 05:40:21.882473 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.026812 (* 1 = 0.026812 loss)
I0823 05:40:21.882481 13823 sgd_solver.cpp:112] Iteration 451300, lr = 1e-06
I0823 05:40:32.837749 13823 solver.cpp:239] Iteration 451400 (9.12801 iter/s, 10.9553s/100 iters), loss = 0.0355412
I0823 05:40:32.837796 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.03554 (* 1 = 0.03554 loss)
I0823 05:40:32.837805 13823 sgd_solver.cpp:112] Iteration 451400, lr = 1e-06
I0823 05:40:43.697454 13823 solver.cpp:239] Iteration 451500 (9.20838 iter/s, 10.8597s/100 iters), loss = 0.0270788
I0823 05:40:43.697506 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0270776 (* 1 = 0.0270776 loss)
I0823 05:40:43.697515 13823 sgd_solver.cpp:112] Iteration 451500, lr = 1e-06
I0823 05:40:54.776753 13823 solver.cpp:239] Iteration 451600 (9.02588 iter/s, 11.0793s/100 iters), loss = 0.0300435
I0823 05:40:54.776816 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0300424 (* 1 = 0.0300424 loss)
I0823 05:40:54.776829 13823 sgd_solver.cpp:112] Iteration 451600, lr = 1e-06
I0823 05:41:05.762279 13823 solver.cpp:239] Iteration 451700 (9.10293 iter/s, 10.9855s/100 iters), loss = 0.0327638
I0823 05:41:05.762331 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0327626 (* 1 = 0.0327626 loss)
I0823 05:41:05.762341 13823 sgd_solver.cpp:112] Iteration 451700, lr = 1e-06
I0823 05:41:16.730672 13823 solver.cpp:239] Iteration 451800 (9.11714 iter/s, 10.9684s/100 iters), loss = 0.0246048
I0823 05:41:16.730728 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0246036 (* 1 = 0.0246036 loss)
I0823 05:41:16.730739 13823 sgd_solver.cpp:112] Iteration 451800, lr = 1e-06
I0823 05:41:27.802500 13823 solver.cpp:239] Iteration 451900 (9.03197 iter/s, 11.0718s/100 iters), loss = 0.0224659
I0823 05:41:27.802562 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0224647 (* 1 = 0.0224647 loss)
I0823 05:41:27.802574 13823 sgd_solver.cpp:112] Iteration 451900, lr = 1e-06
I0823 05:41:38.915405 13823 solver.cpp:239] Iteration 452000 (8.99859 iter/s, 11.1128s/100 iters), loss = 0.0287145
I0823 05:41:38.915473 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0287133 (* 1 = 0.0287133 loss)
I0823 05:41:38.915484 13823 sgd_solver.cpp:112] Iteration 452000, lr = 1e-06
I0823 05:41:50.053710 13823 solver.cpp:239] Iteration 452100 (8.97807 iter/s, 11.1382s/100 iters), loss = 0.0263361
I0823 05:41:50.053776 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0263349 (* 1 = 0.0263349 loss)
I0823 05:41:50.053791 13823 sgd_solver.cpp:112] Iteration 452100, lr = 1e-06
I0823 05:42:01.321597 13823 solver.cpp:239] Iteration 452200 (8.87482 iter/s, 11.2678s/100 iters), loss = 0.0274665
I0823 05:42:01.321656 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0274653 (* 1 = 0.0274653 loss)
I0823 05:42:01.321669 13823 sgd_solver.cpp:112] Iteration 452200, lr = 1e-06
I0823 05:42:12.709640 13823 solver.cpp:239] Iteration 452300 (8.78117 iter/s, 11.388s/100 iters), loss = 0.024902
I0823 05:42:12.709692 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0249009 (* 1 = 0.0249009 loss)
I0823 05:42:12.709700 13823 sgd_solver.cpp:112] Iteration 452300, lr = 1e-06
I0823 05:42:23.902045 13823 solver.cpp:239] Iteration 452400 (8.93463 iter/s, 11.1924s/100 iters), loss = 0.0281696
I0823 05:42:23.902102 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0281684 (* 1 = 0.0281684 loss)
I0823 05:42:23.902113 13823 sgd_solver.cpp:112] Iteration 452400, lr = 1e-06
I0823 05:42:35.189999 13823 solver.cpp:239] Iteration 452500 (8.85899 iter/s, 11.288s/100 iters), loss = 0.0251812
I0823 05:42:35.190062 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.02518 (* 1 = 0.02518 loss)
I0823 05:42:35.190073 13823 sgd_solver.cpp:112] Iteration 452500, lr = 1e-06
I0823 05:42:46.428565 13823 solver.cpp:239] Iteration 452600 (8.89793 iter/s, 11.2386s/100 iters), loss = 0.0260272
I0823 05:42:46.428622 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0260261 (* 1 = 0.0260261 loss)
I0823 05:42:46.428632 13823 sgd_solver.cpp:112] Iteration 452600, lr = 1e-06
I0823 05:42:57.440304 13823 solver.cpp:239] Iteration 452700 (9.08121 iter/s, 11.0117s/100 iters), loss = 0.0290981
I0823 05:42:57.440366 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0290969 (* 1 = 0.0290969 loss)
I0823 05:42:57.440380 13823 sgd_solver.cpp:112] Iteration 452700, lr = 1e-06
I0823 05:43:08.885767 13823 solver.cpp:239] Iteration 452800 (8.73708 iter/s, 11.4455s/100 iters), loss = 0.0333784
I0823 05:43:08.885826 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0333773 (* 1 = 0.0333773 loss)
I0823 05:43:08.885838 13823 sgd_solver.cpp:112] Iteration 452800, lr = 1e-06
I0823 05:43:20.325500 13823 solver.cpp:239] Iteration 452900 (8.74146 iter/s, 11.4397s/100 iters), loss = 0.0296571
I0823 05:43:20.325567 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.029656 (* 1 = 0.029656 loss)
I0823 05:43:20.325583 13823 sgd_solver.cpp:112] Iteration 452900, lr = 1e-06
I0823 05:43:31.562937 13823 solver.cpp:239] Iteration 453000 (8.89882 iter/s, 11.2374s/100 iters), loss = 0.027081
I0823 05:43:31.562990 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0270799 (* 1 = 0.0270799 loss)
I0823 05:43:31.562999 13823 sgd_solver.cpp:112] Iteration 453000, lr = 1e-06
I0823 05:43:42.413288 13823 solver.cpp:239] Iteration 453100 (9.21628 iter/s, 10.8504s/100 iters), loss = 0.0244901
I0823 05:43:42.413328 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0244889 (* 1 = 0.0244889 loss)
I0823 05:43:42.413336 13823 sgd_solver.cpp:112] Iteration 453100, lr = 1e-06
I0823 05:43:53.373535 13823 solver.cpp:239] Iteration 453200 (9.12387 iter/s, 10.9603s/100 iters), loss = 0.0222901
I0823 05:43:53.373586 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0222889 (* 1 = 0.0222889 loss)
I0823 05:43:53.373596 13823 sgd_solver.cpp:112] Iteration 453200, lr = 1e-06
I0823 05:44:04.258931 13823 solver.cpp:239] Iteration 453300 (9.18661 iter/s, 10.8854s/100 iters), loss = 0.0267556
I0823 05:44:04.258982 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0267545 (* 1 = 0.0267545 loss)
I0823 05:44:04.258992 13823 sgd_solver.cpp:112] Iteration 453300, lr = 1e-06
I0823 05:44:15.302423 13823 solver.cpp:239] Iteration 453400 (9.0551 iter/s, 11.0435s/100 iters), loss = 0.0306072
I0823 05:44:15.302465 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0306061 (* 1 = 0.0306061 loss)
I0823 05:44:15.302474 13823 sgd_solver.cpp:112] Iteration 453400, lr = 1e-06
I0823 05:44:26.373690 13823 solver.cpp:239] Iteration 453500 (9.03237 iter/s, 11.0713s/100 iters), loss = 0.0334221
I0823 05:44:26.373730 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.033421 (* 1 = 0.033421 loss)
I0823 05:44:26.373739 13823 sgd_solver.cpp:112] Iteration 453500, lr = 1e-06
I0823 05:44:38.056079 13823 solver.cpp:239] Iteration 453600 (8.55988 iter/s, 11.6824s/100 iters), loss = 0.0255728
I0823 05:44:38.056138 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0255716 (* 1 = 0.0255716 loss)
I0823 05:44:38.056149 13823 sgd_solver.cpp:112] Iteration 453600, lr = 1e-06
I0823 05:44:49.530592 13823 solver.cpp:239] Iteration 453700 (8.71496 iter/s, 11.4745s/100 iters), loss = 0.0256426
I0823 05:44:49.530649 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0256414 (* 1 = 0.0256414 loss)
I0823 05:44:49.530659 13823 sgd_solver.cpp:112] Iteration 453700, lr = 1e-06
I0823 05:45:00.807574 13823 solver.cpp:239] Iteration 453800 (8.86762 iter/s, 11.277s/100 iters), loss = 0.0297919
I0823 05:45:00.807628 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0297908 (* 1 = 0.0297908 loss)
I0823 05:45:00.807638 13823 sgd_solver.cpp:112] Iteration 453800, lr = 1e-06
I0823 05:45:12.178164 13823 solver.cpp:239] Iteration 453900 (8.79462 iter/s, 11.3706s/100 iters), loss = 0.0390546
I0823 05:45:12.178220 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0390534 (* 1 = 0.0390534 loss)
I0823 05:45:12.178231 13823 sgd_solver.cpp:112] Iteration 453900, lr = 1e-06
I0823 05:45:23.460355 13823 solver.cpp:239] Iteration 454000 (8.86353 iter/s, 11.2822s/100 iters), loss = 0.025636
I0823 05:45:23.460413 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0256348 (* 1 = 0.0256348 loss)
I0823 05:45:23.460424 13823 sgd_solver.cpp:112] Iteration 454000, lr = 1e-06
I0823 05:45:34.801245 13823 solver.cpp:239] Iteration 454100 (8.81765 iter/s, 11.3409s/100 iters), loss = 0.0238678
I0823 05:45:34.801307 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0238666 (* 1 = 0.0238666 loss)
I0823 05:45:34.801321 13823 sgd_solver.cpp:112] Iteration 454100, lr = 1e-06
I0823 05:45:45.981190 13823 solver.cpp:239] Iteration 454200 (8.94459 iter/s, 11.1799s/100 iters), loss = 0.0359222
I0823 05:45:45.981241 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.035921 (* 1 = 0.035921 loss)
I0823 05:45:45.981251 13823 sgd_solver.cpp:112] Iteration 454200, lr = 1e-06
I0823 05:45:57.573184 13823 solver.cpp:239] Iteration 454300 (8.62664 iter/s, 11.592s/100 iters), loss = 0.0236839
I0823 05:45:57.573256 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0236828 (* 1 = 0.0236828 loss)
I0823 05:45:57.573274 13823 sgd_solver.cpp:112] Iteration 454300, lr = 1e-06
I0823 05:46:08.920779 13823 solver.cpp:239] Iteration 454400 (8.81245 iter/s, 11.3476s/100 iters), loss = 0.0244711
I0823 05:46:08.920842 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.02447 (* 1 = 0.02447 loss)
I0823 05:46:08.920856 13823 sgd_solver.cpp:112] Iteration 454400, lr = 1e-06
I0823 05:46:20.604878 13823 solver.cpp:239] Iteration 454500 (8.55864 iter/s, 11.6841s/100 iters), loss = 0.096803
I0823 05:46:20.604930 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0968019 (* 1 = 0.0968019 loss)
I0823 05:46:20.604939 13823 sgd_solver.cpp:112] Iteration 454500, lr = 1e-06
I0823 05:46:32.155331 13823 solver.cpp:239] Iteration 454600 (8.65767 iter/s, 11.5505s/100 iters), loss = 0.0249871
I0823 05:46:32.155381 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.024986 (* 1 = 0.024986 loss)
I0823 05:46:32.155390 13823 sgd_solver.cpp:112] Iteration 454600, lr = 1e-06
I0823 05:46:43.610596 13823 solver.cpp:239] Iteration 454700 (8.72961 iter/s, 11.4553s/100 iters), loss = 0.0260267
I0823 05:46:43.610651 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0260255 (* 1 = 0.0260255 loss)
I0823 05:46:43.610662 13823 sgd_solver.cpp:112] Iteration 454700, lr = 1e-06
I0823 05:46:55.333731 13823 solver.cpp:239] Iteration 454800 (8.53014 iter/s, 11.7231s/100 iters), loss = 0.0278129
I0823 05:46:55.333791 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0278117 (* 1 = 0.0278117 loss)
I0823 05:46:55.333802 13823 sgd_solver.cpp:112] Iteration 454800, lr = 1e-06
I0823 05:47:06.910944 13823 solver.cpp:239] Iteration 454900 (8.63766 iter/s, 11.5772s/100 iters), loss = 0.0256344
I0823 05:47:06.910995 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0256332 (* 1 = 0.0256332 loss)
I0823 05:47:06.911003 13823 sgd_solver.cpp:112] Iteration 454900, lr = 1e-06
I0823 05:47:18.207401 13823 solver.cpp:239] Iteration 455000 (8.85233 iter/s, 11.2965s/100 iters), loss = 0.0290699
I0823 05:47:18.207454 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0290687 (* 1 = 0.0290687 loss)
I0823 05:47:18.207464 13823 sgd_solver.cpp:112] Iteration 455000, lr = 1e-06
I0823 05:47:29.840355 13823 solver.cpp:239] Iteration 455100 (8.59627 iter/s, 11.633s/100 iters), loss = 0.0258396
I0823 05:47:29.840410 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0258385 (* 1 = 0.0258385 loss)
I0823 05:47:29.840420 13823 sgd_solver.cpp:112] Iteration 455100, lr = 1e-06
I0823 05:47:41.393678 13823 solver.cpp:239] Iteration 455200 (8.65552 iter/s, 11.5533s/100 iters), loss = 0.0285726
I0823 05:47:41.393745 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0285714 (* 1 = 0.0285714 loss)
I0823 05:47:41.393759 13823 sgd_solver.cpp:112] Iteration 455200, lr = 1e-06
I0823 05:47:53.066715 13823 solver.cpp:239] Iteration 455300 (8.56676 iter/s, 11.673s/100 iters), loss = 0.0240283
I0823 05:47:53.066773 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0240271 (* 1 = 0.0240271 loss)
I0823 05:47:53.066787 13823 sgd_solver.cpp:112] Iteration 455300, lr = 1e-06
I0823 05:48:04.482502 13823 solver.cpp:239] Iteration 455400 (8.75981 iter/s, 11.4158s/100 iters), loss = 0.0432827
I0823 05:48:04.482551 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0432815 (* 1 = 0.0432815 loss)
I0823 05:48:04.482561 13823 sgd_solver.cpp:112] Iteration 455400, lr = 1e-06
I0823 05:48:16.281209 13823 solver.cpp:239] Iteration 455500 (8.4755 iter/s, 11.7987s/100 iters), loss = 0.0275287
I0823 05:48:16.281270 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0275275 (* 1 = 0.0275275 loss)
I0823 05:48:16.281282 13823 sgd_solver.cpp:112] Iteration 455500, lr = 1e-06
I0823 05:48:27.893153 13823 solver.cpp:239] Iteration 455600 (8.61183 iter/s, 11.6119s/100 iters), loss = 0.0311378
I0823 05:48:27.893204 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0311367 (* 1 = 0.0311367 loss)
I0823 05:48:27.893213 13823 sgd_solver.cpp:112] Iteration 455600, lr = 1e-06
I0823 05:48:39.430862 13823 solver.cpp:239] Iteration 455700 (8.66724 iter/s, 11.5377s/100 iters), loss = 0.024698
I0823 05:48:39.430927 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0246969 (* 1 = 0.0246969 loss)
I0823 05:48:39.430941 13823 sgd_solver.cpp:112] Iteration 455700, lr = 1e-06
I0823 05:48:51.219921 13823 solver.cpp:239] Iteration 455800 (8.48245 iter/s, 11.789s/100 iters), loss = 0.0299965
I0823 05:48:51.219979 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0299953 (* 1 = 0.0299953 loss)
I0823 05:48:51.219990 13823 sgd_solver.cpp:112] Iteration 455800, lr = 1e-06
I0823 05:49:02.856029 13823 solver.cpp:239] Iteration 455900 (8.59395 iter/s, 11.6361s/100 iters), loss = 0.0306487
I0823 05:49:02.856078 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0306475 (* 1 = 0.0306475 loss)
I0823 05:49:02.856088 13823 sgd_solver.cpp:112] Iteration 455900, lr = 1e-06
I0823 05:49:14.645984 13823 solver.cpp:239] Iteration 456000 (8.4818 iter/s, 11.79s/100 iters), loss = 0.0286246
I0823 05:49:14.646050 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0286234 (* 1 = 0.0286234 loss)
I0823 05:49:14.646064 13823 sgd_solver.cpp:112] Iteration 456000, lr = 1e-06
I0823 05:49:26.176079 13823 solver.cpp:239] Iteration 456100 (8.67297 iter/s, 11.5301s/100 iters), loss = 0.0286792
I0823 05:49:26.176137 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.028678 (* 1 = 0.028678 loss)
I0823 05:49:26.176148 13823 sgd_solver.cpp:112] Iteration 456100, lr = 1e-06
I0823 05:49:38.094265 13823 solver.cpp:239] Iteration 456200 (8.39054 iter/s, 11.9182s/100 iters), loss = 0.0250861
I0823 05:49:38.094319 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0250849 (* 1 = 0.0250849 loss)
I0823 05:49:38.094329 13823 sgd_solver.cpp:112] Iteration 456200, lr = 1e-06
I0823 05:49:50.000406 13823 solver.cpp:239] Iteration 456300 (8.39903 iter/s, 11.9061s/100 iters), loss = 0.0251336
I0823 05:49:50.000478 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0251324 (* 1 = 0.0251324 loss)
I0823 05:49:50.000494 13823 sgd_solver.cpp:112] Iteration 456300, lr = 1e-06
I0823 05:50:01.569304 13823 solver.cpp:239] Iteration 456400 (8.64388 iter/s, 11.5689s/100 iters), loss = 0.0268654
I0823 05:50:01.569372 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0268642 (* 1 = 0.0268642 loss)
I0823 05:50:01.569388 13823 sgd_solver.cpp:112] Iteration 456400, lr = 1e-06
I0823 05:50:13.047647 13823 solver.cpp:239] Iteration 456500 (8.71207 iter/s, 11.4783s/100 iters), loss = 0.0276062
I0823 05:50:13.047698 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.027605 (* 1 = 0.027605 loss)
I0823 05:50:13.047708 13823 sgd_solver.cpp:112] Iteration 456500, lr = 1e-06
I0823 05:50:22.302181 13823 solver.cpp:239] Iteration 456600 (10.8055 iter/s, 9.25452s/100 iters), loss = 0.0284505
I0823 05:50:22.302222 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0284494 (* 1 = 0.0284494 loss)
I0823 05:50:22.302229 13823 sgd_solver.cpp:112] Iteration 456600, lr = 1e-06
I0823 05:50:31.804450 13823 solver.cpp:239] Iteration 456700 (10.5238 iter/s, 9.50226s/100 iters), loss = 0.0233788
I0823 05:50:31.804492 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0233777 (* 1 = 0.0233777 loss)
I0823 05:50:31.804500 13823 sgd_solver.cpp:112] Iteration 456700, lr = 1e-06
I0823 05:50:41.406016 13823 solver.cpp:239] Iteration 456800 (10.415 iter/s, 9.60156s/100 iters), loss = 0.0239474
I0823 05:50:41.406059 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0239463 (* 1 = 0.0239463 loss)
I0823 05:50:41.406066 13823 sgd_solver.cpp:112] Iteration 456800, lr = 1e-06
I0823 05:50:50.644471 13823 solver.cpp:239] Iteration 456900 (10.8243 iter/s, 9.23845s/100 iters), loss = 0.0267724
I0823 05:50:50.644512 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0267712 (* 1 = 0.0267712 loss)
I0823 05:50:50.644520 13823 sgd_solver.cpp:112] Iteration 456900, lr = 1e-06
I0823 05:51:00.181655 13823 solver.cpp:239] Iteration 457000 (10.4853 iter/s, 9.53717s/100 iters), loss = 0.0325096
I0823 05:51:00.181704 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0325084 (* 1 = 0.0325084 loss)
I0823 05:51:00.181713 13823 sgd_solver.cpp:112] Iteration 457000, lr = 1e-06
I0823 05:51:09.861640 13823 solver.cpp:239] Iteration 457100 (10.3306 iter/s, 9.67997s/100 iters), loss = 0.0250079
I0823 05:51:09.861698 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0250067 (* 1 = 0.0250067 loss)
I0823 05:51:09.861711 13823 sgd_solver.cpp:112] Iteration 457100, lr = 1e-06
I0823 05:51:19.332300 13823 solver.cpp:239] Iteration 457200 (10.5589 iter/s, 9.47064s/100 iters), loss = 0.024578
I0823 05:51:19.332343 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0245768 (* 1 = 0.0245768 loss)
I0823 05:51:19.332350 13823 sgd_solver.cpp:112] Iteration 457200, lr = 1e-06
I0823 05:51:28.727017 13823 solver.cpp:239] Iteration 457300 (10.6443 iter/s, 9.39471s/100 iters), loss = 0.0343456
I0823 05:51:28.727057 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0343444 (* 1 = 0.0343444 loss)
I0823 05:51:28.727066 13823 sgd_solver.cpp:112] Iteration 457300, lr = 1e-06
I0823 05:51:37.886739 13823 solver.cpp:239] Iteration 457400 (10.9174 iter/s, 9.15971s/100 iters), loss = 0.0301425
I0823 05:51:37.886783 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0301413 (* 1 = 0.0301413 loss)
I0823 05:51:37.886791 13823 sgd_solver.cpp:112] Iteration 457400, lr = 1e-06
I0823 05:51:47.422096 13823 solver.cpp:239] Iteration 457500 (10.4873 iter/s, 9.53535s/100 iters), loss = 0.0328408
I0823 05:51:47.422137 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0328397 (* 1 = 0.0328397 loss)
I0823 05:51:47.422145 13823 sgd_solver.cpp:112] Iteration 457500, lr = 1e-06
I0823 05:51:56.778548 13823 solver.cpp:239] Iteration 457600 (10.6878 iter/s, 9.35644s/100 iters), loss = 0.0278365
I0823 05:51:56.778589 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0278354 (* 1 = 0.0278354 loss)
I0823 05:51:56.778597 13823 sgd_solver.cpp:112] Iteration 457600, lr = 1e-06
I0823 05:52:06.335719 13823 solver.cpp:239] Iteration 457700 (10.4634 iter/s, 9.55716s/100 iters), loss = 0.024274
I0823 05:52:06.335762 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0242728 (* 1 = 0.0242728 loss)
I0823 05:52:06.335769 13823 sgd_solver.cpp:112] Iteration 457700, lr = 1e-06
I0823 05:52:15.762768 13823 solver.cpp:239] Iteration 457800 (10.6078 iter/s, 9.42704s/100 iters), loss = 0.0244493
I0823 05:52:15.762809 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0244482 (* 1 = 0.0244482 loss)
I0823 05:52:15.762816 13823 sgd_solver.cpp:112] Iteration 457800, lr = 1e-06
I0823 05:52:25.136575 13823 solver.cpp:239] Iteration 457900 (10.668 iter/s, 9.3738s/100 iters), loss = 0.0340525
I0823 05:52:25.136617 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0340513 (* 1 = 0.0340513 loss)
I0823 05:52:25.136624 13823 sgd_solver.cpp:112] Iteration 457900, lr = 1e-06
I0823 05:52:34.618623 13823 solver.cpp:239] Iteration 458000 (10.5463 iter/s, 9.48203s/100 iters), loss = 0.0329289
I0823 05:52:34.618683 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0329277 (* 1 = 0.0329277 loss)
I0823 05:52:34.618695 13823 sgd_solver.cpp:112] Iteration 458000, lr = 1e-06
I0823 05:52:44.051856 13823 solver.cpp:239] Iteration 458100 (10.6008 iter/s, 9.43321s/100 iters), loss = 0.0347645
I0823 05:52:44.051896 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0347634 (* 1 = 0.0347634 loss)
I0823 05:52:44.051904 13823 sgd_solver.cpp:112] Iteration 458100, lr = 1e-06
I0823 05:52:53.490195 13823 solver.cpp:239] Iteration 458200 (10.5951 iter/s, 9.43833s/100 iters), loss = 0.0328816
I0823 05:52:53.490236 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0328804 (* 1 = 0.0328804 loss)
I0823 05:52:53.490244 13823 sgd_solver.cpp:112] Iteration 458200, lr = 1e-06
I0823 05:53:02.825722 13823 solver.cpp:239] Iteration 458300 (10.7118 iter/s, 9.33552s/100 iters), loss = 0.0312891
I0823 05:53:02.825764 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.031288 (* 1 = 0.031288 loss)
I0823 05:53:02.825773 13823 sgd_solver.cpp:112] Iteration 458300, lr = 1e-06
I0823 05:53:12.441432 13823 solver.cpp:239] Iteration 458400 (10.3997 iter/s, 9.6157s/100 iters), loss = 0.0374952
I0823 05:53:12.441483 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0374941 (* 1 = 0.0374941 loss)
I0823 05:53:12.441493 13823 sgd_solver.cpp:112] Iteration 458400, lr = 1e-06
I0823 05:53:22.094231 13823 solver.cpp:239] Iteration 458500 (10.3597 iter/s, 9.65278s/100 iters), loss = 0.0339421
I0823 05:53:22.094288 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0339409 (* 1 = 0.0339409 loss)
I0823 05:53:22.094300 13823 sgd_solver.cpp:112] Iteration 458500, lr = 1e-06
I0823 05:53:31.865739 13823 solver.cpp:239] Iteration 458600 (10.2339 iter/s, 9.77148s/100 iters), loss = 0.023662
I0823 05:53:31.865790 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0236609 (* 1 = 0.0236609 loss)
I0823 05:53:31.865799 13823 sgd_solver.cpp:112] Iteration 458600, lr = 1e-06
I0823 05:53:41.708765 13823 solver.cpp:239] Iteration 458700 (10.1595 iter/s, 9.843s/100 iters), loss = 0.0330363
I0823 05:53:41.708817 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0330351 (* 1 = 0.0330351 loss)
I0823 05:53:41.708825 13823 sgd_solver.cpp:112] Iteration 458700, lr = 1e-06
I0823 05:53:51.533756 13823 solver.cpp:239] Iteration 458800 (10.1782 iter/s, 9.82497s/100 iters), loss = 0.0253885
I0823 05:53:51.533823 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0253873 (* 1 = 0.0253873 loss)
I0823 05:53:51.533838 13823 sgd_solver.cpp:112] Iteration 458800, lr = 1e-06
I0823 05:54:01.092792 13823 solver.cpp:239] Iteration 458900 (10.4613 iter/s, 9.55901s/100 iters), loss = 0.0298463
I0823 05:54:01.092833 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0298452 (* 1 = 0.0298452 loss)
I0823 05:54:01.092840 13823 sgd_solver.cpp:112] Iteration 458900, lr = 1e-06
I0823 05:54:10.726510 13823 solver.cpp:239] Iteration 459000 (10.3802 iter/s, 9.6337s/100 iters), loss = 0.0267669
I0823 05:54:10.726560 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0267658 (* 1 = 0.0267658 loss)
I0823 05:54:10.726570 13823 sgd_solver.cpp:112] Iteration 459000, lr = 1e-06
I0823 05:54:20.648144 13823 solver.cpp:239] Iteration 459100 (10.079 iter/s, 9.92161s/100 iters), loss = 0.026791
I0823 05:54:20.648195 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0267898 (* 1 = 0.0267898 loss)
I0823 05:54:20.648205 13823 sgd_solver.cpp:112] Iteration 459100, lr = 1e-06
I0823 05:54:30.423527 13823 solver.cpp:239] Iteration 459200 (10.2298 iter/s, 9.77536s/100 iters), loss = 0.0249725
I0823 05:54:30.423576 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0249714 (* 1 = 0.0249714 loss)
I0823 05:54:30.423585 13823 sgd_solver.cpp:112] Iteration 459200, lr = 1e-06
I0823 05:54:40.140271 13823 solver.cpp:239] Iteration 459300 (10.2915 iter/s, 9.71672s/100 iters), loss = 0.0219859
I0823 05:54:40.140328 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0219847 (* 1 = 0.0219847 loss)
I0823 05:54:40.140339 13823 sgd_solver.cpp:112] Iteration 459300, lr = 1e-06
I0823 05:54:50.183140 13823 solver.cpp:239] Iteration 459400 (9.95735 iter/s, 10.0428s/100 iters), loss = 0.0232622
I0823 05:54:50.183203 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0232611 (* 1 = 0.0232611 loss)
I0823 05:54:50.183216 13823 sgd_solver.cpp:112] Iteration 459400, lr = 1e-06
I0823 05:55:00.039901 13823 solver.cpp:239] Iteration 459500 (10.1454 iter/s, 9.85673s/100 iters), loss = 0.0260568
I0823 05:55:00.039952 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0260557 (* 1 = 0.0260557 loss)
I0823 05:55:00.039961 13823 sgd_solver.cpp:112] Iteration 459500, lr = 1e-06
I0823 05:55:09.989831 13823 solver.cpp:239] Iteration 459600 (10.0503 iter/s, 9.94991s/100 iters), loss = 0.0309889
I0823 05:55:09.989881 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0309878 (* 1 = 0.0309878 loss)
I0823 05:55:09.989890 13823 sgd_solver.cpp:112] Iteration 459600, lr = 1e-06
I0823 05:55:19.501822 13823 solver.cpp:239] Iteration 459700 (10.5131 iter/s, 9.51197s/100 iters), loss = 0.028098
I0823 05:55:19.501865 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0280969 (* 1 = 0.0280969 loss)
I0823 05:55:19.501873 13823 sgd_solver.cpp:112] Iteration 459700, lr = 1e-06
I0823 05:55:29.182471 13823 solver.cpp:239] Iteration 459800 (10.3299 iter/s, 9.68063s/100 iters), loss = 0.0249291
I0823 05:55:29.182523 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0249279 (* 1 = 0.0249279 loss)
I0823 05:55:29.182533 13823 sgd_solver.cpp:112] Iteration 459800, lr = 1e-06
I0823 05:55:38.615052 13823 solver.cpp:239] Iteration 459900 (10.6016 iter/s, 9.43256s/100 iters), loss = 0.0267839
I0823 05:55:38.615094 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0267828 (* 1 = 0.0267828 loss)
I0823 05:55:38.615101 13823 sgd_solver.cpp:112] Iteration 459900, lr = 1e-06
I0823 05:55:47.965210 13823 solver.cpp:464] Snapshotting to binary proto file ./model_112/cascade_mobilenet_112_iter_460000.caffemodel
I0823 05:55:48.010936 13823 sgd_solver.cpp:284] Snapshotting solver state to binary proto file ./model_112/cascade_mobilenet_112_iter_460000.solverstate
I0823 05:55:48.041775 13823 solver.cpp:347] Iteration 460000, Testing net (#0)
I0823 05:56:48.797361 13823 solver.cpp:414]     Test net output #0: landmark_loss = 0.0219335 (* 1 = 0.0219335 loss)
I0823 05:56:48.918387 13823 solver.cpp:239] Iteration 460000 (1.4224 iter/s, 70.3035s/100 iters), loss = 0.0309267
I0823 05:56:48.918439 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0309256 (* 1 = 0.0309256 loss)
I0823 05:56:48.918453 13823 sgd_solver.cpp:112] Iteration 460000, lr = 1e-06
I0823 05:56:58.856146 13823 solver.cpp:239] Iteration 460100 (10.0627 iter/s, 9.93773s/100 iters), loss = 0.0281963
I0823 05:56:58.856197 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0281952 (* 1 = 0.0281952 loss)
I0823 05:56:58.856207 13823 sgd_solver.cpp:112] Iteration 460100, lr = 1e-06
I0823 05:57:08.924021 13823 solver.cpp:239] Iteration 460200 (9.9326 iter/s, 10.0679s/100 iters), loss = 0.0267817
I0823 05:57:08.924070 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0267806 (* 1 = 0.0267806 loss)
I0823 05:57:08.924080 13823 sgd_solver.cpp:112] Iteration 460200, lr = 1e-06
I0823 05:57:18.891093 13823 solver.cpp:239] Iteration 460300 (10.0331 iter/s, 9.96705s/100 iters), loss = 0.02899
I0823 05:57:18.891144 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0289888 (* 1 = 0.0289888 loss)
I0823 05:57:18.891153 13823 sgd_solver.cpp:112] Iteration 460300, lr = 1e-06
I0823 05:57:28.741077 13823 solver.cpp:239] Iteration 460400 (10.1523 iter/s, 9.84996s/100 iters), loss = 0.0272197
I0823 05:57:28.741128 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0272185 (* 1 = 0.0272185 loss)
I0823 05:57:28.741137 13823 sgd_solver.cpp:112] Iteration 460400, lr = 1e-06
I0823 05:57:38.954193 13823 solver.cpp:239] Iteration 460500 (9.79135 iter/s, 10.2131s/100 iters), loss = 0.0285357
I0823 05:57:38.954260 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0285345 (* 1 = 0.0285345 loss)
I0823 05:57:38.954275 13823 sgd_solver.cpp:112] Iteration 460500, lr = 1e-06
I0823 05:57:49.246156 13823 solver.cpp:239] Iteration 460600 (9.71635 iter/s, 10.2919s/100 iters), loss = 0.0338632
I0823 05:57:49.246206 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.033862 (* 1 = 0.033862 loss)
I0823 05:57:49.246215 13823 sgd_solver.cpp:112] Iteration 460600, lr = 1e-06
I0823 05:57:59.321995 13823 solver.cpp:239] Iteration 460700 (9.92475 iter/s, 10.0758s/100 iters), loss = 0.0262557
I0823 05:57:59.322047 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0262545 (* 1 = 0.0262545 loss)
I0823 05:57:59.322057 13823 sgd_solver.cpp:112] Iteration 460700, lr = 1e-06
I0823 05:58:09.247515 13823 solver.cpp:239] Iteration 460800 (10.0751 iter/s, 9.9255s/100 iters), loss = 0.0268648
I0823 05:58:09.247567 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0268637 (* 1 = 0.0268637 loss)
I0823 05:58:09.247576 13823 sgd_solver.cpp:112] Iteration 460800, lr = 1e-06
I0823 05:58:19.647600 13823 solver.cpp:239] Iteration 460900 (9.61533 iter/s, 10.4001s/100 iters), loss = 0.0265317
I0823 05:58:19.647660 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0265305 (* 1 = 0.0265305 loss)
I0823 05:58:19.647672 13823 sgd_solver.cpp:112] Iteration 460900, lr = 1e-06
I0823 05:58:29.840903 13823 solver.cpp:239] Iteration 461000 (9.8104 iter/s, 10.1933s/100 iters), loss = 0.0299906
I0823 05:58:29.840965 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0299894 (* 1 = 0.0299894 loss)
I0823 05:58:29.840977 13823 sgd_solver.cpp:112] Iteration 461000, lr = 1e-06
I0823 05:58:39.877998 13823 solver.cpp:239] Iteration 461100 (9.96307 iter/s, 10.0371s/100 iters), loss = 0.02755
I0823 05:58:39.878049 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0275489 (* 1 = 0.0275489 loss)
I0823 05:58:39.878059 13823 sgd_solver.cpp:112] Iteration 461100, lr = 1e-06
I0823 05:58:50.340014 13823 solver.cpp:239] Iteration 461200 (9.55841 iter/s, 10.462s/100 iters), loss = 0.0259094
I0823 05:58:50.340065 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0259082 (* 1 = 0.0259082 loss)
I0823 05:58:50.340075 13823 sgd_solver.cpp:112] Iteration 461200, lr = 1e-06
I0823 05:59:00.527112 13823 solver.cpp:239] Iteration 461300 (9.81636 iter/s, 10.1871s/100 iters), loss = 0.0262911
I0823 05:59:00.527163 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.02629 (* 1 = 0.02629 loss)
I0823 05:59:00.527173 13823 sgd_solver.cpp:112] Iteration 461300, lr = 1e-06
I0823 05:59:10.437444 13823 solver.cpp:239] Iteration 461400 (10.0905 iter/s, 9.91031s/100 iters), loss = 0.0282738
I0823 05:59:10.437499 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0282727 (* 1 = 0.0282727 loss)
I0823 05:59:10.437508 13823 sgd_solver.cpp:112] Iteration 461400, lr = 1e-06
I0823 05:59:20.542134 13823 solver.cpp:239] Iteration 461500 (9.89642 iter/s, 10.1047s/100 iters), loss = 0.0275018
I0823 05:59:20.542186 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0275006 (* 1 = 0.0275006 loss)
I0823 05:59:20.542194 13823 sgd_solver.cpp:112] Iteration 461500, lr = 1e-06
I0823 05:59:30.638728 13823 solver.cpp:239] Iteration 461600 (9.90436 iter/s, 10.0966s/100 iters), loss = 0.0249115
I0823 05:59:30.638784 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0249104 (* 1 = 0.0249104 loss)
I0823 05:59:30.638795 13823 sgd_solver.cpp:112] Iteration 461600, lr = 1e-06
I0823 05:59:40.892351 13823 solver.cpp:239] Iteration 461700 (9.75268 iter/s, 10.2536s/100 iters), loss = 0.0276639
I0823 05:59:40.892400 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0276628 (* 1 = 0.0276628 loss)
I0823 05:59:40.892410 13823 sgd_solver.cpp:112] Iteration 461700, lr = 1e-06
I0823 05:59:51.048188 13823 solver.cpp:239] Iteration 461800 (9.84658 iter/s, 10.1558s/100 iters), loss = 0.0330055
I0823 05:59:51.048239 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0330044 (* 1 = 0.0330044 loss)
I0823 05:59:51.048249 13823 sgd_solver.cpp:112] Iteration 461800, lr = 1e-06
I0823 06:00:01.401454 13823 solver.cpp:239] Iteration 461900 (9.65882 iter/s, 10.3532s/100 iters), loss = 0.0400477
I0823 06:00:01.401517 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0400466 (* 1 = 0.0400466 loss)
I0823 06:00:01.401530 13823 sgd_solver.cpp:112] Iteration 461900, lr = 1e-06
I0823 06:00:11.956148 13823 solver.cpp:239] Iteration 462000 (9.47449 iter/s, 10.5547s/100 iters), loss = 0.0260711
I0823 06:00:11.956199 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0260699 (* 1 = 0.0260699 loss)
I0823 06:00:11.956208 13823 sgd_solver.cpp:112] Iteration 462000, lr = 1e-06
I0823 06:00:22.059723 13823 solver.cpp:239] Iteration 462100 (9.89751 iter/s, 10.1035s/100 iters), loss = 0.0309022
I0823 06:00:22.059772 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0309011 (* 1 = 0.0309011 loss)
I0823 06:00:22.059782 13823 sgd_solver.cpp:112] Iteration 462100, lr = 1e-06
I0823 06:00:32.243285 13823 solver.cpp:239] Iteration 462200 (9.81977 iter/s, 10.1835s/100 iters), loss = 0.0262148
I0823 06:00:32.243338 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0262137 (* 1 = 0.0262137 loss)
I0823 06:00:32.243348 13823 sgd_solver.cpp:112] Iteration 462200, lr = 1e-06
I0823 06:00:42.396713 13823 solver.cpp:239] Iteration 462300 (9.84892 iter/s, 10.1534s/100 iters), loss = 0.0274355
I0823 06:00:42.396773 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0274344 (* 1 = 0.0274344 loss)
I0823 06:00:42.396786 13823 sgd_solver.cpp:112] Iteration 462300, lr = 1e-06
I0823 06:00:52.810931 13823 solver.cpp:239] Iteration 462400 (9.60229 iter/s, 10.4142s/100 iters), loss = 0.0252647
I0823 06:00:52.810982 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0252636 (* 1 = 0.0252636 loss)
I0823 06:00:52.810992 13823 sgd_solver.cpp:112] Iteration 462400, lr = 1e-06
I0823 06:01:02.800935 13823 solver.cpp:239] Iteration 462500 (10.01 iter/s, 9.98998s/100 iters), loss = 0.0243208
I0823 06:01:02.800987 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0243197 (* 1 = 0.0243197 loss)
I0823 06:01:02.800995 13823 sgd_solver.cpp:112] Iteration 462500, lr = 1e-06
I0823 06:01:12.717010 13823 solver.cpp:239] Iteration 462600 (10.0847 iter/s, 9.91605s/100 iters), loss = 0.0275808
I0823 06:01:12.717061 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0275796 (* 1 = 0.0275796 loss)
I0823 06:01:12.717072 13823 sgd_solver.cpp:112] Iteration 462600, lr = 1e-06
I0823 06:01:22.750103 13823 solver.cpp:239] Iteration 462700 (9.96704 iter/s, 10.0331s/100 iters), loss = 0.0287264
I0823 06:01:22.750154 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0287252 (* 1 = 0.0287252 loss)
I0823 06:01:22.750162 13823 sgd_solver.cpp:112] Iteration 462700, lr = 1e-06
I0823 06:01:32.932674 13823 solver.cpp:239] Iteration 462800 (9.82073 iter/s, 10.1825s/100 iters), loss = 0.0363834
I0823 06:01:32.932723 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0363823 (* 1 = 0.0363823 loss)
I0823 06:01:32.932734 13823 sgd_solver.cpp:112] Iteration 462800, lr = 1e-06
I0823 06:01:42.950626 13823 solver.cpp:239] Iteration 462900 (9.98211 iter/s, 10.0179s/100 iters), loss = 0.0292604
I0823 06:01:42.950678 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0292593 (* 1 = 0.0292593 loss)
I0823 06:01:42.950688 13823 sgd_solver.cpp:112] Iteration 462900, lr = 1e-06
I0823 06:01:53.136101 13823 solver.cpp:239] Iteration 463000 (9.81793 iter/s, 10.1854s/100 iters), loss = 0.0254745
I0823 06:01:53.136157 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0254733 (* 1 = 0.0254733 loss)
I0823 06:01:53.136165 13823 sgd_solver.cpp:112] Iteration 463000, lr = 1e-06
I0823 06:02:03.535229 13823 solver.cpp:239] Iteration 463100 (9.61622 iter/s, 10.3991s/100 iters), loss = 0.0267374
I0823 06:02:03.535282 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0267362 (* 1 = 0.0267362 loss)
I0823 06:02:03.535291 13823 sgd_solver.cpp:112] Iteration 463100, lr = 1e-06
I0823 06:02:13.869411 13823 solver.cpp:239] Iteration 463200 (9.67665 iter/s, 10.3342s/100 iters), loss = 0.025511
I0823 06:02:13.869462 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0255099 (* 1 = 0.0255099 loss)
I0823 06:02:13.869472 13823 sgd_solver.cpp:112] Iteration 463200, lr = 1e-06
I0823 06:02:24.296125 13823 solver.cpp:239] Iteration 463300 (9.59077 iter/s, 10.4267s/100 iters), loss = 0.0349293
I0823 06:02:24.296183 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0349282 (* 1 = 0.0349282 loss)
I0823 06:02:24.296193 13823 sgd_solver.cpp:112] Iteration 463300, lr = 1e-06
I0823 06:02:34.498656 13823 solver.cpp:239] Iteration 463400 (9.80152 iter/s, 10.2025s/100 iters), loss = 0.0322347
I0823 06:02:34.498710 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0322335 (* 1 = 0.0322335 loss)
I0823 06:02:34.498721 13823 sgd_solver.cpp:112] Iteration 463400, lr = 1e-06
I0823 06:02:45.159543 13823 solver.cpp:239] Iteration 463500 (9.38011 iter/s, 10.6609s/100 iters), loss = 0.0252754
I0823 06:02:45.159593 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0252742 (* 1 = 0.0252742 loss)
I0823 06:02:45.159603 13823 sgd_solver.cpp:112] Iteration 463500, lr = 1e-06
I0823 06:02:55.739737 13823 solver.cpp:239] Iteration 463600 (9.45165 iter/s, 10.5802s/100 iters), loss = 0.0290767
I0823 06:02:55.739796 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0290755 (* 1 = 0.0290755 loss)
I0823 06:02:55.739809 13823 sgd_solver.cpp:112] Iteration 463600, lr = 1e-06
I0823 06:03:06.139276 13823 solver.cpp:239] Iteration 463700 (9.61584 iter/s, 10.3995s/100 iters), loss = 0.0256861
I0823 06:03:06.139329 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0256849 (* 1 = 0.0256849 loss)
I0823 06:03:06.139338 13823 sgd_solver.cpp:112] Iteration 463700, lr = 1e-06
I0823 06:03:16.656617 13823 solver.cpp:239] Iteration 463800 (9.50813 iter/s, 10.5173s/100 iters), loss = 0.0297552
I0823 06:03:16.656674 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.029754 (* 1 = 0.029754 loss)
I0823 06:03:16.656685 13823 sgd_solver.cpp:112] Iteration 463800, lr = 1e-06
I0823 06:03:27.034934 13823 solver.cpp:239] Iteration 463900 (9.6355 iter/s, 10.3783s/100 iters), loss = 0.0283013
I0823 06:03:27.034991 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0283001 (* 1 = 0.0283001 loss)
I0823 06:03:27.035001 13823 sgd_solver.cpp:112] Iteration 463900, lr = 1e-06
I0823 06:03:37.496089 13823 solver.cpp:239] Iteration 464000 (9.5592 iter/s, 10.4611s/100 iters), loss = 0.0244074
I0823 06:03:37.496148 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0244062 (* 1 = 0.0244062 loss)
I0823 06:03:37.496160 13823 sgd_solver.cpp:112] Iteration 464000, lr = 1e-06
I0823 06:03:48.153525 13823 solver.cpp:239] Iteration 464100 (9.38315 iter/s, 10.6574s/100 iters), loss = 0.0265279
I0823 06:03:48.153589 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0265268 (* 1 = 0.0265268 loss)
I0823 06:03:48.153599 13823 sgd_solver.cpp:112] Iteration 464100, lr = 1e-06
I0823 06:03:58.848269 13823 solver.cpp:239] Iteration 464200 (9.35042 iter/s, 10.6947s/100 iters), loss = 0.0358127
I0823 06:03:58.848320 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0358116 (* 1 = 0.0358116 loss)
I0823 06:03:58.848330 13823 sgd_solver.cpp:112] Iteration 464200, lr = 1e-06
I0823 06:04:09.239953 13823 solver.cpp:239] Iteration 464300 (9.6231 iter/s, 10.3917s/100 iters), loss = 0.0278232
I0823 06:04:09.240003 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.027822 (* 1 = 0.027822 loss)
I0823 06:04:09.240013 13823 sgd_solver.cpp:112] Iteration 464300, lr = 1e-06
I0823 06:04:19.625241 13823 solver.cpp:239] Iteration 464400 (9.62903 iter/s, 10.3853s/100 iters), loss = 0.0240899
I0823 06:04:19.625303 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0240887 (* 1 = 0.0240887 loss)
I0823 06:04:19.625315 13823 sgd_solver.cpp:112] Iteration 464400, lr = 1e-06
I0823 06:04:30.300483 13823 solver.cpp:239] Iteration 464500 (9.3675 iter/s, 10.6752s/100 iters), loss = 0.0249976
I0823 06:04:30.300539 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0249965 (* 1 = 0.0249965 loss)
I0823 06:04:30.300549 13823 sgd_solver.cpp:112] Iteration 464500, lr = 1e-06
I0823 06:04:41.003710 13823 solver.cpp:239] Iteration 464600 (9.34301 iter/s, 10.7032s/100 iters), loss = 0.0261899
I0823 06:04:41.003770 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0261887 (* 1 = 0.0261887 loss)
I0823 06:04:41.003782 13823 sgd_solver.cpp:112] Iteration 464600, lr = 1e-06
I0823 06:04:51.735445 13823 solver.cpp:239] Iteration 464700 (9.31819 iter/s, 10.7317s/100 iters), loss = 0.0226762
I0823 06:04:51.735497 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0226751 (* 1 = 0.0226751 loss)
I0823 06:04:51.735507 13823 sgd_solver.cpp:112] Iteration 464700, lr = 1e-06
I0823 06:05:02.174314 13823 solver.cpp:239] Iteration 464800 (9.57961 iter/s, 10.4388s/100 iters), loss = 0.0260799
I0823 06:05:02.174367 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0260788 (* 1 = 0.0260788 loss)
I0823 06:05:02.174377 13823 sgd_solver.cpp:112] Iteration 464800, lr = 1e-06
I0823 06:05:12.783393 13823 solver.cpp:239] Iteration 464900 (9.42592 iter/s, 10.609s/100 iters), loss = 0.0265744
I0823 06:05:12.783447 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0265733 (* 1 = 0.0265733 loss)
I0823 06:05:12.783457 13823 sgd_solver.cpp:112] Iteration 464900, lr = 1e-06
I0823 06:05:23.435784 13823 solver.cpp:239] Iteration 465000 (9.38759 iter/s, 10.6524s/100 iters), loss = 0.0263244
I0823 06:05:23.435835 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0263232 (* 1 = 0.0263232 loss)
I0823 06:05:23.435844 13823 sgd_solver.cpp:112] Iteration 465000, lr = 1e-06
I0823 06:05:34.260274 13823 solver.cpp:239] Iteration 465100 (9.23833 iter/s, 10.8245s/100 iters), loss = 0.0222714
I0823 06:05:34.260324 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0222703 (* 1 = 0.0222703 loss)
I0823 06:05:34.260332 13823 sgd_solver.cpp:112] Iteration 465100, lr = 1e-06
I0823 06:05:45.014945 13823 solver.cpp:239] Iteration 465200 (9.29831 iter/s, 10.7546s/100 iters), loss = 0.0287803
I0823 06:05:45.015005 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0287791 (* 1 = 0.0287791 loss)
I0823 06:05:45.015017 13823 sgd_solver.cpp:112] Iteration 465200, lr = 1e-06
I0823 06:05:55.655176 13823 solver.cpp:239] Iteration 465300 (9.39832 iter/s, 10.6402s/100 iters), loss = 0.0317985
I0823 06:05:55.655227 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0317974 (* 1 = 0.0317974 loss)
I0823 06:05:55.655237 13823 sgd_solver.cpp:112] Iteration 465300, lr = 1e-06
I0823 06:06:06.441653 13823 solver.cpp:239] Iteration 465400 (9.27089 iter/s, 10.7864s/100 iters), loss = 0.0360435
I0823 06:06:06.441702 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0360424 (* 1 = 0.0360424 loss)
I0823 06:06:06.441712 13823 sgd_solver.cpp:112] Iteration 465400, lr = 1e-06
I0823 06:06:17.200963 13823 solver.cpp:239] Iteration 465500 (9.2943 iter/s, 10.7593s/100 iters), loss = 0.0279012
I0823 06:06:17.201014 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0279 (* 1 = 0.0279 loss)
I0823 06:06:17.201025 13823 sgd_solver.cpp:112] Iteration 465500, lr = 1e-06
I0823 06:06:28.164855 13823 solver.cpp:239] Iteration 465600 (9.12087 iter/s, 10.9639s/100 iters), loss = 0.0278741
I0823 06:06:28.164906 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.027873 (* 1 = 0.027873 loss)
I0823 06:06:28.164916 13823 sgd_solver.cpp:112] Iteration 465600, lr = 1e-06
I0823 06:06:38.749996 13823 solver.cpp:239] Iteration 465700 (9.44723 iter/s, 10.5851s/100 iters), loss = 0.0258122
I0823 06:06:38.750046 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.025811 (* 1 = 0.025811 loss)
I0823 06:06:38.750056 13823 sgd_solver.cpp:112] Iteration 465700, lr = 1e-06
I0823 06:06:49.260219 13823 solver.cpp:239] Iteration 465800 (9.51457 iter/s, 10.5102s/100 iters), loss = 0.0293592
I0823 06:06:49.260282 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0293581 (* 1 = 0.0293581 loss)
I0823 06:06:49.260293 13823 sgd_solver.cpp:112] Iteration 465800, lr = 1e-06
I0823 06:06:59.709818 13823 solver.cpp:239] Iteration 465900 (9.56978 iter/s, 10.4496s/100 iters), loss = 0.0245328
I0823 06:06:59.709882 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0245316 (* 1 = 0.0245316 loss)
I0823 06:06:59.709894 13823 sgd_solver.cpp:112] Iteration 465900, lr = 1e-06
I0823 06:07:10.477859 13823 solver.cpp:239] Iteration 466000 (9.28677 iter/s, 10.768s/100 iters), loss = 0.027175
I0823 06:07:10.477916 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0271738 (* 1 = 0.0271738 loss)
I0823 06:07:10.477927 13823 sgd_solver.cpp:112] Iteration 466000, lr = 1e-06
I0823 06:07:20.975201 13823 solver.cpp:239] Iteration 466100 (9.52625 iter/s, 10.4973s/100 iters), loss = 0.0282173
I0823 06:07:20.975251 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0282161 (* 1 = 0.0282161 loss)
I0823 06:07:20.975261 13823 sgd_solver.cpp:112] Iteration 466100, lr = 1e-06
I0823 06:07:31.783324 13823 solver.cpp:239] Iteration 466200 (9.25233 iter/s, 10.8081s/100 iters), loss = 0.029689
I0823 06:07:31.783385 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0296878 (* 1 = 0.0296878 loss)
I0823 06:07:31.783396 13823 sgd_solver.cpp:112] Iteration 466200, lr = 1e-06
I0823 06:07:42.514883 13823 solver.cpp:239] Iteration 466300 (9.31834 iter/s, 10.7315s/100 iters), loss = 0.031031
I0823 06:07:42.514936 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0310299 (* 1 = 0.0310299 loss)
I0823 06:07:42.514946 13823 sgd_solver.cpp:112] Iteration 466300, lr = 1e-06
I0823 06:07:53.390435 13823 solver.cpp:239] Iteration 466400 (9.19496 iter/s, 10.8755s/100 iters), loss = 0.0296319
I0823 06:07:53.390503 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0296308 (* 1 = 0.0296308 loss)
I0823 06:07:53.390519 13823 sgd_solver.cpp:112] Iteration 466400, lr = 1e-06
I0823 06:08:04.109098 13823 solver.cpp:239] Iteration 466500 (9.32955 iter/s, 10.7186s/100 iters), loss = 0.0316759
I0823 06:08:04.109155 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0316747 (* 1 = 0.0316747 loss)
I0823 06:08:04.109169 13823 sgd_solver.cpp:112] Iteration 466500, lr = 1e-06
I0823 06:08:14.433584 13823 solver.cpp:239] Iteration 466600 (9.68574 iter/s, 10.3245s/100 iters), loss = 0.0260111
I0823 06:08:14.433645 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0260099 (* 1 = 0.0260099 loss)
I0823 06:08:14.433657 13823 sgd_solver.cpp:112] Iteration 466600, lr = 1e-06
I0823 06:08:25.231818 13823 solver.cpp:239] Iteration 466700 (9.2608 iter/s, 10.7982s/100 iters), loss = 0.0281557
I0823 06:08:25.231878 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0281545 (* 1 = 0.0281545 loss)
I0823 06:08:25.231891 13823 sgd_solver.cpp:112] Iteration 466700, lr = 1e-06
I0823 06:08:36.078181 13823 solver.cpp:239] Iteration 466800 (9.21971 iter/s, 10.8463s/100 iters), loss = 0.0236951
I0823 06:08:36.078236 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0236939 (* 1 = 0.0236939 loss)
I0823 06:08:36.078249 13823 sgd_solver.cpp:112] Iteration 466800, lr = 1e-06
I0823 06:08:46.573498 13823 solver.cpp:239] Iteration 466900 (9.52809 iter/s, 10.4953s/100 iters), loss = 0.0384514
I0823 06:08:46.573562 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0384502 (* 1 = 0.0384502 loss)
I0823 06:08:46.573578 13823 sgd_solver.cpp:112] Iteration 466900, lr = 1e-06
I0823 06:08:57.279280 13823 solver.cpp:239] Iteration 467000 (9.34079 iter/s, 10.7057s/100 iters), loss = 0.0288387
I0823 06:08:57.279361 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0288376 (* 1 = 0.0288376 loss)
I0823 06:08:57.279374 13823 sgd_solver.cpp:112] Iteration 467000, lr = 1e-06
I0823 06:09:08.342065 13823 solver.cpp:239] Iteration 467100 (9.03936 iter/s, 11.0627s/100 iters), loss = 0.0277202
I0823 06:09:08.342116 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0277191 (* 1 = 0.0277191 loss)
I0823 06:09:08.342126 13823 sgd_solver.cpp:112] Iteration 467100, lr = 1e-06
I0823 06:09:19.057005 13823 solver.cpp:239] Iteration 467200 (9.33279 iter/s, 10.7149s/100 iters), loss = 0.0243717
I0823 06:09:19.057055 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0243705 (* 1 = 0.0243705 loss)
I0823 06:09:19.057065 13823 sgd_solver.cpp:112] Iteration 467200, lr = 1e-06
I0823 06:09:29.739009 13823 solver.cpp:239] Iteration 467300 (9.36156 iter/s, 10.682s/100 iters), loss = 0.0250416
I0823 06:09:29.739060 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0250404 (* 1 = 0.0250404 loss)
I0823 06:09:29.739070 13823 sgd_solver.cpp:112] Iteration 467300, lr = 1e-06
I0823 06:09:40.680151 13823 solver.cpp:239] Iteration 467400 (9.13984 iter/s, 10.9411s/100 iters), loss = 0.0301724
I0823 06:09:40.680213 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0301713 (* 1 = 0.0301713 loss)
I0823 06:09:40.680225 13823 sgd_solver.cpp:112] Iteration 467400, lr = 1e-06
I0823 06:09:51.702710 13823 solver.cpp:239] Iteration 467500 (9.07234 iter/s, 11.0225s/100 iters), loss = 0.0246858
I0823 06:09:51.702775 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0246847 (* 1 = 0.0246847 loss)
I0823 06:09:51.702787 13823 sgd_solver.cpp:112] Iteration 467500, lr = 1e-06
I0823 06:10:02.792345 13823 solver.cpp:239] Iteration 467600 (9.01746 iter/s, 11.0896s/100 iters), loss = 0.0295331
I0823 06:10:02.792398 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0295319 (* 1 = 0.0295319 loss)
I0823 06:10:02.792407 13823 sgd_solver.cpp:112] Iteration 467600, lr = 1e-06
I0823 06:10:13.424595 13823 solver.cpp:239] Iteration 467700 (9.40537 iter/s, 10.6322s/100 iters), loss = 0.0251005
I0823 06:10:13.424645 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0250994 (* 1 = 0.0250994 loss)
I0823 06:10:13.424654 13823 sgd_solver.cpp:112] Iteration 467700, lr = 1e-06
I0823 06:10:24.354912 13823 solver.cpp:239] Iteration 467800 (9.14889 iter/s, 10.9303s/100 iters), loss = 0.0261368
I0823 06:10:24.354965 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0261357 (* 1 = 0.0261357 loss)
I0823 06:10:24.354975 13823 sgd_solver.cpp:112] Iteration 467800, lr = 1e-06
I0823 06:10:35.209699 13823 solver.cpp:239] Iteration 467900 (9.21255 iter/s, 10.8548s/100 iters), loss = 0.0278643
I0823 06:10:35.209754 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0278631 (* 1 = 0.0278631 loss)
I0823 06:10:35.209764 13823 sgd_solver.cpp:112] Iteration 467900, lr = 1e-06
I0823 06:10:46.040098 13823 solver.cpp:239] Iteration 468000 (9.2333 iter/s, 10.8304s/100 iters), loss = 0.0233104
I0823 06:10:46.040153 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0233092 (* 1 = 0.0233092 loss)
I0823 06:10:46.040163 13823 sgd_solver.cpp:112] Iteration 468000, lr = 1e-06
I0823 06:10:56.751745 13823 solver.cpp:239] Iteration 468100 (9.33566 iter/s, 10.7116s/100 iters), loss = 0.0284118
I0823 06:10:56.751796 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0284106 (* 1 = 0.0284106 loss)
I0823 06:10:56.751804 13823 sgd_solver.cpp:112] Iteration 468100, lr = 1e-06
I0823 06:11:07.602795 13823 solver.cpp:239] Iteration 468200 (9.21572 iter/s, 10.851s/100 iters), loss = 0.0335323
I0823 06:11:07.602859 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0335312 (* 1 = 0.0335312 loss)
I0823 06:11:07.602872 13823 sgd_solver.cpp:112] Iteration 468200, lr = 1e-06
I0823 06:11:18.720091 13823 solver.cpp:239] Iteration 468300 (8.99503 iter/s, 11.1173s/100 iters), loss = 0.0303438
I0823 06:11:18.720158 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0303427 (* 1 = 0.0303427 loss)
I0823 06:11:18.720170 13823 sgd_solver.cpp:112] Iteration 468300, lr = 1e-06
I0823 06:11:29.711678 13823 solver.cpp:239] Iteration 468400 (9.0979 iter/s, 10.9915s/100 iters), loss = 0.0248838
I0823 06:11:29.711731 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0248826 (* 1 = 0.0248826 loss)
I0823 06:11:29.711740 13823 sgd_solver.cpp:112] Iteration 468400, lr = 1e-06
I0823 06:11:40.989821 13823 solver.cpp:239] Iteration 468500 (8.86673 iter/s, 11.2781s/100 iters), loss = 0.031399
I0823 06:11:40.989887 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0313978 (* 1 = 0.0313978 loss)
I0823 06:11:40.989900 13823 sgd_solver.cpp:112] Iteration 468500, lr = 1e-06
I0823 06:11:52.111724 13823 solver.cpp:239] Iteration 468600 (8.9913 iter/s, 11.1219s/100 iters), loss = 0.0235553
I0823 06:11:52.111783 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0235541 (* 1 = 0.0235541 loss)
I0823 06:11:52.111794 13823 sgd_solver.cpp:112] Iteration 468600, lr = 1e-06
I0823 06:12:03.372014 13823 solver.cpp:239] Iteration 468700 (8.88079 iter/s, 11.2603s/100 iters), loss = 0.0275871
I0823 06:12:03.372074 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.027586 (* 1 = 0.027586 loss)
I0823 06:12:03.372086 13823 sgd_solver.cpp:112] Iteration 468700, lr = 1e-06
I0823 06:12:14.402348 13823 solver.cpp:239] Iteration 468800 (9.06594 iter/s, 11.0303s/100 iters), loss = 0.0266443
I0823 06:12:14.402405 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0266432 (* 1 = 0.0266432 loss)
I0823 06:12:14.402415 13823 sgd_solver.cpp:112] Iteration 468800, lr = 1e-06
I0823 06:12:25.231741 13823 solver.cpp:239] Iteration 468900 (9.23416 iter/s, 10.8294s/100 iters), loss = 0.0337923
I0823 06:12:25.231797 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0337912 (* 1 = 0.0337912 loss)
I0823 06:12:25.231808 13823 sgd_solver.cpp:112] Iteration 468900, lr = 1e-06
I0823 06:12:36.065455 13823 solver.cpp:239] Iteration 469000 (9.23047 iter/s, 10.8337s/100 iters), loss = 0.0243445
I0823 06:12:36.065505 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0243434 (* 1 = 0.0243434 loss)
I0823 06:12:36.065515 13823 sgd_solver.cpp:112] Iteration 469000, lr = 1e-06
I0823 06:12:47.220599 13823 solver.cpp:239] Iteration 469100 (8.9645 iter/s, 11.1551s/100 iters), loss = 0.0291686
I0823 06:12:47.220652 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0291674 (* 1 = 0.0291674 loss)
I0823 06:12:47.220664 13823 sgd_solver.cpp:112] Iteration 469100, lr = 1e-06
I0823 06:12:58.369776 13823 solver.cpp:239] Iteration 469200 (8.9693 iter/s, 11.1491s/100 iters), loss = 0.0288613
I0823 06:12:58.369825 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0288602 (* 1 = 0.0288602 loss)
I0823 06:12:58.369834 13823 sgd_solver.cpp:112] Iteration 469200, lr = 1e-06
I0823 06:13:09.195998 13823 solver.cpp:239] Iteration 469300 (9.23686 iter/s, 10.8262s/100 iters), loss = 0.0250857
I0823 06:13:09.196054 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0250846 (* 1 = 0.0250846 loss)
I0823 06:13:09.196064 13823 sgd_solver.cpp:112] Iteration 469300, lr = 1e-06
I0823 06:13:19.972806 13823 solver.cpp:239] Iteration 469400 (9.27921 iter/s, 10.7768s/100 iters), loss = 0.0253749
I0823 06:13:19.972856 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0253738 (* 1 = 0.0253738 loss)
I0823 06:13:19.972867 13823 sgd_solver.cpp:112] Iteration 469400, lr = 1e-06
I0823 06:13:30.741686 13823 solver.cpp:239] Iteration 469500 (9.28604 iter/s, 10.7689s/100 iters), loss = 0.0273695
I0823 06:13:30.741735 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0273684 (* 1 = 0.0273684 loss)
I0823 06:13:30.741745 13823 sgd_solver.cpp:112] Iteration 469500, lr = 1e-06
I0823 06:13:41.687783 13823 solver.cpp:239] Iteration 469600 (9.1357 iter/s, 10.9461s/100 iters), loss = 0.0240184
I0823 06:13:41.687832 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0240173 (* 1 = 0.0240173 loss)
I0823 06:13:41.687842 13823 sgd_solver.cpp:112] Iteration 469600, lr = 1e-06
I0823 06:13:52.611326 13823 solver.cpp:239] Iteration 469700 (9.15456 iter/s, 10.9235s/100 iters), loss = 0.0268989
I0823 06:13:52.611376 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0268978 (* 1 = 0.0268978 loss)
I0823 06:13:52.611385 13823 sgd_solver.cpp:112] Iteration 469700, lr = 1e-06
I0823 06:14:03.568765 13823 solver.cpp:239] Iteration 469800 (9.12624 iter/s, 10.9574s/100 iters), loss = 0.0272373
I0823 06:14:03.568816 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0272362 (* 1 = 0.0272362 loss)
I0823 06:14:03.568825 13823 sgd_solver.cpp:112] Iteration 469800, lr = 1e-06
I0823 06:14:14.656188 13823 solver.cpp:239] Iteration 469900 (9.01925 iter/s, 11.0874s/100 iters), loss = 0.029424
I0823 06:14:14.656237 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0294229 (* 1 = 0.0294229 loss)
I0823 06:14:14.656247 13823 sgd_solver.cpp:112] Iteration 469900, lr = 1e-06
I0823 06:14:25.636593 13823 solver.cpp:239] Iteration 470000 (9.10715 iter/s, 10.9804s/100 iters), loss = 0.0496293
I0823 06:14:25.636644 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0496282 (* 1 = 0.0496282 loss)
I0823 06:14:25.636654 13823 sgd_solver.cpp:112] Iteration 470000, lr = 1e-06
I0823 06:14:36.629263 13823 solver.cpp:239] Iteration 470100 (9.09699 iter/s, 10.9926s/100 iters), loss = 0.0252269
I0823 06:14:36.629314 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0252258 (* 1 = 0.0252258 loss)
I0823 06:14:36.629324 13823 sgd_solver.cpp:112] Iteration 470100, lr = 1e-06
I0823 06:14:47.902626 13823 solver.cpp:239] Iteration 470200 (8.87049 iter/s, 11.2733s/100 iters), loss = 0.0330245
I0823 06:14:47.902693 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0330234 (* 1 = 0.0330234 loss)
I0823 06:14:47.902705 13823 sgd_solver.cpp:112] Iteration 470200, lr = 1e-06
I0823 06:14:59.339803 13823 solver.cpp:239] Iteration 470300 (8.74345 iter/s, 11.4371s/100 iters), loss = 0.0289377
I0823 06:14:59.339851 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0289366 (* 1 = 0.0289366 loss)
I0823 06:14:59.339861 13823 sgd_solver.cpp:112] Iteration 470300, lr = 1e-06
I0823 06:15:10.728889 13823 solver.cpp:239] Iteration 470400 (8.78036 iter/s, 11.3891s/100 iters), loss = 0.0272974
I0823 06:15:10.728953 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0272963 (* 1 = 0.0272963 loss)
I0823 06:15:10.728966 13823 sgd_solver.cpp:112] Iteration 470400, lr = 1e-06
I0823 06:15:21.700861 13823 solver.cpp:239] Iteration 470500 (9.11416 iter/s, 10.9719s/100 iters), loss = 0.0260256
I0823 06:15:21.700913 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0260245 (* 1 = 0.0260245 loss)
I0823 06:15:21.700923 13823 sgd_solver.cpp:112] Iteration 470500, lr = 1e-06
I0823 06:15:32.682444 13823 solver.cpp:239] Iteration 470600 (9.10618 iter/s, 10.9816s/100 iters), loss = 0.0283422
I0823 06:15:32.682502 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0283411 (* 1 = 0.0283411 loss)
I0823 06:15:32.682514 13823 sgd_solver.cpp:112] Iteration 470600, lr = 1e-06
I0823 06:15:43.801250 13823 solver.cpp:239] Iteration 470700 (8.9938 iter/s, 11.1188s/100 iters), loss = 0.0264877
I0823 06:15:43.801303 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0264865 (* 1 = 0.0264865 loss)
I0823 06:15:43.801313 13823 sgd_solver.cpp:112] Iteration 470700, lr = 1e-06
I0823 06:15:54.906327 13823 solver.cpp:239] Iteration 470800 (9.00492 iter/s, 11.105s/100 iters), loss = 0.0320291
I0823 06:15:54.906383 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0320279 (* 1 = 0.0320279 loss)
I0823 06:15:54.906394 13823 sgd_solver.cpp:112] Iteration 470800, lr = 1e-06
I0823 06:16:05.981098 13823 solver.cpp:239] Iteration 470900 (9.02956 iter/s, 11.0747s/100 iters), loss = 0.026426
I0823 06:16:05.981154 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0264248 (* 1 = 0.0264248 loss)
I0823 06:16:05.981165 13823 sgd_solver.cpp:112] Iteration 470900, lr = 1e-06
I0823 06:16:16.980965 13823 solver.cpp:239] Iteration 471000 (9.09105 iter/s, 10.9998s/100 iters), loss = 0.0348915
I0823 06:16:16.981026 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0348903 (* 1 = 0.0348903 loss)
I0823 06:16:16.981039 13823 sgd_solver.cpp:112] Iteration 471000, lr = 1e-06
I0823 06:16:28.204249 13823 solver.cpp:239] Iteration 471100 (8.91005 iter/s, 11.2233s/100 iters), loss = 0.0383547
I0823 06:16:28.204294 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0383536 (* 1 = 0.0383536 loss)
I0823 06:16:28.204303 13823 sgd_solver.cpp:112] Iteration 471100, lr = 1e-06
I0823 06:16:39.172999 13823 solver.cpp:239] Iteration 471200 (9.11678 iter/s, 10.9688s/100 iters), loss = 0.0231019
I0823 06:16:39.173056 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0231008 (* 1 = 0.0231008 loss)
I0823 06:16:39.173068 13823 sgd_solver.cpp:112] Iteration 471200, lr = 1e-06
I0823 06:16:50.551578 13823 solver.cpp:239] Iteration 471300 (8.78842 iter/s, 11.3786s/100 iters), loss = 0.0303453
I0823 06:16:50.551635 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0303441 (* 1 = 0.0303441 loss)
I0823 06:16:50.551645 13823 sgd_solver.cpp:112] Iteration 471300, lr = 1e-06
I0823 06:17:01.667668 13823 solver.cpp:239] Iteration 471400 (8.99594 iter/s, 11.1161s/100 iters), loss = 0.0311895
I0823 06:17:01.667722 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0311883 (* 1 = 0.0311883 loss)
I0823 06:17:01.667733 13823 sgd_solver.cpp:112] Iteration 471400, lr = 1e-06
I0823 06:17:12.850859 13823 solver.cpp:239] Iteration 471500 (8.94197 iter/s, 11.1832s/100 iters), loss = 0.0290063
I0823 06:17:12.850911 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0290052 (* 1 = 0.0290052 loss)
I0823 06:17:12.850921 13823 sgd_solver.cpp:112] Iteration 471500, lr = 1e-06
I0823 06:17:24.175493 13823 solver.cpp:239] Iteration 471600 (8.83028 iter/s, 11.3247s/100 iters), loss = 0.0284408
I0823 06:17:24.175559 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0284396 (* 1 = 0.0284396 loss)
I0823 06:17:24.175572 13823 sgd_solver.cpp:112] Iteration 471600, lr = 1e-06
I0823 06:17:35.521342 13823 solver.cpp:239] Iteration 471700 (8.81378 iter/s, 11.3459s/100 iters), loss = 0.0262175
I0823 06:17:35.521392 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0262164 (* 1 = 0.0262164 loss)
I0823 06:17:35.521401 13823 sgd_solver.cpp:112] Iteration 471700, lr = 1e-06
I0823 06:17:46.720043 13823 solver.cpp:239] Iteration 471800 (8.92958 iter/s, 11.1987s/100 iters), loss = 0.029834
I0823 06:17:46.720099 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0298329 (* 1 = 0.0298329 loss)
I0823 06:17:46.720113 13823 sgd_solver.cpp:112] Iteration 471800, lr = 1e-06
I0823 06:17:57.870038 13823 solver.cpp:239] Iteration 471900 (8.96859 iter/s, 11.15s/100 iters), loss = 0.0239992
I0823 06:17:57.870095 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0239981 (* 1 = 0.0239981 loss)
I0823 06:17:57.870106 13823 sgd_solver.cpp:112] Iteration 471900, lr = 1e-06
I0823 06:18:09.437150 13823 solver.cpp:239] Iteration 472000 (8.64518 iter/s, 11.5671s/100 iters), loss = 0.0323218
I0823 06:18:09.437227 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0323207 (* 1 = 0.0323207 loss)
I0823 06:18:09.437245 13823 sgd_solver.cpp:112] Iteration 472000, lr = 1e-06
I0823 06:18:20.772361 13823 solver.cpp:239] Iteration 472100 (8.82206 iter/s, 11.3352s/100 iters), loss = 0.0459074
I0823 06:18:20.772409 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0459063 (* 1 = 0.0459063 loss)
I0823 06:18:20.772418 13823 sgd_solver.cpp:112] Iteration 472100, lr = 1e-06
I0823 06:18:31.441887 13823 solver.cpp:239] Iteration 472200 (9.37246 iter/s, 10.6696s/100 iters), loss = 0.0337642
I0823 06:18:31.441928 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0337631 (* 1 = 0.0337631 loss)
I0823 06:18:31.441936 13823 sgd_solver.cpp:112] Iteration 472200, lr = 1e-06
I0823 06:18:42.561498 13823 solver.cpp:239] Iteration 472300 (8.99309 iter/s, 11.1196s/100 iters), loss = 0.0259911
I0823 06:18:42.561556 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.02599 (* 1 = 0.02599 loss)
I0823 06:18:42.561570 13823 sgd_solver.cpp:112] Iteration 472300, lr = 1e-06
I0823 06:18:53.928794 13823 solver.cpp:239] Iteration 472400 (8.79715 iter/s, 11.3673s/100 iters), loss = 0.025548
I0823 06:18:53.928854 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0255469 (* 1 = 0.0255469 loss)
I0823 06:18:53.928867 13823 sgd_solver.cpp:112] Iteration 472400, lr = 1e-06
I0823 06:19:05.118690 13823 solver.cpp:239] Iteration 472500 (8.93662 iter/s, 11.1899s/100 iters), loss = 0.0231678
I0823 06:19:05.118754 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0231667 (* 1 = 0.0231667 loss)
I0823 06:19:05.118767 13823 sgd_solver.cpp:112] Iteration 472500, lr = 1e-06
I0823 06:19:16.663429 13823 solver.cpp:239] Iteration 472600 (8.66195 iter/s, 11.5448s/100 iters), loss = 0.0277697
I0823 06:19:16.663491 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0277686 (* 1 = 0.0277686 loss)
I0823 06:19:16.663506 13823 sgd_solver.cpp:112] Iteration 472600, lr = 1e-06
I0823 06:19:28.416966 13823 solver.cpp:239] Iteration 472700 (8.50806 iter/s, 11.7536s/100 iters), loss = 0.0285921
I0823 06:19:28.417017 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.028591 (* 1 = 0.028591 loss)
I0823 06:19:28.417027 13823 sgd_solver.cpp:112] Iteration 472700, lr = 1e-06
I0823 06:19:39.670549 13823 solver.cpp:239] Iteration 472800 (8.88604 iter/s, 11.2536s/100 iters), loss = 0.0245946
I0823 06:19:39.670610 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0245935 (* 1 = 0.0245935 loss)
I0823 06:19:39.670624 13823 sgd_solver.cpp:112] Iteration 472800, lr = 1e-06
I0823 06:19:51.070246 13823 solver.cpp:239] Iteration 472900 (8.77215 iter/s, 11.3997s/100 iters), loss = 0.0290489
I0823 06:19:51.070302 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0290478 (* 1 = 0.0290478 loss)
I0823 06:19:51.070312 13823 sgd_solver.cpp:112] Iteration 472900, lr = 1e-06
I0823 06:20:02.686126 13823 solver.cpp:239] Iteration 473000 (8.60889 iter/s, 11.6159s/100 iters), loss = 0.0290698
I0823 06:20:02.686195 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0290687 (* 1 = 0.0290687 loss)
I0823 06:20:02.686211 13823 sgd_solver.cpp:112] Iteration 473000, lr = 1e-06
I0823 06:20:14.443539 13823 solver.cpp:239] Iteration 473100 (8.50527 iter/s, 11.7574s/100 iters), loss = 0.0260136
I0823 06:20:14.443608 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0260125 (* 1 = 0.0260125 loss)
I0823 06:20:14.443624 13823 sgd_solver.cpp:112] Iteration 473100, lr = 1e-06
I0823 06:20:25.775918 13823 solver.cpp:239] Iteration 473200 (8.82427 iter/s, 11.3324s/100 iters), loss = 0.0279006
I0823 06:20:25.775982 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0278995 (* 1 = 0.0278995 loss)
I0823 06:20:25.775997 13823 sgd_solver.cpp:112] Iteration 473200, lr = 1e-06
I0823 06:20:37.405167 13823 solver.cpp:239] Iteration 473300 (8.599 iter/s, 11.6293s/100 iters), loss = 0.0277624
I0823 06:20:37.405228 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0277613 (* 1 = 0.0277613 loss)
I0823 06:20:37.405239 13823 sgd_solver.cpp:112] Iteration 473300, lr = 1e-06
I0823 06:20:48.911226 13823 solver.cpp:239] Iteration 473400 (8.69107 iter/s, 11.5061s/100 iters), loss = 0.0278292
I0823 06:20:48.911279 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0278281 (* 1 = 0.0278281 loss)
I0823 06:20:48.911289 13823 sgd_solver.cpp:112] Iteration 473400, lr = 1e-06
I0823 06:21:00.507992 13823 solver.cpp:239] Iteration 473500 (8.62308 iter/s, 11.5968s/100 iters), loss = 0.0253977
I0823 06:21:00.508042 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0253966 (* 1 = 0.0253966 loss)
I0823 06:21:00.508052 13823 sgd_solver.cpp:112] Iteration 473500, lr = 1e-06
I0823 06:21:12.028913 13823 solver.cpp:239] Iteration 473600 (8.67985 iter/s, 11.5209s/100 iters), loss = 0.0269767
I0823 06:21:12.028966 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0269756 (* 1 = 0.0269756 loss)
I0823 06:21:12.028977 13823 sgd_solver.cpp:112] Iteration 473600, lr = 1e-06
I0823 06:21:23.520401 13823 solver.cpp:239] Iteration 473700 (8.70208 iter/s, 11.4915s/100 iters), loss = 0.0285458
I0823 06:21:23.520440 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0285447 (* 1 = 0.0285447 loss)
I0823 06:21:23.520447 13823 sgd_solver.cpp:112] Iteration 473700, lr = 1e-06
I0823 06:21:35.011960 13823 solver.cpp:239] Iteration 473800 (8.70202 iter/s, 11.4916s/100 iters), loss = 0.0347616
I0823 06:21:35.012012 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0347605 (* 1 = 0.0347605 loss)
I0823 06:21:35.012022 13823 sgd_solver.cpp:112] Iteration 473800, lr = 1e-06
I0823 06:21:46.512426 13823 solver.cpp:239] Iteration 473900 (8.69529 iter/s, 11.5005s/100 iters), loss = 0.0276347
I0823 06:21:46.512485 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0276335 (* 1 = 0.0276335 loss)
I0823 06:21:46.512495 13823 sgd_solver.cpp:112] Iteration 473900, lr = 1e-06
I0823 06:21:58.244344 13823 solver.cpp:239] Iteration 474000 (8.52375 iter/s, 11.7319s/100 iters), loss = 0.0260859
I0823 06:21:58.244405 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0260848 (* 1 = 0.0260848 loss)
I0823 06:21:58.244415 13823 sgd_solver.cpp:112] Iteration 474000, lr = 1e-06
I0823 06:22:09.977607 13823 solver.cpp:239] Iteration 474100 (8.52277 iter/s, 11.7333s/100 iters), loss = 0.0268005
I0823 06:22:09.977659 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0267994 (* 1 = 0.0267994 loss)
I0823 06:22:09.977669 13823 sgd_solver.cpp:112] Iteration 474100, lr = 1e-06
I0823 06:22:21.718595 13823 solver.cpp:239] Iteration 474200 (8.51716 iter/s, 11.741s/100 iters), loss = 0.0291505
I0823 06:22:21.718652 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0291494 (* 1 = 0.0291494 loss)
I0823 06:22:21.718662 13823 sgd_solver.cpp:112] Iteration 474200, lr = 1e-06
I0823 06:22:33.221539 13823 solver.cpp:239] Iteration 474300 (8.69342 iter/s, 11.5029s/100 iters), loss = 0.0247414
I0823 06:22:33.221597 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0247403 (* 1 = 0.0247403 loss)
I0823 06:22:33.221609 13823 sgd_solver.cpp:112] Iteration 474300, lr = 1e-06
I0823 06:22:44.809201 13823 solver.cpp:239] Iteration 474400 (8.62987 iter/s, 11.5877s/100 iters), loss = 0.0252957
I0823 06:22:44.809258 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0252946 (* 1 = 0.0252946 loss)
I0823 06:22:44.809269 13823 sgd_solver.cpp:112] Iteration 474400, lr = 1e-06
I0823 06:22:56.354813 13823 solver.cpp:239] Iteration 474500 (8.6613 iter/s, 11.5456s/100 iters), loss = 0.0294071
I0823 06:22:56.354874 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.029406 (* 1 = 0.029406 loss)
I0823 06:22:56.354887 13823 sgd_solver.cpp:112] Iteration 474500, lr = 1e-06
I0823 06:23:07.671309 13823 solver.cpp:239] Iteration 474600 (8.83666 iter/s, 11.3165s/100 iters), loss = 0.0270665
I0823 06:23:07.671367 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0270654 (* 1 = 0.0270654 loss)
I0823 06:23:07.671377 13823 sgd_solver.cpp:112] Iteration 474600, lr = 1e-06
I0823 06:23:19.083581 13823 solver.cpp:239] Iteration 474700 (8.7625 iter/s, 11.4123s/100 iters), loss = 0.0290078
I0823 06:23:19.083637 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0290067 (* 1 = 0.0290067 loss)
I0823 06:23:19.083648 13823 sgd_solver.cpp:112] Iteration 474700, lr = 1e-06
I0823 06:23:29.708333 13823 solver.cpp:239] Iteration 474800 (9.41198 iter/s, 10.6248s/100 iters), loss = 0.0307388
I0823 06:23:29.708372 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0307377 (* 1 = 0.0307377 loss)
I0823 06:23:29.708379 13823 sgd_solver.cpp:112] Iteration 474800, lr = 1e-06
I0823 06:23:39.408921 13823 solver.cpp:239] Iteration 474900 (10.3086 iter/s, 9.70059s/100 iters), loss = 0.0252154
I0823 06:23:39.408970 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0252143 (* 1 = 0.0252143 loss)
I0823 06:23:39.408979 13823 sgd_solver.cpp:112] Iteration 474900, lr = 1e-06
I0823 06:23:48.753269 13823 solver.cpp:239] Iteration 475000 (10.7017 iter/s, 9.34435s/100 iters), loss = 0.02597
I0823 06:23:48.753322 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0259689 (* 1 = 0.0259689 loss)
I0823 06:23:48.753330 13823 sgd_solver.cpp:112] Iteration 475000, lr = 1e-06
I0823 06:23:58.164379 13823 solver.cpp:239] Iteration 475100 (10.6257 iter/s, 9.4111s/100 iters), loss = 0.0258062
I0823 06:23:58.164428 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0258051 (* 1 = 0.0258051 loss)
I0823 06:23:58.164438 13823 sgd_solver.cpp:112] Iteration 475100, lr = 1e-06
I0823 06:24:07.488488 13823 solver.cpp:239] Iteration 475200 (10.7249 iter/s, 9.32411s/100 iters), loss = 0.0255949
I0823 06:24:07.488531 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0255938 (* 1 = 0.0255938 loss)
I0823 06:24:07.488539 13823 sgd_solver.cpp:112] Iteration 475200, lr = 1e-06
I0823 06:24:16.663399 13823 solver.cpp:239] Iteration 475300 (10.8993 iter/s, 9.17492s/100 iters), loss = 0.0262261
I0823 06:24:16.663441 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.026225 (* 1 = 0.026225 loss)
I0823 06:24:16.663450 13823 sgd_solver.cpp:112] Iteration 475300, lr = 1e-06
I0823 06:24:25.918663 13823 solver.cpp:239] Iteration 475400 (10.8047 iter/s, 9.25527s/100 iters), loss = 0.0253454
I0823 06:24:25.918715 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0253443 (* 1 = 0.0253443 loss)
I0823 06:24:25.918721 13823 sgd_solver.cpp:112] Iteration 475400, lr = 1e-06
I0823 06:24:35.113821 13823 solver.cpp:239] Iteration 475500 (10.8753 iter/s, 9.19515s/100 iters), loss = 0.0360237
I0823 06:24:35.113873 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0360226 (* 1 = 0.0360226 loss)
I0823 06:24:35.113881 13823 sgd_solver.cpp:112] Iteration 475500, lr = 1e-06
I0823 06:24:44.600646 13823 solver.cpp:239] Iteration 475600 (10.5409 iter/s, 9.48681s/100 iters), loss = 0.0362321
I0823 06:24:44.600695 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.036231 (* 1 = 0.036231 loss)
I0823 06:24:44.600705 13823 sgd_solver.cpp:112] Iteration 475600, lr = 1e-06
I0823 06:24:53.834254 13823 solver.cpp:239] Iteration 475700 (10.83 iter/s, 9.2336s/100 iters), loss = 0.0285266
I0823 06:24:53.834295 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0285255 (* 1 = 0.0285255 loss)
I0823 06:24:53.834303 13823 sgd_solver.cpp:112] Iteration 475700, lr = 1e-06
I0823 06:25:03.374402 13823 solver.cpp:239] Iteration 475800 (10.482 iter/s, 9.54015s/100 iters), loss = 0.0314108
I0823 06:25:03.374442 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0314096 (* 1 = 0.0314096 loss)
I0823 06:25:03.374449 13823 sgd_solver.cpp:112] Iteration 475800, lr = 1e-06
I0823 06:25:12.702397 13823 solver.cpp:239] Iteration 475900 (10.7204 iter/s, 9.328s/100 iters), loss = 0.0248488
I0823 06:25:12.702438 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0248477 (* 1 = 0.0248477 loss)
I0823 06:25:12.702445 13823 sgd_solver.cpp:112] Iteration 475900, lr = 1e-06
I0823 06:25:22.560600 13823 solver.cpp:239] Iteration 476000 (10.1438 iter/s, 9.8582s/100 iters), loss = 0.0283451
I0823 06:25:22.560652 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.028344 (* 1 = 0.028344 loss)
I0823 06:25:22.560662 13823 sgd_solver.cpp:112] Iteration 476000, lr = 1e-06
I0823 06:25:31.920905 13823 solver.cpp:239] Iteration 476100 (10.6834 iter/s, 9.3603s/100 iters), loss = 0.0249848
I0823 06:25:31.920946 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0249837 (* 1 = 0.0249837 loss)
I0823 06:25:31.920953 13823 sgd_solver.cpp:112] Iteration 476100, lr = 1e-06
I0823 06:25:41.301051 13823 solver.cpp:239] Iteration 476200 (10.6608 iter/s, 9.38015s/100 iters), loss = 0.0314611
I0823 06:25:41.301092 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0314599 (* 1 = 0.0314599 loss)
I0823 06:25:41.301100 13823 sgd_solver.cpp:112] Iteration 476200, lr = 1e-06
I0823 06:25:50.969983 13823 solver.cpp:239] Iteration 476300 (10.3424 iter/s, 9.66894s/100 iters), loss = 0.0369735
I0823 06:25:50.970026 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0369724 (* 1 = 0.0369724 loss)
I0823 06:25:50.970033 13823 sgd_solver.cpp:112] Iteration 476300, lr = 1e-06
I0823 06:26:00.574744 13823 solver.cpp:239] Iteration 476400 (10.4115 iter/s, 9.60476s/100 iters), loss = 0.0267156
I0823 06:26:00.574796 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0267145 (* 1 = 0.0267145 loss)
I0823 06:26:00.574805 13823 sgd_solver.cpp:112] Iteration 476400, lr = 1e-06
I0823 06:26:10.190737 13823 solver.cpp:239] Iteration 476500 (10.3994 iter/s, 9.61598s/100 iters), loss = 0.0299948
I0823 06:26:10.190788 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0299937 (* 1 = 0.0299937 loss)
I0823 06:26:10.190798 13823 sgd_solver.cpp:112] Iteration 476500, lr = 1e-06
I0823 06:26:20.032140 13823 solver.cpp:239] Iteration 476600 (10.1612 iter/s, 9.84139s/100 iters), loss = 0.0287381
I0823 06:26:20.032191 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.028737 (* 1 = 0.028737 loss)
I0823 06:26:20.032200 13823 sgd_solver.cpp:112] Iteration 476600, lr = 1e-06
I0823 06:26:29.562364 13823 solver.cpp:239] Iteration 476700 (10.4929 iter/s, 9.53021s/100 iters), loss = 0.0244322
I0823 06:26:29.562413 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0244311 (* 1 = 0.0244311 loss)
I0823 06:26:29.562423 13823 sgd_solver.cpp:112] Iteration 476700, lr = 1e-06
I0823 06:26:39.395886 13823 solver.cpp:239] Iteration 476800 (10.1693 iter/s, 9.83351s/100 iters), loss = 0.0271875
I0823 06:26:39.395937 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0271864 (* 1 = 0.0271864 loss)
I0823 06:26:39.395947 13823 sgd_solver.cpp:112] Iteration 476800, lr = 1e-06
I0823 06:26:49.371392 13823 solver.cpp:239] Iteration 476900 (10.0246 iter/s, 9.9755s/100 iters), loss = 0.0305364
I0823 06:26:49.371443 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0305353 (* 1 = 0.0305353 loss)
I0823 06:26:49.371453 13823 sgd_solver.cpp:112] Iteration 476900, lr = 1e-06
I0823 06:26:59.192245 13823 solver.cpp:239] Iteration 477000 (10.1824 iter/s, 9.82084s/100 iters), loss = 0.0249206
I0823 06:26:59.192296 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0249195 (* 1 = 0.0249195 loss)
I0823 06:26:59.192306 13823 sgd_solver.cpp:112] Iteration 477000, lr = 1e-06
I0823 06:27:08.803122 13823 solver.cpp:239] Iteration 477100 (10.4049 iter/s, 9.61086s/100 iters), loss = 0.0241179
I0823 06:27:08.803170 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0241168 (* 1 = 0.0241168 loss)
I0823 06:27:08.803179 13823 sgd_solver.cpp:112] Iteration 477100, lr = 1e-06
I0823 06:27:18.520162 13823 solver.cpp:239] Iteration 477200 (10.2912 iter/s, 9.71703s/100 iters), loss = 0.033674
I0823 06:27:18.520222 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0336729 (* 1 = 0.0336729 loss)
I0823 06:27:18.520234 13823 sgd_solver.cpp:112] Iteration 477200, lr = 1e-06
I0823 06:27:28.421541 13823 solver.cpp:239] Iteration 477300 (10.0996 iter/s, 9.90136s/100 iters), loss = 0.0249808
I0823 06:27:28.421591 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0249797 (* 1 = 0.0249797 loss)
I0823 06:27:28.421600 13823 sgd_solver.cpp:112] Iteration 477300, lr = 1e-06
I0823 06:27:37.961737 13823 solver.cpp:239] Iteration 477400 (10.482 iter/s, 9.54019s/100 iters), loss = 0.0252879
I0823 06:27:37.961778 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0252868 (* 1 = 0.0252868 loss)
I0823 06:27:37.961786 13823 sgd_solver.cpp:112] Iteration 477400, lr = 1e-06
I0823 06:27:47.626394 13823 solver.cpp:239] Iteration 477500 (10.347 iter/s, 9.66465s/100 iters), loss = 0.0402784
I0823 06:27:47.626446 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0402773 (* 1 = 0.0402773 loss)
I0823 06:27:47.626456 13823 sgd_solver.cpp:112] Iteration 477500, lr = 1e-06
I0823 06:27:57.571738 13823 solver.cpp:239] Iteration 477600 (10.055 iter/s, 9.94533s/100 iters), loss = 0.026594
I0823 06:27:57.571789 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0265929 (* 1 = 0.0265929 loss)
I0823 06:27:57.571799 13823 sgd_solver.cpp:112] Iteration 477600, lr = 1e-06
I0823 06:28:07.357702 13823 solver.cpp:239] Iteration 477700 (10.2187 iter/s, 9.78595s/100 iters), loss = 0.0269418
I0823 06:28:07.357751 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0269407 (* 1 = 0.0269407 loss)
I0823 06:28:07.357761 13823 sgd_solver.cpp:112] Iteration 477700, lr = 1e-06
I0823 06:28:16.957820 13823 solver.cpp:239] Iteration 477800 (10.4166 iter/s, 9.60011s/100 iters), loss = 0.0287188
I0823 06:28:16.957870 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0287177 (* 1 = 0.0287177 loss)
I0823 06:28:16.957878 13823 sgd_solver.cpp:112] Iteration 477800, lr = 1e-06
I0823 06:28:26.392235 13823 solver.cpp:239] Iteration 477900 (10.5995 iter/s, 9.43441s/100 iters), loss = 0.0242723
I0823 06:28:26.392290 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0242712 (* 1 = 0.0242712 loss)
I0823 06:28:26.392298 13823 sgd_solver.cpp:112] Iteration 477900, lr = 1e-06
I0823 06:28:35.860538 13823 solver.cpp:239] Iteration 478000 (10.5616 iter/s, 9.46828s/100 iters), loss = 0.0280252
I0823 06:28:35.860589 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0280241 (* 1 = 0.0280241 loss)
I0823 06:28:35.860599 13823 sgd_solver.cpp:112] Iteration 478000, lr = 1e-06
I0823 06:28:45.810909 13823 solver.cpp:239] Iteration 478100 (10.0499 iter/s, 9.95036s/100 iters), loss = 0.0328103
I0823 06:28:45.810961 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0328092 (* 1 = 0.0328092 loss)
I0823 06:28:45.810971 13823 sgd_solver.cpp:112] Iteration 478100, lr = 1e-06
I0823 06:28:55.462571 13823 solver.cpp:239] Iteration 478200 (10.3609 iter/s, 9.65165s/100 iters), loss = 0.025713
I0823 06:28:55.462620 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0257119 (* 1 = 0.0257119 loss)
I0823 06:28:55.462630 13823 sgd_solver.cpp:112] Iteration 478200, lr = 1e-06
I0823 06:29:05.433277 13823 solver.cpp:239] Iteration 478300 (10.0294 iter/s, 9.97069s/100 iters), loss = 0.0366086
I0823 06:29:05.433331 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0366075 (* 1 = 0.0366075 loss)
I0823 06:29:05.433341 13823 sgd_solver.cpp:112] Iteration 478300, lr = 1e-06
I0823 06:29:15.392330 13823 solver.cpp:239] Iteration 478400 (10.0411 iter/s, 9.95904s/100 iters), loss = 0.0357351
I0823 06:29:15.392381 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.035734 (* 1 = 0.035734 loss)
I0823 06:29:15.392391 13823 sgd_solver.cpp:112] Iteration 478400, lr = 1e-06
I0823 06:29:25.097841 13823 solver.cpp:239] Iteration 478500 (10.3034 iter/s, 9.7055s/100 iters), loss = 0.0262381
I0823 06:29:25.097892 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.026237 (* 1 = 0.026237 loss)
I0823 06:29:25.097900 13823 sgd_solver.cpp:112] Iteration 478500, lr = 1e-06
I0823 06:29:35.002738 13823 solver.cpp:239] Iteration 478600 (10.096 iter/s, 9.90489s/100 iters), loss = 0.0247015
I0823 06:29:35.002781 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0247004 (* 1 = 0.0247004 loss)
I0823 06:29:35.002789 13823 sgd_solver.cpp:112] Iteration 478600, lr = 1e-06
I0823 06:29:44.967628 13823 solver.cpp:239] Iteration 478700 (10.0352 iter/s, 9.96488s/100 iters), loss = 0.0278001
I0823 06:29:44.967692 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0277989 (* 1 = 0.0277989 loss)
I0823 06:29:44.967705 13823 sgd_solver.cpp:112] Iteration 478700, lr = 1e-06
I0823 06:29:55.057462 13823 solver.cpp:239] Iteration 478800 (9.91099 iter/s, 10.0898s/100 iters), loss = 0.0295081
I0823 06:29:55.057520 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.029507 (* 1 = 0.029507 loss)
I0823 06:29:55.057530 13823 sgd_solver.cpp:112] Iteration 478800, lr = 1e-06
I0823 06:30:04.926065 13823 solver.cpp:239] Iteration 478900 (10.1332 iter/s, 9.86858s/100 iters), loss = 0.0264155
I0823 06:30:04.926115 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0264144 (* 1 = 0.0264144 loss)
I0823 06:30:04.926124 13823 sgd_solver.cpp:112] Iteration 478900, lr = 1e-06
I0823 06:30:14.458833 13823 solver.cpp:239] Iteration 479000 (10.4901 iter/s, 9.53276s/100 iters), loss = 0.0238541
I0823 06:30:14.458887 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.023853 (* 1 = 0.023853 loss)
I0823 06:30:14.458895 13823 sgd_solver.cpp:112] Iteration 479000, lr = 1e-06
I0823 06:30:24.041357 13823 solver.cpp:239] Iteration 479100 (10.4357 iter/s, 9.58251s/100 iters), loss = 0.0277035
I0823 06:30:24.041399 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0277024 (* 1 = 0.0277024 loss)
I0823 06:30:24.041405 13823 sgd_solver.cpp:112] Iteration 479100, lr = 1e-06
I0823 06:30:33.746361 13823 solver.cpp:239] Iteration 479200 (10.304 iter/s, 9.705s/100 iters), loss = 0.0276256
I0823 06:30:33.746402 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0276245 (* 1 = 0.0276245 loss)
I0823 06:30:33.746409 13823 sgd_solver.cpp:112] Iteration 479200, lr = 1e-06
I0823 06:30:43.545902 13823 solver.cpp:239] Iteration 479300 (10.2046 iter/s, 9.79954s/100 iters), loss = 0.0252429
I0823 06:30:43.545943 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0252418 (* 1 = 0.0252418 loss)
I0823 06:30:43.545949 13823 sgd_solver.cpp:112] Iteration 479300, lr = 1e-06
I0823 06:30:53.363085 13823 solver.cpp:239] Iteration 479400 (10.1862 iter/s, 9.81717s/100 iters), loss = 0.0297907
I0823 06:30:53.363135 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0297896 (* 1 = 0.0297896 loss)
I0823 06:30:53.363145 13823 sgd_solver.cpp:112] Iteration 479400, lr = 1e-06
I0823 06:31:03.507575 13823 solver.cpp:239] Iteration 479500 (9.85758 iter/s, 10.1445s/100 iters), loss = 0.0284742
I0823 06:31:03.507634 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0284731 (* 1 = 0.0284731 loss)
I0823 06:31:03.507645 13823 sgd_solver.cpp:112] Iteration 479500, lr = 1e-06
I0823 06:31:13.718415 13823 solver.cpp:239] Iteration 479600 (9.79354 iter/s, 10.2108s/100 iters), loss = 0.0250732
I0823 06:31:13.718478 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0250721 (* 1 = 0.0250721 loss)
I0823 06:31:13.718492 13823 sgd_solver.cpp:112] Iteration 479600, lr = 1e-06
I0823 06:31:23.758967 13823 solver.cpp:239] Iteration 479700 (9.95964 iter/s, 10.0405s/100 iters), loss = 0.0271237
I0823 06:31:23.759027 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0271226 (* 1 = 0.0271226 loss)
I0823 06:31:23.759039 13823 sgd_solver.cpp:112] Iteration 479700, lr = 1e-06
I0823 06:31:33.568361 13823 solver.cpp:239] Iteration 479800 (10.1943 iter/s, 9.80937s/100 iters), loss = 0.0339954
I0823 06:31:33.568410 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0339943 (* 1 = 0.0339943 loss)
I0823 06:31:33.568420 13823 sgd_solver.cpp:112] Iteration 479800, lr = 1e-06
I0823 06:31:43.381141 13823 solver.cpp:239] Iteration 479900 (10.1908 iter/s, 9.81277s/100 iters), loss = 0.0271085
I0823 06:31:43.381191 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0271073 (* 1 = 0.0271073 loss)
I0823 06:31:43.381199 13823 sgd_solver.cpp:112] Iteration 479900, lr = 1e-06
I0823 06:31:52.963289 13823 solver.cpp:464] Snapshotting to binary proto file ./model_112/cascade_mobilenet_112_iter_480000.caffemodel
I0823 06:31:53.007027 13823 sgd_solver.cpp:284] Snapshotting solver state to binary proto file ./model_112/cascade_mobilenet_112_iter_480000.solverstate
I0823 06:31:53.038357 13823 solver.cpp:347] Iteration 480000, Testing net (#0)
I0823 06:32:52.915617 13823 solver.cpp:414]     Test net output #0: landmark_loss = 0.021906 (* 1 = 0.021906 loss)
I0823 06:32:53.037173 13823 solver.cpp:239] Iteration 480000 (1.43562 iter/s, 69.6563s/100 iters), loss = 0.0284141
I0823 06:32:53.037225 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.028413 (* 1 = 0.028413 loss)
I0823 06:32:53.037240 13823 sgd_solver.cpp:112] Iteration 480000, lr = 1e-06
I0823 06:33:03.090025 13823 solver.cpp:239] Iteration 480100 (9.94744 iter/s, 10.0528s/100 iters), loss = 0.0290453
I0823 06:33:03.090077 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0290442 (* 1 = 0.0290442 loss)
I0823 06:33:03.090087 13823 sgd_solver.cpp:112] Iteration 480100, lr = 1e-06
I0823 06:33:13.237511 13823 solver.cpp:239] Iteration 480200 (9.85467 iter/s, 10.1475s/100 iters), loss = 0.0241785
I0823 06:33:13.237562 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0241774 (* 1 = 0.0241774 loss)
I0823 06:33:13.237572 13823 sgd_solver.cpp:112] Iteration 480200, lr = 1e-06
I0823 06:33:23.281985 13823 solver.cpp:239] Iteration 480300 (9.95574 iter/s, 10.0445s/100 iters), loss = 0.032806
I0823 06:33:23.282035 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0328048 (* 1 = 0.0328048 loss)
I0823 06:33:23.282044 13823 sgd_solver.cpp:112] Iteration 480300, lr = 1e-06
I0823 06:33:33.332353 13823 solver.cpp:239] Iteration 480400 (9.9499 iter/s, 10.0504s/100 iters), loss = 0.0285307
I0823 06:33:33.332406 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0285296 (* 1 = 0.0285296 loss)
I0823 06:33:33.332417 13823 sgd_solver.cpp:112] Iteration 480400, lr = 1e-06
I0823 06:33:43.700433 13823 solver.cpp:239] Iteration 480500 (9.645 iter/s, 10.3681s/100 iters), loss = 0.0266013
I0823 06:33:43.700481 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0266002 (* 1 = 0.0266002 loss)
I0823 06:33:43.700490 13823 sgd_solver.cpp:112] Iteration 480500, lr = 1e-06
I0823 06:33:54.076066 13823 solver.cpp:239] Iteration 480600 (9.63798 iter/s, 10.3756s/100 iters), loss = 0.0268484
I0823 06:33:54.076117 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0268473 (* 1 = 0.0268473 loss)
I0823 06:33:54.076126 13823 sgd_solver.cpp:112] Iteration 480600, lr = 1e-06
I0823 06:34:04.753489 13823 solver.cpp:239] Iteration 480700 (9.36557 iter/s, 10.6774s/100 iters), loss = 0.0237502
I0823 06:34:04.753540 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0237491 (* 1 = 0.0237491 loss)
I0823 06:34:04.753549 13823 sgd_solver.cpp:112] Iteration 480700, lr = 1e-06
I0823 06:34:14.951565 13823 solver.cpp:239] Iteration 480800 (9.80579 iter/s, 10.1981s/100 iters), loss = 0.0269497
I0823 06:34:14.951625 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0269486 (* 1 = 0.0269486 loss)
I0823 06:34:14.951637 13823 sgd_solver.cpp:112] Iteration 480800, lr = 1e-06
I0823 06:34:25.222470 13823 solver.cpp:239] Iteration 480900 (9.73626 iter/s, 10.2709s/100 iters), loss = 0.0266334
I0823 06:34:25.222522 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0266322 (* 1 = 0.0266322 loss)
I0823 06:34:25.222530 13823 sgd_solver.cpp:112] Iteration 480900, lr = 1e-06
I0823 06:34:35.470175 13823 solver.cpp:239] Iteration 481000 (9.7583 iter/s, 10.2477s/100 iters), loss = 0.0259911
I0823 06:34:35.470237 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0259899 (* 1 = 0.0259899 loss)
I0823 06:34:35.470249 13823 sgd_solver.cpp:112] Iteration 481000, lr = 1e-06
I0823 06:34:45.676304 13823 solver.cpp:239] Iteration 481100 (9.79806 iter/s, 10.2061s/100 iters), loss = 0.0234165
I0823 06:34:45.676353 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0234153 (* 1 = 0.0234153 loss)
I0823 06:34:45.676362 13823 sgd_solver.cpp:112] Iteration 481100, lr = 1e-06
I0823 06:34:56.044150 13823 solver.cpp:239] Iteration 481200 (9.64522 iter/s, 10.3678s/100 iters), loss = 0.0317377
I0823 06:34:56.044203 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0317366 (* 1 = 0.0317366 loss)
I0823 06:34:56.044212 13823 sgd_solver.cpp:112] Iteration 481200, lr = 1e-06
I0823 06:35:06.407286 13823 solver.cpp:239] Iteration 481300 (9.64961 iter/s, 10.3631s/100 iters), loss = 0.0233483
I0823 06:35:06.407344 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0233472 (* 1 = 0.0233472 loss)
I0823 06:35:06.407356 13823 sgd_solver.cpp:112] Iteration 481300, lr = 1e-06
I0823 06:35:16.780246 13823 solver.cpp:239] Iteration 481400 (9.64047 iter/s, 10.3729s/100 iters), loss = 0.024056
I0823 06:35:16.780305 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0240549 (* 1 = 0.0240549 loss)
I0823 06:35:16.780316 13823 sgd_solver.cpp:112] Iteration 481400, lr = 1e-06
I0823 06:35:27.078357 13823 solver.cpp:239] Iteration 481500 (9.71054 iter/s, 10.2981s/100 iters), loss = 0.0271022
I0823 06:35:27.078410 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.027101 (* 1 = 0.027101 loss)
I0823 06:35:27.078420 13823 sgd_solver.cpp:112] Iteration 481500, lr = 1e-06
I0823 06:35:37.117091 13823 solver.cpp:239] Iteration 481600 (9.96144 iter/s, 10.0387s/100 iters), loss = 0.0292372
I0823 06:35:37.117151 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0292361 (* 1 = 0.0292361 loss)
I0823 06:35:37.117163 13823 sgd_solver.cpp:112] Iteration 481600, lr = 1e-06
I0823 06:35:47.699687 13823 solver.cpp:239] Iteration 481700 (9.4495 iter/s, 10.5826s/100 iters), loss = 0.0263629
I0823 06:35:47.699745 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0263617 (* 1 = 0.0263617 loss)
I0823 06:35:47.699756 13823 sgd_solver.cpp:112] Iteration 481700, lr = 1e-06
I0823 06:35:58.138461 13823 solver.cpp:239] Iteration 481800 (9.57969 iter/s, 10.4387s/100 iters), loss = 0.0330363
I0823 06:35:58.138520 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0330352 (* 1 = 0.0330352 loss)
I0823 06:35:58.138532 13823 sgd_solver.cpp:112] Iteration 481800, lr = 1e-06
I0823 06:36:08.550535 13823 solver.cpp:239] Iteration 481900 (9.60426 iter/s, 10.412s/100 iters), loss = 0.0275851
I0823 06:36:08.550595 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.027584 (* 1 = 0.027584 loss)
I0823 06:36:08.550606 13823 sgd_solver.cpp:112] Iteration 481900, lr = 1e-06
I0823 06:36:18.959419 13823 solver.cpp:239] Iteration 482000 (9.6072 iter/s, 10.4089s/100 iters), loss = 0.0339966
I0823 06:36:18.959471 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0339954 (* 1 = 0.0339954 loss)
I0823 06:36:18.959481 13823 sgd_solver.cpp:112] Iteration 482000, lr = 1e-06
I0823 06:36:29.547811 13823 solver.cpp:239] Iteration 482100 (9.44432 iter/s, 10.5884s/100 iters), loss = 0.0284395
I0823 06:36:29.547869 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0284384 (* 1 = 0.0284384 loss)
I0823 06:36:29.547880 13823 sgd_solver.cpp:112] Iteration 482100, lr = 1e-06
I0823 06:36:39.952739 13823 solver.cpp:239] Iteration 482200 (9.61085 iter/s, 10.4049s/100 iters), loss = 0.0244648
I0823 06:36:39.952790 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0244636 (* 1 = 0.0244636 loss)
I0823 06:36:39.952797 13823 sgd_solver.cpp:112] Iteration 482200, lr = 1e-06
I0823 06:36:50.042804 13823 solver.cpp:239] Iteration 482300 (9.91076 iter/s, 10.09s/100 iters), loss = 0.0261104
I0823 06:36:50.042868 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0261093 (* 1 = 0.0261093 loss)
I0823 06:36:50.042881 13823 sgd_solver.cpp:112] Iteration 482300, lr = 1e-06
I0823 06:37:00.436375 13823 solver.cpp:239] Iteration 482400 (9.62136 iter/s, 10.3935s/100 iters), loss = 0.0282642
I0823 06:37:00.436439 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0282631 (* 1 = 0.0282631 loss)
I0823 06:37:00.436447 13823 sgd_solver.cpp:112] Iteration 482400, lr = 1e-06
I0823 06:37:10.685493 13823 solver.cpp:239] Iteration 482500 (9.75697 iter/s, 10.2491s/100 iters), loss = 0.0320213
I0823 06:37:10.685554 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0320202 (* 1 = 0.0320202 loss)
I0823 06:37:10.685564 13823 sgd_solver.cpp:112] Iteration 482500, lr = 1e-06
I0823 06:37:20.830440 13823 solver.cpp:239] Iteration 482600 (9.85715 iter/s, 10.1449s/100 iters), loss = 0.0246205
I0823 06:37:20.830488 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0246194 (* 1 = 0.0246194 loss)
I0823 06:37:20.830497 13823 sgd_solver.cpp:112] Iteration 482600, lr = 1e-06
I0823 06:37:31.266098 13823 solver.cpp:239] Iteration 482700 (9.58254 iter/s, 10.4356s/100 iters), loss = 0.0516267
I0823 06:37:31.266149 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0516256 (* 1 = 0.0516256 loss)
I0823 06:37:31.266158 13823 sgd_solver.cpp:112] Iteration 482700, lr = 1e-06
I0823 06:37:41.512219 13823 solver.cpp:239] Iteration 482800 (9.75981 iter/s, 10.2461s/100 iters), loss = 0.0247699
I0823 06:37:41.512276 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0247687 (* 1 = 0.0247687 loss)
I0823 06:37:41.512286 13823 sgd_solver.cpp:112] Iteration 482800, lr = 1e-06
I0823 06:37:51.848502 13823 solver.cpp:239] Iteration 482900 (9.67468 iter/s, 10.3363s/100 iters), loss = 0.0339843
I0823 06:37:51.848551 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0339832 (* 1 = 0.0339832 loss)
I0823 06:37:51.848560 13823 sgd_solver.cpp:112] Iteration 482900, lr = 1e-06
I0823 06:38:01.923034 13823 solver.cpp:239] Iteration 483000 (9.92604 iter/s, 10.0745s/100 iters), loss = 0.0262833
I0823 06:38:01.923082 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0262822 (* 1 = 0.0262822 loss)
I0823 06:38:01.923091 13823 sgd_solver.cpp:112] Iteration 483000, lr = 1e-06
I0823 06:38:12.129880 13823 solver.cpp:239] Iteration 483100 (9.79736 iter/s, 10.2068s/100 iters), loss = 0.0377961
I0823 06:38:12.129930 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0377949 (* 1 = 0.0377949 loss)
I0823 06:38:12.129940 13823 sgd_solver.cpp:112] Iteration 483100, lr = 1e-06
I0823 06:38:22.436404 13823 solver.cpp:239] Iteration 483200 (9.70261 iter/s, 10.3065s/100 iters), loss = 0.0254669
I0823 06:38:22.436455 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0254658 (* 1 = 0.0254658 loss)
I0823 06:38:22.436463 13823 sgd_solver.cpp:112] Iteration 483200, lr = 1e-06
I0823 06:38:32.983202 13823 solver.cpp:239] Iteration 483300 (9.48157 iter/s, 10.5468s/100 iters), loss = 0.02639
I0823 06:38:32.983249 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0263889 (* 1 = 0.0263889 loss)
I0823 06:38:32.983258 13823 sgd_solver.cpp:112] Iteration 483300, lr = 1e-06
I0823 06:38:43.239333 13823 solver.cpp:239] Iteration 483400 (9.75028 iter/s, 10.2561s/100 iters), loss = 0.0253684
I0823 06:38:43.239384 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0253673 (* 1 = 0.0253673 loss)
I0823 06:38:43.239394 13823 sgd_solver.cpp:112] Iteration 483400, lr = 1e-06
I0823 06:38:53.777335 13823 solver.cpp:239] Iteration 483500 (9.48948 iter/s, 10.538s/100 iters), loss = 0.0291338
I0823 06:38:53.777396 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0291327 (* 1 = 0.0291327 loss)
I0823 06:38:53.777408 13823 sgd_solver.cpp:112] Iteration 483500, lr = 1e-06
I0823 06:39:04.521994 13823 solver.cpp:239] Iteration 483600 (9.30697 iter/s, 10.7446s/100 iters), loss = 0.0340092
I0823 06:39:04.522044 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.034008 (* 1 = 0.034008 loss)
I0823 06:39:04.522054 13823 sgd_solver.cpp:112] Iteration 483600, lr = 1e-06
I0823 06:39:14.900092 13823 solver.cpp:239] Iteration 483700 (9.6357 iter/s, 10.3781s/100 iters), loss = 0.0303843
I0823 06:39:14.900153 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0303831 (* 1 = 0.0303831 loss)
I0823 06:39:14.900166 13823 sgd_solver.cpp:112] Iteration 483700, lr = 1e-06
I0823 06:39:25.133045 13823 solver.cpp:239] Iteration 483800 (9.77238 iter/s, 10.2329s/100 iters), loss = 0.0285936
I0823 06:39:25.133100 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0285924 (* 1 = 0.0285924 loss)
I0823 06:39:25.133111 13823 sgd_solver.cpp:112] Iteration 483800, lr = 1e-06
I0823 06:39:35.737097 13823 solver.cpp:239] Iteration 483900 (9.43038 iter/s, 10.604s/100 iters), loss = 0.0255721
I0823 06:39:35.737145 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.025571 (* 1 = 0.025571 loss)
I0823 06:39:35.737154 13823 sgd_solver.cpp:112] Iteration 483900, lr = 1e-06
I0823 06:39:46.376648 13823 solver.cpp:239] Iteration 484000 (9.39891 iter/s, 10.6395s/100 iters), loss = 0.0314138
I0823 06:39:46.376698 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0314126 (* 1 = 0.0314126 loss)
I0823 06:39:46.376708 13823 sgd_solver.cpp:112] Iteration 484000, lr = 1e-06
I0823 06:39:57.086472 13823 solver.cpp:239] Iteration 484100 (9.33724 iter/s, 10.7098s/100 iters), loss = 0.0274978
I0823 06:39:57.086526 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0274966 (* 1 = 0.0274966 loss)
I0823 06:39:57.086536 13823 sgd_solver.cpp:112] Iteration 484100, lr = 1e-06
I0823 06:40:07.963301 13823 solver.cpp:239] Iteration 484200 (9.19387 iter/s, 10.8768s/100 iters), loss = 0.0294807
I0823 06:40:07.963358 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0294795 (* 1 = 0.0294795 loss)
I0823 06:40:07.963369 13823 sgd_solver.cpp:112] Iteration 484200, lr = 1e-06
I0823 06:40:18.546413 13823 solver.cpp:239] Iteration 484300 (9.44904 iter/s, 10.5831s/100 iters), loss = 0.0303783
I0823 06:40:18.546463 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0303771 (* 1 = 0.0303771 loss)
I0823 06:40:18.546471 13823 sgd_solver.cpp:112] Iteration 484300, lr = 1e-06
I0823 06:40:29.459681 13823 solver.cpp:239] Iteration 484400 (9.16317 iter/s, 10.9133s/100 iters), loss = 0.02826
I0823 06:40:29.459731 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0282588 (* 1 = 0.0282588 loss)
I0823 06:40:29.459740 13823 sgd_solver.cpp:112] Iteration 484400, lr = 1e-06
I0823 06:40:39.972726 13823 solver.cpp:239] Iteration 484500 (9.51201 iter/s, 10.513s/100 iters), loss = 0.0311578
I0823 06:40:39.972779 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0311566 (* 1 = 0.0311566 loss)
I0823 06:40:39.972787 13823 sgd_solver.cpp:112] Iteration 484500, lr = 1e-06
I0823 06:40:50.683830 13823 solver.cpp:239] Iteration 484600 (9.33612 iter/s, 10.7111s/100 iters), loss = 0.0279977
I0823 06:40:50.683881 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0279965 (* 1 = 0.0279965 loss)
I0823 06:40:50.683890 13823 sgd_solver.cpp:112] Iteration 484600, lr = 1e-06
I0823 06:41:01.669842 13823 solver.cpp:239] Iteration 484700 (9.1025 iter/s, 10.986s/100 iters), loss = 0.0253262
I0823 06:41:01.669890 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.025325 (* 1 = 0.025325 loss)
I0823 06:41:01.669899 13823 sgd_solver.cpp:112] Iteration 484700, lr = 1e-06
I0823 06:41:12.281769 13823 solver.cpp:239] Iteration 484800 (9.42338 iter/s, 10.6119s/100 iters), loss = 0.0427747
I0823 06:41:12.281817 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0427736 (* 1 = 0.0427736 loss)
I0823 06:41:12.281826 13823 sgd_solver.cpp:112] Iteration 484800, lr = 1e-06
I0823 06:41:23.029810 13823 solver.cpp:239] Iteration 484900 (9.30404 iter/s, 10.748s/100 iters), loss = 0.0238512
I0823 06:41:23.029862 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.02385 (* 1 = 0.02385 loss)
I0823 06:41:23.029872 13823 sgd_solver.cpp:112] Iteration 484900, lr = 1e-06
I0823 06:41:33.800487 13823 solver.cpp:239] Iteration 485000 (9.28449 iter/s, 10.7707s/100 iters), loss = 0.02395
I0823 06:41:33.800540 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0239488 (* 1 = 0.0239488 loss)
I0823 06:41:33.800550 13823 sgd_solver.cpp:112] Iteration 485000, lr = 1e-06
I0823 06:41:44.639827 13823 solver.cpp:239] Iteration 485100 (9.22567 iter/s, 10.8393s/100 iters), loss = 0.024031
I0823 06:41:44.639878 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0240298 (* 1 = 0.0240298 loss)
I0823 06:41:44.639888 13823 sgd_solver.cpp:112] Iteration 485100, lr = 1e-06
I0823 06:41:55.456629 13823 solver.cpp:239] Iteration 485200 (9.24489 iter/s, 10.8168s/100 iters), loss = 0.0417166
I0823 06:41:55.456679 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0417154 (* 1 = 0.0417154 loss)
I0823 06:41:55.456688 13823 sgd_solver.cpp:112] Iteration 485200, lr = 1e-06
I0823 06:42:06.095069 13823 solver.cpp:239] Iteration 485300 (9.39989 iter/s, 10.6384s/100 iters), loss = 0.0273385
I0823 06:42:06.095124 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0273373 (* 1 = 0.0273373 loss)
I0823 06:42:06.095134 13823 sgd_solver.cpp:112] Iteration 485300, lr = 1e-06
I0823 06:42:16.845479 13823 solver.cpp:239] Iteration 485400 (9.30199 iter/s, 10.7504s/100 iters), loss = 0.0239
I0823 06:42:16.845540 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0238988 (* 1 = 0.0238988 loss)
I0823 06:42:16.845551 13823 sgd_solver.cpp:112] Iteration 485400, lr = 1e-06
I0823 06:42:27.839625 13823 solver.cpp:239] Iteration 485500 (9.09577 iter/s, 10.9941s/100 iters), loss = 0.0318253
I0823 06:42:27.839673 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0318241 (* 1 = 0.0318241 loss)
I0823 06:42:27.839682 13823 sgd_solver.cpp:112] Iteration 485500, lr = 1e-06
I0823 06:42:38.714686 13823 solver.cpp:239] Iteration 485600 (9.19537 iter/s, 10.875s/100 iters), loss = 0.0251495
I0823 06:42:38.714743 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0251483 (* 1 = 0.0251483 loss)
I0823 06:42:38.714754 13823 sgd_solver.cpp:112] Iteration 485600, lr = 1e-06
I0823 06:42:49.658550 13823 solver.cpp:239] Iteration 485700 (9.13756 iter/s, 10.9438s/100 iters), loss = 0.0320538
I0823 06:42:49.658603 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0320526 (* 1 = 0.0320526 loss)
I0823 06:42:49.658612 13823 sgd_solver.cpp:112] Iteration 485700, lr = 1e-06
I0823 06:43:00.260052 13823 solver.cpp:239] Iteration 485800 (9.43264 iter/s, 10.6015s/100 iters), loss = 0.0338893
I0823 06:43:00.260103 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0338881 (* 1 = 0.0338881 loss)
I0823 06:43:00.260113 13823 sgd_solver.cpp:112] Iteration 485800, lr = 1e-06
I0823 06:43:11.251880 13823 solver.cpp:239] Iteration 485900 (9.09768 iter/s, 10.9918s/100 iters), loss = 0.0244297
I0823 06:43:11.251938 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0244286 (* 1 = 0.0244286 loss)
I0823 06:43:11.251950 13823 sgd_solver.cpp:112] Iteration 485900, lr = 1e-06
I0823 06:43:22.043277 13823 solver.cpp:239] Iteration 486000 (9.26666 iter/s, 10.7914s/100 iters), loss = 0.0271107
I0823 06:43:22.043328 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0271096 (* 1 = 0.0271096 loss)
I0823 06:43:22.043337 13823 sgd_solver.cpp:112] Iteration 486000, lr = 1e-06
I0823 06:43:32.979342 13823 solver.cpp:239] Iteration 486100 (9.14407 iter/s, 10.936s/100 iters), loss = 0.0381868
I0823 06:43:32.979393 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0381856 (* 1 = 0.0381856 loss)
I0823 06:43:32.979403 13823 sgd_solver.cpp:112] Iteration 486100, lr = 1e-06
I0823 06:43:43.913250 13823 solver.cpp:239] Iteration 486200 (9.14588 iter/s, 10.9339s/100 iters), loss = 0.0255151
I0823 06:43:43.913303 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.025514 (* 1 = 0.025514 loss)
I0823 06:43:43.913313 13823 sgd_solver.cpp:112] Iteration 486200, lr = 1e-06
I0823 06:43:54.683236 13823 solver.cpp:239] Iteration 486300 (9.28508 iter/s, 10.77s/100 iters), loss = 0.0271574
I0823 06:43:54.683285 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0271562 (* 1 = 0.0271562 loss)
I0823 06:43:54.683295 13823 sgd_solver.cpp:112] Iteration 486300, lr = 1e-06
I0823 06:44:05.787801 13823 solver.cpp:239] Iteration 486400 (9.00532 iter/s, 11.1045s/100 iters), loss = 0.0272158
I0823 06:44:05.787854 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0272146 (* 1 = 0.0272146 loss)
I0823 06:44:05.787863 13823 sgd_solver.cpp:112] Iteration 486400, lr = 1e-06
I0823 06:44:16.651319 13823 solver.cpp:239] Iteration 486500 (9.20514 iter/s, 10.8635s/100 iters), loss = 0.0256874
I0823 06:44:16.651368 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0256862 (* 1 = 0.0256862 loss)
I0823 06:44:16.651377 13823 sgd_solver.cpp:112] Iteration 486500, lr = 1e-06
I0823 06:44:27.340082 13823 solver.cpp:239] Iteration 486600 (9.35563 iter/s, 10.6887s/100 iters), loss = 0.0242511
I0823 06:44:27.340139 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0242499 (* 1 = 0.0242499 loss)
I0823 06:44:27.340149 13823 sgd_solver.cpp:112] Iteration 486600, lr = 1e-06
I0823 06:44:38.314635 13823 solver.cpp:239] Iteration 486700 (9.11201 iter/s, 10.9745s/100 iters), loss = 0.0233626
I0823 06:44:38.314684 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0233614 (* 1 = 0.0233614 loss)
I0823 06:44:38.314693 13823 sgd_solver.cpp:112] Iteration 486700, lr = 1e-06
I0823 06:44:49.619556 13823 solver.cpp:239] Iteration 486800 (8.84572 iter/s, 11.3049s/100 iters), loss = 0.0252779
I0823 06:44:49.619621 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0252768 (* 1 = 0.0252768 loss)
I0823 06:44:49.619634 13823 sgd_solver.cpp:112] Iteration 486800, lr = 1e-06
I0823 06:45:00.592849 13823 solver.cpp:239] Iteration 486900 (9.11306 iter/s, 10.9733s/100 iters), loss = 0.0260212
I0823 06:45:00.592900 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.02602 (* 1 = 0.02602 loss)
I0823 06:45:00.592911 13823 sgd_solver.cpp:112] Iteration 486900, lr = 1e-06
I0823 06:45:11.716576 13823 solver.cpp:239] Iteration 487000 (8.98981 iter/s, 11.1237s/100 iters), loss = 0.0263617
I0823 06:45:11.716634 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0263605 (* 1 = 0.0263605 loss)
I0823 06:45:11.716645 13823 sgd_solver.cpp:112] Iteration 487000, lr = 1e-06
I0823 06:45:22.688669 13823 solver.cpp:239] Iteration 487100 (9.11405 iter/s, 10.9721s/100 iters), loss = 0.0263705
I0823 06:45:22.688719 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0263693 (* 1 = 0.0263693 loss)
I0823 06:45:22.688729 13823 sgd_solver.cpp:112] Iteration 487100, lr = 1e-06
I0823 06:45:33.602077 13823 solver.cpp:239] Iteration 487200 (9.16306 iter/s, 10.9134s/100 iters), loss = 0.0257233
I0823 06:45:33.602138 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.025722 (* 1 = 0.025722 loss)
I0823 06:45:33.602149 13823 sgd_solver.cpp:112] Iteration 487200, lr = 1e-06
I0823 06:45:44.484892 13823 solver.cpp:239] Iteration 487300 (9.18882 iter/s, 10.8828s/100 iters), loss = 0.0273505
I0823 06:45:44.484944 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0273492 (* 1 = 0.0273492 loss)
I0823 06:45:44.484954 13823 sgd_solver.cpp:112] Iteration 487300, lr = 1e-06
I0823 06:45:55.333854 13823 solver.cpp:239] Iteration 487400 (9.21749 iter/s, 10.8489s/100 iters), loss = 0.0256416
I0823 06:45:55.333904 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0256404 (* 1 = 0.0256404 loss)
I0823 06:45:55.333914 13823 sgd_solver.cpp:112] Iteration 487400, lr = 1e-06
I0823 06:46:06.385975 13823 solver.cpp:239] Iteration 487500 (9.04805 iter/s, 11.0521s/100 iters), loss = 0.0264721
I0823 06:46:06.386037 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0264709 (* 1 = 0.0264709 loss)
I0823 06:46:06.386049 13823 sgd_solver.cpp:112] Iteration 487500, lr = 1e-06
I0823 06:46:16.955410 13823 solver.cpp:239] Iteration 487600 (9.46127 iter/s, 10.5694s/100 iters), loss = 0.0371911
I0823 06:46:16.955467 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0371899 (* 1 = 0.0371899 loss)
I0823 06:46:16.955478 13823 sgd_solver.cpp:112] Iteration 487600, lr = 1e-06
I0823 06:46:27.870491 13823 solver.cpp:239] Iteration 487700 (9.16166 iter/s, 10.9151s/100 iters), loss = 0.0255476
I0823 06:46:27.870543 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0255464 (* 1 = 0.0255464 loss)
I0823 06:46:27.870553 13823 sgd_solver.cpp:112] Iteration 487700, lr = 1e-06
I0823 06:46:38.643443 13823 solver.cpp:239] Iteration 487800 (9.28253 iter/s, 10.7729s/100 iters), loss = 0.0237637
I0823 06:46:38.643491 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0237625 (* 1 = 0.0237625 loss)
I0823 06:46:38.643501 13823 sgd_solver.cpp:112] Iteration 487800, lr = 1e-06
I0823 06:46:49.729799 13823 solver.cpp:239] Iteration 487900 (9.02011 iter/s, 11.0863s/100 iters), loss = 0.02516
I0823 06:46:49.729851 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0251587 (* 1 = 0.0251587 loss)
I0823 06:46:49.729861 13823 sgd_solver.cpp:112] Iteration 487900, lr = 1e-06
I0823 06:47:00.581326 13823 solver.cpp:239] Iteration 488000 (9.21531 iter/s, 10.8515s/100 iters), loss = 0.0361221
I0823 06:47:00.581388 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0361208 (* 1 = 0.0361208 loss)
I0823 06:47:00.581401 13823 sgd_solver.cpp:112] Iteration 488000, lr = 1e-06
I0823 06:47:11.434265 13823 solver.cpp:239] Iteration 488100 (9.21412 iter/s, 10.8529s/100 iters), loss = 0.0223263
I0823 06:47:11.434327 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0223251 (* 1 = 0.0223251 loss)
I0823 06:47:11.434340 13823 sgd_solver.cpp:112] Iteration 488100, lr = 1e-06
I0823 06:47:22.721957 13823 solver.cpp:239] Iteration 488200 (8.85923 iter/s, 11.2877s/100 iters), loss = 0.0336973
I0823 06:47:22.722015 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.033696 (* 1 = 0.033696 loss)
I0823 06:47:22.722026 13823 sgd_solver.cpp:112] Iteration 488200, lr = 1e-06
I0823 06:47:34.235837 13823 solver.cpp:239] Iteration 488300 (8.68519 iter/s, 11.5139s/100 iters), loss = 0.0249101
I0823 06:47:34.235898 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0249089 (* 1 = 0.0249089 loss)
I0823 06:47:34.235909 13823 sgd_solver.cpp:112] Iteration 488300, lr = 1e-06
I0823 06:47:45.270212 13823 solver.cpp:239] Iteration 488400 (9.06261 iter/s, 11.0343s/100 iters), loss = 0.0248138
I0823 06:47:45.270263 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0248125 (* 1 = 0.0248125 loss)
I0823 06:47:45.270273 13823 sgd_solver.cpp:112] Iteration 488400, lr = 1e-06
I0823 06:47:56.232367 13823 solver.cpp:239] Iteration 488500 (9.12231 iter/s, 10.9621s/100 iters), loss = 0.024979
I0823 06:47:56.232417 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0249778 (* 1 = 0.0249778 loss)
I0823 06:47:56.232426 13823 sgd_solver.cpp:112] Iteration 488500, lr = 1e-06
I0823 06:48:07.396558 13823 solver.cpp:239] Iteration 488600 (8.95723 iter/s, 11.1642s/100 iters), loss = 0.0379789
I0823 06:48:07.396605 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0379777 (* 1 = 0.0379777 loss)
I0823 06:48:07.396615 13823 sgd_solver.cpp:112] Iteration 488600, lr = 1e-06
I0823 06:48:18.583734 13823 solver.cpp:239] Iteration 488700 (8.93882 iter/s, 11.1872s/100 iters), loss = 0.0376434
I0823 06:48:18.583786 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0376422 (* 1 = 0.0376422 loss)
I0823 06:48:18.583794 13823 sgd_solver.cpp:112] Iteration 488700, lr = 1e-06
I0823 06:48:29.316756 13823 solver.cpp:239] Iteration 488800 (9.31706 iter/s, 10.733s/100 iters), loss = 0.0253626
I0823 06:48:29.316810 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0253614 (* 1 = 0.0253614 loss)
I0823 06:48:29.316821 13823 sgd_solver.cpp:112] Iteration 488800, lr = 1e-06
I0823 06:48:40.427184 13823 solver.cpp:239] Iteration 488900 (9.00057 iter/s, 11.1104s/100 iters), loss = 0.0276589
I0823 06:48:40.427232 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0276577 (* 1 = 0.0276577 loss)
I0823 06:48:40.427242 13823 sgd_solver.cpp:112] Iteration 488900, lr = 1e-06
I0823 06:48:51.502655 13823 solver.cpp:239] Iteration 489000 (9.02898 iter/s, 11.0755s/100 iters), loss = 0.0260505
I0823 06:48:51.502714 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0260493 (* 1 = 0.0260493 loss)
I0823 06:48:51.502727 13823 sgd_solver.cpp:112] Iteration 489000, lr = 1e-06
I0823 06:49:02.701261 13823 solver.cpp:239] Iteration 489100 (8.9297 iter/s, 11.1986s/100 iters), loss = 0.0488607
I0823 06:49:02.701310 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0488595 (* 1 = 0.0488595 loss)
I0823 06:49:02.701319 13823 sgd_solver.cpp:112] Iteration 489100, lr = 1e-06
I0823 06:49:13.582072 13823 solver.cpp:239] Iteration 489200 (9.19051 iter/s, 10.8808s/100 iters), loss = 0.0267733
I0823 06:49:13.582130 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0267721 (* 1 = 0.0267721 loss)
I0823 06:49:13.582141 13823 sgd_solver.cpp:112] Iteration 489200, lr = 1e-06
I0823 06:49:24.720414 13823 solver.cpp:239] Iteration 489300 (8.97802 iter/s, 11.1383s/100 iters), loss = 0.0303318
I0823 06:49:24.720463 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0303306 (* 1 = 0.0303306 loss)
I0823 06:49:24.720472 13823 sgd_solver.cpp:112] Iteration 489300, lr = 1e-06
I0823 06:49:35.676424 13823 solver.cpp:239] Iteration 489400 (9.12743 iter/s, 10.956s/100 iters), loss = 0.0248348
I0823 06:49:35.676476 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0248336 (* 1 = 0.0248336 loss)
I0823 06:49:35.676486 13823 sgd_solver.cpp:112] Iteration 489400, lr = 1e-06
I0823 06:49:46.693388 13823 solver.cpp:239] Iteration 489500 (9.07693 iter/s, 11.0169s/100 iters), loss = 0.0324014
I0823 06:49:46.693444 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0324001 (* 1 = 0.0324001 loss)
I0823 06:49:46.693455 13823 sgd_solver.cpp:112] Iteration 489500, lr = 1e-06
I0823 06:49:57.779722 13823 solver.cpp:239] Iteration 489600 (9.02014 iter/s, 11.0863s/100 iters), loss = 0.0275212
I0823 06:49:57.779803 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.02752 (* 1 = 0.02752 loss)
I0823 06:49:57.779816 13823 sgd_solver.cpp:112] Iteration 489600, lr = 1e-06
I0823 06:50:09.174088 13823 solver.cpp:239] Iteration 489700 (8.7763 iter/s, 11.3943s/100 iters), loss = 0.0268759
I0823 06:50:09.174142 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0268746 (* 1 = 0.0268746 loss)
I0823 06:50:09.174154 13823 sgd_solver.cpp:112] Iteration 489700, lr = 1e-06
I0823 06:50:20.583003 13823 solver.cpp:239] Iteration 489800 (8.76509 iter/s, 11.4089s/100 iters), loss = 0.0221647
I0823 06:50:20.583055 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0221635 (* 1 = 0.0221635 loss)
I0823 06:50:20.583063 13823 sgd_solver.cpp:112] Iteration 489800, lr = 1e-06
I0823 06:50:31.933609 13823 solver.cpp:239] Iteration 489900 (8.81012 iter/s, 11.3506s/100 iters), loss = 0.0269103
I0823 06:50:31.933657 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0269091 (* 1 = 0.0269091 loss)
I0823 06:50:31.933666 13823 sgd_solver.cpp:112] Iteration 489900, lr = 1e-06
I0823 06:50:42.832691 13823 solver.cpp:239] Iteration 490000 (9.17513 iter/s, 10.899s/100 iters), loss = 0.025546
I0823 06:50:42.832741 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0255448 (* 1 = 0.0255448 loss)
I0823 06:50:42.832751 13823 sgd_solver.cpp:112] Iteration 490000, lr = 1e-06
I0823 06:50:54.339392 13823 solver.cpp:239] Iteration 490100 (8.69063 iter/s, 11.5066s/100 iters), loss = 0.0255122
I0823 06:50:54.339452 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.025511 (* 1 = 0.025511 loss)
I0823 06:50:54.339463 13823 sgd_solver.cpp:112] Iteration 490100, lr = 1e-06
I0823 06:51:05.395159 13823 solver.cpp:239] Iteration 490200 (9.0451 iter/s, 11.0557s/100 iters), loss = 0.0369771
I0823 06:51:05.395215 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.036976 (* 1 = 0.036976 loss)
I0823 06:51:05.395226 13823 sgd_solver.cpp:112] Iteration 490200, lr = 1e-06
I0823 06:51:16.638497 13823 solver.cpp:239] Iteration 490300 (8.8942 iter/s, 11.2433s/100 iters), loss = 0.0280328
I0823 06:51:16.638546 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0280316 (* 1 = 0.0280316 loss)
I0823 06:51:16.638556 13823 sgd_solver.cpp:112] Iteration 490300, lr = 1e-06
I0823 06:51:27.819201 13823 solver.cpp:239] Iteration 490400 (8.94402 iter/s, 11.1807s/100 iters), loss = 0.0273009
I0823 06:51:27.819252 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0272997 (* 1 = 0.0272997 loss)
I0823 06:51:27.819260 13823 sgd_solver.cpp:112] Iteration 490400, lr = 1e-06
I0823 06:51:39.174190 13823 solver.cpp:239] Iteration 490500 (8.80674 iter/s, 11.3549s/100 iters), loss = 0.0275798
I0823 06:51:39.174243 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0275786 (* 1 = 0.0275786 loss)
I0823 06:51:39.174253 13823 sgd_solver.cpp:112] Iteration 490500, lr = 1e-06
I0823 06:51:50.204183 13823 solver.cpp:239] Iteration 490600 (9.06623 iter/s, 11.0299s/100 iters), loss = 0.026292
I0823 06:51:50.204237 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0262908 (* 1 = 0.0262908 loss)
I0823 06:51:50.204247 13823 sgd_solver.cpp:112] Iteration 490600, lr = 1e-06
I0823 06:52:01.750349 13823 solver.cpp:239] Iteration 490700 (8.66093 iter/s, 11.5461s/100 iters), loss = 0.0301232
I0823 06:52:01.750407 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.030122 (* 1 = 0.030122 loss)
I0823 06:52:01.750418 13823 sgd_solver.cpp:112] Iteration 490700, lr = 1e-06
I0823 06:52:13.227241 13823 solver.cpp:239] Iteration 490800 (8.7132 iter/s, 11.4768s/100 iters), loss = 0.0299334
I0823 06:52:13.227291 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0299322 (* 1 = 0.0299322 loss)
I0823 06:52:13.227300 13823 sgd_solver.cpp:112] Iteration 490800, lr = 1e-06
I0823 06:52:24.972234 13823 solver.cpp:239] Iteration 490900 (8.5143 iter/s, 11.7449s/100 iters), loss = 0.038837
I0823 06:52:24.972302 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0388358 (* 1 = 0.0388358 loss)
I0823 06:52:24.972316 13823 sgd_solver.cpp:112] Iteration 490900, lr = 1e-06
I0823 06:52:36.401574 13823 solver.cpp:239] Iteration 491000 (8.74946 iter/s, 11.4293s/100 iters), loss = 0.0260531
I0823 06:52:36.401633 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0260519 (* 1 = 0.0260519 loss)
I0823 06:52:36.401644 13823 sgd_solver.cpp:112] Iteration 491000, lr = 1e-06
I0823 06:52:47.811547 13823 solver.cpp:239] Iteration 491100 (8.76431 iter/s, 11.4099s/100 iters), loss = 0.204343
I0823 06:52:47.811609 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.204342 (* 1 = 0.204342 loss)
I0823 06:52:47.811621 13823 sgd_solver.cpp:112] Iteration 491100, lr = 1e-06
I0823 06:52:59.481945 13823 solver.cpp:239] Iteration 491200 (8.56873 iter/s, 11.6703s/100 iters), loss = 0.0312199
I0823 06:52:59.482000 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0312187 (* 1 = 0.0312187 loss)
I0823 06:52:59.482012 13823 sgd_solver.cpp:112] Iteration 491200, lr = 1e-06
I0823 06:53:10.957114 13823 solver.cpp:239] Iteration 491300 (8.71451 iter/s, 11.4751s/100 iters), loss = 0.0472581
I0823 06:53:10.957175 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.047257 (* 1 = 0.047257 loss)
I0823 06:53:10.957186 13823 sgd_solver.cpp:112] Iteration 491300, lr = 1e-06
I0823 06:53:22.379849 13823 solver.cpp:239] Iteration 491400 (8.75451 iter/s, 11.4227s/100 iters), loss = 0.0257953
I0823 06:53:22.379904 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0257941 (* 1 = 0.0257941 loss)
I0823 06:53:22.379914 13823 sgd_solver.cpp:112] Iteration 491400, lr = 1e-06
I0823 06:53:34.059482 13823 solver.cpp:239] Iteration 491500 (8.56195 iter/s, 11.6796s/100 iters), loss = 0.0256771
I0823 06:53:34.059542 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0256759 (* 1 = 0.0256759 loss)
I0823 06:53:34.059554 13823 sgd_solver.cpp:112] Iteration 491500, lr = 1e-06
I0823 06:53:45.705123 13823 solver.cpp:239] Iteration 491600 (8.58695 iter/s, 11.6456s/100 iters), loss = 0.0333974
I0823 06:53:45.705185 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0333962 (* 1 = 0.0333962 loss)
I0823 06:53:45.705197 13823 sgd_solver.cpp:112] Iteration 491600, lr = 1e-06
I0823 06:53:57.293720 13823 solver.cpp:239] Iteration 491700 (8.62921 iter/s, 11.5885s/100 iters), loss = 0.0268518
I0823 06:53:57.293772 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0268506 (* 1 = 0.0268506 loss)
I0823 06:53:57.293782 13823 sgd_solver.cpp:112] Iteration 491700, lr = 1e-06
I0823 06:54:08.960175 13823 solver.cpp:239] Iteration 491800 (8.57162 iter/s, 11.6664s/100 iters), loss = 0.0254389
I0823 06:54:08.960233 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0254377 (* 1 = 0.0254377 loss)
I0823 06:54:08.960244 13823 sgd_solver.cpp:112] Iteration 491800, lr = 1e-06
I0823 06:54:20.611551 13823 solver.cpp:239] Iteration 491900 (8.58272 iter/s, 11.6513s/100 iters), loss = 0.0281033
I0823 06:54:20.611609 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0281021 (* 1 = 0.0281021 loss)
I0823 06:54:20.611620 13823 sgd_solver.cpp:112] Iteration 491900, lr = 1e-06
I0823 06:54:32.341048 13823 solver.cpp:239] Iteration 492000 (8.52555 iter/s, 11.7294s/100 iters), loss = 0.0303445
I0823 06:54:32.341109 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0303433 (* 1 = 0.0303433 loss)
I0823 06:54:32.341120 13823 sgd_solver.cpp:112] Iteration 492000, lr = 1e-06
I0823 06:54:44.039324 13823 solver.cpp:239] Iteration 492100 (8.5483 iter/s, 11.6982s/100 iters), loss = 0.0267352
I0823 06:54:44.039376 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.026734 (* 1 = 0.026734 loss)
I0823 06:54:44.039384 13823 sgd_solver.cpp:112] Iteration 492100, lr = 1e-06
I0823 06:54:55.575428 13823 solver.cpp:239] Iteration 492200 (8.66847 iter/s, 11.5361s/100 iters), loss = 0.0244277
I0823 06:54:55.575486 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0244265 (* 1 = 0.0244265 loss)
I0823 06:54:55.575497 13823 sgd_solver.cpp:112] Iteration 492200, lr = 1e-06
I0823 06:55:07.206404 13823 solver.cpp:239] Iteration 492300 (8.59777 iter/s, 11.6309s/100 iters), loss = 0.0324448
I0823 06:55:07.206459 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0324436 (* 1 = 0.0324436 loss)
I0823 06:55:07.206470 13823 sgd_solver.cpp:112] Iteration 492300, lr = 1e-06
I0823 06:55:18.953447 13823 solver.cpp:239] Iteration 492400 (8.51282 iter/s, 11.747s/100 iters), loss = 0.0260527
I0823 06:55:18.953507 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0260515 (* 1 = 0.0260515 loss)
I0823 06:55:18.953519 13823 sgd_solver.cpp:112] Iteration 492400, lr = 1e-06
I0823 06:55:30.723598 13823 solver.cpp:239] Iteration 492500 (8.4961 iter/s, 11.7701s/100 iters), loss = 0.0266598
I0823 06:55:30.723649 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0266587 (* 1 = 0.0266587 loss)
I0823 06:55:30.723659 13823 sgd_solver.cpp:112] Iteration 492500, lr = 1e-06
I0823 06:55:42.455865 13823 solver.cpp:239] Iteration 492600 (8.52353 iter/s, 11.7322s/100 iters), loss = 0.0345776
I0823 06:55:42.455924 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0345764 (* 1 = 0.0345764 loss)
I0823 06:55:42.455936 13823 sgd_solver.cpp:112] Iteration 492600, lr = 1e-06
I0823 06:55:54.126592 13823 solver.cpp:239] Iteration 492700 (8.56848 iter/s, 11.6707s/100 iters), loss = 0.0289533
I0823 06:55:54.126646 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0289521 (* 1 = 0.0289521 loss)
I0823 06:55:54.126655 13823 sgd_solver.cpp:112] Iteration 492700, lr = 1e-06
I0823 06:56:05.750977 13823 solver.cpp:239] Iteration 492800 (8.60264 iter/s, 11.6243s/100 iters), loss = 0.0264615
I0823 06:56:05.751040 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0264603 (* 1 = 0.0264603 loss)
I0823 06:56:05.751053 13823 sgd_solver.cpp:112] Iteration 492800, lr = 1e-06
I0823 06:56:17.332054 13823 solver.cpp:239] Iteration 492900 (8.63482 iter/s, 11.581s/100 iters), loss = 0.0356765
I0823 06:56:17.332116 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0356753 (* 1 = 0.0356753 loss)
I0823 06:56:17.332129 13823 sgd_solver.cpp:112] Iteration 492900, lr = 1e-06
I0823 06:56:29.128125 13823 solver.cpp:239] Iteration 493000 (8.47743 iter/s, 11.796s/100 iters), loss = 0.0278046
I0823 06:56:29.128180 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0278034 (* 1 = 0.0278034 loss)
I0823 06:56:29.128190 13823 sgd_solver.cpp:112] Iteration 493000, lr = 1e-06
I0823 06:56:39.133579 13823 solver.cpp:239] Iteration 493100 (9.99459 iter/s, 10.0054s/100 iters), loss = 0.0258763
I0823 06:56:39.133633 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0258751 (* 1 = 0.0258751 loss)
I0823 06:56:39.133643 13823 sgd_solver.cpp:112] Iteration 493100, lr = 1e-06
I0823 06:56:48.554380 13823 solver.cpp:239] Iteration 493200 (10.6149 iter/s, 9.42076s/100 iters), loss = 0.023653
I0823 06:56:48.554431 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0236519 (* 1 = 0.0236519 loss)
I0823 06:56:48.554441 13823 sgd_solver.cpp:112] Iteration 493200, lr = 1e-06
I0823 06:56:58.245107 13823 solver.cpp:239] Iteration 493300 (10.3192 iter/s, 9.69068s/100 iters), loss = 0.0267155
I0823 06:56:58.245157 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0267144 (* 1 = 0.0267144 loss)
I0823 06:56:58.245165 13823 sgd_solver.cpp:112] Iteration 493300, lr = 1e-06
I0823 06:57:07.667526 13823 solver.cpp:239] Iteration 493400 (10.613 iter/s, 9.42238s/100 iters), loss = 0.0288328
I0823 06:57:07.667577 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0288316 (* 1 = 0.0288316 loss)
I0823 06:57:07.667587 13823 sgd_solver.cpp:112] Iteration 493400, lr = 1e-06
I0823 06:57:17.392211 13823 solver.cpp:239] Iteration 493500 (10.2832 iter/s, 9.72464s/100 iters), loss = 0.0242123
I0823 06:57:17.392263 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0242111 (* 1 = 0.0242111 loss)
I0823 06:57:17.392272 13823 sgd_solver.cpp:112] Iteration 493500, lr = 1e-06
I0823 06:57:27.016239 13823 solver.cpp:239] Iteration 493600 (10.3907 iter/s, 9.62398s/100 iters), loss = 0.0345068
I0823 06:57:27.016290 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0345057 (* 1 = 0.0345057 loss)
I0823 06:57:27.016299 13823 sgd_solver.cpp:112] Iteration 493600, lr = 1e-06
I0823 06:57:36.668143 13823 solver.cpp:239] Iteration 493700 (10.3607 iter/s, 9.65186s/100 iters), loss = 0.0343304
I0823 06:57:36.668192 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0343292 (* 1 = 0.0343292 loss)
I0823 06:57:36.668202 13823 sgd_solver.cpp:112] Iteration 493700, lr = 1e-06
I0823 06:57:46.207551 13823 solver.cpp:239] Iteration 493800 (10.4829 iter/s, 9.53937s/100 iters), loss = 0.0275924
I0823 06:57:46.207600 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0275912 (* 1 = 0.0275912 loss)
I0823 06:57:46.207610 13823 sgd_solver.cpp:112] Iteration 493800, lr = 1e-06
I0823 06:57:55.880326 13823 solver.cpp:239] Iteration 493900 (10.3383 iter/s, 9.67274s/100 iters), loss = 0.0288629
I0823 06:57:55.880368 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0288617 (* 1 = 0.0288617 loss)
I0823 06:57:55.880376 13823 sgd_solver.cpp:112] Iteration 493900, lr = 1e-06
I0823 06:58:05.435962 13823 solver.cpp:239] Iteration 494000 (10.4651 iter/s, 9.55561s/100 iters), loss = 0.0255422
I0823 06:58:05.436003 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.025541 (* 1 = 0.025541 loss)
I0823 06:58:05.436012 13823 sgd_solver.cpp:112] Iteration 494000, lr = 1e-06
I0823 06:58:14.652771 13823 solver.cpp:239] Iteration 494100 (10.8498 iter/s, 9.21678s/100 iters), loss = 0.0301538
I0823 06:58:14.652812 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0301527 (* 1 = 0.0301527 loss)
I0823 06:58:14.652820 13823 sgd_solver.cpp:112] Iteration 494100, lr = 1e-06
I0823 06:58:23.992023 13823 solver.cpp:239] Iteration 494200 (10.7075 iter/s, 9.33922s/100 iters), loss = 0.0391563
I0823 06:58:23.992063 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0391551 (* 1 = 0.0391551 loss)
I0823 06:58:23.992071 13823 sgd_solver.cpp:112] Iteration 494200, lr = 1e-06
I0823 06:58:33.626219 13823 solver.cpp:239] Iteration 494300 (10.3797 iter/s, 9.63416s/100 iters), loss = 0.0319187
I0823 06:58:33.626276 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0319175 (* 1 = 0.0319175 loss)
I0823 06:58:33.626287 13823 sgd_solver.cpp:112] Iteration 494300, lr = 1e-06
I0823 06:58:43.325260 13823 solver.cpp:239] Iteration 494400 (10.3103 iter/s, 9.699s/100 iters), loss = 0.0281613
I0823 06:58:43.325309 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0281602 (* 1 = 0.0281602 loss)
I0823 06:58:43.325320 13823 sgd_solver.cpp:112] Iteration 494400, lr = 1e-06
I0823 06:58:52.826568 13823 solver.cpp:239] Iteration 494500 (10.5249 iter/s, 9.50127s/100 iters), loss = 0.0258638
I0823 06:58:52.826608 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0258627 (* 1 = 0.0258627 loss)
I0823 06:58:52.826615 13823 sgd_solver.cpp:112] Iteration 494500, lr = 1e-06
I0823 06:59:02.296782 13823 solver.cpp:239] Iteration 494600 (10.5595 iter/s, 9.47018s/100 iters), loss = 0.0279204
I0823 06:59:02.296831 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0279193 (* 1 = 0.0279193 loss)
I0823 06:59:02.296841 13823 sgd_solver.cpp:112] Iteration 494600, lr = 1e-06
I0823 06:59:12.194736 13823 solver.cpp:239] Iteration 494700 (10.1031 iter/s, 9.89791s/100 iters), loss = 0.0239411
I0823 06:59:12.194787 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0239399 (* 1 = 0.0239399 loss)
I0823 06:59:12.194797 13823 sgd_solver.cpp:112] Iteration 494700, lr = 1e-06
I0823 06:59:21.867043 13823 solver.cpp:239] Iteration 494800 (10.3388 iter/s, 9.67227s/100 iters), loss = 0.025064
I0823 06:59:21.867094 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0250629 (* 1 = 0.0250629 loss)
I0823 06:59:21.867103 13823 sgd_solver.cpp:112] Iteration 494800, lr = 1e-06
I0823 06:59:31.487476 13823 solver.cpp:239] Iteration 494900 (10.3946 iter/s, 9.6204s/100 iters), loss = 0.0242311
I0823 06:59:31.487516 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0242299 (* 1 = 0.0242299 loss)
I0823 06:59:31.487524 13823 sgd_solver.cpp:112] Iteration 494900, lr = 1e-06
I0823 06:59:41.061681 13823 solver.cpp:239] Iteration 495000 (10.4448 iter/s, 9.57417s/100 iters), loss = 0.0247566
I0823 06:59:41.061733 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0247554 (* 1 = 0.0247554 loss)
I0823 06:59:41.061743 13823 sgd_solver.cpp:112] Iteration 495000, lr = 1e-06
I0823 06:59:50.746791 13823 solver.cpp:239] Iteration 495100 (10.3252 iter/s, 9.68507s/100 iters), loss = 0.0245929
I0823 06:59:50.746843 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0245917 (* 1 = 0.0245917 loss)
I0823 06:59:50.746852 13823 sgd_solver.cpp:112] Iteration 495100, lr = 1e-06
I0823 07:00:00.261745 13823 solver.cpp:239] Iteration 495200 (10.5098 iter/s, 9.51491s/100 iters), loss = 0.0261283
I0823 07:00:00.261808 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0261271 (* 1 = 0.0261271 loss)
I0823 07:00:00.261821 13823 sgd_solver.cpp:112] Iteration 495200, lr = 1e-06
I0823 07:00:10.097445 13823 solver.cpp:239] Iteration 495300 (10.1671 iter/s, 9.83565s/100 iters), loss = 0.0266923
I0823 07:00:10.097493 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0266911 (* 1 = 0.0266911 loss)
I0823 07:00:10.097503 13823 sgd_solver.cpp:112] Iteration 495300, lr = 1e-06
I0823 07:00:19.436405 13823 solver.cpp:239] Iteration 495400 (10.7079 iter/s, 9.33892s/100 iters), loss = 0.0364992
I0823 07:00:19.436455 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.036498 (* 1 = 0.036498 loss)
I0823 07:00:19.436465 13823 sgd_solver.cpp:112] Iteration 495400, lr = 1e-06
I0823 07:00:29.043205 13823 solver.cpp:239] Iteration 495500 (10.4093 iter/s, 9.60676s/100 iters), loss = 0.0309417
I0823 07:00:29.043253 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0309405 (* 1 = 0.0309405 loss)
I0823 07:00:29.043262 13823 sgd_solver.cpp:112] Iteration 495500, lr = 1e-06
I0823 07:00:38.441030 13823 solver.cpp:239] Iteration 495600 (10.6408 iter/s, 9.39779s/100 iters), loss = 0.02729
I0823 07:00:38.441082 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0272889 (* 1 = 0.0272889 loss)
I0823 07:00:38.441090 13823 sgd_solver.cpp:112] Iteration 495600, lr = 1e-06
I0823 07:00:47.989838 13823 solver.cpp:239] Iteration 495700 (10.4726 iter/s, 9.54877s/100 iters), loss = 0.0263326
I0823 07:00:47.989881 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0263314 (* 1 = 0.0263314 loss)
I0823 07:00:47.989887 13823 sgd_solver.cpp:112] Iteration 495700, lr = 1e-06
I0823 07:00:57.572140 13823 solver.cpp:239] Iteration 495800 (10.4359 iter/s, 9.58227s/100 iters), loss = 0.0267351
I0823 07:00:57.572197 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0267339 (* 1 = 0.0267339 loss)
I0823 07:00:57.572208 13823 sgd_solver.cpp:112] Iteration 495800, lr = 1e-06
I0823 07:01:07.158351 13823 solver.cpp:239] Iteration 495900 (10.4317 iter/s, 9.58617s/100 iters), loss = 0.0378888
I0823 07:01:07.158403 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0378876 (* 1 = 0.0378876 loss)
I0823 07:01:07.158412 13823 sgd_solver.cpp:112] Iteration 495900, lr = 1e-06
I0823 07:01:16.740625 13823 solver.cpp:239] Iteration 496000 (10.436 iter/s, 9.58224s/100 iters), loss = 0.0257929
I0823 07:01:16.740666 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0257918 (* 1 = 0.0257918 loss)
I0823 07:01:16.740674 13823 sgd_solver.cpp:112] Iteration 496000, lr = 1e-06
I0823 07:01:26.537531 13823 solver.cpp:239] Iteration 496100 (10.2073 iter/s, 9.79688s/100 iters), loss = 0.0289849
I0823 07:01:26.537573 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0289837 (* 1 = 0.0289837 loss)
I0823 07:01:26.537580 13823 sgd_solver.cpp:112] Iteration 496100, lr = 1e-06
I0823 07:01:36.228890 13823 solver.cpp:239] Iteration 496200 (10.3185 iter/s, 9.69133s/100 iters), loss = 0.0291428
I0823 07:01:36.228932 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0291416 (* 1 = 0.0291416 loss)
I0823 07:01:36.228940 13823 sgd_solver.cpp:112] Iteration 496200, lr = 1e-06
I0823 07:01:45.695235 13823 solver.cpp:239] Iteration 496300 (10.5638 iter/s, 9.46631s/100 iters), loss = 0.0272493
I0823 07:01:45.695284 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0272482 (* 1 = 0.0272482 loss)
I0823 07:01:45.695293 13823 sgd_solver.cpp:112] Iteration 496300, lr = 1e-06
I0823 07:01:55.529557 13823 solver.cpp:239] Iteration 496400 (10.1685 iter/s, 9.83429s/100 iters), loss = 0.0306533
I0823 07:01:55.529610 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0306521 (* 1 = 0.0306521 loss)
I0823 07:01:55.529619 13823 sgd_solver.cpp:112] Iteration 496400, lr = 1e-06
I0823 07:02:05.094914 13823 solver.cpp:239] Iteration 496500 (10.4544 iter/s, 9.56532s/100 iters), loss = 0.0237691
I0823 07:02:05.094955 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0237679 (* 1 = 0.0237679 loss)
I0823 07:02:05.094964 13823 sgd_solver.cpp:112] Iteration 496500, lr = 1e-06
I0823 07:02:14.814646 13823 solver.cpp:239] Iteration 496600 (10.2884 iter/s, 9.7197s/100 iters), loss = 0.0246882
I0823 07:02:14.814697 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.024687 (* 1 = 0.024687 loss)
I0823 07:02:14.814707 13823 sgd_solver.cpp:112] Iteration 496600, lr = 1e-06
I0823 07:02:24.802371 13823 solver.cpp:239] Iteration 496700 (10.0123 iter/s, 9.98769s/100 iters), loss = 0.0262793
I0823 07:02:24.802422 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0262782 (* 1 = 0.0262782 loss)
I0823 07:02:24.802430 13823 sgd_solver.cpp:112] Iteration 496700, lr = 1e-06
I0823 07:02:34.366158 13823 solver.cpp:239] Iteration 496800 (10.4561 iter/s, 9.56375s/100 iters), loss = 0.0297263
I0823 07:02:34.366211 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0297252 (* 1 = 0.0297252 loss)
I0823 07:02:34.366219 13823 sgd_solver.cpp:112] Iteration 496800, lr = 1e-06
I0823 07:02:44.382445 13823 solver.cpp:239] Iteration 496900 (9.98378 iter/s, 10.0162s/100 iters), loss = 0.0268102
I0823 07:02:44.382504 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0268091 (* 1 = 0.0268091 loss)
I0823 07:02:44.382515 13823 sgd_solver.cpp:112] Iteration 496900, lr = 1e-06
I0823 07:02:54.188302 13823 solver.cpp:239] Iteration 497000 (10.198 iter/s, 9.80581s/100 iters), loss = 0.0361228
I0823 07:02:54.188355 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0361217 (* 1 = 0.0361217 loss)
I0823 07:02:54.188364 13823 sgd_solver.cpp:112] Iteration 497000, lr = 1e-06
I0823 07:03:04.292654 13823 solver.cpp:239] Iteration 497100 (9.89676 iter/s, 10.1043s/100 iters), loss = 0.0304015
I0823 07:03:04.292711 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0304003 (* 1 = 0.0304003 loss)
I0823 07:03:04.292723 13823 sgd_solver.cpp:112] Iteration 497100, lr = 1e-06
I0823 07:03:13.849102 13823 solver.cpp:239] Iteration 497200 (10.4642 iter/s, 9.55641s/100 iters), loss = 0.0282328
I0823 07:03:13.849143 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0282316 (* 1 = 0.0282316 loss)
I0823 07:03:13.849150 13823 sgd_solver.cpp:112] Iteration 497200, lr = 1e-06
I0823 07:03:23.455018 13823 solver.cpp:239] Iteration 497300 (10.4103 iter/s, 9.60588s/100 iters), loss = 0.0266298
I0823 07:03:23.455081 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0266286 (* 1 = 0.0266286 loss)
I0823 07:03:23.455093 13823 sgd_solver.cpp:112] Iteration 497300, lr = 1e-06
I0823 07:03:33.559468 13823 solver.cpp:239] Iteration 497400 (9.89668 iter/s, 10.1044s/100 iters), loss = 0.0244096
I0823 07:03:33.559532 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0244084 (* 1 = 0.0244084 loss)
I0823 07:03:33.559545 13823 sgd_solver.cpp:112] Iteration 497400, lr = 1e-06
I0823 07:03:43.414325 13823 solver.cpp:239] Iteration 497500 (10.1473 iter/s, 9.85481s/100 iters), loss = 0.02915
I0823 07:03:43.414367 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0291489 (* 1 = 0.0291489 loss)
I0823 07:03:43.414376 13823 sgd_solver.cpp:112] Iteration 497500, lr = 1e-06
I0823 07:03:53.164496 13823 solver.cpp:239] Iteration 497600 (10.2563 iter/s, 9.75014s/100 iters), loss = 0.0251887
I0823 07:03:53.164546 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0251875 (* 1 = 0.0251875 loss)
I0823 07:03:53.164556 13823 sgd_solver.cpp:112] Iteration 497600, lr = 1e-06
I0823 07:04:02.822455 13823 solver.cpp:239] Iteration 497700 (10.3542 iter/s, 9.65792s/100 iters), loss = 0.0260763
I0823 07:04:02.822508 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0260751 (* 1 = 0.0260751 loss)
I0823 07:04:02.822518 13823 sgd_solver.cpp:112] Iteration 497700, lr = 1e-06
I0823 07:04:12.715668 13823 solver.cpp:239] Iteration 497800 (10.108 iter/s, 9.89318s/100 iters), loss = 0.0336907
I0823 07:04:12.715720 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0336895 (* 1 = 0.0336895 loss)
I0823 07:04:12.715729 13823 sgd_solver.cpp:112] Iteration 497800, lr = 1e-06
I0823 07:04:22.702459 13823 solver.cpp:239] Iteration 497900 (10.0133 iter/s, 9.98675s/100 iters), loss = 0.0267252
I0823 07:04:22.702509 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.026724 (* 1 = 0.026724 loss)
I0823 07:04:22.702519 13823 sgd_solver.cpp:112] Iteration 497900, lr = 1e-06
I0823 07:04:32.493218 13823 solver.cpp:239] Iteration 498000 (10.2137 iter/s, 9.79072s/100 iters), loss = 0.0379792
I0823 07:04:32.493271 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.037978 (* 1 = 0.037978 loss)
I0823 07:04:32.493280 13823 sgd_solver.cpp:112] Iteration 498000, lr = 1e-06
I0823 07:04:42.451226 13823 solver.cpp:239] Iteration 498100 (10.0422 iter/s, 9.95797s/100 iters), loss = 0.0262051
I0823 07:04:42.451287 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0262039 (* 1 = 0.0262039 loss)
I0823 07:04:42.451297 13823 sgd_solver.cpp:112] Iteration 498100, lr = 1e-06
I0823 07:04:52.247578 13823 solver.cpp:239] Iteration 498200 (10.2079 iter/s, 9.79631s/100 iters), loss = 0.0308126
I0823 07:04:52.247628 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0308114 (* 1 = 0.0308114 loss)
I0823 07:04:52.247637 13823 sgd_solver.cpp:112] Iteration 498200, lr = 1e-06
I0823 07:05:02.037381 13823 solver.cpp:239] Iteration 498300 (10.2147 iter/s, 9.78977s/100 iters), loss = 0.0269112
I0823 07:05:02.037436 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.02691 (* 1 = 0.02691 loss)
I0823 07:05:02.037448 13823 sgd_solver.cpp:112] Iteration 498300, lr = 1e-06
I0823 07:05:12.196672 13823 solver.cpp:239] Iteration 498400 (9.84324 iter/s, 10.1593s/100 iters), loss = 0.0281743
I0823 07:05:12.196732 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0281731 (* 1 = 0.0281731 loss)
I0823 07:05:12.196744 13823 sgd_solver.cpp:112] Iteration 498400, lr = 1e-06
I0823 07:05:22.051704 13823 solver.cpp:239] Iteration 498500 (10.1471 iter/s, 9.85499s/100 iters), loss = 0.0270843
I0823 07:05:22.051762 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0270831 (* 1 = 0.0270831 loss)
I0823 07:05:22.051775 13823 sgd_solver.cpp:112] Iteration 498500, lr = 1e-06
I0823 07:05:32.110693 13823 solver.cpp:239] Iteration 498600 (9.94139 iter/s, 10.059s/100 iters), loss = 0.0261607
I0823 07:05:32.110735 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0261595 (* 1 = 0.0261595 loss)
I0823 07:05:32.110743 13823 sgd_solver.cpp:112] Iteration 498600, lr = 1e-06
I0823 07:05:42.055466 13823 solver.cpp:239] Iteration 498700 (10.0556 iter/s, 9.94475s/100 iters), loss = 0.0230875
I0823 07:05:42.055517 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0230863 (* 1 = 0.0230863 loss)
I0823 07:05:42.055527 13823 sgd_solver.cpp:112] Iteration 498700, lr = 1e-06
I0823 07:05:52.134027 13823 solver.cpp:239] Iteration 498800 (9.92209 iter/s, 10.0785s/100 iters), loss = 0.026326
I0823 07:05:52.134078 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0263248 (* 1 = 0.0263248 loss)
I0823 07:05:52.134088 13823 sgd_solver.cpp:112] Iteration 498800, lr = 1e-06
I0823 07:06:02.158071 13823 solver.cpp:239] Iteration 498900 (9.97605 iter/s, 10.024s/100 iters), loss = 0.0269704
I0823 07:06:02.158121 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0269692 (* 1 = 0.0269692 loss)
I0823 07:06:02.158130 13823 sgd_solver.cpp:112] Iteration 498900, lr = 1e-06
I0823 07:06:12.311434 13823 solver.cpp:239] Iteration 499000 (9.84899 iter/s, 10.1533s/100 iters), loss = 0.0266151
I0823 07:06:12.311491 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0266139 (* 1 = 0.0266139 loss)
I0823 07:06:12.311501 13823 sgd_solver.cpp:112] Iteration 499000, lr = 1e-06
I0823 07:06:22.460858 13823 solver.cpp:239] Iteration 499100 (9.85281 iter/s, 10.1494s/100 iters), loss = 0.0285451
I0823 07:06:22.460908 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0285439 (* 1 = 0.0285439 loss)
I0823 07:06:22.460917 13823 sgd_solver.cpp:112] Iteration 499100, lr = 1e-06
I0823 07:06:32.422479 13823 solver.cpp:239] Iteration 499200 (10.0386 iter/s, 9.96159s/100 iters), loss = 0.0241716
I0823 07:06:32.422533 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0241704 (* 1 = 0.0241704 loss)
I0823 07:06:32.422541 13823 sgd_solver.cpp:112] Iteration 499200, lr = 1e-06
I0823 07:06:42.665036 13823 solver.cpp:239] Iteration 499300 (9.76322 iter/s, 10.2425s/100 iters), loss = 0.0341853
I0823 07:06:42.665086 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0341841 (* 1 = 0.0341841 loss)
I0823 07:06:42.665096 13823 sgd_solver.cpp:112] Iteration 499300, lr = 1e-06
I0823 07:06:52.723613 13823 solver.cpp:239] Iteration 499400 (9.9418 iter/s, 10.0585s/100 iters), loss = 0.0266407
I0823 07:06:52.723664 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0266395 (* 1 = 0.0266395 loss)
I0823 07:06:52.723673 13823 sgd_solver.cpp:112] Iteration 499400, lr = 1e-06
I0823 07:07:02.571166 13823 solver.cpp:239] Iteration 499500 (10.1548 iter/s, 9.84752s/100 iters), loss = 0.0277025
I0823 07:07:02.571224 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0277013 (* 1 = 0.0277013 loss)
I0823 07:07:02.571235 13823 sgd_solver.cpp:112] Iteration 499500, lr = 1e-06
I0823 07:07:12.792485 13823 solver.cpp:239] Iteration 499600 (9.78351 iter/s, 10.2213s/100 iters), loss = 0.0231223
I0823 07:07:12.792537 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0231211 (* 1 = 0.0231211 loss)
I0823 07:07:12.792547 13823 sgd_solver.cpp:112] Iteration 499600, lr = 1e-06
I0823 07:07:22.901742 13823 solver.cpp:239] Iteration 499700 (9.89196 iter/s, 10.1092s/100 iters), loss = 0.0287612
I0823 07:07:22.901793 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.02876 (* 1 = 0.02876 loss)
I0823 07:07:22.901803 13823 sgd_solver.cpp:112] Iteration 499700, lr = 1e-06
I0823 07:07:33.149926 13823 solver.cpp:239] Iteration 499800 (9.75786 iter/s, 10.2481s/100 iters), loss = 0.0328486
I0823 07:07:33.149976 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0328474 (* 1 = 0.0328474 loss)
I0823 07:07:33.149986 13823 sgd_solver.cpp:112] Iteration 499800, lr = 1e-06
I0823 07:07:43.585484 13823 solver.cpp:239] Iteration 499900 (9.58266 iter/s, 10.4355s/100 iters), loss = 0.0266818
I0823 07:07:43.585547 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0266806 (* 1 = 0.0266806 loss)
I0823 07:07:43.585557 13823 sgd_solver.cpp:112] Iteration 499900, lr = 1e-06
I0823 07:07:53.461529 13823 solver.cpp:464] Snapshotting to binary proto file ./model_112/cascade_mobilenet_112_iter_500000.caffemodel
I0823 07:07:53.504822 13823 sgd_solver.cpp:284] Snapshotting solver state to binary proto file ./model_112/cascade_mobilenet_112_iter_500000.solverstate
I0823 07:07:53.535779 13823 solver.cpp:347] Iteration 500000, Testing net (#0)
I0823 07:08:53.431668 13823 solver.cpp:414]     Test net output #0: landmark_loss = 0.0219715 (* 1 = 0.0219715 loss)
I0823 07:08:53.523130 13823 solver.cpp:239] Iteration 500000 (1.42984 iter/s, 69.9378s/100 iters), loss = 0.0243049
I0823 07:08:53.523178 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0243037 (* 1 = 0.0243037 loss)
I0823 07:08:53.523190 13823 sgd_solver.cpp:112] Iteration 500000, lr = 1e-06
I0823 07:09:03.731026 13823 solver.cpp:239] Iteration 500100 (9.79636 iter/s, 10.2079s/100 iters), loss = 0.0263054
I0823 07:09:03.731086 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0263042 (* 1 = 0.0263042 loss)
I0823 07:09:03.731099 13823 sgd_solver.cpp:112] Iteration 500100, lr = 1e-06
I0823 07:09:14.232334 13823 solver.cpp:239] Iteration 500200 (9.52265 iter/s, 10.5013s/100 iters), loss = 0.0284372
I0823 07:09:14.232386 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.028436 (* 1 = 0.028436 loss)
I0823 07:09:14.232396 13823 sgd_solver.cpp:112] Iteration 500200, lr = 1e-06
I0823 07:09:24.510972 13823 solver.cpp:239] Iteration 500300 (9.72895 iter/s, 10.2786s/100 iters), loss = 0.0268728
I0823 07:09:24.511040 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0268717 (* 1 = 0.0268717 loss)
I0823 07:09:24.511057 13823 sgd_solver.cpp:112] Iteration 500300, lr = 1e-06
I0823 07:09:34.699188 13823 solver.cpp:239] Iteration 500400 (9.8153 iter/s, 10.1882s/100 iters), loss = 0.0274429
I0823 07:09:34.699246 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0274418 (* 1 = 0.0274418 loss)
I0823 07:09:34.699259 13823 sgd_solver.cpp:112] Iteration 500400, lr = 1e-06
I0823 07:09:44.979977 13823 solver.cpp:239] Iteration 500500 (9.72691 iter/s, 10.2808s/100 iters), loss = 0.0253102
I0823 07:09:44.980051 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.025309 (* 1 = 0.025309 loss)
I0823 07:09:44.980067 13823 sgd_solver.cpp:112] Iteration 500500, lr = 1e-06
I0823 07:09:55.232977 13823 solver.cpp:239] Iteration 500600 (9.75328 iter/s, 10.253s/100 iters), loss = 0.0247695
I0823 07:09:55.233019 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0247684 (* 1 = 0.0247684 loss)
I0823 07:09:55.233026 13823 sgd_solver.cpp:112] Iteration 500600, lr = 1e-06
I0823 07:10:05.649288 13823 solver.cpp:239] Iteration 500700 (9.60035 iter/s, 10.4163s/100 iters), loss = 0.0234424
I0823 07:10:05.649339 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0234412 (* 1 = 0.0234412 loss)
I0823 07:10:05.649349 13823 sgd_solver.cpp:112] Iteration 500700, lr = 1e-06
I0823 07:10:15.914752 13823 solver.cpp:239] Iteration 500800 (9.74143 iter/s, 10.2654s/100 iters), loss = 0.0243568
I0823 07:10:15.914791 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0243556 (* 1 = 0.0243556 loss)
I0823 07:10:15.914798 13823 sgd_solver.cpp:112] Iteration 500800, lr = 1e-06
I0823 07:10:26.032748 13823 solver.cpp:239] Iteration 500900 (9.8834 iter/s, 10.118s/100 iters), loss = 0.0332876
I0823 07:10:26.032802 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0332864 (* 1 = 0.0332864 loss)
I0823 07:10:26.032810 13823 sgd_solver.cpp:112] Iteration 500900, lr = 1e-06
I0823 07:10:36.251672 13823 solver.cpp:239] Iteration 501000 (9.7858 iter/s, 10.2189s/100 iters), loss = 0.0266832
I0823 07:10:36.251724 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.026682 (* 1 = 0.026682 loss)
I0823 07:10:36.251734 13823 sgd_solver.cpp:112] Iteration 501000, lr = 1e-06
I0823 07:10:46.643349 13823 solver.cpp:239] Iteration 501100 (9.62311 iter/s, 10.3917s/100 iters), loss = 0.0300116
I0823 07:10:46.643391 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0300104 (* 1 = 0.0300104 loss)
I0823 07:10:46.643399 13823 sgd_solver.cpp:112] Iteration 501100, lr = 1e-06
I0823 07:10:56.640115 13823 solver.cpp:239] Iteration 501200 (10.0033 iter/s, 9.99675s/100 iters), loss = 0.0291181
I0823 07:10:56.640161 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0291169 (* 1 = 0.0291169 loss)
I0823 07:10:56.640168 13823 sgd_solver.cpp:112] Iteration 501200, lr = 1e-06
I0823 07:11:06.618324 13823 solver.cpp:239] Iteration 501300 (10.0219 iter/s, 9.97819s/100 iters), loss = 0.0276572
I0823 07:11:06.618367 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.027656 (* 1 = 0.027656 loss)
I0823 07:11:06.618374 13823 sgd_solver.cpp:112] Iteration 501300, lr = 1e-06
I0823 07:11:16.793236 13823 solver.cpp:239] Iteration 501400 (9.82812 iter/s, 10.1749s/100 iters), loss = 0.0297163
I0823 07:11:16.793287 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0297151 (* 1 = 0.0297151 loss)
I0823 07:11:16.793298 13823 sgd_solver.cpp:112] Iteration 501400, lr = 1e-06
I0823 07:11:27.397167 13823 solver.cpp:239] Iteration 501500 (9.4305 iter/s, 10.6039s/100 iters), loss = 0.0324168
I0823 07:11:27.397229 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0324156 (* 1 = 0.0324156 loss)
I0823 07:11:27.397241 13823 sgd_solver.cpp:112] Iteration 501500, lr = 1e-06
I0823 07:11:37.723280 13823 solver.cpp:239] Iteration 501600 (9.68422 iter/s, 10.3261s/100 iters), loss = 0.0298497
I0823 07:11:37.723335 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0298485 (* 1 = 0.0298485 loss)
I0823 07:11:37.723345 13823 sgd_solver.cpp:112] Iteration 501600, lr = 1e-06
I0823 07:11:48.206586 13823 solver.cpp:239] Iteration 501700 (9.53901 iter/s, 10.4833s/100 iters), loss = 0.0243687
I0823 07:11:48.206645 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0243675 (* 1 = 0.0243675 loss)
I0823 07:11:48.206656 13823 sgd_solver.cpp:112] Iteration 501700, lr = 1e-06
I0823 07:11:58.765369 13823 solver.cpp:239] Iteration 501800 (9.47082 iter/s, 10.5587s/100 iters), loss = 0.030681
I0823 07:11:58.765424 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0306798 (* 1 = 0.0306798 loss)
I0823 07:11:58.765435 13823 sgd_solver.cpp:112] Iteration 501800, lr = 1e-06
I0823 07:12:09.541884 13823 solver.cpp:239] Iteration 501900 (9.27946 iter/s, 10.7765s/100 iters), loss = 0.0266209
I0823 07:12:09.541935 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0266197 (* 1 = 0.0266197 loss)
I0823 07:12:09.541944 13823 sgd_solver.cpp:112] Iteration 501900, lr = 1e-06
I0823 07:12:20.305003 13823 solver.cpp:239] Iteration 502000 (9.29101 iter/s, 10.7631s/100 iters), loss = 0.0351195
I0823 07:12:20.305056 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0351183 (* 1 = 0.0351183 loss)
I0823 07:12:20.305065 13823 sgd_solver.cpp:112] Iteration 502000, lr = 1e-06
I0823 07:12:30.830505 13823 solver.cpp:239] Iteration 502100 (9.50076 iter/s, 10.5255s/100 iters), loss = 0.0295864
I0823 07:12:30.830561 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0295853 (* 1 = 0.0295853 loss)
I0823 07:12:30.830571 13823 sgd_solver.cpp:112] Iteration 502100, lr = 1e-06
I0823 07:12:41.374665 13823 solver.cpp:239] Iteration 502200 (9.48395 iter/s, 10.5441s/100 iters), loss = 0.027923
I0823 07:12:41.374713 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0279218 (* 1 = 0.0279218 loss)
I0823 07:12:41.374723 13823 sgd_solver.cpp:112] Iteration 502200, lr = 1e-06
I0823 07:12:52.313268 13823 solver.cpp:239] Iteration 502300 (9.14196 iter/s, 10.9386s/100 iters), loss = 0.024053
I0823 07:12:52.313325 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0240518 (* 1 = 0.0240518 loss)
I0823 07:12:52.313336 13823 sgd_solver.cpp:112] Iteration 502300, lr = 1e-06
I0823 07:13:02.968116 13823 solver.cpp:239] Iteration 502400 (9.38543 iter/s, 10.6548s/100 iters), loss = 0.0250245
I0823 07:13:02.968179 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0250233 (* 1 = 0.0250233 loss)
I0823 07:13:02.968191 13823 sgd_solver.cpp:112] Iteration 502400, lr = 1e-06
I0823 07:13:13.806975 13823 solver.cpp:239] Iteration 502500 (9.2261 iter/s, 10.8388s/100 iters), loss = 0.0239766
I0823 07:13:13.807027 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0239754 (* 1 = 0.0239754 loss)
I0823 07:13:13.807037 13823 sgd_solver.cpp:112] Iteration 502500, lr = 1e-06
I0823 07:13:24.590878 13823 solver.cpp:239] Iteration 502600 (9.27311 iter/s, 10.7839s/100 iters), loss = 0.0244031
I0823 07:13:24.590929 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.024402 (* 1 = 0.024402 loss)
I0823 07:13:24.590939 13823 sgd_solver.cpp:112] Iteration 502600, lr = 1e-06
I0823 07:13:35.055639 13823 solver.cpp:239] Iteration 502700 (9.55591 iter/s, 10.4647s/100 iters), loss = 0.0270522
I0823 07:13:35.055696 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.027051 (* 1 = 0.027051 loss)
I0823 07:13:35.055707 13823 sgd_solver.cpp:112] Iteration 502700, lr = 1e-06
I0823 07:13:46.072667 13823 solver.cpp:239] Iteration 502800 (9.07689 iter/s, 11.017s/100 iters), loss = 0.030162
I0823 07:13:46.072717 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0301608 (* 1 = 0.0301608 loss)
I0823 07:13:46.072727 13823 sgd_solver.cpp:112] Iteration 502800, lr = 1e-06
I0823 07:13:56.976194 13823 solver.cpp:239] Iteration 502900 (9.17137 iter/s, 10.9035s/100 iters), loss = 0.0276969
I0823 07:13:56.976255 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0276958 (* 1 = 0.0276958 loss)
I0823 07:13:56.976267 13823 sgd_solver.cpp:112] Iteration 502900, lr = 1e-06
I0823 07:14:07.847306 13823 solver.cpp:239] Iteration 503000 (9.19872 iter/s, 10.8711s/100 iters), loss = 0.0255709
I0823 07:14:07.847367 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0255697 (* 1 = 0.0255697 loss)
I0823 07:14:07.847378 13823 sgd_solver.cpp:112] Iteration 503000, lr = 1e-06
I0823 07:14:18.816838 13823 solver.cpp:239] Iteration 503100 (9.11619 iter/s, 10.9695s/100 iters), loss = 0.0261133
I0823 07:14:18.816889 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0261121 (* 1 = 0.0261121 loss)
I0823 07:14:18.816897 13823 sgd_solver.cpp:112] Iteration 503100, lr = 1e-06
I0823 07:14:30.004194 13823 solver.cpp:239] Iteration 503200 (8.93868 iter/s, 11.1873s/100 iters), loss = 0.0235146
I0823 07:14:30.004254 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0235134 (* 1 = 0.0235134 loss)
I0823 07:14:30.004266 13823 sgd_solver.cpp:112] Iteration 503200, lr = 1e-06
I0823 07:14:40.723570 13823 solver.cpp:239] Iteration 503300 (9.32893 iter/s, 10.7193s/100 iters), loss = 0.0245172
I0823 07:14:40.723623 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0245161 (* 1 = 0.0245161 loss)
I0823 07:14:40.723632 13823 sgd_solver.cpp:112] Iteration 503300, lr = 1e-06
I0823 07:14:51.576905 13823 solver.cpp:239] Iteration 503400 (9.21378 iter/s, 10.8533s/100 iters), loss = 0.0237355
I0823 07:14:51.576959 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0237343 (* 1 = 0.0237343 loss)
I0823 07:14:51.576968 13823 sgd_solver.cpp:112] Iteration 503400, lr = 1e-06
I0823 07:15:02.690866 13823 solver.cpp:239] Iteration 503500 (8.99772 iter/s, 11.1139s/100 iters), loss = 0.0289451
I0823 07:15:02.690925 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0289439 (* 1 = 0.0289439 loss)
I0823 07:15:02.690937 13823 sgd_solver.cpp:112] Iteration 503500, lr = 1e-06
I0823 07:15:13.601194 13823 solver.cpp:239] Iteration 503600 (9.16566 iter/s, 10.9103s/100 iters), loss = 0.0256373
I0823 07:15:13.601246 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0256361 (* 1 = 0.0256361 loss)
I0823 07:15:13.601255 13823 sgd_solver.cpp:112] Iteration 503600, lr = 1e-06
I0823 07:15:24.246268 13823 solver.cpp:239] Iteration 503700 (9.39404 iter/s, 10.645s/100 iters), loss = 0.0260818
I0823 07:15:24.246330 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0260806 (* 1 = 0.0260806 loss)
I0823 07:15:24.246341 13823 sgd_solver.cpp:112] Iteration 503700, lr = 1e-06
I0823 07:15:35.428462 13823 solver.cpp:239] Iteration 503800 (8.94282 iter/s, 11.1822s/100 iters), loss = 0.0247938
I0823 07:15:35.428522 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0247926 (* 1 = 0.0247926 loss)
I0823 07:15:35.428534 13823 sgd_solver.cpp:112] Iteration 503800, lr = 1e-06
I0823 07:15:46.359568 13823 solver.cpp:239] Iteration 503900 (9.14824 iter/s, 10.9311s/100 iters), loss = 0.0379689
I0823 07:15:46.359632 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0379677 (* 1 = 0.0379677 loss)
I0823 07:15:46.359644 13823 sgd_solver.cpp:112] Iteration 503900, lr = 1e-06
I0823 07:15:57.240233 13823 solver.cpp:239] Iteration 504000 (9.19065 iter/s, 10.8806s/100 iters), loss = 0.0279404
I0823 07:15:57.240284 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0279392 (* 1 = 0.0279392 loss)
I0823 07:15:57.240293 13823 sgd_solver.cpp:112] Iteration 504000, lr = 1e-06
I0823 07:16:08.142772 13823 solver.cpp:239] Iteration 504100 (9.1722 iter/s, 10.9025s/100 iters), loss = 0.0253634
I0823 07:16:08.142823 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0253622 (* 1 = 0.0253622 loss)
I0823 07:16:08.142833 13823 sgd_solver.cpp:112] Iteration 504100, lr = 1e-06
I0823 07:16:19.078676 13823 solver.cpp:239] Iteration 504200 (9.14421 iter/s, 10.9359s/100 iters), loss = 0.0251526
I0823 07:16:19.078727 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0251514 (* 1 = 0.0251514 loss)
I0823 07:16:19.078737 13823 sgd_solver.cpp:112] Iteration 504200, lr = 1e-06
I0823 07:16:30.012475 13823 solver.cpp:239] Iteration 504300 (9.14598 iter/s, 10.9338s/100 iters), loss = 0.0285643
I0823 07:16:30.012527 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0285631 (* 1 = 0.0285631 loss)
I0823 07:16:30.012537 13823 sgd_solver.cpp:112] Iteration 504300, lr = 1e-06
I0823 07:16:40.724493 13823 solver.cpp:239] Iteration 504400 (9.33533 iter/s, 10.712s/100 iters), loss = 0.0266969
I0823 07:16:40.724545 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0266958 (* 1 = 0.0266958 loss)
I0823 07:16:40.724556 13823 sgd_solver.cpp:112] Iteration 504400, lr = 1e-06
I0823 07:16:51.607761 13823 solver.cpp:239] Iteration 504500 (9.18844 iter/s, 10.8832s/100 iters), loss = 0.0243073
I0823 07:16:51.607810 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0243061 (* 1 = 0.0243061 loss)
I0823 07:16:51.607820 13823 sgd_solver.cpp:112] Iteration 504500, lr = 1e-06
I0823 07:17:02.162624 13823 solver.cpp:239] Iteration 504600 (9.47433 iter/s, 10.5548s/100 iters), loss = 0.0295605
I0823 07:17:02.162678 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0295593 (* 1 = 0.0295593 loss)
I0823 07:17:02.162688 13823 sgd_solver.cpp:112] Iteration 504600, lr = 1e-06
I0823 07:17:12.916818 13823 solver.cpp:239] Iteration 504700 (9.29872 iter/s, 10.7542s/100 iters), loss = 0.027786
I0823 07:17:12.916870 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0277848 (* 1 = 0.0277848 loss)
I0823 07:17:12.916879 13823 sgd_solver.cpp:112] Iteration 504700, lr = 1e-06
I0823 07:17:23.724056 13823 solver.cpp:239] Iteration 504800 (9.25308 iter/s, 10.8072s/100 iters), loss = 0.0273008
I0823 07:17:23.724108 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0272996 (* 1 = 0.0272996 loss)
I0823 07:17:23.724119 13823 sgd_solver.cpp:112] Iteration 504800, lr = 1e-06
I0823 07:17:34.713727 13823 solver.cpp:239] Iteration 504900 (9.09948 iter/s, 10.9896s/100 iters), loss = 0.0258356
I0823 07:17:34.713776 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0258345 (* 1 = 0.0258345 loss)
I0823 07:17:34.713785 13823 sgd_solver.cpp:112] Iteration 504900, lr = 1e-06
I0823 07:17:45.434324 13823 solver.cpp:239] Iteration 505000 (9.32786 iter/s, 10.7206s/100 iters), loss = 0.0314513
I0823 07:17:45.434376 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0314501 (* 1 = 0.0314501 loss)
I0823 07:17:45.434386 13823 sgd_solver.cpp:112] Iteration 505000, lr = 1e-06
I0823 07:17:56.258111 13823 solver.cpp:239] Iteration 505100 (9.23894 iter/s, 10.8238s/100 iters), loss = 0.0250583
I0823 07:17:56.258170 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0250571 (* 1 = 0.0250571 loss)
I0823 07:17:56.258183 13823 sgd_solver.cpp:112] Iteration 505100, lr = 1e-06
I0823 07:18:07.074301 13823 solver.cpp:239] Iteration 505200 (9.24543 iter/s, 10.8162s/100 iters), loss = 0.0285934
I0823 07:18:07.074352 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0285922 (* 1 = 0.0285922 loss)
I0823 07:18:07.074362 13823 sgd_solver.cpp:112] Iteration 505200, lr = 1e-06
I0823 07:18:17.987903 13823 solver.cpp:239] Iteration 505300 (9.1629 iter/s, 10.9136s/100 iters), loss = 0.026785
I0823 07:18:17.987951 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0267838 (* 1 = 0.0267838 loss)
I0823 07:18:17.987960 13823 sgd_solver.cpp:112] Iteration 505300, lr = 1e-06
I0823 07:18:28.954566 13823 solver.cpp:239] Iteration 505400 (9.11857 iter/s, 10.9666s/100 iters), loss = 0.028164
I0823 07:18:28.954622 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0281628 (* 1 = 0.0281628 loss)
I0823 07:18:28.954632 13823 sgd_solver.cpp:112] Iteration 505400, lr = 1e-06
I0823 07:18:39.803989 13823 solver.cpp:239] Iteration 505500 (9.21711 iter/s, 10.8494s/100 iters), loss = 0.0275448
I0823 07:18:39.804039 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0275437 (* 1 = 0.0275437 loss)
I0823 07:18:39.804049 13823 sgd_solver.cpp:112] Iteration 505500, lr = 1e-06
I0823 07:18:50.713460 13823 solver.cpp:239] Iteration 505600 (9.16637 iter/s, 10.9094s/100 iters), loss = 0.0307163
I0823 07:18:50.713510 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0307151 (* 1 = 0.0307151 loss)
I0823 07:18:50.713518 13823 sgd_solver.cpp:112] Iteration 505600, lr = 1e-06
I0823 07:19:01.665947 13823 solver.cpp:239] Iteration 505700 (9.13037 iter/s, 10.9525s/100 iters), loss = 0.0245917
I0823 07:19:01.666004 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0245905 (* 1 = 0.0245905 loss)
I0823 07:19:01.666016 13823 sgd_solver.cpp:112] Iteration 505700, lr = 1e-06
I0823 07:19:12.508849 13823 solver.cpp:239] Iteration 505800 (9.22265 iter/s, 10.8429s/100 iters), loss = 0.0246775
I0823 07:19:12.508900 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0246763 (* 1 = 0.0246763 loss)
I0823 07:19:12.508910 13823 sgd_solver.cpp:112] Iteration 505800, lr = 1e-06
I0823 07:19:23.436126 13823 solver.cpp:239] Iteration 505900 (9.15143 iter/s, 10.9272s/100 iters), loss = 0.0273245
I0823 07:19:23.436180 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0273233 (* 1 = 0.0273233 loss)
I0823 07:19:23.436190 13823 sgd_solver.cpp:112] Iteration 505900, lr = 1e-06
I0823 07:19:34.320405 13823 solver.cpp:239] Iteration 506000 (9.18759 iter/s, 10.8842s/100 iters), loss = 0.0269492
I0823 07:19:34.320454 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.026948 (* 1 = 0.026948 loss)
I0823 07:19:34.320463 13823 sgd_solver.cpp:112] Iteration 506000, lr = 1e-06
I0823 07:19:45.123729 13823 solver.cpp:239] Iteration 506100 (9.25643 iter/s, 10.8033s/100 iters), loss = 0.0253618
I0823 07:19:45.123780 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0253606 (* 1 = 0.0253606 loss)
I0823 07:19:45.123790 13823 sgd_solver.cpp:112] Iteration 506100, lr = 1e-06
I0823 07:19:56.068682 13823 solver.cpp:239] Iteration 506200 (9.13665 iter/s, 10.9449s/100 iters), loss = 0.0307618
I0823 07:19:56.068733 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0307606 (* 1 = 0.0307606 loss)
I0823 07:19:56.068742 13823 sgd_solver.cpp:112] Iteration 506200, lr = 1e-06
I0823 07:20:07.042196 13823 solver.cpp:239] Iteration 506300 (9.11287 iter/s, 10.9735s/100 iters), loss = 0.0253173
I0823 07:20:07.042256 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0253161 (* 1 = 0.0253161 loss)
I0823 07:20:07.042268 13823 sgd_solver.cpp:112] Iteration 506300, lr = 1e-06
I0823 07:20:17.671991 13823 solver.cpp:239] Iteration 506400 (9.40755 iter/s, 10.6298s/100 iters), loss = 0.0228451
I0823 07:20:17.672040 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0228439 (* 1 = 0.0228439 loss)
I0823 07:20:17.672049 13823 sgd_solver.cpp:112] Iteration 506400, lr = 1e-06
I0823 07:20:28.675482 13823 solver.cpp:239] Iteration 506500 (9.08805 iter/s, 11.0035s/100 iters), loss = 0.0288577
I0823 07:20:28.675534 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0288565 (* 1 = 0.0288565 loss)
I0823 07:20:28.675542 13823 sgd_solver.cpp:112] Iteration 506500, lr = 1e-06
I0823 07:20:39.636148 13823 solver.cpp:239] Iteration 506600 (9.12356 iter/s, 10.9606s/100 iters), loss = 0.0416398
I0823 07:20:39.636198 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0416386 (* 1 = 0.0416386 loss)
I0823 07:20:39.636206 13823 sgd_solver.cpp:112] Iteration 506600, lr = 1e-06
I0823 07:20:50.691933 13823 solver.cpp:239] Iteration 506700 (9.04506 iter/s, 11.0558s/100 iters), loss = 0.0238698
I0823 07:20:50.691982 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0238686 (* 1 = 0.0238686 loss)
I0823 07:20:50.691992 13823 sgd_solver.cpp:112] Iteration 506700, lr = 1e-06
I0823 07:21:02.008277 13823 solver.cpp:239] Iteration 506800 (8.83679 iter/s, 11.3163s/100 iters), loss = 0.0267511
I0823 07:21:02.008327 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0267499 (* 1 = 0.0267499 loss)
I0823 07:21:02.008335 13823 sgd_solver.cpp:112] Iteration 506800, lr = 1e-06
I0823 07:21:13.334319 13823 solver.cpp:239] Iteration 506900 (8.82923 iter/s, 11.326s/100 iters), loss = 0.0302281
I0823 07:21:13.334376 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0302269 (* 1 = 0.0302269 loss)
I0823 07:21:13.334388 13823 sgd_solver.cpp:112] Iteration 506900, lr = 1e-06
I0823 07:21:24.553055 13823 solver.cpp:239] Iteration 507000 (8.91368 iter/s, 11.2187s/100 iters), loss = 0.0333362
I0823 07:21:24.553109 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0333351 (* 1 = 0.0333351 loss)
I0823 07:21:24.553120 13823 sgd_solver.cpp:112] Iteration 507000, lr = 1e-06
I0823 07:21:35.956102 13823 solver.cpp:239] Iteration 507100 (8.76961 iter/s, 11.403s/100 iters), loss = 0.0303746
I0823 07:21:35.956166 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0303734 (* 1 = 0.0303734 loss)
I0823 07:21:35.956176 13823 sgd_solver.cpp:112] Iteration 507100, lr = 1e-06
I0823 07:21:47.239181 13823 solver.cpp:239] Iteration 507200 (8.86286 iter/s, 11.283s/100 iters), loss = 0.0281186
I0823 07:21:47.239231 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0281174 (* 1 = 0.0281174 loss)
I0823 07:21:47.239240 13823 sgd_solver.cpp:112] Iteration 507200, lr = 1e-06
I0823 07:21:58.471284 13823 solver.cpp:239] Iteration 507300 (8.90307 iter/s, 11.2321s/100 iters), loss = 0.0271068
I0823 07:21:58.471344 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0271056 (* 1 = 0.0271056 loss)
I0823 07:21:58.471356 13823 sgd_solver.cpp:112] Iteration 507300, lr = 1e-06
I0823 07:22:09.507721 13823 solver.cpp:239] Iteration 507400 (9.06092 iter/s, 11.0364s/100 iters), loss = 0.0248446
I0823 07:22:09.507772 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0248434 (* 1 = 0.0248434 loss)
I0823 07:22:09.507782 13823 sgd_solver.cpp:112] Iteration 507400, lr = 1e-06
I0823 07:22:20.950686 13823 solver.cpp:239] Iteration 507500 (8.73901 iter/s, 11.4429s/100 iters), loss = 0.0299142
I0823 07:22:20.950737 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0299131 (* 1 = 0.0299131 loss)
I0823 07:22:20.950747 13823 sgd_solver.cpp:112] Iteration 507500, lr = 1e-06
I0823 07:22:32.497503 13823 solver.cpp:239] Iteration 507600 (8.66042 iter/s, 11.5468s/100 iters), loss = 0.0284674
I0823 07:22:32.497561 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0284662 (* 1 = 0.0284662 loss)
I0823 07:22:32.497572 13823 sgd_solver.cpp:112] Iteration 507600, lr = 1e-06
I0823 07:22:43.818449 13823 solver.cpp:239] Iteration 507700 (8.83321 iter/s, 11.3209s/100 iters), loss = 0.027996
I0823 07:22:43.818508 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0279948 (* 1 = 0.0279948 loss)
I0823 07:22:43.818521 13823 sgd_solver.cpp:112] Iteration 507700, lr = 1e-06
I0823 07:22:55.131930 13823 solver.cpp:239] Iteration 507800 (8.83904 iter/s, 11.3134s/100 iters), loss = 0.0276207
I0823 07:22:55.131986 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0276196 (* 1 = 0.0276196 loss)
I0823 07:22:55.131997 13823 sgd_solver.cpp:112] Iteration 507800, lr = 1e-06
I0823 07:23:06.673457 13823 solver.cpp:239] Iteration 507900 (8.66439 iter/s, 11.5415s/100 iters), loss = 0.0339806
I0823 07:23:06.673506 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0339795 (* 1 = 0.0339795 loss)
I0823 07:23:06.673516 13823 sgd_solver.cpp:112] Iteration 507900, lr = 1e-06
I0823 07:23:18.022091 13823 solver.cpp:239] Iteration 508000 (8.81165 iter/s, 11.3486s/100 iters), loss = 0.0259241
I0823 07:23:18.022146 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0259229 (* 1 = 0.0259229 loss)
I0823 07:23:18.022157 13823 sgd_solver.cpp:112] Iteration 508000, lr = 1e-06
I0823 07:23:29.433459 13823 solver.cpp:239] Iteration 508100 (8.76321 iter/s, 11.4113s/100 iters), loss = 0.0254723
I0823 07:23:29.433517 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0254711 (* 1 = 0.0254711 loss)
I0823 07:23:29.433528 13823 sgd_solver.cpp:112] Iteration 508100, lr = 1e-06
I0823 07:23:40.765074 13823 solver.cpp:239] Iteration 508200 (8.82489 iter/s, 11.3316s/100 iters), loss = 0.0276175
I0823 07:23:40.765131 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0276164 (* 1 = 0.0276164 loss)
I0823 07:23:40.765142 13823 sgd_solver.cpp:112] Iteration 508200, lr = 1e-06
I0823 07:23:52.507290 13823 solver.cpp:239] Iteration 508300 (8.5163 iter/s, 11.7422s/100 iters), loss = 0.0290208
I0823 07:23:52.507345 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0290197 (* 1 = 0.0290197 loss)
I0823 07:23:52.507355 13823 sgd_solver.cpp:112] Iteration 508300, lr = 1e-06
I0823 07:24:03.999208 13823 solver.cpp:239] Iteration 508400 (8.70179 iter/s, 11.4919s/100 iters), loss = 0.0261304
I0823 07:24:03.999269 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0261292 (* 1 = 0.0261292 loss)
I0823 07:24:03.999281 13823 sgd_solver.cpp:112] Iteration 508400, lr = 1e-06
I0823 07:24:15.513463 13823 solver.cpp:239] Iteration 508500 (8.68492 iter/s, 11.5142s/100 iters), loss = 0.0278074
I0823 07:24:15.513525 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0278063 (* 1 = 0.0278063 loss)
I0823 07:24:15.513537 13823 sgd_solver.cpp:112] Iteration 508500, lr = 1e-06
I0823 07:24:27.043318 13823 solver.cpp:239] Iteration 508600 (8.67316 iter/s, 11.5298s/100 iters), loss = 0.0257505
I0823 07:24:27.043376 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0257494 (* 1 = 0.0257494 loss)
I0823 07:24:27.043388 13823 sgd_solver.cpp:112] Iteration 508600, lr = 1e-06
I0823 07:24:38.565901 13823 solver.cpp:239] Iteration 508700 (8.67863 iter/s, 11.5226s/100 iters), loss = 0.0307468
I0823 07:24:38.565953 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0307457 (* 1 = 0.0307457 loss)
I0823 07:24:38.565963 13823 sgd_solver.cpp:112] Iteration 508700, lr = 1e-06
I0823 07:24:49.664698 13823 solver.cpp:239] Iteration 508800 (9.01002 iter/s, 11.0988s/100 iters), loss = 0.0347949
I0823 07:24:49.664758 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0347937 (* 1 = 0.0347937 loss)
I0823 07:24:49.664769 13823 sgd_solver.cpp:112] Iteration 508800, lr = 1e-06
I0823 07:25:00.816268 13823 solver.cpp:239] Iteration 508900 (8.96739 iter/s, 11.1515s/100 iters), loss = 0.022622
I0823 07:25:00.816329 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0226208 (* 1 = 0.0226208 loss)
I0823 07:25:00.816341 13823 sgd_solver.cpp:112] Iteration 508900, lr = 1e-06
I0823 07:25:11.994942 13823 solver.cpp:239] Iteration 509000 (8.94565 iter/s, 11.1786s/100 iters), loss = 0.0252915
I0823 07:25:11.994999 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0252903 (* 1 = 0.0252903 loss)
I0823 07:25:11.995012 13823 sgd_solver.cpp:112] Iteration 509000, lr = 1e-06
I0823 07:25:23.380244 13823 solver.cpp:239] Iteration 509100 (8.78329 iter/s, 11.3853s/100 iters), loss = 0.0403591
I0823 07:25:23.380300 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0403579 (* 1 = 0.0403579 loss)
I0823 07:25:23.380311 13823 sgd_solver.cpp:112] Iteration 509100, lr = 1e-06
I0823 07:25:35.148655 13823 solver.cpp:239] Iteration 509200 (8.49736 iter/s, 11.7684s/100 iters), loss = 0.033484
I0823 07:25:35.148710 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0334829 (* 1 = 0.0334829 loss)
I0823 07:25:35.148721 13823 sgd_solver.cpp:112] Iteration 509200, lr = 1e-06
I0823 07:25:46.559083 13823 solver.cpp:239] Iteration 509300 (8.76395 iter/s, 11.4104s/100 iters), loss = 0.0269941
I0823 07:25:46.559140 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0269929 (* 1 = 0.0269929 loss)
I0823 07:25:46.559151 13823 sgd_solver.cpp:112] Iteration 509300, lr = 1e-06
I0823 07:25:58.255964 13823 solver.cpp:239] Iteration 509400 (8.54932 iter/s, 11.6968s/100 iters), loss = 0.0553216
I0823 07:25:58.256026 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0553205 (* 1 = 0.0553205 loss)
I0823 07:25:58.256039 13823 sgd_solver.cpp:112] Iteration 509400, lr = 1e-06
I0823 07:26:09.816092 13823 solver.cpp:239] Iteration 509500 (8.65046 iter/s, 11.5601s/100 iters), loss = 0.0284602
I0823 07:26:09.816171 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.028459 (* 1 = 0.028459 loss)
I0823 07:26:09.816184 13823 sgd_solver.cpp:112] Iteration 509500, lr = 1e-06
I0823 07:26:21.075181 13823 solver.cpp:239] Iteration 509600 (8.88175 iter/s, 11.259s/100 iters), loss = 0.0350797
I0823 07:26:21.075232 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0350785 (* 1 = 0.0350785 loss)
I0823 07:26:21.075243 13823 sgd_solver.cpp:112] Iteration 509600, lr = 1e-06
I0823 07:26:32.700268 13823 solver.cpp:239] Iteration 509700 (8.60212 iter/s, 11.625s/100 iters), loss = 0.0379286
I0823 07:26:32.700316 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0379274 (* 1 = 0.0379274 loss)
I0823 07:26:32.700325 13823 sgd_solver.cpp:112] Iteration 509700, lr = 1e-06
I0823 07:26:44.455600 13823 solver.cpp:239] Iteration 509800 (8.5068 iter/s, 11.7553s/100 iters), loss = 0.0242365
I0823 07:26:44.455649 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0242353 (* 1 = 0.0242353 loss)
I0823 07:26:44.455659 13823 sgd_solver.cpp:112] Iteration 509800, lr = 1e-06
I0823 07:26:56.102852 13823 solver.cpp:239] Iteration 509900 (8.58574 iter/s, 11.6472s/100 iters), loss = 0.030176
I0823 07:26:56.102901 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0301748 (* 1 = 0.0301748 loss)
I0823 07:26:56.102911 13823 sgd_solver.cpp:112] Iteration 509900, lr = 1e-06
I0823 07:27:07.348783 13823 solver.cpp:239] Iteration 510000 (8.89214 iter/s, 11.2459s/100 iters), loss = 0.0435884
I0823 07:27:07.348834 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0435872 (* 1 = 0.0435872 loss)
I0823 07:27:07.348845 13823 sgd_solver.cpp:112] Iteration 510000, lr = 1e-06
I0823 07:27:18.672103 13823 solver.cpp:239] Iteration 510100 (8.83136 iter/s, 11.3233s/100 iters), loss = 0.0266196
I0823 07:27:18.672165 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0266184 (* 1 = 0.0266184 loss)
I0823 07:27:18.672178 13823 sgd_solver.cpp:112] Iteration 510100, lr = 1e-06
I0823 07:27:30.091153 13823 solver.cpp:239] Iteration 510200 (8.75733 iter/s, 11.419s/100 iters), loss = 0.0298562
I0823 07:27:30.091207 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0298549 (* 1 = 0.0298549 loss)
I0823 07:27:30.091217 13823 sgd_solver.cpp:112] Iteration 510200, lr = 1e-06
I0823 07:27:41.394181 13823 solver.cpp:239] Iteration 510300 (8.84722 iter/s, 11.303s/100 iters), loss = 0.0265166
I0823 07:27:41.394237 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0265154 (* 1 = 0.0265154 loss)
I0823 07:27:41.394248 13823 sgd_solver.cpp:112] Iteration 510300, lr = 1e-06
I0823 07:27:52.631692 13823 solver.cpp:239] Iteration 510400 (8.8988 iter/s, 11.2375s/100 iters), loss = 0.0408499
I0823 07:27:52.631742 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0408487 (* 1 = 0.0408487 loss)
I0823 07:27:52.631752 13823 sgd_solver.cpp:112] Iteration 510400, lr = 1e-06
I0823 07:28:03.983006 13823 solver.cpp:239] Iteration 510500 (8.80958 iter/s, 11.3513s/100 iters), loss = 0.0308627
I0823 07:28:03.983057 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0308615 (* 1 = 0.0308615 loss)
I0823 07:28:03.983065 13823 sgd_solver.cpp:112] Iteration 510500, lr = 1e-06
I0823 07:28:15.358557 13823 solver.cpp:239] Iteration 510600 (8.79081 iter/s, 11.3755s/100 iters), loss = 0.0244621
I0823 07:28:15.358608 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0244609 (* 1 = 0.0244609 loss)
I0823 07:28:15.358618 13823 sgd_solver.cpp:112] Iteration 510600, lr = 1e-06
I0823 07:28:27.049042 13823 solver.cpp:239] Iteration 510700 (8.55399 iter/s, 11.6904s/100 iters), loss = 0.0283659
I0823 07:28:27.049096 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0283647 (* 1 = 0.0283647 loss)
I0823 07:28:27.049108 13823 sgd_solver.cpp:112] Iteration 510700, lr = 1e-06
I0823 07:28:38.640288 13823 solver.cpp:239] Iteration 510800 (8.62723 iter/s, 11.5912s/100 iters), loss = 0.0289804
I0823 07:28:38.640345 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0289792 (* 1 = 0.0289792 loss)
I0823 07:28:38.640357 13823 sgd_solver.cpp:112] Iteration 510800, lr = 1e-06
I0823 07:28:50.383357 13823 solver.cpp:239] Iteration 510900 (8.51569 iter/s, 11.743s/100 iters), loss = 0.0320119
I0823 07:28:50.383412 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0320107 (* 1 = 0.0320107 loss)
I0823 07:28:50.383424 13823 sgd_solver.cpp:112] Iteration 510900, lr = 1e-06
I0823 07:29:02.187845 13823 solver.cpp:239] Iteration 511000 (8.47138 iter/s, 11.8045s/100 iters), loss = 0.0232324
I0823 07:29:02.187896 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0232313 (* 1 = 0.0232313 loss)
I0823 07:29:02.187906 13823 sgd_solver.cpp:112] Iteration 511000, lr = 1e-06
I0823 07:29:13.907514 13823 solver.cpp:239] Iteration 511100 (8.53269 iter/s, 11.7196s/100 iters), loss = 0.0338313
I0823 07:29:13.907573 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0338301 (* 1 = 0.0338301 loss)
I0823 07:29:13.907584 13823 sgd_solver.cpp:112] Iteration 511100, lr = 1e-06
I0823 07:29:25.873327 13823 solver.cpp:239] Iteration 511200 (8.35717 iter/s, 11.9658s/100 iters), loss = 0.033864
I0823 07:29:25.873385 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0338628 (* 1 = 0.0338628 loss)
I0823 07:29:25.873396 13823 sgd_solver.cpp:112] Iteration 511200, lr = 1e-06
I0823 07:29:37.226502 13823 solver.cpp:239] Iteration 511300 (8.80814 iter/s, 11.3531s/100 iters), loss = 0.0281774
I0823 07:29:37.226553 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0281762 (* 1 = 0.0281762 loss)
I0823 07:29:37.226563 13823 sgd_solver.cpp:112] Iteration 511300, lr = 1e-06
I0823 07:29:46.581917 13823 solver.cpp:239] Iteration 511400 (10.689 iter/s, 9.35538s/100 iters), loss = 0.0283221
I0823 07:29:46.581972 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0283209 (* 1 = 0.0283209 loss)
I0823 07:29:46.581980 13823 sgd_solver.cpp:112] Iteration 511400, lr = 1e-06
I0823 07:29:56.160456 13823 solver.cpp:239] Iteration 511500 (10.4401 iter/s, 9.57849s/100 iters), loss = 0.0257237
I0823 07:29:56.160508 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0257225 (* 1 = 0.0257225 loss)
I0823 07:29:56.160518 13823 sgd_solver.cpp:112] Iteration 511500, lr = 1e-06
I0823 07:30:05.865881 13823 solver.cpp:239] Iteration 511600 (10.3036 iter/s, 9.70539s/100 iters), loss = 0.0313993
I0823 07:30:05.865931 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.031398 (* 1 = 0.031398 loss)
I0823 07:30:05.865942 13823 sgd_solver.cpp:112] Iteration 511600, lr = 1e-06
I0823 07:30:15.391921 13823 solver.cpp:239] Iteration 511700 (10.4976 iter/s, 9.52601s/100 iters), loss = 0.0333541
I0823 07:30:15.391963 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0333529 (* 1 = 0.0333529 loss)
I0823 07:30:15.391969 13823 sgd_solver.cpp:112] Iteration 511700, lr = 1e-06
I0823 07:30:24.881168 13823 solver.cpp:239] Iteration 511800 (10.5383 iter/s, 9.48922s/100 iters), loss = 0.0263636
I0823 07:30:24.881228 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0263624 (* 1 = 0.0263624 loss)
I0823 07:30:24.881239 13823 sgd_solver.cpp:112] Iteration 511800, lr = 1e-06
I0823 07:30:34.519608 13823 solver.cpp:239] Iteration 511900 (10.3752 iter/s, 9.63839s/100 iters), loss = 0.0355318
I0823 07:30:34.519659 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0355306 (* 1 = 0.0355306 loss)
I0823 07:30:34.519670 13823 sgd_solver.cpp:112] Iteration 511900, lr = 1e-06
I0823 07:30:44.076499 13823 solver.cpp:239] Iteration 512000 (10.4637 iter/s, 9.55685s/100 iters), loss = 0.022661
I0823 07:30:44.076550 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0226597 (* 1 = 0.0226597 loss)
I0823 07:30:44.076560 13823 sgd_solver.cpp:112] Iteration 512000, lr = 1e-06
I0823 07:30:53.690057 13823 solver.cpp:239] Iteration 512100 (10.402 iter/s, 9.61352s/100 iters), loss = 0.0278665
I0823 07:30:53.690106 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0278652 (* 1 = 0.0278652 loss)
I0823 07:30:53.690116 13823 sgd_solver.cpp:112] Iteration 512100, lr = 1e-06
I0823 07:31:03.558725 13823 solver.cpp:239] Iteration 512200 (10.1331 iter/s, 9.86863s/100 iters), loss = 0.0294938
I0823 07:31:03.558790 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0294925 (* 1 = 0.0294925 loss)
I0823 07:31:03.558802 13823 sgd_solver.cpp:112] Iteration 512200, lr = 1e-06
I0823 07:31:13.045398 13823 solver.cpp:239] Iteration 512300 (10.5412 iter/s, 9.48662s/100 iters), loss = 0.0223589
I0823 07:31:13.045451 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0223576 (* 1 = 0.0223576 loss)
I0823 07:31:13.045461 13823 sgd_solver.cpp:112] Iteration 512300, lr = 1e-06
I0823 07:31:22.774080 13823 solver.cpp:239] Iteration 512400 (10.2789 iter/s, 9.72864s/100 iters), loss = 0.0244914
I0823 07:31:22.774137 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0244901 (* 1 = 0.0244901 loss)
I0823 07:31:22.774147 13823 sgd_solver.cpp:112] Iteration 512400, lr = 1e-06
I0823 07:31:32.248903 13823 solver.cpp:239] Iteration 512500 (10.5543 iter/s, 9.47478s/100 iters), loss = 0.0311263
I0823 07:31:32.248944 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.031125 (* 1 = 0.031125 loss)
I0823 07:31:32.248952 13823 sgd_solver.cpp:112] Iteration 512500, lr = 1e-06
I0823 07:31:41.622017 13823 solver.cpp:239] Iteration 512600 (10.6688 iter/s, 9.37309s/100 iters), loss = 0.0268978
I0823 07:31:41.622071 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0268966 (* 1 = 0.0268966 loss)
I0823 07:31:41.622078 13823 sgd_solver.cpp:112] Iteration 512600, lr = 1e-06
I0823 07:31:51.385058 13823 solver.cpp:239] Iteration 512700 (10.2428 iter/s, 9.763s/100 iters), loss = 0.0273112
I0823 07:31:51.385108 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.02731 (* 1 = 0.02731 loss)
I0823 07:31:51.385118 13823 sgd_solver.cpp:112] Iteration 512700, lr = 1e-06
I0823 07:32:00.880256 13823 solver.cpp:239] Iteration 512800 (10.5317 iter/s, 9.49517s/100 iters), loss = 0.0245001
I0823 07:32:00.880297 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0244988 (* 1 = 0.0244988 loss)
I0823 07:32:00.880306 13823 sgd_solver.cpp:112] Iteration 512800, lr = 1e-06
I0823 07:32:10.520225 13823 solver.cpp:239] Iteration 512900 (10.3735 iter/s, 9.63994s/100 iters), loss = 0.0255903
I0823 07:32:10.520284 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0255891 (* 1 = 0.0255891 loss)
I0823 07:32:10.520295 13823 sgd_solver.cpp:112] Iteration 512900, lr = 1e-06
I0823 07:32:20.252338 13823 solver.cpp:239] Iteration 513000 (10.2753 iter/s, 9.73207s/100 iters), loss = 0.0242712
I0823 07:32:20.252388 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.02427 (* 1 = 0.02427 loss)
I0823 07:32:20.252398 13823 sgd_solver.cpp:112] Iteration 513000, lr = 1e-06
I0823 07:32:30.048063 13823 solver.cpp:239] Iteration 513100 (10.2086 iter/s, 9.79569s/100 iters), loss = 0.0247969
I0823 07:32:30.048120 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0247957 (* 1 = 0.0247957 loss)
I0823 07:32:30.048135 13823 sgd_solver.cpp:112] Iteration 513100, lr = 1e-06
I0823 07:32:39.937820 13823 solver.cpp:239] Iteration 513200 (10.1115 iter/s, 9.88971s/100 iters), loss = 0.0273679
I0823 07:32:39.937875 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0273667 (* 1 = 0.0273667 loss)
I0823 07:32:39.937885 13823 sgd_solver.cpp:112] Iteration 513200, lr = 1e-06
I0823 07:32:49.479595 13823 solver.cpp:239] Iteration 513300 (10.4803 iter/s, 9.54174s/100 iters), loss = 0.0243118
I0823 07:32:49.479640 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0243106 (* 1 = 0.0243106 loss)
I0823 07:32:49.479646 13823 sgd_solver.cpp:112] Iteration 513300, lr = 1e-06
I0823 07:32:59.124971 13823 solver.cpp:239] Iteration 513400 (10.3677 iter/s, 9.64534s/100 iters), loss = 0.0256047
I0823 07:32:59.125025 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0256035 (* 1 = 0.0256035 loss)
I0823 07:32:59.125035 13823 sgd_solver.cpp:112] Iteration 513400, lr = 1e-06
I0823 07:33:08.995306 13823 solver.cpp:239] Iteration 513500 (10.1314 iter/s, 9.87029s/100 iters), loss = 0.0297081
I0823 07:33:08.995358 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0297069 (* 1 = 0.0297069 loss)
I0823 07:33:08.995368 13823 sgd_solver.cpp:112] Iteration 513500, lr = 1e-06
I0823 07:33:18.748484 13823 solver.cpp:239] Iteration 513600 (10.2531 iter/s, 9.75314s/100 iters), loss = 0.0253961
I0823 07:33:18.748536 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0253949 (* 1 = 0.0253949 loss)
I0823 07:33:18.748546 13823 sgd_solver.cpp:112] Iteration 513600, lr = 1e-06
I0823 07:33:28.482532 13823 solver.cpp:239] Iteration 513700 (10.2733 iter/s, 9.73401s/100 iters), loss = 0.0278791
I0823 07:33:28.482589 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0278778 (* 1 = 0.0278778 loss)
I0823 07:33:28.482600 13823 sgd_solver.cpp:112] Iteration 513700, lr = 1e-06
I0823 07:33:38.163343 13823 solver.cpp:239] Iteration 513800 (10.3298 iter/s, 9.68077s/100 iters), loss = 0.0242897
I0823 07:33:38.163386 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0242885 (* 1 = 0.0242885 loss)
I0823 07:33:38.163394 13823 sgd_solver.cpp:112] Iteration 513800, lr = 1e-06
I0823 07:33:47.996325 13823 solver.cpp:239] Iteration 513900 (10.1699 iter/s, 9.83295s/100 iters), loss = 0.0291242
I0823 07:33:47.996379 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0291229 (* 1 = 0.0291229 loss)
I0823 07:33:47.996388 13823 sgd_solver.cpp:112] Iteration 513900, lr = 1e-06
I0823 07:33:58.008066 13823 solver.cpp:239] Iteration 514000 (9.98831 iter/s, 10.0117s/100 iters), loss = 0.0244317
I0823 07:33:58.008128 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0244305 (* 1 = 0.0244305 loss)
I0823 07:33:58.008147 13823 sgd_solver.cpp:112] Iteration 514000, lr = 1e-06
I0823 07:34:07.924410 13823 solver.cpp:239] Iteration 514100 (10.0844 iter/s, 9.9163s/100 iters), loss = 0.0269107
I0823 07:34:07.924463 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0269095 (* 1 = 0.0269095 loss)
I0823 07:34:07.924473 13823 sgd_solver.cpp:112] Iteration 514100, lr = 1e-06
I0823 07:34:17.657301 13823 solver.cpp:239] Iteration 514200 (10.2745 iter/s, 9.73285s/100 iters), loss = 0.0270728
I0823 07:34:17.657353 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0270716 (* 1 = 0.0270716 loss)
I0823 07:34:17.657362 13823 sgd_solver.cpp:112] Iteration 514200, lr = 1e-06
I0823 07:34:27.439615 13823 solver.cpp:239] Iteration 514300 (10.2226 iter/s, 9.78227s/100 iters), loss = 0.0241552
I0823 07:34:27.439666 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.024154 (* 1 = 0.024154 loss)
I0823 07:34:27.439677 13823 sgd_solver.cpp:112] Iteration 514300, lr = 1e-06
I0823 07:34:37.196087 13823 solver.cpp:239] Iteration 514400 (10.2496 iter/s, 9.75644s/100 iters), loss = 0.0255866
I0823 07:34:37.196146 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0255853 (* 1 = 0.0255853 loss)
I0823 07:34:37.196156 13823 sgd_solver.cpp:112] Iteration 514400, lr = 1e-06
I0823 07:34:46.997792 13823 solver.cpp:239] Iteration 514500 (10.2024 iter/s, 9.80166s/100 iters), loss = 0.028209
I0823 07:34:46.997844 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0282078 (* 1 = 0.0282078 loss)
I0823 07:34:46.997854 13823 sgd_solver.cpp:112] Iteration 514500, lr = 1e-06
I0823 07:34:56.455209 13823 solver.cpp:239] Iteration 514600 (10.5737 iter/s, 9.45738s/100 iters), loss = 0.0254746
I0823 07:34:56.455252 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0254733 (* 1 = 0.0254733 loss)
I0823 07:34:56.455260 13823 sgd_solver.cpp:112] Iteration 514600, lr = 1e-06
I0823 07:35:05.993705 13823 solver.cpp:239] Iteration 514700 (10.4839 iter/s, 9.53847s/100 iters), loss = 0.0280761
I0823 07:35:05.993750 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0280749 (* 1 = 0.0280749 loss)
I0823 07:35:05.993759 13823 sgd_solver.cpp:112] Iteration 514700, lr = 1e-06
I0823 07:35:15.663264 13823 solver.cpp:239] Iteration 514800 (10.3418 iter/s, 9.66953s/100 iters), loss = 0.0240246
I0823 07:35:15.663318 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0240233 (* 1 = 0.0240233 loss)
I0823 07:35:15.663329 13823 sgd_solver.cpp:112] Iteration 514800, lr = 1e-06
I0823 07:35:25.848644 13823 solver.cpp:239] Iteration 514900 (9.81804 iter/s, 10.1853s/100 iters), loss = 0.0234875
I0823 07:35:25.848696 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0234862 (* 1 = 0.0234862 loss)
I0823 07:35:25.848707 13823 sgd_solver.cpp:112] Iteration 514900, lr = 1e-06
I0823 07:35:35.651345 13823 solver.cpp:239] Iteration 515000 (10.2013 iter/s, 9.80267s/100 iters), loss = 0.0353409
I0823 07:35:35.651394 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0353396 (* 1 = 0.0353396 loss)
I0823 07:35:35.651404 13823 sgd_solver.cpp:112] Iteration 515000, lr = 1e-06
I0823 07:35:45.777276 13823 solver.cpp:239] Iteration 515100 (9.87567 iter/s, 10.1259s/100 iters), loss = 0.0416947
I0823 07:35:45.777329 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0416935 (* 1 = 0.0416935 loss)
I0823 07:35:45.777338 13823 sgd_solver.cpp:112] Iteration 515100, lr = 1e-06
I0823 07:35:55.826515 13823 solver.cpp:239] Iteration 515200 (9.95104 iter/s, 10.0492s/100 iters), loss = 0.0305063
I0823 07:35:55.826566 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0305051 (* 1 = 0.0305051 loss)
I0823 07:35:55.826576 13823 sgd_solver.cpp:112] Iteration 515200, lr = 1e-06
I0823 07:36:05.603026 13823 solver.cpp:239] Iteration 515300 (10.2286 iter/s, 9.77647s/100 iters), loss = 0.0253496
I0823 07:36:05.603090 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0253483 (* 1 = 0.0253483 loss)
I0823 07:36:05.603101 13823 sgd_solver.cpp:112] Iteration 515300, lr = 1e-06
I0823 07:36:15.607450 13823 solver.cpp:239] Iteration 515400 (9.99562 iter/s, 10.0044s/100 iters), loss = 0.0253558
I0823 07:36:15.607501 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0253545 (* 1 = 0.0253545 loss)
I0823 07:36:15.607509 13823 sgd_solver.cpp:112] Iteration 515400, lr = 1e-06
I0823 07:36:25.674175 13823 solver.cpp:239] Iteration 515500 (9.93375 iter/s, 10.0667s/100 iters), loss = 0.0275343
I0823 07:36:25.674227 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.027533 (* 1 = 0.027533 loss)
I0823 07:36:25.674237 13823 sgd_solver.cpp:112] Iteration 515500, lr = 1e-06
I0823 07:36:35.381168 13823 solver.cpp:239] Iteration 515600 (10.3019 iter/s, 9.70696s/100 iters), loss = 0.0233682
I0823 07:36:35.381219 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0233669 (* 1 = 0.0233669 loss)
I0823 07:36:35.381228 13823 sgd_solver.cpp:112] Iteration 515600, lr = 1e-06
I0823 07:36:45.277809 13823 solver.cpp:239] Iteration 515700 (10.1045 iter/s, 9.8966s/100 iters), loss = 0.0311331
I0823 07:36:45.277860 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0311319 (* 1 = 0.0311319 loss)
I0823 07:36:45.277869 13823 sgd_solver.cpp:112] Iteration 515700, lr = 1e-06
I0823 07:36:54.890379 13823 solver.cpp:239] Iteration 515800 (10.4031 iter/s, 9.61253s/100 iters), loss = 0.0246316
I0823 07:36:54.890427 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0246303 (* 1 = 0.0246303 loss)
I0823 07:36:54.890436 13823 sgd_solver.cpp:112] Iteration 515800, lr = 1e-06
I0823 07:37:05.006083 13823 solver.cpp:239] Iteration 515900 (9.88565 iter/s, 10.1157s/100 iters), loss = 0.0254043
I0823 07:37:05.006135 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0254031 (* 1 = 0.0254031 loss)
I0823 07:37:05.006145 13823 sgd_solver.cpp:112] Iteration 515900, lr = 1e-06
I0823 07:37:14.950923 13823 solver.cpp:239] Iteration 516000 (10.0555 iter/s, 9.94481s/100 iters), loss = 0.0357236
I0823 07:37:14.950973 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0357223 (* 1 = 0.0357223 loss)
I0823 07:37:14.950983 13823 sgd_solver.cpp:112] Iteration 516000, lr = 1e-06
I0823 07:37:24.872872 13823 solver.cpp:239] Iteration 516100 (10.0787 iter/s, 9.92192s/100 iters), loss = 0.0276536
I0823 07:37:24.872923 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0276523 (* 1 = 0.0276523 loss)
I0823 07:37:24.872932 13823 sgd_solver.cpp:112] Iteration 516100, lr = 1e-06
I0823 07:37:35.066483 13823 solver.cpp:239] Iteration 516200 (9.8101 iter/s, 10.1936s/100 iters), loss = 0.0361374
I0823 07:37:35.066545 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0361361 (* 1 = 0.0361361 loss)
I0823 07:37:35.066556 13823 sgd_solver.cpp:112] Iteration 516200, lr = 1e-06
I0823 07:37:44.773063 13823 solver.cpp:239] Iteration 516300 (10.3023 iter/s, 9.70654s/100 iters), loss = 0.0325499
I0823 07:37:44.773114 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0325486 (* 1 = 0.0325486 loss)
I0823 07:37:44.773123 13823 sgd_solver.cpp:112] Iteration 516300, lr = 1e-06
I0823 07:37:54.903394 13823 solver.cpp:239] Iteration 516400 (9.87138 iter/s, 10.1303s/100 iters), loss = 0.0277295
I0823 07:37:54.903443 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0277282 (* 1 = 0.0277282 loss)
I0823 07:37:54.903453 13823 sgd_solver.cpp:112] Iteration 516400, lr = 1e-06
I0823 07:38:04.876507 13823 solver.cpp:239] Iteration 516500 (10.027 iter/s, 9.97308s/100 iters), loss = 0.0274771
I0823 07:38:04.876562 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0274758 (* 1 = 0.0274758 loss)
I0823 07:38:04.876574 13823 sgd_solver.cpp:112] Iteration 516500, lr = 1e-06
I0823 07:38:14.866914 13823 solver.cpp:239] Iteration 516600 (10.0096 iter/s, 9.99036s/100 iters), loss = 0.024005
I0823 07:38:14.866976 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0240038 (* 1 = 0.0240038 loss)
I0823 07:38:14.866986 13823 sgd_solver.cpp:112] Iteration 516600, lr = 1e-06
I0823 07:38:25.065807 13823 solver.cpp:239] Iteration 516700 (9.80503 iter/s, 10.1988s/100 iters), loss = 0.02431
I0823 07:38:25.065858 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0243087 (* 1 = 0.0243087 loss)
I0823 07:38:25.065868 13823 sgd_solver.cpp:112] Iteration 516700, lr = 1e-06
I0823 07:38:34.911013 13823 solver.cpp:239] Iteration 516800 (10.1573 iter/s, 9.84517s/100 iters), loss = 0.0275827
I0823 07:38:34.911063 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0275814 (* 1 = 0.0275814 loss)
I0823 07:38:34.911072 13823 sgd_solver.cpp:112] Iteration 516800, lr = 1e-06
I0823 07:38:44.689569 13823 solver.cpp:239] Iteration 516900 (10.2265 iter/s, 9.77852s/100 iters), loss = 0.0289671
I0823 07:38:44.689618 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0289658 (* 1 = 0.0289658 loss)
I0823 07:38:44.689628 13823 sgd_solver.cpp:112] Iteration 516900, lr = 1e-06
I0823 07:38:54.533437 13823 solver.cpp:239] Iteration 517000 (10.1586 iter/s, 9.84383s/100 iters), loss = 0.0236716
I0823 07:38:54.533486 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0236703 (* 1 = 0.0236703 loss)
I0823 07:38:54.533496 13823 sgd_solver.cpp:112] Iteration 517000, lr = 1e-06
I0823 07:39:04.563655 13823 solver.cpp:239] Iteration 517100 (9.96991 iter/s, 10.0302s/100 iters), loss = 0.0360283
I0823 07:39:04.563706 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.036027 (* 1 = 0.036027 loss)
I0823 07:39:04.563716 13823 sgd_solver.cpp:112] Iteration 517100, lr = 1e-06
I0823 07:39:14.432838 13823 solver.cpp:239] Iteration 517200 (10.1326 iter/s, 9.86915s/100 iters), loss = 0.0342278
I0823 07:39:14.432888 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0342265 (* 1 = 0.0342265 loss)
I0823 07:39:14.432898 13823 sgd_solver.cpp:112] Iteration 517200, lr = 1e-06
I0823 07:39:24.433161 13823 solver.cpp:239] Iteration 517300 (9.99971 iter/s, 10.0003s/100 iters), loss = 0.0241474
I0823 07:39:24.433210 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0241461 (* 1 = 0.0241461 loss)
I0823 07:39:24.433219 13823 sgd_solver.cpp:112] Iteration 517300, lr = 1e-06
I0823 07:39:34.276115 13823 solver.cpp:239] Iteration 517400 (10.1596 iter/s, 9.84292s/100 iters), loss = 0.0268688
I0823 07:39:34.276170 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0268675 (* 1 = 0.0268675 loss)
I0823 07:39:34.276178 13823 sgd_solver.cpp:112] Iteration 517400, lr = 1e-06
I0823 07:39:44.247856 13823 solver.cpp:239] Iteration 517500 (10.0284 iter/s, 9.9717s/100 iters), loss = 0.0263005
I0823 07:39:44.247905 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0262992 (* 1 = 0.0262992 loss)
I0823 07:39:44.247915 13823 sgd_solver.cpp:112] Iteration 517500, lr = 1e-06
I0823 07:39:54.234966 13823 solver.cpp:239] Iteration 517600 (10.0129 iter/s, 9.98708s/100 iters), loss = 0.0273528
I0823 07:39:54.235015 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0273514 (* 1 = 0.0273514 loss)
I0823 07:39:54.235024 13823 sgd_solver.cpp:112] Iteration 517600, lr = 1e-06
I0823 07:40:04.392998 13823 solver.cpp:239] Iteration 517700 (9.84446 iter/s, 10.158s/100 iters), loss = 0.0244004
I0823 07:40:04.393046 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0243991 (* 1 = 0.0243991 loss)
I0823 07:40:04.393056 13823 sgd_solver.cpp:112] Iteration 517700, lr = 1e-06
I0823 07:40:14.390450 13823 solver.cpp:239] Iteration 517800 (10.0026 iter/s, 9.99742s/100 iters), loss = 0.0244805
I0823 07:40:14.390506 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0244792 (* 1 = 0.0244792 loss)
I0823 07:40:14.390517 13823 sgd_solver.cpp:112] Iteration 517800, lr = 1e-06
I0823 07:40:24.536520 13823 solver.cpp:239] Iteration 517900 (9.85607 iter/s, 10.146s/100 iters), loss = 0.0258866
I0823 07:40:24.536571 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0258853 (* 1 = 0.0258853 loss)
I0823 07:40:24.536581 13823 sgd_solver.cpp:112] Iteration 517900, lr = 1e-06
I0823 07:40:34.629865 13823 solver.cpp:239] Iteration 518000 (9.90755 iter/s, 10.0933s/100 iters), loss = 0.037763
I0823 07:40:34.629914 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0377616 (* 1 = 0.0377616 loss)
I0823 07:40:34.629925 13823 sgd_solver.cpp:112] Iteration 518000, lr = 1e-06
I0823 07:40:44.823318 13823 solver.cpp:239] Iteration 518100 (9.81025 iter/s, 10.1934s/100 iters), loss = 0.0537709
I0823 07:40:44.823372 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0537696 (* 1 = 0.0537696 loss)
I0823 07:40:44.823384 13823 sgd_solver.cpp:112] Iteration 518100, lr = 1e-06
I0823 07:40:54.778712 13823 solver.cpp:239] Iteration 518200 (10.0448 iter/s, 9.95536s/100 iters), loss = 0.0285026
I0823 07:40:54.778764 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0285013 (* 1 = 0.0285013 loss)
I0823 07:40:54.778771 13823 sgd_solver.cpp:112] Iteration 518200, lr = 1e-06
I0823 07:41:04.852607 13823 solver.cpp:239] Iteration 518300 (9.92669 iter/s, 10.0739s/100 iters), loss = 0.0253571
I0823 07:41:04.852664 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0253558 (* 1 = 0.0253558 loss)
I0823 07:41:04.852676 13823 sgd_solver.cpp:112] Iteration 518300, lr = 1e-06
I0823 07:41:15.317265 13823 solver.cpp:239] Iteration 518400 (9.55601 iter/s, 10.4646s/100 iters), loss = 0.0241409
I0823 07:41:15.317319 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0241396 (* 1 = 0.0241396 loss)
I0823 07:41:15.317330 13823 sgd_solver.cpp:112] Iteration 518400, lr = 1e-06
I0823 07:41:25.281366 13823 solver.cpp:239] Iteration 518500 (10.0361 iter/s, 9.96406s/100 iters), loss = 0.0231914
I0823 07:41:25.281431 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0231901 (* 1 = 0.0231901 loss)
I0823 07:41:25.281445 13823 sgd_solver.cpp:112] Iteration 518500, lr = 1e-06
I0823 07:41:35.359865 13823 solver.cpp:239] Iteration 518600 (9.92216 iter/s, 10.0785s/100 iters), loss = 0.0254589
I0823 07:41:35.359915 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0254576 (* 1 = 0.0254576 loss)
I0823 07:41:35.359925 13823 sgd_solver.cpp:112] Iteration 518600, lr = 1e-06
I0823 07:41:45.529417 13823 solver.cpp:239] Iteration 518700 (9.83331 iter/s, 10.1695s/100 iters), loss = 0.0341239
I0823 07:41:45.529466 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0341226 (* 1 = 0.0341226 loss)
I0823 07:41:45.529476 13823 sgd_solver.cpp:112] Iteration 518700, lr = 1e-06
I0823 07:41:55.736624 13823 solver.cpp:239] Iteration 518800 (9.79703 iter/s, 10.2072s/100 iters), loss = 0.0276907
I0823 07:41:55.736672 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0276894 (* 1 = 0.0276894 loss)
I0823 07:41:55.736681 13823 sgd_solver.cpp:112] Iteration 518800, lr = 1e-06
I0823 07:42:05.920325 13823 solver.cpp:239] Iteration 518900 (9.81964 iter/s, 10.1837s/100 iters), loss = 0.033715
I0823 07:42:05.920379 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0337137 (* 1 = 0.0337137 loss)
I0823 07:42:05.920390 13823 sgd_solver.cpp:112] Iteration 518900, lr = 1e-06
I0823 07:42:16.093247 13823 solver.cpp:239] Iteration 519000 (9.83005 iter/s, 10.1729s/100 iters), loss = 0.0236005
I0823 07:42:16.093297 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0235992 (* 1 = 0.0235992 loss)
I0823 07:42:16.093308 13823 sgd_solver.cpp:112] Iteration 519000, lr = 1e-06
I0823 07:42:26.053269 13823 solver.cpp:239] Iteration 519100 (10.0402 iter/s, 9.95999s/100 iters), loss = 0.0267381
I0823 07:42:26.053319 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0267367 (* 1 = 0.0267367 loss)
I0823 07:42:26.053329 13823 sgd_solver.cpp:112] Iteration 519100, lr = 1e-06
I0823 07:42:36.592598 13823 solver.cpp:239] Iteration 519200 (9.4883 iter/s, 10.5393s/100 iters), loss = 0.0267809
I0823 07:42:36.592655 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0267796 (* 1 = 0.0267796 loss)
I0823 07:42:36.592666 13823 sgd_solver.cpp:112] Iteration 519200, lr = 1e-06
I0823 07:42:47.028384 13823 solver.cpp:239] Iteration 519300 (9.58245 iter/s, 10.4357s/100 iters), loss = 0.0298558
I0823 07:42:47.028445 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0298545 (* 1 = 0.0298545 loss)
I0823 07:42:47.028456 13823 sgd_solver.cpp:112] Iteration 519300, lr = 1e-06
I0823 07:42:57.333917 13823 solver.cpp:239] Iteration 519400 (9.70356 iter/s, 10.3055s/100 iters), loss = 0.0266748
I0823 07:42:57.333966 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0266735 (* 1 = 0.0266735 loss)
I0823 07:42:57.333976 13823 sgd_solver.cpp:112] Iteration 519400, lr = 1e-06
I0823 07:43:07.671797 13823 solver.cpp:239] Iteration 519500 (9.67319 iter/s, 10.3378s/100 iters), loss = 0.0270334
I0823 07:43:07.671859 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0270321 (* 1 = 0.0270321 loss)
I0823 07:43:07.671872 13823 sgd_solver.cpp:112] Iteration 519500, lr = 1e-06
I0823 07:43:17.991916 13823 solver.cpp:239] Iteration 519600 (9.68985 iter/s, 10.3201s/100 iters), loss = 0.0277082
I0823 07:43:17.991974 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0277069 (* 1 = 0.0277069 loss)
I0823 07:43:17.991986 13823 sgd_solver.cpp:112] Iteration 519600, lr = 1e-06
I0823 07:43:28.543833 13823 solver.cpp:239] Iteration 519700 (9.47699 iter/s, 10.5519s/100 iters), loss = 0.0355661
I0823 07:43:28.543893 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0355647 (* 1 = 0.0355647 loss)
I0823 07:43:28.543905 13823 sgd_solver.cpp:112] Iteration 519700, lr = 1e-06
I0823 07:43:38.837779 13823 solver.cpp:239] Iteration 519800 (9.71449 iter/s, 10.2939s/100 iters), loss = 0.0245796
I0823 07:43:38.837843 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0245783 (* 1 = 0.0245783 loss)
I0823 07:43:38.837855 13823 sgd_solver.cpp:112] Iteration 519800, lr = 1e-06
I0823 07:43:49.535620 13823 solver.cpp:239] Iteration 519900 (9.34772 iter/s, 10.6978s/100 iters), loss = 0.0240263
I0823 07:43:49.535670 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.024025 (* 1 = 0.024025 loss)
I0823 07:43:49.535678 13823 sgd_solver.cpp:112] Iteration 519900, lr = 1e-06
I0823 07:44:00.031365 13823 solver.cpp:464] Snapshotting to binary proto file ./model_112/cascade_mobilenet_112_iter_520000.caffemodel
I0823 07:44:00.074170 13823 sgd_solver.cpp:284] Snapshotting solver state to binary proto file ./model_112/cascade_mobilenet_112_iter_520000.solverstate
I0823 07:44:00.105108 13823 solver.cpp:347] Iteration 520000, Testing net (#0)
I0823 07:45:01.241873 13823 solver.cpp:414]     Test net output #0: landmark_loss = 0.0219838 (* 1 = 0.0219838 loss)
I0823 07:45:01.329164 13823 solver.cpp:239] Iteration 520000 (1.39288 iter/s, 71.7937s/100 iters), loss = 0.0254918
I0823 07:45:01.329201 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0254905 (* 1 = 0.0254905 loss)
I0823 07:45:01.329212 13823 sgd_solver.cpp:112] Iteration 520000, lr = 1e-06
I0823 07:45:12.175575 13823 solver.cpp:239] Iteration 520100 (9.21966 iter/s, 10.8464s/100 iters), loss = 0.0253531
I0823 07:45:12.175631 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0253518 (* 1 = 0.0253518 loss)
I0823 07:45:12.175642 13823 sgd_solver.cpp:112] Iteration 520100, lr = 1e-06
I0823 07:45:22.786164 13823 solver.cpp:239] Iteration 520200 (9.42458 iter/s, 10.6106s/100 iters), loss = 0.0253638
I0823 07:45:22.786211 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0253624 (* 1 = 0.0253624 loss)
I0823 07:45:22.786219 13823 sgd_solver.cpp:112] Iteration 520200, lr = 1e-06
I0823 07:45:33.301250 13823 solver.cpp:239] Iteration 520300 (9.51017 iter/s, 10.5151s/100 iters), loss = 0.0312257
I0823 07:45:33.301301 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0312243 (* 1 = 0.0312243 loss)
I0823 07:45:33.301311 13823 sgd_solver.cpp:112] Iteration 520300, lr = 1e-06
I0823 07:45:43.887387 13823 solver.cpp:239] Iteration 520400 (9.44634 iter/s, 10.5861s/100 iters), loss = 0.0277776
I0823 07:45:43.887449 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0277762 (* 1 = 0.0277762 loss)
I0823 07:45:43.887462 13823 sgd_solver.cpp:112] Iteration 520400, lr = 1e-06
I0823 07:45:54.502501 13823 solver.cpp:239] Iteration 520500 (9.42056 iter/s, 10.6151s/100 iters), loss = 0.0212574
I0823 07:45:54.502558 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0212561 (* 1 = 0.0212561 loss)
I0823 07:45:54.502569 13823 sgd_solver.cpp:112] Iteration 520500, lr = 1e-06
I0823 07:46:05.180346 13823 solver.cpp:239] Iteration 520600 (9.36521 iter/s, 10.6778s/100 iters), loss = 0.0302969
I0823 07:46:05.180397 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0302956 (* 1 = 0.0302956 loss)
I0823 07:46:05.180408 13823 sgd_solver.cpp:112] Iteration 520600, lr = 1e-06
I0823 07:46:15.930152 13823 solver.cpp:239] Iteration 520700 (9.30252 iter/s, 10.7498s/100 iters), loss = 0.0281753
I0823 07:46:15.930203 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.028174 (* 1 = 0.028174 loss)
I0823 07:46:15.930212 13823 sgd_solver.cpp:112] Iteration 520700, lr = 1e-06
I0823 07:46:26.784168 13823 solver.cpp:239] Iteration 520800 (9.21321 iter/s, 10.854s/100 iters), loss = 0.026138
I0823 07:46:26.784234 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0261366 (* 1 = 0.0261366 loss)
I0823 07:46:26.784246 13823 sgd_solver.cpp:112] Iteration 520800, lr = 1e-06
I0823 07:46:37.220707 13823 solver.cpp:239] Iteration 520900 (9.58176 iter/s, 10.4365s/100 iters), loss = 0.0267372
I0823 07:46:37.220757 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0267359 (* 1 = 0.0267359 loss)
I0823 07:46:37.220765 13823 sgd_solver.cpp:112] Iteration 520900, lr = 1e-06
I0823 07:46:47.900002 13823 solver.cpp:239] Iteration 521000 (9.36394 iter/s, 10.6793s/100 iters), loss = 0.0264047
I0823 07:46:47.900060 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0264034 (* 1 = 0.0264034 loss)
I0823 07:46:47.900072 13823 sgd_solver.cpp:112] Iteration 521000, lr = 1e-06
I0823 07:46:58.870853 13823 solver.cpp:239] Iteration 521100 (9.11509 iter/s, 10.9708s/100 iters), loss = 0.0261529
I0823 07:46:58.870913 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0261516 (* 1 = 0.0261516 loss)
I0823 07:46:58.870923 13823 sgd_solver.cpp:112] Iteration 521100, lr = 1e-06
I0823 07:47:09.899042 13823 solver.cpp:239] Iteration 521200 (9.0677 iter/s, 11.0282s/100 iters), loss = 0.0302829
I0823 07:47:09.899093 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0302815 (* 1 = 0.0302815 loss)
I0823 07:47:09.899102 13823 sgd_solver.cpp:112] Iteration 521200, lr = 1e-06
I0823 07:47:20.868535 13823 solver.cpp:239] Iteration 521300 (9.11622 iter/s, 10.9695s/100 iters), loss = 0.0377433
I0823 07:47:20.868597 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0377419 (* 1 = 0.0377419 loss)
I0823 07:47:20.868609 13823 sgd_solver.cpp:112] Iteration 521300, lr = 1e-06
I0823 07:47:31.587654 13823 solver.cpp:239] Iteration 521400 (9.32916 iter/s, 10.7191s/100 iters), loss = 0.0327362
I0823 07:47:31.587714 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0327349 (* 1 = 0.0327349 loss)
I0823 07:47:31.587726 13823 sgd_solver.cpp:112] Iteration 521400, lr = 1e-06
I0823 07:47:42.723079 13823 solver.cpp:239] Iteration 521500 (8.98038 iter/s, 11.1354s/100 iters), loss = 0.0265703
I0823 07:47:42.723131 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.026569 (* 1 = 0.026569 loss)
I0823 07:47:42.723141 13823 sgd_solver.cpp:112] Iteration 521500, lr = 1e-06
I0823 07:47:53.339982 13823 solver.cpp:239] Iteration 521600 (9.41897 iter/s, 10.6169s/100 iters), loss = 0.0235958
I0823 07:47:53.340044 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0235945 (* 1 = 0.0235945 loss)
I0823 07:47:53.340055 13823 sgd_solver.cpp:112] Iteration 521600, lr = 1e-06
I0823 07:48:04.214538 13823 solver.cpp:239] Iteration 521700 (9.19581 iter/s, 10.8745s/100 iters), loss = 0.0286206
I0823 07:48:04.214599 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0286193 (* 1 = 0.0286193 loss)
I0823 07:48:04.214612 13823 sgd_solver.cpp:112] Iteration 521700, lr = 1e-06
I0823 07:48:15.071877 13823 solver.cpp:239] Iteration 521800 (9.21039 iter/s, 10.8573s/100 iters), loss = 0.0256827
I0823 07:48:15.071936 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0256814 (* 1 = 0.0256814 loss)
I0823 07:48:15.071949 13823 sgd_solver.cpp:112] Iteration 521800, lr = 1e-06
I0823 07:48:25.830078 13823 solver.cpp:239] Iteration 521900 (9.29526 iter/s, 10.7582s/100 iters), loss = 0.0307922
I0823 07:48:25.830130 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0307909 (* 1 = 0.0307909 loss)
I0823 07:48:25.830139 13823 sgd_solver.cpp:112] Iteration 521900, lr = 1e-06
I0823 07:48:36.838094 13823 solver.cpp:239] Iteration 522000 (9.08431 iter/s, 11.008s/100 iters), loss = 0.0236518
I0823 07:48:36.838147 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0236505 (* 1 = 0.0236505 loss)
I0823 07:48:36.838157 13823 sgd_solver.cpp:112] Iteration 522000, lr = 1e-06
I0823 07:48:47.735013 13823 solver.cpp:239] Iteration 522100 (9.17693 iter/s, 10.8969s/100 iters), loss = 0.026542
I0823 07:48:47.735075 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0265406 (* 1 = 0.0265406 loss)
I0823 07:48:47.735086 13823 sgd_solver.cpp:112] Iteration 522100, lr = 1e-06
I0823 07:48:58.649140 13823 solver.cpp:239] Iteration 522200 (9.16247 iter/s, 10.9141s/100 iters), loss = 0.0366046
I0823 07:48:58.649191 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0366032 (* 1 = 0.0366032 loss)
I0823 07:48:58.649201 13823 sgd_solver.cpp:112] Iteration 522200, lr = 1e-06
I0823 07:49:09.123836 13823 solver.cpp:239] Iteration 522300 (9.54685 iter/s, 10.4747s/100 iters), loss = 0.0270923
I0823 07:49:09.123893 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0270909 (* 1 = 0.0270909 loss)
I0823 07:49:09.123904 13823 sgd_solver.cpp:112] Iteration 522300, lr = 1e-06
I0823 07:49:20.046710 13823 solver.cpp:239] Iteration 522400 (9.15513 iter/s, 10.9228s/100 iters), loss = 0.0274602
I0823 07:49:20.046761 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0274589 (* 1 = 0.0274589 loss)
I0823 07:49:20.046769 13823 sgd_solver.cpp:112] Iteration 522400, lr = 1e-06
I0823 07:49:30.941134 13823 solver.cpp:239] Iteration 522500 (9.17903 iter/s, 10.8944s/100 iters), loss = 0.0245354
I0823 07:49:30.941186 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0245341 (* 1 = 0.0245341 loss)
I0823 07:49:30.941196 13823 sgd_solver.cpp:112] Iteration 522500, lr = 1e-06
I0823 07:49:41.614619 13823 solver.cpp:239] Iteration 522600 (9.36904 iter/s, 10.6735s/100 iters), loss = 0.0285242
I0823 07:49:41.614668 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0285229 (* 1 = 0.0285229 loss)
I0823 07:49:41.614677 13823 sgd_solver.cpp:112] Iteration 522600, lr = 1e-06
I0823 07:49:52.125830 13823 solver.cpp:239] Iteration 522700 (9.51368 iter/s, 10.5112s/100 iters), loss = 0.0294541
I0823 07:49:52.125880 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0294527 (* 1 = 0.0294527 loss)
I0823 07:49:52.125888 13823 sgd_solver.cpp:112] Iteration 522700, lr = 1e-06
I0823 07:50:02.970696 13823 solver.cpp:239] Iteration 522800 (9.22097 iter/s, 10.8448s/100 iters), loss = 0.0263717
I0823 07:50:02.970744 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0263704 (* 1 = 0.0263704 loss)
I0823 07:50:02.970753 13823 sgd_solver.cpp:112] Iteration 522800, lr = 1e-06
I0823 07:50:13.806695 13823 solver.cpp:239] Iteration 522900 (9.22852 iter/s, 10.836s/100 iters), loss = 0.0256508
I0823 07:50:13.806746 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0256495 (* 1 = 0.0256495 loss)
I0823 07:50:13.806756 13823 sgd_solver.cpp:112] Iteration 522900, lr = 1e-06
I0823 07:50:24.635522 13823 solver.cpp:239] Iteration 523000 (9.23464 iter/s, 10.8288s/100 iters), loss = 0.0311685
I0823 07:50:24.635576 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0311672 (* 1 = 0.0311672 loss)
I0823 07:50:24.635586 13823 sgd_solver.cpp:112] Iteration 523000, lr = 1e-06
I0823 07:50:35.493798 13823 solver.cpp:239] Iteration 523100 (9.20959 iter/s, 10.8582s/100 iters), loss = 0.0277122
I0823 07:50:35.493849 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0277108 (* 1 = 0.0277108 loss)
I0823 07:50:35.493860 13823 sgd_solver.cpp:112] Iteration 523100, lr = 1e-06
I0823 07:50:46.247849 13823 solver.cpp:239] Iteration 523200 (9.29885 iter/s, 10.754s/100 iters), loss = 0.0269546
I0823 07:50:46.247900 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0269533 (* 1 = 0.0269533 loss)
I0823 07:50:46.247910 13823 sgd_solver.cpp:112] Iteration 523200, lr = 1e-06
I0823 07:50:57.204206 13823 solver.cpp:239] Iteration 523300 (9.12714 iter/s, 10.9563s/100 iters), loss = 0.0265953
I0823 07:50:57.204258 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.026594 (* 1 = 0.026594 loss)
I0823 07:50:57.204268 13823 sgd_solver.cpp:112] Iteration 523300, lr = 1e-06
I0823 07:51:08.184490 13823 solver.cpp:239] Iteration 523400 (9.10726 iter/s, 10.9803s/100 iters), loss = 0.0256567
I0823 07:51:08.184540 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0256554 (* 1 = 0.0256554 loss)
I0823 07:51:08.184551 13823 sgd_solver.cpp:112] Iteration 523400, lr = 1e-06
I0823 07:51:19.388468 13823 solver.cpp:239] Iteration 523500 (8.92542 iter/s, 11.2039s/100 iters), loss = 0.0307747
I0823 07:51:19.388516 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0307734 (* 1 = 0.0307734 loss)
I0823 07:51:19.388525 13823 sgd_solver.cpp:112] Iteration 523500, lr = 1e-06
I0823 07:51:30.523228 13823 solver.cpp:239] Iteration 523600 (8.98091 iter/s, 11.1347s/100 iters), loss = 0.0399578
I0823 07:51:30.523280 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0399565 (* 1 = 0.0399565 loss)
I0823 07:51:30.523289 13823 sgd_solver.cpp:112] Iteration 523600, lr = 1e-06
I0823 07:51:41.155936 13823 solver.cpp:239] Iteration 523700 (9.40497 iter/s, 10.6327s/100 iters), loss = 0.0274836
I0823 07:51:41.155988 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0274823 (* 1 = 0.0274823 loss)
I0823 07:51:41.155997 13823 sgd_solver.cpp:112] Iteration 523700, lr = 1e-06
I0823 07:51:52.283406 13823 solver.cpp:239] Iteration 523800 (8.98679 iter/s, 11.1274s/100 iters), loss = 0.0284746
I0823 07:51:52.283464 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0284733 (* 1 = 0.0284733 loss)
I0823 07:51:52.283475 13823 sgd_solver.cpp:112] Iteration 523800, lr = 1e-06
I0823 07:52:03.494451 13823 solver.cpp:239] Iteration 523900 (8.9198 iter/s, 11.211s/100 iters), loss = 0.0262907
I0823 07:52:03.494505 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0262894 (* 1 = 0.0262894 loss)
I0823 07:52:03.494515 13823 sgd_solver.cpp:112] Iteration 523900, lr = 1e-06
I0823 07:52:14.501842 13823 solver.cpp:239] Iteration 524000 (9.08483 iter/s, 11.0074s/100 iters), loss = 0.0322672
I0823 07:52:14.501904 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0322659 (* 1 = 0.0322659 loss)
I0823 07:52:14.501915 13823 sgd_solver.cpp:112] Iteration 524000, lr = 1e-06
I0823 07:52:25.468816 13823 solver.cpp:239] Iteration 524100 (9.11832 iter/s, 10.9669s/100 iters), loss = 0.0283305
I0823 07:52:25.468870 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0283292 (* 1 = 0.0283292 loss)
I0823 07:52:25.468881 13823 sgd_solver.cpp:112] Iteration 524100, lr = 1e-06
I0823 07:52:36.365994 13823 solver.cpp:239] Iteration 524200 (9.17671 iter/s, 10.8971s/100 iters), loss = 0.025816
I0823 07:52:36.366042 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0258147 (* 1 = 0.0258147 loss)
I0823 07:52:36.366051 13823 sgd_solver.cpp:112] Iteration 524200, lr = 1e-06
I0823 07:52:47.549557 13823 solver.cpp:239] Iteration 524300 (8.94171 iter/s, 11.1835s/100 iters), loss = 0.0261133
I0823 07:52:47.549597 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.026112 (* 1 = 0.026112 loss)
I0823 07:52:47.549604 13823 sgd_solver.cpp:112] Iteration 524300, lr = 1e-06
I0823 07:52:58.640015 13823 solver.cpp:239] Iteration 524400 (9.01678 iter/s, 11.0904s/100 iters), loss = 0.0284481
I0823 07:52:58.640069 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0284468 (* 1 = 0.0284468 loss)
I0823 07:52:58.640079 13823 sgd_solver.cpp:112] Iteration 524400, lr = 1e-06
I0823 07:53:09.679769 13823 solver.cpp:239] Iteration 524500 (9.0582 iter/s, 11.0397s/100 iters), loss = 0.024131
I0823 07:53:09.679826 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0241297 (* 1 = 0.0241297 loss)
I0823 07:53:09.679836 13823 sgd_solver.cpp:112] Iteration 524500, lr = 1e-06
I0823 07:53:20.839591 13823 solver.cpp:239] Iteration 524600 (8.96074 iter/s, 11.1598s/100 iters), loss = 0.026767
I0823 07:53:20.839643 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0267657 (* 1 = 0.0267657 loss)
I0823 07:53:20.839653 13823 sgd_solver.cpp:112] Iteration 524600, lr = 1e-06
I0823 07:53:31.931337 13823 solver.cpp:239] Iteration 524700 (9.01574 iter/s, 11.0917s/100 iters), loss = 0.025311
I0823 07:53:31.931396 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0253097 (* 1 = 0.0253097 loss)
I0823 07:53:31.931406 13823 sgd_solver.cpp:112] Iteration 524700, lr = 1e-06
I0823 07:53:43.046975 13823 solver.cpp:239] Iteration 524800 (8.99636 iter/s, 11.1156s/100 iters), loss = 0.0275832
I0823 07:53:43.047029 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0275819 (* 1 = 0.0275819 loss)
I0823 07:53:43.047039 13823 sgd_solver.cpp:112] Iteration 524800, lr = 1e-06
I0823 07:53:54.399740 13823 solver.cpp:239] Iteration 524900 (8.80845 iter/s, 11.3527s/100 iters), loss = 0.0242547
I0823 07:53:54.399802 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0242533 (* 1 = 0.0242533 loss)
I0823 07:53:54.399816 13823 sgd_solver.cpp:112] Iteration 524900, lr = 1e-06
I0823 07:54:05.602656 13823 solver.cpp:239] Iteration 525000 (8.92628 iter/s, 11.2029s/100 iters), loss = 0.0288514
I0823 07:54:05.602715 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0288501 (* 1 = 0.0288501 loss)
I0823 07:54:05.602726 13823 sgd_solver.cpp:112] Iteration 525000, lr = 1e-06
I0823 07:54:16.819954 13823 solver.cpp:239] Iteration 525100 (8.91483 iter/s, 11.2173s/100 iters), loss = 0.0319235
I0823 07:54:16.820016 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0319222 (* 1 = 0.0319222 loss)
I0823 07:54:16.820029 13823 sgd_solver.cpp:112] Iteration 525100, lr = 1e-06
I0823 07:54:28.081475 13823 solver.cpp:239] Iteration 525200 (8.87982 iter/s, 11.2615s/100 iters), loss = 0.0240984
I0823 07:54:28.081532 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0240971 (* 1 = 0.0240971 loss)
I0823 07:54:28.081542 13823 sgd_solver.cpp:112] Iteration 525200, lr = 1e-06
I0823 07:54:39.064585 13823 solver.cpp:239] Iteration 525300 (9.10492 iter/s, 10.9831s/100 iters), loss = 0.0372014
I0823 07:54:39.064661 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0372001 (* 1 = 0.0372001 loss)
I0823 07:54:39.064673 13823 sgd_solver.cpp:112] Iteration 525300, lr = 1e-06
I0823 07:54:50.286233 13823 solver.cpp:239] Iteration 525400 (8.91138 iter/s, 11.2216s/100 iters), loss = 0.027408
I0823 07:54:50.286283 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0274067 (* 1 = 0.0274067 loss)
I0823 07:54:50.286293 13823 sgd_solver.cpp:112] Iteration 525400, lr = 1e-06
I0823 07:55:01.601474 13823 solver.cpp:239] Iteration 525500 (8.83766 iter/s, 11.3152s/100 iters), loss = 0.0252819
I0823 07:55:01.601537 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0252805 (* 1 = 0.0252805 loss)
I0823 07:55:01.601550 13823 sgd_solver.cpp:112] Iteration 525500, lr = 1e-06
I0823 07:55:12.881989 13823 solver.cpp:239] Iteration 525600 (8.86487 iter/s, 11.2805s/100 iters), loss = 0.0259017
I0823 07:55:12.882040 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0259004 (* 1 = 0.0259004 loss)
I0823 07:55:12.882050 13823 sgd_solver.cpp:112] Iteration 525600, lr = 1e-06
I0823 07:55:24.182231 13823 solver.cpp:239] Iteration 525700 (8.84939 iter/s, 11.3002s/100 iters), loss = 0.0268631
I0823 07:55:24.182284 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0268617 (* 1 = 0.0268617 loss)
I0823 07:55:24.182294 13823 sgd_solver.cpp:112] Iteration 525700, lr = 1e-06
I0823 07:55:35.307757 13823 solver.cpp:239] Iteration 525800 (8.98837 iter/s, 11.1255s/100 iters), loss = 0.0347193
I0823 07:55:35.307808 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.034718 (* 1 = 0.034718 loss)
I0823 07:55:35.307817 13823 sgd_solver.cpp:112] Iteration 525800, lr = 1e-06
I0823 07:55:46.431236 13823 solver.cpp:239] Iteration 525900 (8.99001 iter/s, 11.1235s/100 iters), loss = 0.0254151
I0823 07:55:46.431288 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0254137 (* 1 = 0.0254137 loss)
I0823 07:55:46.431298 13823 sgd_solver.cpp:112] Iteration 525900, lr = 1e-06
I0823 07:55:57.744582 13823 solver.cpp:239] Iteration 526000 (8.83914 iter/s, 11.3133s/100 iters), loss = 0.0268096
I0823 07:55:57.744639 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0268082 (* 1 = 0.0268082 loss)
I0823 07:55:57.744650 13823 sgd_solver.cpp:112] Iteration 526000, lr = 1e-06
I0823 07:56:09.117496 13823 solver.cpp:239] Iteration 526100 (8.79285 iter/s, 11.3729s/100 iters), loss = 0.0244979
I0823 07:56:09.117545 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0244966 (* 1 = 0.0244966 loss)
I0823 07:56:09.117555 13823 sgd_solver.cpp:112] Iteration 526100, lr = 1e-06
I0823 07:56:20.186938 13823 solver.cpp:239] Iteration 526200 (9.0339 iter/s, 11.0694s/100 iters), loss = 0.0263266
I0823 07:56:20.186990 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0263253 (* 1 = 0.0263253 loss)
I0823 07:56:20.186998 13823 sgd_solver.cpp:112] Iteration 526200, lr = 1e-06
I0823 07:56:31.802382 13823 solver.cpp:239] Iteration 526300 (8.60925 iter/s, 11.6154s/100 iters), loss = 0.0263752
I0823 07:56:31.802441 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0263739 (* 1 = 0.0263739 loss)
I0823 07:56:31.802451 13823 sgd_solver.cpp:112] Iteration 526300, lr = 1e-06
I0823 07:56:43.120584 13823 solver.cpp:239] Iteration 526400 (8.83535 iter/s, 11.3182s/100 iters), loss = 0.0252454
I0823 07:56:43.120645 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0252441 (* 1 = 0.0252441 loss)
I0823 07:56:43.120656 13823 sgd_solver.cpp:112] Iteration 526400, lr = 1e-06
I0823 07:56:54.571966 13823 solver.cpp:239] Iteration 526500 (8.7326 iter/s, 11.4513s/100 iters), loss = 0.0329029
I0823 07:56:54.572024 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0329016 (* 1 = 0.0329016 loss)
I0823 07:56:54.572036 13823 sgd_solver.cpp:112] Iteration 526500, lr = 1e-06
I0823 07:57:05.901670 13823 solver.cpp:239] Iteration 526600 (8.82638 iter/s, 11.3297s/100 iters), loss = 0.0255958
I0823 07:57:05.901736 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0255945 (* 1 = 0.0255945 loss)
I0823 07:57:05.901747 13823 sgd_solver.cpp:112] Iteration 526600, lr = 1e-06
I0823 07:57:17.416915 13823 solver.cpp:239] Iteration 526700 (8.68417 iter/s, 11.5152s/100 iters), loss = 0.0297484
I0823 07:57:17.416970 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0297471 (* 1 = 0.0297471 loss)
I0823 07:57:17.416980 13823 sgd_solver.cpp:112] Iteration 526700, lr = 1e-06
I0823 07:57:28.849819 13823 solver.cpp:239] Iteration 526800 (8.74671 iter/s, 11.4329s/100 iters), loss = 0.0215747
I0823 07:57:28.849874 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0215734 (* 1 = 0.0215734 loss)
I0823 07:57:28.849884 13823 sgd_solver.cpp:112] Iteration 526800, lr = 1e-06
I0823 07:57:39.979588 13823 solver.cpp:239] Iteration 526900 (8.98494 iter/s, 11.1297s/100 iters), loss = 0.031122
I0823 07:57:39.979645 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0311206 (* 1 = 0.0311206 loss)
I0823 07:57:39.979655 13823 sgd_solver.cpp:112] Iteration 526900, lr = 1e-06
I0823 07:57:51.082579 13823 solver.cpp:239] Iteration 527000 (9.00661 iter/s, 11.103s/100 iters), loss = 0.0261798
I0823 07:57:51.082630 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0261784 (* 1 = 0.0261784 loss)
I0823 07:57:51.082640 13823 sgd_solver.cpp:112] Iteration 527000, lr = 1e-06
I0823 07:58:02.290376 13823 solver.cpp:239] Iteration 527100 (8.92238 iter/s, 11.2078s/100 iters), loss = 0.026013
I0823 07:58:02.290431 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0260117 (* 1 = 0.0260117 loss)
I0823 07:58:02.290442 13823 sgd_solver.cpp:112] Iteration 527100, lr = 1e-06
I0823 07:58:13.572090 13823 solver.cpp:239] Iteration 527200 (8.86393 iter/s, 11.2817s/100 iters), loss = 0.0269549
I0823 07:58:13.572152 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0269536 (* 1 = 0.0269536 loss)
I0823 07:58:13.572165 13823 sgd_solver.cpp:112] Iteration 527200, lr = 1e-06
I0823 07:58:25.001613 13823 solver.cpp:239] Iteration 527300 (8.7493 iter/s, 11.4295s/100 iters), loss = 0.0284359
I0823 07:58:25.001668 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0284346 (* 1 = 0.0284346 loss)
I0823 07:58:25.001678 13823 sgd_solver.cpp:112] Iteration 527300, lr = 1e-06
I0823 07:58:36.444272 13823 solver.cpp:239] Iteration 527400 (8.73925 iter/s, 11.4426s/100 iters), loss = 0.0397805
I0823 07:58:36.444347 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0397792 (* 1 = 0.0397792 loss)
I0823 07:58:36.444360 13823 sgd_solver.cpp:112] Iteration 527400, lr = 1e-06
I0823 07:58:48.091425 13823 solver.cpp:239] Iteration 527500 (8.58583 iter/s, 11.6471s/100 iters), loss = 0.0257739
I0823 07:58:48.091485 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0257726 (* 1 = 0.0257726 loss)
I0823 07:58:48.091496 13823 sgd_solver.cpp:112] Iteration 527500, lr = 1e-06
I0823 07:58:59.047596 13823 solver.cpp:239] Iteration 527600 (9.12727 iter/s, 10.9562s/100 iters), loss = 0.0406174
I0823 07:58:59.047646 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0406161 (* 1 = 0.0406161 loss)
I0823 07:58:59.047655 13823 sgd_solver.cpp:112] Iteration 527600, lr = 1e-06
I0823 07:59:10.438040 13823 solver.cpp:239] Iteration 527700 (8.77927 iter/s, 11.3905s/100 iters), loss = 0.0263273
I0823 07:59:10.438099 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.026326 (* 1 = 0.026326 loss)
I0823 07:59:10.438112 13823 sgd_solver.cpp:112] Iteration 527700, lr = 1e-06
I0823 07:59:21.905306 13823 solver.cpp:239] Iteration 527800 (8.72046 iter/s, 11.4673s/100 iters), loss = 0.0311226
I0823 07:59:21.905369 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0311213 (* 1 = 0.0311213 loss)
I0823 07:59:21.905381 13823 sgd_solver.cpp:112] Iteration 527800, lr = 1e-06
I0823 07:59:33.432305 13823 solver.cpp:239] Iteration 527900 (8.67527 iter/s, 11.527s/100 iters), loss = 0.0248567
I0823 07:59:33.432374 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0248554 (* 1 = 0.0248554 loss)
I0823 07:59:33.432384 13823 sgd_solver.cpp:112] Iteration 527900, lr = 1e-06
I0823 07:59:44.782781 13823 solver.cpp:239] Iteration 528000 (8.81019 iter/s, 11.3505s/100 iters), loss = 0.0235612
I0823 07:59:44.782831 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0235599 (* 1 = 0.0235599 loss)
I0823 07:59:44.782840 13823 sgd_solver.cpp:112] Iteration 528000, lr = 1e-06
I0823 07:59:56.424432 13823 solver.cpp:239] Iteration 528100 (8.58983 iter/s, 11.6417s/100 iters), loss = 0.0275093
I0823 07:59:56.424494 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.027508 (* 1 = 0.027508 loss)
I0823 07:59:56.424506 13823 sgd_solver.cpp:112] Iteration 528100, lr = 1e-06
I0823 08:00:07.997367 13823 solver.cpp:239] Iteration 528200 (8.64084 iter/s, 11.5729s/100 iters), loss = 0.0238667
I0823 08:00:07.997429 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0238654 (* 1 = 0.0238654 loss)
I0823 08:00:07.997442 13823 sgd_solver.cpp:112] Iteration 528200, lr = 1e-06
I0823 08:00:19.582883 13823 solver.cpp:239] Iteration 528300 (8.63146 iter/s, 11.5855s/100 iters), loss = 0.0346862
I0823 08:00:19.582938 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.034685 (* 1 = 0.034685 loss)
I0823 08:00:19.582948 13823 sgd_solver.cpp:112] Iteration 528300, lr = 1e-06
I0823 08:00:31.265293 13823 solver.cpp:239] Iteration 528400 (8.55987 iter/s, 11.6824s/100 iters), loss = 0.0243985
I0823 08:00:31.265353 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0243972 (* 1 = 0.0243972 loss)
I0823 08:00:31.265365 13823 sgd_solver.cpp:112] Iteration 528400, lr = 1e-06
I0823 08:00:42.841125 13823 solver.cpp:239] Iteration 528500 (8.63868 iter/s, 11.5758s/100 iters), loss = 0.0579431
I0823 08:00:42.841186 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0579419 (* 1 = 0.0579419 loss)
I0823 08:00:42.841197 13823 sgd_solver.cpp:112] Iteration 528500, lr = 1e-06
I0823 08:00:54.390493 13823 solver.cpp:239] Iteration 528600 (8.65847 iter/s, 11.5494s/100 iters), loss = 0.0265099
I0823 08:00:54.390549 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0265086 (* 1 = 0.0265086 loss)
I0823 08:00:54.390560 13823 sgd_solver.cpp:112] Iteration 528600, lr = 1e-06
I0823 08:01:05.848835 13823 solver.cpp:239] Iteration 528700 (8.72725 iter/s, 11.4584s/100 iters), loss = 0.0298245
I0823 08:01:05.848886 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0298232 (* 1 = 0.0298232 loss)
I0823 08:01:05.848896 13823 sgd_solver.cpp:112] Iteration 528700, lr = 1e-06
I0823 08:01:17.421238 13823 solver.cpp:239] Iteration 528800 (8.64123 iter/s, 11.5724s/100 iters), loss = 0.0435558
I0823 08:01:17.421288 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0435545 (* 1 = 0.0435545 loss)
I0823 08:01:17.421298 13823 sgd_solver.cpp:112] Iteration 528800, lr = 1e-06
I0823 08:01:28.942021 13823 solver.cpp:239] Iteration 528900 (8.67996 iter/s, 11.5208s/100 iters), loss = 0.0265526
I0823 08:01:28.942081 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0265513 (* 1 = 0.0265513 loss)
I0823 08:01:28.942093 13823 sgd_solver.cpp:112] Iteration 528900, lr = 1e-06
I0823 08:01:40.361101 13823 solver.cpp:239] Iteration 529000 (8.75727 iter/s, 11.4191s/100 iters), loss = 0.0311526
I0823 08:01:40.361158 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0311513 (* 1 = 0.0311513 loss)
I0823 08:01:40.361168 13823 sgd_solver.cpp:112] Iteration 529000, lr = 1e-06
I0823 08:01:51.738826 13823 solver.cpp:239] Iteration 529100 (8.7891 iter/s, 11.3777s/100 iters), loss = 0.0305718
I0823 08:01:51.738878 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0305705 (* 1 = 0.0305705 loss)
I0823 08:01:51.738888 13823 sgd_solver.cpp:112] Iteration 529100, lr = 1e-06
I0823 08:02:03.360216 13823 solver.cpp:239] Iteration 529200 (8.60481 iter/s, 11.6214s/100 iters), loss = 0.0301821
I0823 08:02:03.360275 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0301808 (* 1 = 0.0301808 loss)
I0823 08:02:03.360287 13823 sgd_solver.cpp:112] Iteration 529200, lr = 1e-06
I0823 08:02:15.119385 13823 solver.cpp:239] Iteration 529300 (8.504 iter/s, 11.7592s/100 iters), loss = 0.0266931
I0823 08:02:15.119454 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0266918 (* 1 = 0.0266918 loss)
I0823 08:02:15.119472 13823 sgd_solver.cpp:112] Iteration 529300, lr = 1e-06
I0823 08:02:27.083043 13823 solver.cpp:239] Iteration 529400 (8.35865 iter/s, 11.9637s/100 iters), loss = 0.0264914
I0823 08:02:27.083103 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0264902 (* 1 = 0.0264902 loss)
I0823 08:02:27.083115 13823 sgd_solver.cpp:112] Iteration 529400, lr = 1e-06
I0823 08:02:38.710249 13823 solver.cpp:239] Iteration 529500 (8.60052 iter/s, 11.6272s/100 iters), loss = 0.0243192
I0823 08:02:38.710299 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0243179 (* 1 = 0.0243179 loss)
I0823 08:02:38.710309 13823 sgd_solver.cpp:112] Iteration 529500, lr = 1e-06
I0823 08:02:49.103483 13823 solver.cpp:239] Iteration 529600 (9.62164 iter/s, 10.3932s/100 iters), loss = 0.0270715
I0823 08:02:49.103535 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0270702 (* 1 = 0.0270702 loss)
I0823 08:02:49.103546 13823 sgd_solver.cpp:112] Iteration 529600, lr = 1e-06
I0823 08:02:58.428014 13823 solver.cpp:239] Iteration 529700 (10.7244 iter/s, 9.32453s/100 iters), loss = 0.0236003
I0823 08:02:58.428067 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.023599 (* 1 = 0.023599 loss)
I0823 08:02:58.428077 13823 sgd_solver.cpp:112] Iteration 529700, lr = 1e-06
I0823 08:03:07.983791 13823 solver.cpp:239] Iteration 529800 (10.4649 iter/s, 9.55577s/100 iters), loss = 0.0338367
I0823 08:03:07.983844 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0338355 (* 1 = 0.0338355 loss)
I0823 08:03:07.983853 13823 sgd_solver.cpp:112] Iteration 529800, lr = 1e-06
I0823 08:03:17.584381 13823 solver.cpp:239] Iteration 529900 (10.416 iter/s, 9.60059s/100 iters), loss = 0.0298288
I0823 08:03:17.584431 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0298275 (* 1 = 0.0298275 loss)
I0823 08:03:17.584440 13823 sgd_solver.cpp:112] Iteration 529900, lr = 1e-06
I0823 08:03:27.268438 13823 solver.cpp:239] Iteration 530000 (10.3263 iter/s, 9.68406s/100 iters), loss = 0.0250005
I0823 08:03:27.268491 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0249992 (* 1 = 0.0249992 loss)
I0823 08:03:27.268501 13823 sgd_solver.cpp:112] Iteration 530000, lr = 1e-06
I0823 08:03:36.986874 13823 solver.cpp:239] Iteration 530100 (10.2897 iter/s, 9.71843s/100 iters), loss = 0.0379971
I0823 08:03:36.986929 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0379959 (* 1 = 0.0379959 loss)
I0823 08:03:36.986939 13823 sgd_solver.cpp:112] Iteration 530100, lr = 1e-06
I0823 08:03:46.541707 13823 solver.cpp:239] Iteration 530200 (10.4659 iter/s, 9.55482s/100 iters), loss = 0.0272673
I0823 08:03:46.541759 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.027266 (* 1 = 0.027266 loss)
I0823 08:03:46.541769 13823 sgd_solver.cpp:112] Iteration 530200, lr = 1e-06
I0823 08:03:56.110651 13823 solver.cpp:239] Iteration 530300 (10.4505 iter/s, 9.56894s/100 iters), loss = 0.0318865
I0823 08:03:56.110713 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0318852 (* 1 = 0.0318852 loss)
I0823 08:03:56.110723 13823 sgd_solver.cpp:112] Iteration 530300, lr = 1e-06
I0823 08:04:05.961199 13823 solver.cpp:239] Iteration 530400 (10.1517 iter/s, 9.85054s/100 iters), loss = 0.0241702
I0823 08:04:05.961251 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0241689 (* 1 = 0.0241689 loss)
I0823 08:04:05.961262 13823 sgd_solver.cpp:112] Iteration 530400, lr = 1e-06
I0823 08:04:15.660409 13823 solver.cpp:239] Iteration 530500 (10.3101 iter/s, 9.6992s/100 iters), loss = 0.0259136
I0823 08:04:15.660459 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0259124 (* 1 = 0.0259124 loss)
I0823 08:04:15.660470 13823 sgd_solver.cpp:112] Iteration 530500, lr = 1e-06
I0823 08:04:25.450106 13823 solver.cpp:239] Iteration 530600 (10.2148 iter/s, 9.78969s/100 iters), loss = 0.0255408
I0823 08:04:25.450158 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0255396 (* 1 = 0.0255396 loss)
I0823 08:04:25.450168 13823 sgd_solver.cpp:112] Iteration 530600, lr = 1e-06
I0823 08:04:35.271594 13823 solver.cpp:239] Iteration 530700 (10.1818 iter/s, 9.82148s/100 iters), loss = 0.0271493
I0823 08:04:35.271661 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.027148 (* 1 = 0.027148 loss)
I0823 08:04:35.271673 13823 sgd_solver.cpp:112] Iteration 530700, lr = 1e-06
I0823 08:04:45.098950 13823 solver.cpp:239] Iteration 530800 (10.1757 iter/s, 9.82734s/100 iters), loss = 0.0308531
I0823 08:04:45.099004 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0308519 (* 1 = 0.0308519 loss)
I0823 08:04:45.099014 13823 sgd_solver.cpp:112] Iteration 530800, lr = 1e-06
I0823 08:04:54.941988 13823 solver.cpp:239] Iteration 530900 (10.1595 iter/s, 9.84303s/100 iters), loss = 0.0280191
I0823 08:04:54.942040 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0280179 (* 1 = 0.0280179 loss)
I0823 08:04:54.942050 13823 sgd_solver.cpp:112] Iteration 530900, lr = 1e-06
I0823 08:05:04.645087 13823 solver.cpp:239] Iteration 531000 (10.306 iter/s, 9.7031s/100 iters), loss = 0.0235794
I0823 08:05:04.645136 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0235782 (* 1 = 0.0235782 loss)
I0823 08:05:04.645146 13823 sgd_solver.cpp:112] Iteration 531000, lr = 1e-06
I0823 08:05:14.223331 13823 solver.cpp:239] Iteration 531100 (10.4403 iter/s, 9.57824s/100 iters), loss = 0.031567
I0823 08:05:14.223383 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0315657 (* 1 = 0.0315657 loss)
I0823 08:05:14.223392 13823 sgd_solver.cpp:112] Iteration 531100, lr = 1e-06
I0823 08:05:24.181897 13823 solver.cpp:239] Iteration 531200 (10.0416 iter/s, 9.95856s/100 iters), loss = 0.0260736
I0823 08:05:24.181949 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0260724 (* 1 = 0.0260724 loss)
I0823 08:05:24.181958 13823 sgd_solver.cpp:112] Iteration 531200, lr = 1e-06
I0823 08:05:33.824499 13823 solver.cpp:239] Iteration 531300 (10.3707 iter/s, 9.64259s/100 iters), loss = 0.0241814
I0823 08:05:33.824551 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0241802 (* 1 = 0.0241802 loss)
I0823 08:05:33.824560 13823 sgd_solver.cpp:112] Iteration 531300, lr = 1e-06
I0823 08:05:43.734634 13823 solver.cpp:239] Iteration 531400 (10.0907 iter/s, 9.91012s/100 iters), loss = 0.0414637
I0823 08:05:43.734692 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0414624 (* 1 = 0.0414624 loss)
I0823 08:05:43.734704 13823 sgd_solver.cpp:112] Iteration 531400, lr = 1e-06
I0823 08:05:53.594280 13823 solver.cpp:239] Iteration 531500 (10.1424 iter/s, 9.85963s/100 iters), loss = 0.0490489
I0823 08:05:53.594331 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0490476 (* 1 = 0.0490476 loss)
I0823 08:05:53.594339 13823 sgd_solver.cpp:112] Iteration 531500, lr = 1e-06
I0823 08:06:03.292582 13823 solver.cpp:239] Iteration 531600 (10.3111 iter/s, 9.69829s/100 iters), loss = 0.0351331
I0823 08:06:03.292631 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0351318 (* 1 = 0.0351318 loss)
I0823 08:06:03.292640 13823 sgd_solver.cpp:112] Iteration 531600, lr = 1e-06
I0823 08:06:13.184674 13823 solver.cpp:239] Iteration 531700 (10.1091 iter/s, 9.89209s/100 iters), loss = 0.0276693
I0823 08:06:13.184723 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0276681 (* 1 = 0.0276681 loss)
I0823 08:06:13.184732 13823 sgd_solver.cpp:112] Iteration 531700, lr = 1e-06
I0823 08:06:22.905102 13823 solver.cpp:239] Iteration 531800 (10.2876 iter/s, 9.72042s/100 iters), loss = 0.0369279
I0823 08:06:22.905153 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0369266 (* 1 = 0.0369266 loss)
I0823 08:06:22.905162 13823 sgd_solver.cpp:112] Iteration 531800, lr = 1e-06
I0823 08:06:32.950577 13823 solver.cpp:239] Iteration 531900 (9.95474 iter/s, 10.0455s/100 iters), loss = 0.0283243
I0823 08:06:32.950634 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.028323 (* 1 = 0.028323 loss)
I0823 08:06:32.950644 13823 sgd_solver.cpp:112] Iteration 531900, lr = 1e-06
I0823 08:06:42.244501 13823 solver.cpp:239] Iteration 532000 (10.7597 iter/s, 9.29391s/100 iters), loss = 0.0260217
I0823 08:06:42.244544 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0260204 (* 1 = 0.0260204 loss)
I0823 08:06:42.244551 13823 sgd_solver.cpp:112] Iteration 532000, lr = 1e-06
I0823 08:06:52.333830 13823 solver.cpp:239] Iteration 532100 (9.91146 iter/s, 10.0893s/100 iters), loss = 0.0268734
I0823 08:06:52.333879 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0268722 (* 1 = 0.0268722 loss)
I0823 08:06:52.333889 13823 sgd_solver.cpp:112] Iteration 532100, lr = 1e-06
I0823 08:07:02.102418 13823 solver.cpp:239] Iteration 532200 (10.2369 iter/s, 9.76858s/100 iters), loss = 0.0256862
I0823 08:07:02.102460 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0256849 (* 1 = 0.0256849 loss)
I0823 08:07:02.102468 13823 sgd_solver.cpp:112] Iteration 532200, lr = 1e-06
I0823 08:07:11.872970 13823 solver.cpp:239] Iteration 532300 (10.2348 iter/s, 9.77055s/100 iters), loss = 0.0246721
I0823 08:07:11.873020 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0246709 (* 1 = 0.0246709 loss)
I0823 08:07:11.873030 13823 sgd_solver.cpp:112] Iteration 532300, lr = 1e-06
I0823 08:07:21.848949 13823 solver.cpp:239] Iteration 532400 (10.0241 iter/s, 9.97597s/100 iters), loss = 0.0500553
I0823 08:07:21.849002 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.050054 (* 1 = 0.050054 loss)
I0823 08:07:21.849012 13823 sgd_solver.cpp:112] Iteration 532400, lr = 1e-06
I0823 08:07:31.606967 13823 solver.cpp:239] Iteration 532500 (10.248 iter/s, 9.75801s/100 iters), loss = 0.0276051
I0823 08:07:31.607018 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0276039 (* 1 = 0.0276039 loss)
I0823 08:07:31.607028 13823 sgd_solver.cpp:112] Iteration 532500, lr = 1e-06
I0823 08:07:41.432834 13823 solver.cpp:239] Iteration 532600 (10.1772 iter/s, 9.82586s/100 iters), loss = 0.0227267
I0823 08:07:41.432886 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0227254 (* 1 = 0.0227254 loss)
I0823 08:07:41.432896 13823 sgd_solver.cpp:112] Iteration 532600, lr = 1e-06
I0823 08:07:51.247566 13823 solver.cpp:239] Iteration 532700 (10.1888 iter/s, 9.81472s/100 iters), loss = 0.0282023
I0823 08:07:51.247608 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.028201 (* 1 = 0.028201 loss)
I0823 08:07:51.247615 13823 sgd_solver.cpp:112] Iteration 532700, lr = 1e-06
I0823 08:08:01.113173 13823 solver.cpp:239] Iteration 532800 (10.1362 iter/s, 9.8656s/100 iters), loss = 0.025424
I0823 08:08:01.113224 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0254227 (* 1 = 0.0254227 loss)
I0823 08:08:01.113234 13823 sgd_solver.cpp:112] Iteration 532800, lr = 1e-06
I0823 08:08:11.273352 13823 solver.cpp:239] Iteration 532900 (9.84236 iter/s, 10.1602s/100 iters), loss = 0.0337602
I0823 08:08:11.273406 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0337589 (* 1 = 0.0337589 loss)
I0823 08:08:11.273416 13823 sgd_solver.cpp:112] Iteration 532900, lr = 1e-06
I0823 08:08:20.863083 13823 solver.cpp:239] Iteration 533000 (10.4278 iter/s, 9.58972s/100 iters), loss = 0.0689737
I0823 08:08:20.863137 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0689725 (* 1 = 0.0689725 loss)
I0823 08:08:20.863147 13823 sgd_solver.cpp:112] Iteration 533000, lr = 1e-06
I0823 08:08:30.718832 13823 solver.cpp:239] Iteration 533100 (10.1464 iter/s, 9.85573s/100 iters), loss = 0.0242856
I0823 08:08:30.718885 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0242843 (* 1 = 0.0242843 loss)
I0823 08:08:30.718895 13823 sgd_solver.cpp:112] Iteration 533100, lr = 1e-06
I0823 08:08:40.677557 13823 solver.cpp:239] Iteration 533200 (10.0415 iter/s, 9.95871s/100 iters), loss = 0.0278363
I0823 08:08:40.677611 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.027835 (* 1 = 0.027835 loss)
I0823 08:08:40.677623 13823 sgd_solver.cpp:112] Iteration 533200, lr = 1e-06
I0823 08:08:50.692157 13823 solver.cpp:239] Iteration 533300 (9.98544 iter/s, 10.0146s/100 iters), loss = 0.036736
I0823 08:08:50.692207 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0367347 (* 1 = 0.0367347 loss)
I0823 08:08:50.692216 13823 sgd_solver.cpp:112] Iteration 533300, lr = 1e-06
I0823 08:09:00.637884 13823 solver.cpp:239] Iteration 533400 (10.0546 iter/s, 9.94571s/100 iters), loss = 0.026303
I0823 08:09:00.637935 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0263017 (* 1 = 0.0263017 loss)
I0823 08:09:00.637945 13823 sgd_solver.cpp:112] Iteration 533400, lr = 1e-06
I0823 08:09:10.311569 13823 solver.cpp:239] Iteration 533500 (10.3373 iter/s, 9.67367s/100 iters), loss = 0.0302462
I0823 08:09:10.311621 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0302449 (* 1 = 0.0302449 loss)
I0823 08:09:10.311631 13823 sgd_solver.cpp:112] Iteration 533500, lr = 1e-06
I0823 08:09:20.164283 13823 solver.cpp:239] Iteration 533600 (10.1495 iter/s, 9.8527s/100 iters), loss = 0.0258416
I0823 08:09:20.164333 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0258404 (* 1 = 0.0258404 loss)
I0823 08:09:20.164342 13823 sgd_solver.cpp:112] Iteration 533600, lr = 1e-06
I0823 08:09:30.066629 13823 solver.cpp:239] Iteration 533700 (10.0986 iter/s, 9.90233s/100 iters), loss = 0.026062
I0823 08:09:30.066681 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0260608 (* 1 = 0.0260608 loss)
I0823 08:09:30.066691 13823 sgd_solver.cpp:112] Iteration 533700, lr = 1e-06
I0823 08:09:39.909865 13823 solver.cpp:239] Iteration 533800 (10.1593 iter/s, 9.84322s/100 iters), loss = 0.0261296
I0823 08:09:39.909921 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0261284 (* 1 = 0.0261284 loss)
I0823 08:09:39.909932 13823 sgd_solver.cpp:112] Iteration 533800, lr = 1e-06
I0823 08:09:49.551280 13823 solver.cpp:239] Iteration 533900 (10.3719 iter/s, 9.64139s/100 iters), loss = 0.026886
I0823 08:09:49.551329 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0268848 (* 1 = 0.0268848 loss)
I0823 08:09:49.551339 13823 sgd_solver.cpp:112] Iteration 533900, lr = 1e-06
I0823 08:09:59.285722 13823 solver.cpp:239] Iteration 534000 (10.2728 iter/s, 9.73443s/100 iters), loss = 0.0330606
I0823 08:09:59.285773 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0330593 (* 1 = 0.0330593 loss)
I0823 08:09:59.285784 13823 sgd_solver.cpp:112] Iteration 534000, lr = 1e-06
I0823 08:10:09.333583 13823 solver.cpp:239] Iteration 534100 (9.95238 iter/s, 10.0478s/100 iters), loss = 0.0266286
I0823 08:10:09.333636 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0266274 (* 1 = 0.0266274 loss)
I0823 08:10:09.333644 13823 sgd_solver.cpp:112] Iteration 534100, lr = 1e-06
I0823 08:10:19.331852 13823 solver.cpp:239] Iteration 534200 (10.0017 iter/s, 9.99825s/100 iters), loss = 0.0249849
I0823 08:10:19.331902 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0249837 (* 1 = 0.0249837 loss)
I0823 08:10:19.331909 13823 sgd_solver.cpp:112] Iteration 534200, lr = 1e-06
I0823 08:10:29.353209 13823 solver.cpp:239] Iteration 534300 (9.97871 iter/s, 10.0213s/100 iters), loss = 0.0436256
I0823 08:10:29.353260 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0436244 (* 1 = 0.0436244 loss)
I0823 08:10:29.353269 13823 sgd_solver.cpp:112] Iteration 534300, lr = 1e-06
I0823 08:10:39.241276 13823 solver.cpp:239] Iteration 534400 (10.1132 iter/s, 9.88805s/100 iters), loss = 0.0249885
I0823 08:10:39.241325 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0249873 (* 1 = 0.0249873 loss)
I0823 08:10:39.241335 13823 sgd_solver.cpp:112] Iteration 534400, lr = 1e-06
I0823 08:10:49.217316 13823 solver.cpp:239] Iteration 534500 (10.024 iter/s, 9.97603s/100 iters), loss = 0.0290094
I0823 08:10:49.217367 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0290082 (* 1 = 0.0290082 loss)
I0823 08:10:49.217377 13823 sgd_solver.cpp:112] Iteration 534500, lr = 1e-06
I0823 08:10:58.922596 13823 solver.cpp:239] Iteration 534600 (10.3037 iter/s, 9.70526s/100 iters), loss = 0.0278926
I0823 08:10:58.922648 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0278913 (* 1 = 0.0278913 loss)
I0823 08:10:58.922658 13823 sgd_solver.cpp:112] Iteration 534600, lr = 1e-06
I0823 08:11:08.944049 13823 solver.cpp:239] Iteration 534700 (9.97861 iter/s, 10.0214s/100 iters), loss = 0.0366471
I0823 08:11:08.944099 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0366458 (* 1 = 0.0366458 loss)
I0823 08:11:08.944109 13823 sgd_solver.cpp:112] Iteration 534700, lr = 1e-06
I0823 08:11:18.953181 13823 solver.cpp:239] Iteration 534800 (9.99089 iter/s, 10.0091s/100 iters), loss = 0.0244793
I0823 08:11:18.953241 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0244781 (* 1 = 0.0244781 loss)
I0823 08:11:18.953253 13823 sgd_solver.cpp:112] Iteration 534800, lr = 1e-06
I0823 08:11:28.903931 13823 solver.cpp:239] Iteration 534900 (10.0495 iter/s, 9.95073s/100 iters), loss = 0.0284833
I0823 08:11:28.903982 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0284821 (* 1 = 0.0284821 loss)
I0823 08:11:28.903992 13823 sgd_solver.cpp:112] Iteration 534900, lr = 1e-06
I0823 08:11:38.712735 13823 solver.cpp:239] Iteration 535000 (10.1949 iter/s, 9.80879s/100 iters), loss = 0.0267919
I0823 08:11:38.712790 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0267907 (* 1 = 0.0267907 loss)
I0823 08:11:38.712800 13823 sgd_solver.cpp:112] Iteration 535000, lr = 1e-06
I0823 08:11:48.820886 13823 solver.cpp:239] Iteration 535100 (9.89303 iter/s, 10.1081s/100 iters), loss = 0.0317215
I0823 08:11:48.820936 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0317203 (* 1 = 0.0317203 loss)
I0823 08:11:48.820945 13823 sgd_solver.cpp:112] Iteration 535100, lr = 1e-06
I0823 08:11:58.629320 13823 solver.cpp:239] Iteration 535200 (10.1953 iter/s, 9.80842s/100 iters), loss = 0.0243424
I0823 08:11:58.629371 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0243412 (* 1 = 0.0243412 loss)
I0823 08:11:58.629380 13823 sgd_solver.cpp:112] Iteration 535200, lr = 1e-06
I0823 08:12:08.810613 13823 solver.cpp:239] Iteration 535300 (9.82195 iter/s, 10.1813s/100 iters), loss = 0.0278137
I0823 08:12:08.810662 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0278124 (* 1 = 0.0278124 loss)
I0823 08:12:08.810672 13823 sgd_solver.cpp:112] Iteration 535300, lr = 1e-06
I0823 08:12:18.841049 13823 solver.cpp:239] Iteration 535400 (9.96967 iter/s, 10.0304s/100 iters), loss = 0.0262053
I0823 08:12:18.841109 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0262041 (* 1 = 0.0262041 loss)
I0823 08:12:18.841120 13823 sgd_solver.cpp:112] Iteration 535400, lr = 1e-06
I0823 08:12:28.898468 13823 solver.cpp:239] Iteration 535500 (9.94293 iter/s, 10.0574s/100 iters), loss = 0.0230758
I0823 08:12:28.898517 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0230745 (* 1 = 0.0230745 loss)
I0823 08:12:28.898526 13823 sgd_solver.cpp:112] Iteration 535500, lr = 1e-06
I0823 08:12:39.025189 13823 solver.cpp:239] Iteration 535600 (9.87488 iter/s, 10.1267s/100 iters), loss = 0.0278268
I0823 08:12:39.025255 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0278256 (* 1 = 0.0278256 loss)
I0823 08:12:39.025269 13823 sgd_solver.cpp:112] Iteration 535600, lr = 1e-06
I0823 08:12:49.146168 13823 solver.cpp:239] Iteration 535700 (9.8805 iter/s, 10.1209s/100 iters), loss = 0.0324683
I0823 08:12:49.146219 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0324671 (* 1 = 0.0324671 loss)
I0823 08:12:49.146229 13823 sgd_solver.cpp:112] Iteration 535700, lr = 1e-06
I0823 08:12:59.083412 13823 solver.cpp:239] Iteration 535800 (10.0632 iter/s, 9.93723s/100 iters), loss = 0.0268288
I0823 08:12:59.083464 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0268276 (* 1 = 0.0268276 loss)
I0823 08:12:59.083473 13823 sgd_solver.cpp:112] Iteration 535800, lr = 1e-06
I0823 08:13:09.165010 13823 solver.cpp:239] Iteration 535900 (9.91908 iter/s, 10.0816s/100 iters), loss = 0.0267207
I0823 08:13:09.165069 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0267195 (* 1 = 0.0267195 loss)
I0823 08:13:09.165081 13823 sgd_solver.cpp:112] Iteration 535900, lr = 1e-06
I0823 08:13:19.333514 13823 solver.cpp:239] Iteration 536000 (9.83431 iter/s, 10.1685s/100 iters), loss = 0.03808
I0823 08:13:19.333570 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0380788 (* 1 = 0.0380788 loss)
I0823 08:13:19.333581 13823 sgd_solver.cpp:112] Iteration 536000, lr = 1e-06
I0823 08:13:29.600677 13823 solver.cpp:239] Iteration 536100 (9.73981 iter/s, 10.2671s/100 iters), loss = 0.0276858
I0823 08:13:29.600733 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0276845 (* 1 = 0.0276845 loss)
I0823 08:13:29.600744 13823 sgd_solver.cpp:112] Iteration 536100, lr = 1e-06
I0823 08:13:40.113903 13823 solver.cpp:239] Iteration 536200 (9.51185 iter/s, 10.5132s/100 iters), loss = 0.0237935
I0823 08:13:40.113967 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0237923 (* 1 = 0.0237923 loss)
I0823 08:13:40.113981 13823 sgd_solver.cpp:112] Iteration 536200, lr = 1e-06
I0823 08:13:50.185068 13823 solver.cpp:239] Iteration 536300 (9.92937 iter/s, 10.0711s/100 iters), loss = 0.0257952
I0823 08:13:50.185123 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.025794 (* 1 = 0.025794 loss)
I0823 08:13:50.185133 13823 sgd_solver.cpp:112] Iteration 536300, lr = 1e-06
I0823 08:14:00.328482 13823 solver.cpp:239] Iteration 536400 (9.85864 iter/s, 10.1434s/100 iters), loss = 0.0255526
I0823 08:14:00.328546 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0255513 (* 1 = 0.0255513 loss)
I0823 08:14:00.328558 13823 sgd_solver.cpp:112] Iteration 536400, lr = 1e-06
I0823 08:14:10.719347 13823 solver.cpp:239] Iteration 536500 (9.62386 iter/s, 10.3908s/100 iters), loss = 0.0264061
I0823 08:14:10.719398 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0264049 (* 1 = 0.0264049 loss)
I0823 08:14:10.719408 13823 sgd_solver.cpp:112] Iteration 536500, lr = 1e-06
I0823 08:14:20.947080 13823 solver.cpp:239] Iteration 536600 (9.77735 iter/s, 10.2277s/100 iters), loss = 0.0294077
I0823 08:14:20.947134 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0294065 (* 1 = 0.0294065 loss)
I0823 08:14:20.947142 13823 sgd_solver.cpp:112] Iteration 536600, lr = 1e-06
I0823 08:14:31.089416 13823 solver.cpp:239] Iteration 536700 (9.85968 iter/s, 10.1423s/100 iters), loss = 0.0268566
I0823 08:14:31.089470 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0268554 (* 1 = 0.0268554 loss)
I0823 08:14:31.089480 13823 sgd_solver.cpp:112] Iteration 536700, lr = 1e-06
I0823 08:14:41.180032 13823 solver.cpp:239] Iteration 536800 (9.91022 iter/s, 10.0906s/100 iters), loss = 0.0265527
I0823 08:14:41.180085 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0265515 (* 1 = 0.0265515 loss)
I0823 08:14:41.180095 13823 sgd_solver.cpp:112] Iteration 536800, lr = 1e-06
I0823 08:14:51.465461 13823 solver.cpp:239] Iteration 536900 (9.72251 iter/s, 10.2854s/100 iters), loss = 0.0236154
I0823 08:14:51.465509 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0236141 (* 1 = 0.0236141 loss)
I0823 08:14:51.465518 13823 sgd_solver.cpp:112] Iteration 536900, lr = 1e-06
I0823 08:15:01.723654 13823 solver.cpp:239] Iteration 537000 (9.74832 iter/s, 10.2582s/100 iters), loss = 0.0329292
I0823 08:15:01.723704 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.032928 (* 1 = 0.032928 loss)
I0823 08:15:01.723713 13823 sgd_solver.cpp:112] Iteration 537000, lr = 1e-06
I0823 08:15:11.858245 13823 solver.cpp:239] Iteration 537100 (9.86721 iter/s, 10.1346s/100 iters), loss = 0.0311394
I0823 08:15:11.858304 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0311381 (* 1 = 0.0311381 loss)
I0823 08:15:11.858315 13823 sgd_solver.cpp:112] Iteration 537100, lr = 1e-06
I0823 08:15:22.222290 13823 solver.cpp:239] Iteration 537200 (9.64877 iter/s, 10.364s/100 iters), loss = 0.0279871
I0823 08:15:22.222347 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0279859 (* 1 = 0.0279859 loss)
I0823 08:15:22.222359 13823 sgd_solver.cpp:112] Iteration 537200, lr = 1e-06
I0823 08:15:32.834489 13823 solver.cpp:239] Iteration 537300 (9.42314 iter/s, 10.6122s/100 iters), loss = 0.0293662
I0823 08:15:32.834548 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.029365 (* 1 = 0.029365 loss)
I0823 08:15:32.834559 13823 sgd_solver.cpp:112] Iteration 537300, lr = 1e-06
I0823 08:15:42.913624 13823 solver.cpp:239] Iteration 537400 (9.92151 iter/s, 10.0791s/100 iters), loss = 0.02755
I0823 08:15:42.913672 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0275487 (* 1 = 0.0275487 loss)
I0823 08:15:42.913682 13823 sgd_solver.cpp:112] Iteration 537400, lr = 1e-06
I0823 08:15:53.037237 13823 solver.cpp:239] Iteration 537500 (9.87791 iter/s, 10.1236s/100 iters), loss = 0.0287394
I0823 08:15:53.037290 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0287381 (* 1 = 0.0287381 loss)
I0823 08:15:53.037300 13823 sgd_solver.cpp:112] Iteration 537500, lr = 1e-06
I0823 08:16:03.531404 13823 solver.cpp:239] Iteration 537600 (9.52912 iter/s, 10.4941s/100 iters), loss = 0.0854606
I0823 08:16:03.531460 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0854594 (* 1 = 0.0854594 loss)
I0823 08:16:03.531469 13823 sgd_solver.cpp:112] Iteration 537600, lr = 1e-06
I0823 08:16:14.021951 13823 solver.cpp:239] Iteration 537700 (9.53241 iter/s, 10.4905s/100 iters), loss = 0.0276367
I0823 08:16:14.022011 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0276354 (* 1 = 0.0276354 loss)
I0823 08:16:14.022022 13823 sgd_solver.cpp:112] Iteration 537700, lr = 1e-06
I0823 08:16:24.426736 13823 solver.cpp:239] Iteration 537800 (9.61099 iter/s, 10.4048s/100 iters), loss = 0.0296902
I0823 08:16:24.426786 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.029689 (* 1 = 0.029689 loss)
I0823 08:16:24.426795 13823 sgd_solver.cpp:112] Iteration 537800, lr = 1e-06
I0823 08:16:34.649401 13823 solver.cpp:239] Iteration 537900 (9.7822 iter/s, 10.2226s/100 iters), loss = 0.0267357
I0823 08:16:34.649456 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0267345 (* 1 = 0.0267345 loss)
I0823 08:16:34.649466 13823 sgd_solver.cpp:112] Iteration 537900, lr = 1e-06
I0823 08:16:44.948874 13823 solver.cpp:239] Iteration 538000 (9.70926 iter/s, 10.2994s/100 iters), loss = 0.0227427
I0823 08:16:44.948931 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0227414 (* 1 = 0.0227414 loss)
I0823 08:16:44.948940 13823 sgd_solver.cpp:112] Iteration 538000, lr = 1e-06
I0823 08:16:55.280046 13823 solver.cpp:239] Iteration 538100 (9.67947 iter/s, 10.3311s/100 iters), loss = 0.0296343
I0823 08:16:55.280097 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0296331 (* 1 = 0.0296331 loss)
I0823 08:16:55.280107 13823 sgd_solver.cpp:112] Iteration 538100, lr = 1e-06
I0823 08:17:05.858335 13823 solver.cpp:239] Iteration 538200 (9.45334 iter/s, 10.5783s/100 iters), loss = 0.0241516
I0823 08:17:05.858388 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0241504 (* 1 = 0.0241504 loss)
I0823 08:17:05.858399 13823 sgd_solver.cpp:112] Iteration 538200, lr = 1e-06
I0823 08:17:16.371449 13823 solver.cpp:239] Iteration 538300 (9.51195 iter/s, 10.5131s/100 iters), loss = 0.0270737
I0823 08:17:16.371500 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0270725 (* 1 = 0.0270725 loss)
I0823 08:17:16.371510 13823 sgd_solver.cpp:112] Iteration 538300, lr = 1e-06
I0823 08:17:26.810201 13823 solver.cpp:239] Iteration 538400 (9.57971 iter/s, 10.4387s/100 iters), loss = 0.0281312
I0823 08:17:26.810250 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.02813 (* 1 = 0.02813 loss)
I0823 08:17:26.810261 13823 sgd_solver.cpp:112] Iteration 538400, lr = 1e-06
I0823 08:17:37.084956 13823 solver.cpp:239] Iteration 538500 (9.73261 iter/s, 10.2747s/100 iters), loss = 0.0282629
I0823 08:17:37.085005 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0282617 (* 1 = 0.0282617 loss)
I0823 08:17:37.085014 13823 sgd_solver.cpp:112] Iteration 538500, lr = 1e-06
I0823 08:17:47.527086 13823 solver.cpp:239] Iteration 538600 (9.57661 iter/s, 10.4421s/100 iters), loss = 0.0243024
I0823 08:17:47.527138 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0243011 (* 1 = 0.0243011 loss)
I0823 08:17:47.527148 13823 sgd_solver.cpp:112] Iteration 538600, lr = 1e-06
I0823 08:17:57.994081 13823 solver.cpp:239] Iteration 538700 (9.55386 iter/s, 10.467s/100 iters), loss = 0.0290801
I0823 08:17:57.994132 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0290788 (* 1 = 0.0290788 loss)
I0823 08:17:57.994143 13823 sgd_solver.cpp:112] Iteration 538700, lr = 1e-06
I0823 08:18:08.589599 13823 solver.cpp:239] Iteration 538800 (9.43797 iter/s, 10.5955s/100 iters), loss = 0.0279878
I0823 08:18:08.589663 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0279866 (* 1 = 0.0279866 loss)
I0823 08:18:08.589674 13823 sgd_solver.cpp:112] Iteration 538800, lr = 1e-06
I0823 08:18:19.193163 13823 solver.cpp:239] Iteration 538900 (9.43082 iter/s, 10.6035s/100 iters), loss = 0.0250133
I0823 08:18:19.193218 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.025012 (* 1 = 0.025012 loss)
I0823 08:18:19.193228 13823 sgd_solver.cpp:112] Iteration 538900, lr = 1e-06
I0823 08:18:30.066956 13823 solver.cpp:239] Iteration 539000 (9.19644 iter/s, 10.8738s/100 iters), loss = 0.0272294
I0823 08:18:30.067008 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0272282 (* 1 = 0.0272282 loss)
I0823 08:18:30.067018 13823 sgd_solver.cpp:112] Iteration 539000, lr = 1e-06
I0823 08:18:40.987120 13823 solver.cpp:239] Iteration 539100 (9.15739 iter/s, 10.9201s/100 iters), loss = 0.0267307
I0823 08:18:40.987179 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0267294 (* 1 = 0.0267294 loss)
I0823 08:18:40.987190 13823 sgd_solver.cpp:112] Iteration 539100, lr = 1e-06
I0823 08:18:51.614758 13823 solver.cpp:239] Iteration 539200 (9.40945 iter/s, 10.6276s/100 iters), loss = 0.0267726
I0823 08:18:51.614810 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0267713 (* 1 = 0.0267713 loss)
I0823 08:18:51.614820 13823 sgd_solver.cpp:112] Iteration 539200, lr = 1e-06
I0823 08:19:02.107437 13823 solver.cpp:239] Iteration 539300 (9.53047 iter/s, 10.4927s/100 iters), loss = 0.025859
I0823 08:19:02.107486 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0258577 (* 1 = 0.0258577 loss)
I0823 08:19:02.107496 13823 sgd_solver.cpp:112] Iteration 539300, lr = 1e-06
I0823 08:19:12.533921 13823 solver.cpp:239] Iteration 539400 (9.59098 iter/s, 10.4265s/100 iters), loss = 0.0332595
I0823 08:19:12.533972 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0332582 (* 1 = 0.0332582 loss)
I0823 08:19:12.533982 13823 sgd_solver.cpp:112] Iteration 539400, lr = 1e-06
I0823 08:19:23.216576 13823 solver.cpp:239] Iteration 539500 (9.36099 iter/s, 10.6826s/100 iters), loss = 0.0386893
I0823 08:19:23.216635 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.038688 (* 1 = 0.038688 loss)
I0823 08:19:23.216646 13823 sgd_solver.cpp:112] Iteration 539500, lr = 1e-06
I0823 08:19:33.675467 13823 solver.cpp:239] Iteration 539600 (9.56127 iter/s, 10.4589s/100 iters), loss = 0.0290591
I0823 08:19:33.675518 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0290579 (* 1 = 0.0290579 loss)
I0823 08:19:33.675527 13823 sgd_solver.cpp:112] Iteration 539600, lr = 1e-06
I0823 08:19:44.136205 13823 solver.cpp:239] Iteration 539700 (9.55957 iter/s, 10.4607s/100 iters), loss = 0.0324589
I0823 08:19:44.136257 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0324576 (* 1 = 0.0324576 loss)
I0823 08:19:44.136268 13823 sgd_solver.cpp:112] Iteration 539700, lr = 1e-06
I0823 08:19:54.652501 13823 solver.cpp:239] Iteration 539800 (9.50907 iter/s, 10.5163s/100 iters), loss = 0.0278513
I0823 08:19:54.652551 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.02785 (* 1 = 0.02785 loss)
I0823 08:19:54.652561 13823 sgd_solver.cpp:112] Iteration 539800, lr = 1e-06
I0823 08:20:05.066673 13823 solver.cpp:239] Iteration 539900 (9.60232 iter/s, 10.4141s/100 iters), loss = 0.0288313
I0823 08:20:05.066727 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0288301 (* 1 = 0.0288301 loss)
I0823 08:20:05.066737 13823 sgd_solver.cpp:112] Iteration 539900, lr = 1e-06
I0823 08:20:15.600932 13823 solver.cpp:464] Snapshotting to binary proto file ./model_112/cascade_mobilenet_112_iter_540000.caffemodel
I0823 08:20:15.645926 13823 sgd_solver.cpp:284] Snapshotting solver state to binary proto file ./model_112/cascade_mobilenet_112_iter_540000.solverstate
I0823 08:20:15.676980 13823 solver.cpp:347] Iteration 540000, Testing net (#0)
I0823 08:21:19.055749 13823 solver.cpp:414]     Test net output #0: landmark_loss = 0.0218577 (* 1 = 0.0218577 loss)
I0823 08:21:19.178112 13823 solver.cpp:239] Iteration 540000 (1.34932 iter/s, 74.1117s/100 iters), loss = 0.0265309
I0823 08:21:19.178169 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0265297 (* 1 = 0.0265297 loss)
I0823 08:21:19.178184 13823 sgd_solver.cpp:112] Iteration 540000, lr = 1e-06
I0823 08:21:30.148334 13823 solver.cpp:239] Iteration 540100 (9.1156 iter/s, 10.9702s/100 iters), loss = 0.0268445
I0823 08:21:30.148393 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0268433 (* 1 = 0.0268433 loss)
I0823 08:21:30.148406 13823 sgd_solver.cpp:112] Iteration 540100, lr = 1e-06
I0823 08:21:41.213307 13823 solver.cpp:239] Iteration 540200 (9.03755 iter/s, 11.0649s/100 iters), loss = 0.0245595
I0823 08:21:41.213366 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0245583 (* 1 = 0.0245583 loss)
I0823 08:21:41.213378 13823 sgd_solver.cpp:112] Iteration 540200, lr = 1e-06
I0823 08:21:52.146670 13823 solver.cpp:239] Iteration 540300 (9.14634 iter/s, 10.9333s/100 iters), loss = 0.0246011
I0823 08:21:52.146724 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0245998 (* 1 = 0.0245998 loss)
I0823 08:21:52.146734 13823 sgd_solver.cpp:112] Iteration 540300, lr = 1e-06
I0823 08:22:03.126576 13823 solver.cpp:239] Iteration 540400 (9.10756 iter/s, 10.9799s/100 iters), loss = 0.02676
I0823 08:22:03.126627 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0267587 (* 1 = 0.0267587 loss)
I0823 08:22:03.126637 13823 sgd_solver.cpp:112] Iteration 540400, lr = 1e-06
I0823 08:22:14.192850 13823 solver.cpp:239] Iteration 540500 (9.03648 iter/s, 11.0663s/100 iters), loss = 0.0341735
I0823 08:22:14.192901 13823 solver.cpp:258]     Train net output #0: landmark_loss = 0.0341722 (* 1 = 0.0341722 loss)
I0823 08:22:14.192911 13823 sgd_solver.cpp:112] Iteration 540500, lr = 1e-06
