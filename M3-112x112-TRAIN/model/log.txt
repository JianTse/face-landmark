I0820 09:43:48.871518 12052 caffe.cpp:204] Using GPUs 0
I0820 09:43:48.932502 12052 caffe.cpp:209] GPU 0: GeForce RTX 2070
I0820 09:43:49.448899 12052 solver.cpp:45] Initializing solver from parameters: 
test_iter: 950
test_interval: 6000
base_lr: 0.001
display: 100
max_iter: 3500000
lr_policy: "fixed"
momentum: 0.9
snapshot: 10000
snapshot_prefix: "./model/M3"
solver_mode: GPU
device_id: 0
net: "./M3_train_test_h5.prototxt"
train_state {
  level: 0
  stage: ""
}
momentum2: 0.999
type: "Adam"
I0820 09:43:49.449048 12052 solver.cpp:102] Creating training net from net file: ./M3_train_test_h5.prototxt
I0820 09:43:49.449316 12052 net.cpp:294] The NetState phase (0) differed from the phase (1) specified by a rule in layer data
I0820 09:43:49.449450 12052 net.cpp:51] Initializing net from parameters: 
name: "MobileNet-V2"
state {
  phase: TRAIN
  level: 0
  stage: ""
}
layer {
  name: "data"
  type: "HDF5Data"
  top: "data"
  top: "label"
  include {
    phase: TRAIN
  }
  hdf5_data_param {
    source: "/home/sxdz/data/landmark/98/train_hdf5/112/train_hdf5.txt"
    batch_size: 64
    shuffle: true
  }
}
layer {
  name: "conv1"
  type: "Convolution"
  bottom: "data"
  top: "conv1"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 1
  }
  convolution_param {
    num_output: 32
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "prelu1"
  type: "PReLU"
  bottom: "conv1"
  top: "conv1"
}
layer {
  name: "pool1"
  type: "Pooling"
  bottom: "conv1"
  top: "pool1"
  pooling_param {
    pool: MAX
    kernel_size: 3
    stride: 2
  }
}
layer {
  name: "conv2"
  type: "Convolution"
  bottom: "pool1"
  top: "conv2"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 1
  }
  convolution_param {
    num_output: 64
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "prelu2"
  type: "PReLU"
  bottom: "conv2"
  top: "conv2"
}
layer {
  name: "pool2"
  type: "Pooling"
  bottom: "conv2"
  top: "pool2"
  pooling_param {
    pool: MAX
    kernel_size: 3
    stride: 2
  }
}
layer {
  name: "conv3"
  type: "Convolution"
  bottom: "pool2"
  top: "conv3"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 1
  }
  convolution_param {
    num_output: 64
    kernel_size: 3
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "prelu3"
  type: "PReLU"
  bottom: "conv3"
  top: "conv3"
}
layer {
  name: "pool3"
  type: "Pooling"
  bottom: "conv3"
  top: "pool3"
  pooling_param {
    pool: MAX
    kernel_size: 2
    stride: 2
  }
}
layer {
  name: "conv4"
  type: "Convolution"
  bottom: "pool3"
  top: "conv4"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 1
  }
  convolution_param {
    num_output: 128
    kernel_size: 2
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "prelu4"
  type: "PReLU"
  bottom: "conv4"
  top: "conv4"
}
layer {
  name: "conv5"
  type: "InnerProduct"
  bottom: "conv4"
  top: "conv5"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 1
  }
  inner_product_param {
    num_output: 256
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "drop5"
  type: "Dropout"
  bottom: "conv5"
  top: "conv5"
  dropout_param {
    dropout_ratio: 0.25
  }
}
layer {
  name: "prelu5"
  type: "PReLU"
  bottom: "conv5"
  top: "conv5"
}
layer {
  name: "landmark_pred"
  type: "InnerProduct"
  bottom: "conv5"
  top: "landmark_pred"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 1
  }
  inner_product_param {
    num_output: 196
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "landmark_loss"
  type: "EuclideanLoss"
  bottom: "landmark_pred"
  bottom: "label"
  top: "landmark_loss"
  loss_weight: 1
}
I0820 09:43:49.449534 12052 layer_factory.hpp:77] Creating layer data
I0820 09:43:49.449549 12052 net.cpp:84] Creating Layer data
I0820 09:43:49.449555 12052 net.cpp:380] data -> data
I0820 09:43:49.449579 12052 net.cpp:380] data -> label
I0820 09:43:49.449589 12052 hdf5_data_layer.cpp:80] Loading list of HDF5 filenames from: /home/sxdz/data/landmark/98/train_hdf5/112/train_hdf5.txt
I0820 09:43:49.452069 12052 hdf5_data_layer.cpp:94] Number of HDF5 files: 5625
I0820 09:43:49.453276 12052 hdf5.cpp:32] Datatype class: H5T_FLOAT
I0820 09:43:49.454675 12052 net.cpp:122] Setting up data
I0820 09:43:49.454694 12052 net.cpp:129] Top shape: 64 3 112 112 (2408448)
I0820 09:43:49.454700 12052 net.cpp:129] Top shape: 64 196 (12544)
I0820 09:43:49.454704 12052 net.cpp:137] Memory required for data: 9683968
I0820 09:43:49.454708 12052 layer_factory.hpp:77] Creating layer conv1
I0820 09:43:49.454725 12052 net.cpp:84] Creating Layer conv1
I0820 09:43:49.454730 12052 net.cpp:406] conv1 <- data
I0820 09:43:49.454741 12052 net.cpp:380] conv1 -> conv1
I0820 09:43:49.455343 12052 net.cpp:122] Setting up conv1
I0820 09:43:49.455355 12052 net.cpp:129] Top shape: 64 32 110 110 (24780800)
I0820 09:43:49.455358 12052 net.cpp:137] Memory required for data: 108807168
I0820 09:43:49.455374 12052 layer_factory.hpp:77] Creating layer prelu1
I0820 09:43:49.455380 12052 net.cpp:84] Creating Layer prelu1
I0820 09:43:49.455384 12052 net.cpp:406] prelu1 <- conv1
I0820 09:43:49.455389 12052 net.cpp:367] prelu1 -> conv1 (in-place)
I0820 09:43:49.456569 12052 net.cpp:122] Setting up prelu1
I0820 09:43:49.456586 12052 net.cpp:129] Top shape: 64 32 110 110 (24780800)
I0820 09:43:49.456590 12052 net.cpp:137] Memory required for data: 207930368
I0820 09:43:49.456598 12052 layer_factory.hpp:77] Creating layer pool1
I0820 09:43:49.456605 12052 net.cpp:84] Creating Layer pool1
I0820 09:43:49.456609 12052 net.cpp:406] pool1 <- conv1
I0820 09:43:49.456614 12052 net.cpp:380] pool1 -> pool1
I0820 09:43:49.456660 12052 net.cpp:122] Setting up pool1
I0820 09:43:49.456668 12052 net.cpp:129] Top shape: 64 32 55 55 (6195200)
I0820 09:43:49.456672 12052 net.cpp:137] Memory required for data: 232711168
I0820 09:43:49.456676 12052 layer_factory.hpp:77] Creating layer conv2
I0820 09:43:49.456686 12052 net.cpp:84] Creating Layer conv2
I0820 09:43:49.456688 12052 net.cpp:406] conv2 <- pool1
I0820 09:43:49.456694 12052 net.cpp:380] conv2 -> conv2
I0820 09:43:49.457007 12052 net.cpp:122] Setting up conv2
I0820 09:43:49.457017 12052 net.cpp:129] Top shape: 64 64 53 53 (11505664)
I0820 09:43:49.457021 12052 net.cpp:137] Memory required for data: 278733824
I0820 09:43:49.457028 12052 layer_factory.hpp:77] Creating layer prelu2
I0820 09:43:49.457034 12052 net.cpp:84] Creating Layer prelu2
I0820 09:43:49.457037 12052 net.cpp:406] prelu2 <- conv2
I0820 09:43:49.457042 12052 net.cpp:367] prelu2 -> conv2 (in-place)
I0820 09:43:49.457244 12052 net.cpp:122] Setting up prelu2
I0820 09:43:49.457255 12052 net.cpp:129] Top shape: 64 64 53 53 (11505664)
I0820 09:43:49.457258 12052 net.cpp:137] Memory required for data: 324756480
I0820 09:43:49.457263 12052 layer_factory.hpp:77] Creating layer pool2
I0820 09:43:49.457268 12052 net.cpp:84] Creating Layer pool2
I0820 09:43:49.457271 12052 net.cpp:406] pool2 <- conv2
I0820 09:43:49.457276 12052 net.cpp:380] pool2 -> pool2
I0820 09:43:49.457309 12052 net.cpp:122] Setting up pool2
I0820 09:43:49.457316 12052 net.cpp:129] Top shape: 64 64 26 26 (2768896)
I0820 09:43:49.457320 12052 net.cpp:137] Memory required for data: 335832064
I0820 09:43:49.457324 12052 layer_factory.hpp:77] Creating layer conv3
I0820 09:43:49.457330 12052 net.cpp:84] Creating Layer conv3
I0820 09:43:49.457334 12052 net.cpp:406] conv3 <- pool2
I0820 09:43:49.457340 12052 net.cpp:380] conv3 -> conv3
I0820 09:43:49.457775 12052 net.cpp:122] Setting up conv3
I0820 09:43:49.457784 12052 net.cpp:129] Top shape: 64 64 24 24 (2359296)
I0820 09:43:49.457787 12052 net.cpp:137] Memory required for data: 345269248
I0820 09:43:49.457793 12052 layer_factory.hpp:77] Creating layer prelu3
I0820 09:43:49.457799 12052 net.cpp:84] Creating Layer prelu3
I0820 09:43:49.457803 12052 net.cpp:406] prelu3 <- conv3
I0820 09:43:49.457808 12052 net.cpp:367] prelu3 -> conv3 (in-place)
I0820 09:43:49.457902 12052 net.cpp:122] Setting up prelu3
I0820 09:43:49.457912 12052 net.cpp:129] Top shape: 64 64 24 24 (2359296)
I0820 09:43:49.457916 12052 net.cpp:137] Memory required for data: 354706432
I0820 09:43:49.457922 12052 layer_factory.hpp:77] Creating layer pool3
I0820 09:43:49.457927 12052 net.cpp:84] Creating Layer pool3
I0820 09:43:49.457931 12052 net.cpp:406] pool3 <- conv3
I0820 09:43:49.457935 12052 net.cpp:380] pool3 -> pool3
I0820 09:43:49.457967 12052 net.cpp:122] Setting up pool3
I0820 09:43:49.457975 12052 net.cpp:129] Top shape: 64 64 12 12 (589824)
I0820 09:43:49.457978 12052 net.cpp:137] Memory required for data: 357065728
I0820 09:43:49.457981 12052 layer_factory.hpp:77] Creating layer conv4
I0820 09:43:49.457988 12052 net.cpp:84] Creating Layer conv4
I0820 09:43:49.457991 12052 net.cpp:406] conv4 <- pool3
I0820 09:43:49.457998 12052 net.cpp:380] conv4 -> conv4
I0820 09:43:49.458397 12052 net.cpp:122] Setting up conv4
I0820 09:43:49.458406 12052 net.cpp:129] Top shape: 64 128 11 11 (991232)
I0820 09:43:49.458410 12052 net.cpp:137] Memory required for data: 361030656
I0820 09:43:49.458415 12052 layer_factory.hpp:77] Creating layer prelu4
I0820 09:43:49.458420 12052 net.cpp:84] Creating Layer prelu4
I0820 09:43:49.458423 12052 net.cpp:406] prelu4 <- conv4
I0820 09:43:49.458428 12052 net.cpp:367] prelu4 -> conv4 (in-place)
I0820 09:43:49.458515 12052 net.cpp:122] Setting up prelu4
I0820 09:43:49.458524 12052 net.cpp:129] Top shape: 64 128 11 11 (991232)
I0820 09:43:49.458528 12052 net.cpp:137] Memory required for data: 364995584
I0820 09:43:49.458532 12052 layer_factory.hpp:77] Creating layer conv5
I0820 09:43:49.458539 12052 net.cpp:84] Creating Layer conv5
I0820 09:43:49.458542 12052 net.cpp:406] conv5 <- conv4
I0820 09:43:49.458547 12052 net.cpp:380] conv5 -> conv5
I0820 09:43:49.488348 12052 net.cpp:122] Setting up conv5
I0820 09:43:49.488365 12052 net.cpp:129] Top shape: 64 256 (16384)
I0820 09:43:49.488369 12052 net.cpp:137] Memory required for data: 365061120
I0820 09:43:49.488376 12052 layer_factory.hpp:77] Creating layer drop5
I0820 09:43:49.488384 12052 net.cpp:84] Creating Layer drop5
I0820 09:43:49.488387 12052 net.cpp:406] drop5 <- conv5
I0820 09:43:49.488392 12052 net.cpp:367] drop5 -> conv5 (in-place)
I0820 09:43:49.488420 12052 net.cpp:122] Setting up drop5
I0820 09:43:49.488425 12052 net.cpp:129] Top shape: 64 256 (16384)
I0820 09:43:49.488428 12052 net.cpp:137] Memory required for data: 365126656
I0820 09:43:49.488431 12052 layer_factory.hpp:77] Creating layer prelu5
I0820 09:43:49.488436 12052 net.cpp:84] Creating Layer prelu5
I0820 09:43:49.488440 12052 net.cpp:406] prelu5 <- conv5
I0820 09:43:49.488443 12052 net.cpp:367] prelu5 -> conv5 (in-place)
I0820 09:43:49.488510 12052 net.cpp:122] Setting up prelu5
I0820 09:43:49.488518 12052 net.cpp:129] Top shape: 64 256 (16384)
I0820 09:43:49.488521 12052 net.cpp:137] Memory required for data: 365192192
I0820 09:43:49.488526 12052 layer_factory.hpp:77] Creating layer landmark_pred
I0820 09:43:49.488533 12052 net.cpp:84] Creating Layer landmark_pred
I0820 09:43:49.488536 12052 net.cpp:406] landmark_pred <- conv5
I0820 09:43:49.488541 12052 net.cpp:380] landmark_pred -> landmark_pred
I0820 09:43:49.489768 12052 net.cpp:122] Setting up landmark_pred
I0820 09:43:49.489784 12052 net.cpp:129] Top shape: 64 196 (12544)
I0820 09:43:49.489786 12052 net.cpp:137] Memory required for data: 365242368
I0820 09:43:49.489796 12052 layer_factory.hpp:77] Creating layer landmark_loss
I0820 09:43:49.489805 12052 net.cpp:84] Creating Layer landmark_loss
I0820 09:43:49.489809 12052 net.cpp:406] landmark_loss <- landmark_pred
I0820 09:43:49.489814 12052 net.cpp:406] landmark_loss <- label
I0820 09:43:49.489820 12052 net.cpp:380] landmark_loss -> landmark_loss
I0820 09:43:49.489856 12052 net.cpp:122] Setting up landmark_loss
I0820 09:43:49.489862 12052 net.cpp:129] Top shape: (1)
I0820 09:43:49.489866 12052 net.cpp:132]     with loss weight 1
I0820 09:43:49.489886 12052 net.cpp:137] Memory required for data: 365242372
I0820 09:43:49.489890 12052 net.cpp:198] landmark_loss needs backward computation.
I0820 09:43:49.489897 12052 net.cpp:198] landmark_pred needs backward computation.
I0820 09:43:49.489900 12052 net.cpp:198] prelu5 needs backward computation.
I0820 09:43:49.489903 12052 net.cpp:198] drop5 needs backward computation.
I0820 09:43:49.489907 12052 net.cpp:198] conv5 needs backward computation.
I0820 09:43:49.489909 12052 net.cpp:198] prelu4 needs backward computation.
I0820 09:43:49.489912 12052 net.cpp:198] conv4 needs backward computation.
I0820 09:43:49.489915 12052 net.cpp:198] pool3 needs backward computation.
I0820 09:43:49.489919 12052 net.cpp:198] prelu3 needs backward computation.
I0820 09:43:49.489923 12052 net.cpp:198] conv3 needs backward computation.
I0820 09:43:49.489925 12052 net.cpp:198] pool2 needs backward computation.
I0820 09:43:49.489928 12052 net.cpp:198] prelu2 needs backward computation.
I0820 09:43:49.489931 12052 net.cpp:198] conv2 needs backward computation.
I0820 09:43:49.489934 12052 net.cpp:198] pool1 needs backward computation.
I0820 09:43:49.489938 12052 net.cpp:198] prelu1 needs backward computation.
I0820 09:43:49.489940 12052 net.cpp:198] conv1 needs backward computation.
I0820 09:43:49.489944 12052 net.cpp:200] data does not need backward computation.
I0820 09:43:49.489948 12052 net.cpp:242] This network produces output landmark_loss
I0820 09:43:49.489959 12052 net.cpp:255] Network initialization done.
I0820 09:43:49.490176 12052 solver.cpp:190] Creating test net (#0) specified by net file: ./M3_train_test_h5.prototxt
I0820 09:43:49.490206 12052 net.cpp:294] The NetState phase (1) differed from the phase (0) specified by a rule in layer data
I0820 09:43:49.490334 12052 net.cpp:51] Initializing net from parameters: 
name: "MobileNet-V2"
state {
  phase: TEST
}
layer {
  name: "data"
  type: "HDF5Data"
  top: "data"
  top: "label"
  include {
    phase: TEST
  }
  hdf5_data_param {
    source: "/home/sxdz/data/landmark/98/train_hdf5/112/train_hdf5.txt"
    batch_size: 64
    shuffle: true
  }
}
layer {
  name: "conv1"
  type: "Convolution"
  bottom: "data"
  top: "conv1"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 1
  }
  convolution_param {
    num_output: 32
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "prelu1"
  type: "PReLU"
  bottom: "conv1"
  top: "conv1"
}
layer {
  name: "pool1"
  type: "Pooling"
  bottom: "conv1"
  top: "pool1"
  pooling_param {
    pool: MAX
    kernel_size: 3
    stride: 2
  }
}
layer {
  name: "conv2"
  type: "Convolution"
  bottom: "pool1"
  top: "conv2"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 1
  }
  convolution_param {
    num_output: 64
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "prelu2"
  type: "PReLU"
  bottom: "conv2"
  top: "conv2"
}
layer {
  name: "pool2"
  type: "Pooling"
  bottom: "conv2"
  top: "pool2"
  pooling_param {
    pool: MAX
    kernel_size: 3
    stride: 2
  }
}
layer {
  name: "conv3"
  type: "Convolution"
  bottom: "pool2"
  top: "conv3"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 1
  }
  convolution_param {
    num_output: 64
    kernel_size: 3
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "prelu3"
  type: "PReLU"
  bottom: "conv3"
  top: "conv3"
}
layer {
  name: "pool3"
  type: "Pooling"
  bottom: "conv3"
  top: "pool3"
  pooling_param {
    pool: MAX
    kernel_size: 2
    stride: 2
  }
}
layer {
  name: "conv4"
  type: "Convolution"
  bottom: "pool3"
  top: "conv4"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 1
  }
  convolution_param {
    num_output: 128
    kernel_size: 2
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "prelu4"
  type: "PReLU"
  bottom: "conv4"
  top: "conv4"
}
layer {
  name: "conv5"
  type: "InnerProduct"
  bottom: "conv4"
  top: "conv5"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 1
  }
  inner_product_param {
    num_output: 256
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "drop5"
  type: "Dropout"
  bottom: "conv5"
  top: "conv5"
  dropout_param {
    dropout_ratio: 0.25
  }
}
layer {
  name: "prelu5"
  type: "PReLU"
  bottom: "conv5"
  top: "conv5"
}
layer {
  name: "landmark_pred"
  type: "InnerProduct"
  bottom: "conv5"
  top: "landmark_pred"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 1
  }
  inner_product_param {
    num_output: 196
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "landmark_loss"
  type: "EuclideanLoss"
  bottom: "landmark_pred"
  bottom: "label"
  top: "landmark_loss"
  loss_weight: 1
}
I0820 09:43:49.490386 12052 layer_factory.hpp:77] Creating layer data
I0820 09:43:49.490394 12052 net.cpp:84] Creating Layer data
I0820 09:43:49.490398 12052 net.cpp:380] data -> data
I0820 09:43:49.490406 12052 net.cpp:380] data -> label
I0820 09:43:49.490412 12052 hdf5_data_layer.cpp:80] Loading list of HDF5 filenames from: /home/sxdz/data/landmark/98/train_hdf5/112/train_hdf5.txt
I0820 09:43:49.492792 12052 hdf5_data_layer.cpp:94] Number of HDF5 files: 5625
I0820 09:43:49.493857 12052 net.cpp:122] Setting up data
I0820 09:43:49.493872 12052 net.cpp:129] Top shape: 64 3 112 112 (2408448)
I0820 09:43:49.493877 12052 net.cpp:129] Top shape: 64 196 (12544)
I0820 09:43:49.493880 12052 net.cpp:137] Memory required for data: 9683968
I0820 09:43:49.493885 12052 layer_factory.hpp:77] Creating layer conv1
I0820 09:43:49.493896 12052 net.cpp:84] Creating Layer conv1
I0820 09:43:49.493899 12052 net.cpp:406] conv1 <- data
I0820 09:43:49.493906 12052 net.cpp:380] conv1 -> conv1
I0820 09:43:49.494140 12052 net.cpp:122] Setting up conv1
I0820 09:43:49.494151 12052 net.cpp:129] Top shape: 64 32 110 110 (24780800)
I0820 09:43:49.494155 12052 net.cpp:137] Memory required for data: 108807168
I0820 09:43:49.494164 12052 layer_factory.hpp:77] Creating layer prelu1
I0820 09:43:49.494171 12052 net.cpp:84] Creating Layer prelu1
I0820 09:43:49.494174 12052 net.cpp:406] prelu1 <- conv1
I0820 09:43:49.494179 12052 net.cpp:367] prelu1 -> conv1 (in-place)
I0820 09:43:49.495330 12052 net.cpp:122] Setting up prelu1
I0820 09:43:49.495347 12052 net.cpp:129] Top shape: 64 32 110 110 (24780800)
I0820 09:43:49.495350 12052 net.cpp:137] Memory required for data: 207930368
I0820 09:43:49.495359 12052 layer_factory.hpp:77] Creating layer pool1
I0820 09:43:49.495365 12052 net.cpp:84] Creating Layer pool1
I0820 09:43:49.495369 12052 net.cpp:406] pool1 <- conv1
I0820 09:43:49.495374 12052 net.cpp:380] pool1 -> pool1
I0820 09:43:49.495410 12052 net.cpp:122] Setting up pool1
I0820 09:43:49.495416 12052 net.cpp:129] Top shape: 64 32 55 55 (6195200)
I0820 09:43:49.495420 12052 net.cpp:137] Memory required for data: 232711168
I0820 09:43:49.495424 12052 layer_factory.hpp:77] Creating layer conv2
I0820 09:43:49.495432 12052 net.cpp:84] Creating Layer conv2
I0820 09:43:49.495436 12052 net.cpp:406] conv2 <- pool1
I0820 09:43:49.495441 12052 net.cpp:380] conv2 -> conv2
I0820 09:43:49.495774 12052 net.cpp:122] Setting up conv2
I0820 09:43:49.495784 12052 net.cpp:129] Top shape: 64 64 53 53 (11505664)
I0820 09:43:49.495787 12052 net.cpp:137] Memory required for data: 278733824
I0820 09:43:49.495796 12052 layer_factory.hpp:77] Creating layer prelu2
I0820 09:43:49.495801 12052 net.cpp:84] Creating Layer prelu2
I0820 09:43:49.495805 12052 net.cpp:406] prelu2 <- conv2
I0820 09:43:49.495808 12052 net.cpp:367] prelu2 -> conv2 (in-place)
I0820 09:43:49.496810 12052 net.cpp:122] Setting up prelu2
I0820 09:43:49.496826 12052 net.cpp:129] Top shape: 64 64 53 53 (11505664)
I0820 09:43:49.496830 12052 net.cpp:137] Memory required for data: 324756480
I0820 09:43:49.496836 12052 layer_factory.hpp:77] Creating layer pool2
I0820 09:43:49.496842 12052 net.cpp:84] Creating Layer pool2
I0820 09:43:49.496846 12052 net.cpp:406] pool2 <- conv2
I0820 09:43:49.496851 12052 net.cpp:380] pool2 -> pool2
I0820 09:43:49.496888 12052 net.cpp:122] Setting up pool2
I0820 09:43:49.496897 12052 net.cpp:129] Top shape: 64 64 26 26 (2768896)
I0820 09:43:49.496901 12052 net.cpp:137] Memory required for data: 335832064
I0820 09:43:49.496904 12052 layer_factory.hpp:77] Creating layer conv3
I0820 09:43:49.496912 12052 net.cpp:84] Creating Layer conv3
I0820 09:43:49.496917 12052 net.cpp:406] conv3 <- pool2
I0820 09:43:49.496922 12052 net.cpp:380] conv3 -> conv3
I0820 09:43:49.497359 12052 net.cpp:122] Setting up conv3
I0820 09:43:49.497370 12052 net.cpp:129] Top shape: 64 64 24 24 (2359296)
I0820 09:43:49.497372 12052 net.cpp:137] Memory required for data: 345269248
I0820 09:43:49.497378 12052 layer_factory.hpp:77] Creating layer prelu3
I0820 09:43:49.497385 12052 net.cpp:84] Creating Layer prelu3
I0820 09:43:49.497387 12052 net.cpp:406] prelu3 <- conv3
I0820 09:43:49.497392 12052 net.cpp:367] prelu3 -> conv3 (in-place)
I0820 09:43:49.497498 12052 net.cpp:122] Setting up prelu3
I0820 09:43:49.497506 12052 net.cpp:129] Top shape: 64 64 24 24 (2359296)
I0820 09:43:49.497510 12052 net.cpp:137] Memory required for data: 354706432
I0820 09:43:49.497517 12052 layer_factory.hpp:77] Creating layer pool3
I0820 09:43:49.497522 12052 net.cpp:84] Creating Layer pool3
I0820 09:43:49.497526 12052 net.cpp:406] pool3 <- conv3
I0820 09:43:49.497530 12052 net.cpp:380] pool3 -> pool3
I0820 09:43:49.497563 12052 net.cpp:122] Setting up pool3
I0820 09:43:49.497571 12052 net.cpp:129] Top shape: 64 64 12 12 (589824)
I0820 09:43:49.497575 12052 net.cpp:137] Memory required for data: 357065728
I0820 09:43:49.497577 12052 layer_factory.hpp:77] Creating layer conv4
I0820 09:43:49.497586 12052 net.cpp:84] Creating Layer conv4
I0820 09:43:49.497588 12052 net.cpp:406] conv4 <- pool3
I0820 09:43:49.497593 12052 net.cpp:380] conv4 -> conv4
I0820 09:43:49.498003 12052 net.cpp:122] Setting up conv4
I0820 09:43:49.498013 12052 net.cpp:129] Top shape: 64 128 11 11 (991232)
I0820 09:43:49.498016 12052 net.cpp:137] Memory required for data: 361030656
I0820 09:43:49.498023 12052 layer_factory.hpp:77] Creating layer prelu4
I0820 09:43:49.498028 12052 net.cpp:84] Creating Layer prelu4
I0820 09:43:49.498030 12052 net.cpp:406] prelu4 <- conv4
I0820 09:43:49.498035 12052 net.cpp:367] prelu4 -> conv4 (in-place)
I0820 09:43:49.498123 12052 net.cpp:122] Setting up prelu4
I0820 09:43:49.498132 12052 net.cpp:129] Top shape: 64 128 11 11 (991232)
I0820 09:43:49.498136 12052 net.cpp:137] Memory required for data: 364995584
I0820 09:43:49.498140 12052 layer_factory.hpp:77] Creating layer conv5
I0820 09:43:49.498147 12052 net.cpp:84] Creating Layer conv5
I0820 09:43:49.498150 12052 net.cpp:406] conv5 <- conv4
I0820 09:43:49.498155 12052 net.cpp:380] conv5 -> conv5
I0820 09:43:49.527658 12052 net.cpp:122] Setting up conv5
I0820 09:43:49.527675 12052 net.cpp:129] Top shape: 64 256 (16384)
I0820 09:43:49.527679 12052 net.cpp:137] Memory required for data: 365061120
I0820 09:43:49.527686 12052 layer_factory.hpp:77] Creating layer drop5
I0820 09:43:49.527693 12052 net.cpp:84] Creating Layer drop5
I0820 09:43:49.527696 12052 net.cpp:406] drop5 <- conv5
I0820 09:43:49.527703 12052 net.cpp:367] drop5 -> conv5 (in-place)
I0820 09:43:49.527725 12052 net.cpp:122] Setting up drop5
I0820 09:43:49.527730 12052 net.cpp:129] Top shape: 64 256 (16384)
I0820 09:43:49.527734 12052 net.cpp:137] Memory required for data: 365126656
I0820 09:43:49.527736 12052 layer_factory.hpp:77] Creating layer prelu5
I0820 09:43:49.527740 12052 net.cpp:84] Creating Layer prelu5
I0820 09:43:49.527743 12052 net.cpp:406] prelu5 <- conv5
I0820 09:43:49.527747 12052 net.cpp:367] prelu5 -> conv5 (in-place)
I0820 09:43:49.527814 12052 net.cpp:122] Setting up prelu5
I0820 09:43:49.527822 12052 net.cpp:129] Top shape: 64 256 (16384)
I0820 09:43:49.527827 12052 net.cpp:137] Memory required for data: 365192192
I0820 09:43:49.527830 12052 layer_factory.hpp:77] Creating layer landmark_pred
I0820 09:43:49.527837 12052 net.cpp:84] Creating Layer landmark_pred
I0820 09:43:49.527840 12052 net.cpp:406] landmark_pred <- conv5
I0820 09:43:49.527845 12052 net.cpp:380] landmark_pred -> landmark_pred
I0820 09:43:49.528264 12052 net.cpp:122] Setting up landmark_pred
I0820 09:43:49.528275 12052 net.cpp:129] Top shape: 64 196 (12544)
I0820 09:43:49.528277 12052 net.cpp:137] Memory required for data: 365242368
I0820 09:43:49.528286 12052 layer_factory.hpp:77] Creating layer landmark_loss
I0820 09:43:49.528293 12052 net.cpp:84] Creating Layer landmark_loss
I0820 09:43:49.528297 12052 net.cpp:406] landmark_loss <- landmark_pred
I0820 09:43:49.528301 12052 net.cpp:406] landmark_loss <- label
I0820 09:43:49.528306 12052 net.cpp:380] landmark_loss -> landmark_loss
I0820 09:43:49.528339 12052 net.cpp:122] Setting up landmark_loss
I0820 09:43:49.528345 12052 net.cpp:129] Top shape: (1)
I0820 09:43:49.528347 12052 net.cpp:132]     with loss weight 1
I0820 09:43:49.528362 12052 net.cpp:137] Memory required for data: 365242372
I0820 09:43:49.528367 12052 net.cpp:198] landmark_loss needs backward computation.
I0820 09:43:49.528371 12052 net.cpp:198] landmark_pred needs backward computation.
I0820 09:43:49.528374 12052 net.cpp:198] prelu5 needs backward computation.
I0820 09:43:49.528378 12052 net.cpp:198] drop5 needs backward computation.
I0820 09:43:49.528380 12052 net.cpp:198] conv5 needs backward computation.
I0820 09:43:49.528383 12052 net.cpp:198] prelu4 needs backward computation.
I0820 09:43:49.528386 12052 net.cpp:198] conv4 needs backward computation.
I0820 09:43:49.528389 12052 net.cpp:198] pool3 needs backward computation.
I0820 09:43:49.528393 12052 net.cpp:198] prelu3 needs backward computation.
I0820 09:43:49.528395 12052 net.cpp:198] conv3 needs backward computation.
I0820 09:43:49.528399 12052 net.cpp:198] pool2 needs backward computation.
I0820 09:43:49.528403 12052 net.cpp:198] prelu2 needs backward computation.
I0820 09:43:49.528405 12052 net.cpp:198] conv2 needs backward computation.
I0820 09:43:49.528409 12052 net.cpp:198] pool1 needs backward computation.
I0820 09:43:49.528412 12052 net.cpp:198] prelu1 needs backward computation.
I0820 09:43:49.528415 12052 net.cpp:198] conv1 needs backward computation.
I0820 09:43:49.528419 12052 net.cpp:200] data does not need backward computation.
I0820 09:43:49.528422 12052 net.cpp:242] This network produces output landmark_loss
I0820 09:43:49.528432 12052 net.cpp:255] Network initialization done.
I0820 09:43:49.528482 12052 solver.cpp:57] Solver scaffolding done.
I0820 09:43:49.529186 12052 caffe.cpp:239] Starting Optimization
I0820 09:43:49.529192 12052 solver.cpp:289] Solving MobileNet-V2
I0820 09:43:49.529196 12052 solver.cpp:290] Learning Rate Policy: fixed
I0820 09:43:49.529673 12052 solver.cpp:347] Iteration 0, Testing net (#0)
I0820 09:44:04.322659 12052 solver.cpp:414]     Test net output #0: landmark_loss = 29.2035 (* 1 = 29.2035 loss)
I0820 09:44:04.366135 12052 solver.cpp:239] Iteration 0 (1.76426e+33 iter/s, 14.837s/100 iters), loss = 29.1746
I0820 09:44:04.366166 12052 solver.cpp:258]     Train net output #0: landmark_loss = 29.1746 (* 1 = 29.1746 loss)
I0820 09:44:04.366173 12052 sgd_solver.cpp:112] Iteration 0, lr = 0.001
I0820 09:44:08.257068 12052 solver.cpp:239] Iteration 100 (25.7009 iter/s, 3.89092s/100 iters), loss = 1.41143
I0820 09:44:08.257108 12052 solver.cpp:258]     Train net output #0: landmark_loss = 1.41143 (* 1 = 1.41143 loss)
I0820 09:44:08.257113 12052 sgd_solver.cpp:112] Iteration 100, lr = 0.001
I0820 09:44:12.153734 12052 solver.cpp:239] Iteration 200 (25.6631 iter/s, 3.89664s/100 iters), loss = 1.0637
I0820 09:44:12.153774 12052 solver.cpp:258]     Train net output #0: landmark_loss = 1.0637 (* 1 = 1.0637 loss)
I0820 09:44:12.153780 12052 sgd_solver.cpp:112] Iteration 200, lr = 0.001
I0820 09:44:16.050277 12052 solver.cpp:239] Iteration 300 (25.6639 iter/s, 3.89652s/100 iters), loss = 0.700224
I0820 09:44:16.050318 12052 solver.cpp:258]     Train net output #0: landmark_loss = 0.700224 (* 1 = 0.700224 loss)
I0820 09:44:16.050323 12052 sgd_solver.cpp:112] Iteration 300, lr = 0.001
I0820 09:44:19.948408 12052 solver.cpp:239] Iteration 400 (25.6535 iter/s, 3.89811s/100 iters), loss = 0.531367
I0820 09:44:19.948449 12052 solver.cpp:258]     Train net output #0: landmark_loss = 0.531367 (* 1 = 0.531367 loss)
I0820 09:44:19.948455 12052 sgd_solver.cpp:112] Iteration 400, lr = 0.001
I0820 09:44:23.844862 12052 solver.cpp:239] Iteration 500 (25.6645 iter/s, 3.89643s/100 iters), loss = 0.49461
I0820 09:44:23.844903 12052 solver.cpp:258]     Train net output #0: landmark_loss = 0.49461 (* 1 = 0.49461 loss)
I0820 09:44:23.844909 12052 sgd_solver.cpp:112] Iteration 500, lr = 0.001
I0820 09:44:27.746933 12052 solver.cpp:239] Iteration 600 (25.6276 iter/s, 3.90204s/100 iters), loss = 0.431147
I0820 09:44:27.746975 12052 solver.cpp:258]     Train net output #0: landmark_loss = 0.431147 (* 1 = 0.431147 loss)
I0820 09:44:27.746980 12052 sgd_solver.cpp:112] Iteration 600, lr = 0.001
I0820 09:44:31.643651 12052 solver.cpp:239] Iteration 700 (25.6628 iter/s, 3.89669s/100 iters), loss = 0.496068
I0820 09:44:31.643693 12052 solver.cpp:258]     Train net output #0: landmark_loss = 0.496068 (* 1 = 0.496068 loss)
I0820 09:44:31.643698 12052 sgd_solver.cpp:112] Iteration 700, lr = 0.001
I0820 09:44:35.540017 12052 solver.cpp:239] Iteration 800 (25.6651 iter/s, 3.89634s/100 iters), loss = 0.418353
I0820 09:44:35.540057 12052 solver.cpp:258]     Train net output #0: landmark_loss = 0.418353 (* 1 = 0.418353 loss)
I0820 09:44:35.540062 12052 sgd_solver.cpp:112] Iteration 800, lr = 0.001
I0820 09:44:39.437633 12052 solver.cpp:239] Iteration 900 (25.6569 iter/s, 3.89759s/100 iters), loss = 0.391629
I0820 09:44:39.437685 12052 solver.cpp:258]     Train net output #0: landmark_loss = 0.391629 (* 1 = 0.391629 loss)
I0820 09:44:39.437691 12052 sgd_solver.cpp:112] Iteration 900, lr = 0.001
I0820 09:44:43.334481 12052 solver.cpp:239] Iteration 1000 (25.662 iter/s, 3.89681s/100 iters), loss = 0.32334
I0820 09:44:43.334520 12052 solver.cpp:258]     Train net output #0: landmark_loss = 0.32334 (* 1 = 0.32334 loss)
I0820 09:44:43.334527 12052 sgd_solver.cpp:112] Iteration 1000, lr = 0.001
I0820 09:44:47.234153 12052 solver.cpp:239] Iteration 1100 (25.6433 iter/s, 3.89965s/100 iters), loss = 0.32193
I0820 09:44:47.234206 12052 solver.cpp:258]     Train net output #0: landmark_loss = 0.32193 (* 1 = 0.32193 loss)
I0820 09:44:47.234211 12052 sgd_solver.cpp:112] Iteration 1100, lr = 0.001
I0820 09:44:51.131422 12052 solver.cpp:239] Iteration 1200 (25.6592 iter/s, 3.89723s/100 iters), loss = 0.371463
I0820 09:44:51.131462 12052 solver.cpp:258]     Train net output #0: landmark_loss = 0.371463 (* 1 = 0.371463 loss)
I0820 09:44:51.131469 12052 sgd_solver.cpp:112] Iteration 1200, lr = 0.001
I0820 09:44:55.028125 12052 solver.cpp:239] Iteration 1300 (25.6629 iter/s, 3.89668s/100 iters), loss = 0.282752
I0820 09:44:55.028180 12052 solver.cpp:258]     Train net output #0: landmark_loss = 0.282752 (* 1 = 0.282752 loss)
I0820 09:44:55.028187 12052 sgd_solver.cpp:112] Iteration 1300, lr = 0.001
I0820 09:44:58.927443 12052 solver.cpp:239] Iteration 1400 (25.6458 iter/s, 3.89928s/100 iters), loss = 0.289305
I0820 09:44:58.927495 12052 solver.cpp:258]     Train net output #0: landmark_loss = 0.289305 (* 1 = 0.289305 loss)
I0820 09:44:58.927500 12052 sgd_solver.cpp:112] Iteration 1400, lr = 0.001
I0820 09:45:02.867643 12052 solver.cpp:239] Iteration 1500 (25.3797 iter/s, 3.94016s/100 iters), loss = 0.26262
I0820 09:45:02.867686 12052 solver.cpp:258]     Train net output #0: landmark_loss = 0.26262 (* 1 = 0.26262 loss)
I0820 09:45:02.867692 12052 sgd_solver.cpp:112] Iteration 1500, lr = 0.001
I0820 09:45:06.770927 12052 solver.cpp:239] Iteration 1600 (25.6196 iter/s, 3.90326s/100 iters), loss = 0.212937
I0820 09:45:06.770980 12052 solver.cpp:258]     Train net output #0: landmark_loss = 0.212937 (* 1 = 0.212937 loss)
I0820 09:45:06.770987 12052 sgd_solver.cpp:112] Iteration 1600, lr = 0.001
I0820 09:45:10.667830 12052 solver.cpp:239] Iteration 1700 (25.6616 iter/s, 3.89687s/100 iters), loss = 0.320459
I0820 09:45:10.667882 12052 solver.cpp:258]     Train net output #0: landmark_loss = 0.320459 (* 1 = 0.320459 loss)
I0820 09:45:10.667888 12052 sgd_solver.cpp:112] Iteration 1700, lr = 0.001
I0820 09:45:14.564759 12052 solver.cpp:239] Iteration 1800 (25.6614 iter/s, 3.8969s/100 iters), loss = 0.274408
I0820 09:45:14.564800 12052 solver.cpp:258]     Train net output #0: landmark_loss = 0.274408 (* 1 = 0.274408 loss)
I0820 09:45:14.564805 12052 sgd_solver.cpp:112] Iteration 1800, lr = 0.001
I0820 09:45:18.461527 12052 solver.cpp:239] Iteration 1900 (25.6625 iter/s, 3.89674s/100 iters), loss = 0.230943
I0820 09:45:18.461567 12052 solver.cpp:258]     Train net output #0: landmark_loss = 0.230943 (* 1 = 0.230943 loss)
I0820 09:45:18.461573 12052 sgd_solver.cpp:112] Iteration 1900, lr = 0.001
I0820 09:45:22.359794 12052 solver.cpp:239] Iteration 2000 (25.6526 iter/s, 3.89824s/100 iters), loss = 0.237759
I0820 09:45:22.359834 12052 solver.cpp:258]     Train net output #0: landmark_loss = 0.237759 (* 1 = 0.237759 loss)
I0820 09:45:22.359839 12052 sgd_solver.cpp:112] Iteration 2000, lr = 0.001
I0820 09:45:26.256379 12052 solver.cpp:239] Iteration 2100 (25.6636 iter/s, 3.89656s/100 iters), loss = 0.212445
I0820 09:45:26.256433 12052 solver.cpp:258]     Train net output #0: landmark_loss = 0.212445 (* 1 = 0.212445 loss)
I0820 09:45:26.256438 12052 sgd_solver.cpp:112] Iteration 2100, lr = 0.001
I0820 09:45:30.153442 12052 solver.cpp:239] Iteration 2200 (25.6606 iter/s, 3.89702s/100 iters), loss = 0.186222
I0820 09:45:30.153483 12052 solver.cpp:258]     Train net output #0: landmark_loss = 0.186222 (* 1 = 0.186222 loss)
I0820 09:45:30.153488 12052 sgd_solver.cpp:112] Iteration 2200, lr = 0.001
I0820 09:45:34.050180 12052 solver.cpp:239] Iteration 2300 (25.6627 iter/s, 3.89671s/100 iters), loss = 0.254632
I0820 09:45:34.050221 12052 solver.cpp:258]     Train net output #0: landmark_loss = 0.254632 (* 1 = 0.254632 loss)
I0820 09:45:34.050227 12052 sgd_solver.cpp:112] Iteration 2300, lr = 0.001
I0820 09:45:37.947402 12052 solver.cpp:239] Iteration 2400 (25.6595 iter/s, 3.89719s/100 iters), loss = 0.164383
I0820 09:45:37.947441 12052 solver.cpp:258]     Train net output #0: landmark_loss = 0.164383 (* 1 = 0.164383 loss)
I0820 09:45:37.947448 12052 sgd_solver.cpp:112] Iteration 2400, lr = 0.001
I0820 09:45:41.844660 12052 solver.cpp:239] Iteration 2500 (25.6592 iter/s, 3.89723s/100 iters), loss = 0.181559
I0820 09:45:41.844699 12052 solver.cpp:258]     Train net output #0: landmark_loss = 0.181559 (* 1 = 0.181559 loss)
I0820 09:45:41.844705 12052 sgd_solver.cpp:112] Iteration 2500, lr = 0.001
I0820 09:45:45.741946 12052 solver.cpp:239] Iteration 2600 (25.659 iter/s, 3.89726s/100 iters), loss = 0.205952
I0820 09:45:45.741986 12052 solver.cpp:258]     Train net output #0: landmark_loss = 0.205952 (* 1 = 0.205952 loss)
I0820 09:45:45.741992 12052 sgd_solver.cpp:112] Iteration 2600, lr = 0.001
I0820 09:45:49.638687 12052 solver.cpp:239] Iteration 2700 (25.6626 iter/s, 3.89671s/100 iters), loss = 0.222576
I0820 09:45:49.638741 12052 solver.cpp:258]     Train net output #0: landmark_loss = 0.222576 (* 1 = 0.222576 loss)
I0820 09:45:49.638746 12052 sgd_solver.cpp:112] Iteration 2700, lr = 0.001
I0820 09:45:53.538513 12052 solver.cpp:239] Iteration 2800 (25.6424 iter/s, 3.89979s/100 iters), loss = 0.181297
I0820 09:45:53.538554 12052 solver.cpp:258]     Train net output #0: landmark_loss = 0.181297 (* 1 = 0.181297 loss)
I0820 09:45:53.538560 12052 sgd_solver.cpp:112] Iteration 2800, lr = 0.001
I0820 09:45:57.443254 12052 solver.cpp:239] Iteration 2900 (25.6101 iter/s, 3.90471s/100 iters), loss = 0.191623
I0820 09:45:57.443295 12052 solver.cpp:258]     Train net output #0: landmark_loss = 0.191623 (* 1 = 0.191623 loss)
I0820 09:45:57.443300 12052 sgd_solver.cpp:112] Iteration 2900, lr = 0.001
I0820 09:46:01.366843 12052 solver.cpp:239] Iteration 3000 (25.487 iter/s, 3.92356s/100 iters), loss = 0.165819
I0820 09:46:01.366885 12052 solver.cpp:258]     Train net output #0: landmark_loss = 0.165819 (* 1 = 0.165819 loss)
I0820 09:46:01.366891 12052 sgd_solver.cpp:112] Iteration 3000, lr = 0.001
I0820 09:46:05.287078 12052 solver.cpp:239] Iteration 3100 (25.5089 iter/s, 3.92021s/100 iters), loss = 0.146354
I0820 09:46:05.287130 12052 solver.cpp:258]     Train net output #0: landmark_loss = 0.146354 (* 1 = 0.146354 loss)
I0820 09:46:05.287137 12052 sgd_solver.cpp:112] Iteration 3100, lr = 0.001
I0820 09:46:09.186913 12052 solver.cpp:239] Iteration 3200 (25.6424 iter/s, 3.8998s/100 iters), loss = 0.128
I0820 09:46:09.186954 12052 solver.cpp:258]     Train net output #0: landmark_loss = 0.128 (* 1 = 0.128 loss)
I0820 09:46:09.186959 12052 sgd_solver.cpp:112] Iteration 3200, lr = 0.001
I0820 09:46:13.084071 12052 solver.cpp:239] Iteration 3300 (25.6599 iter/s, 3.89713s/100 iters), loss = 0.176982
I0820 09:46:13.084111 12052 solver.cpp:258]     Train net output #0: landmark_loss = 0.176982 (* 1 = 0.176982 loss)
I0820 09:46:13.084117 12052 sgd_solver.cpp:112] Iteration 3300, lr = 0.001
I0820 09:46:16.981503 12052 solver.cpp:239] Iteration 3400 (25.6581 iter/s, 3.8974s/100 iters), loss = 0.195774
I0820 09:46:16.981544 12052 solver.cpp:258]     Train net output #0: landmark_loss = 0.195774 (* 1 = 0.195774 loss)
I0820 09:46:16.981549 12052 sgd_solver.cpp:112] Iteration 3400, lr = 0.001
I0820 09:46:20.878582 12052 solver.cpp:239] Iteration 3500 (25.6604 iter/s, 3.89705s/100 iters), loss = 0.162689
I0820 09:46:20.878623 12052 solver.cpp:258]     Train net output #0: landmark_loss = 0.162689 (* 1 = 0.162689 loss)
I0820 09:46:20.878628 12052 sgd_solver.cpp:112] Iteration 3500, lr = 0.001
I0820 09:46:24.776479 12052 solver.cpp:239] Iteration 3600 (25.655 iter/s, 3.89787s/100 iters), loss = 0.129421
I0820 09:46:24.776520 12052 solver.cpp:258]     Train net output #0: landmark_loss = 0.129421 (* 1 = 0.129421 loss)
I0820 09:46:24.776525 12052 sgd_solver.cpp:112] Iteration 3600, lr = 0.001
I0820 09:46:28.673790 12052 solver.cpp:239] Iteration 3700 (25.6589 iter/s, 3.89728s/100 iters), loss = 0.144038
I0820 09:46:28.673830 12052 solver.cpp:258]     Train net output #0: landmark_loss = 0.144038 (* 1 = 0.144038 loss)
I0820 09:46:28.673836 12052 sgd_solver.cpp:112] Iteration 3700, lr = 0.001
I0820 09:46:32.571000 12052 solver.cpp:239] Iteration 3800 (25.6596 iter/s, 3.89718s/100 iters), loss = 0.126757
I0820 09:46:32.571041 12052 solver.cpp:258]     Train net output #0: landmark_loss = 0.126757 (* 1 = 0.126757 loss)
I0820 09:46:32.571048 12052 sgd_solver.cpp:112] Iteration 3800, lr = 0.001
I0820 09:46:36.468267 12052 solver.cpp:239] Iteration 3900 (25.6592 iter/s, 3.89724s/100 iters), loss = 0.201713
I0820 09:46:36.468308 12052 solver.cpp:258]     Train net output #0: landmark_loss = 0.201713 (* 1 = 0.201713 loss)
I0820 09:46:36.468314 12052 sgd_solver.cpp:112] Iteration 3900, lr = 0.001
I0820 09:46:40.370548 12052 solver.cpp:239] Iteration 4000 (25.6262 iter/s, 3.90225s/100 iters), loss = 0.10655
I0820 09:46:40.370589 12052 solver.cpp:258]     Train net output #0: landmark_loss = 0.10655 (* 1 = 0.10655 loss)
I0820 09:46:40.370594 12052 sgd_solver.cpp:112] Iteration 4000, lr = 0.001
I0820 09:46:44.267874 12052 solver.cpp:239] Iteration 4100 (25.6588 iter/s, 3.8973s/100 iters), loss = 0.140065
I0820 09:46:44.267915 12052 solver.cpp:258]     Train net output #0: landmark_loss = 0.140065 (* 1 = 0.140065 loss)
I0820 09:46:44.267920 12052 sgd_solver.cpp:112] Iteration 4100, lr = 0.001
I0820 09:46:48.168231 12052 solver.cpp:239] Iteration 4200 (25.6389 iter/s, 3.90033s/100 iters), loss = 0.127866
I0820 09:46:48.168285 12052 solver.cpp:258]     Train net output #0: landmark_loss = 0.127866 (* 1 = 0.127866 loss)
I0820 09:46:48.168290 12052 sgd_solver.cpp:112] Iteration 4200, lr = 0.001
I0820 09:46:52.065856 12052 solver.cpp:239] Iteration 4300 (25.6569 iter/s, 3.89759s/100 iters), loss = 0.120367
I0820 09:46:52.065896 12052 solver.cpp:258]     Train net output #0: landmark_loss = 0.120367 (* 1 = 0.120367 loss)
I0820 09:46:52.065901 12052 sgd_solver.cpp:112] Iteration 4300, lr = 0.001
I0820 09:46:55.964016 12052 solver.cpp:239] Iteration 4400 (25.6533 iter/s, 3.89813s/100 iters), loss = 0.114582
I0820 09:46:55.964057 12052 solver.cpp:258]     Train net output #0: landmark_loss = 0.114582 (* 1 = 0.114582 loss)
I0820 09:46:55.964062 12052 sgd_solver.cpp:112] Iteration 4400, lr = 0.001
I0820 09:46:59.861793 12052 solver.cpp:239] Iteration 4500 (25.6558 iter/s, 3.89775s/100 iters), loss = 0.13449
I0820 09:46:59.861832 12052 solver.cpp:258]     Train net output #0: landmark_loss = 0.13449 (* 1 = 0.13449 loss)
I0820 09:46:59.861838 12052 sgd_solver.cpp:112] Iteration 4500, lr = 0.001
I0820 09:47:03.808867 12052 solver.cpp:239] Iteration 4600 (25.3354 iter/s, 3.94705s/100 iters), loss = 0.121851
I0820 09:47:03.808909 12052 solver.cpp:258]     Train net output #0: landmark_loss = 0.121851 (* 1 = 0.121851 loss)
I0820 09:47:03.808915 12052 sgd_solver.cpp:112] Iteration 4600, lr = 0.001
I0820 09:47:07.708179 12052 solver.cpp:239] Iteration 4700 (25.6457 iter/s, 3.89928s/100 iters), loss = 0.145508
I0820 09:47:07.708220 12052 solver.cpp:258]     Train net output #0: landmark_loss = 0.145508 (* 1 = 0.145508 loss)
I0820 09:47:07.708225 12052 sgd_solver.cpp:112] Iteration 4700, lr = 0.001
I0820 09:47:11.606011 12052 solver.cpp:239] Iteration 4800 (25.6555 iter/s, 3.8978s/100 iters), loss = 0.123207
I0820 09:47:11.606051 12052 solver.cpp:258]     Train net output #0: landmark_loss = 0.123207 (* 1 = 0.123207 loss)
I0820 09:47:11.606057 12052 sgd_solver.cpp:112] Iteration 4800, lr = 0.001
I0820 09:47:15.505108 12052 solver.cpp:239] Iteration 4900 (25.6471 iter/s, 3.89907s/100 iters), loss = 0.108158
I0820 09:47:15.505161 12052 solver.cpp:258]     Train net output #0: landmark_loss = 0.108158 (* 1 = 0.108158 loss)
I0820 09:47:15.505167 12052 sgd_solver.cpp:112] Iteration 4900, lr = 0.001
I0820 09:47:19.403326 12052 solver.cpp:239] Iteration 5000 (25.653 iter/s, 3.89818s/100 iters), loss = 0.111441
I0820 09:47:19.403368 12052 solver.cpp:258]     Train net output #0: landmark_loss = 0.111441 (* 1 = 0.111441 loss)
I0820 09:47:19.403374 12052 sgd_solver.cpp:112] Iteration 5000, lr = 0.001
I0820 09:47:23.301506 12052 solver.cpp:239] Iteration 5100 (25.6532 iter/s, 3.89815s/100 iters), loss = 0.0985155
I0820 09:47:23.301548 12052 solver.cpp:258]     Train net output #0: landmark_loss = 0.0985155 (* 1 = 0.0985155 loss)
I0820 09:47:23.301553 12052 sgd_solver.cpp:112] Iteration 5100, lr = 0.001
I0820 09:47:27.202549 12052 solver.cpp:239] Iteration 5200 (25.6344 iter/s, 3.90102s/100 iters), loss = 0.142192
I0820 09:47:27.202601 12052 solver.cpp:258]     Train net output #0: landmark_loss = 0.142192 (* 1 = 0.142192 loss)
I0820 09:47:27.202607 12052 sgd_solver.cpp:112] Iteration 5200, lr = 0.001
I0820 09:47:31.101153 12052 solver.cpp:239] Iteration 5300 (25.6504 iter/s, 3.89857s/100 iters), loss = 0.106967
I0820 09:47:31.101194 12052 solver.cpp:258]     Train net output #0: landmark_loss = 0.106967 (* 1 = 0.106967 loss)
I0820 09:47:31.101199 12052 sgd_solver.cpp:112] Iteration 5300, lr = 0.001
I0820 09:47:34.999038 12052 solver.cpp:239] Iteration 5400 (25.6551 iter/s, 3.89786s/100 iters), loss = 0.143284
I0820 09:47:34.999079 12052 solver.cpp:258]     Train net output #0: landmark_loss = 0.143284 (* 1 = 0.143284 loss)
I0820 09:47:34.999085 12052 sgd_solver.cpp:112] Iteration 5400, lr = 0.001
I0820 09:47:38.897385 12052 solver.cpp:239] Iteration 5500 (25.6521 iter/s, 3.89832s/100 iters), loss = 0.093368
I0820 09:47:38.897426 12052 solver.cpp:258]     Train net output #0: landmark_loss = 0.093368 (* 1 = 0.093368 loss)
I0820 09:47:38.897433 12052 sgd_solver.cpp:112] Iteration 5500, lr = 0.001
I0820 09:47:42.798673 12052 solver.cpp:239] Iteration 5600 (25.6327 iter/s, 3.90126s/100 iters), loss = 0.112436
I0820 09:47:42.798725 12052 solver.cpp:258]     Train net output #0: landmark_loss = 0.112436 (* 1 = 0.112436 loss)
I0820 09:47:42.798732 12052 sgd_solver.cpp:112] Iteration 5600, lr = 0.001
I0820 09:47:46.698043 12052 solver.cpp:239] Iteration 5700 (25.6454 iter/s, 3.89933s/100 iters), loss = 0.102219
I0820 09:47:46.698084 12052 solver.cpp:258]     Train net output #0: landmark_loss = 0.102219 (* 1 = 0.102219 loss)
I0820 09:47:46.698089 12052 sgd_solver.cpp:112] Iteration 5700, lr = 0.001
I0820 09:47:50.596153 12052 solver.cpp:239] Iteration 5800 (25.6537 iter/s, 3.89808s/100 iters), loss = 0.104583
I0820 09:47:50.596194 12052 solver.cpp:258]     Train net output #0: landmark_loss = 0.104583 (* 1 = 0.104583 loss)
I0820 09:47:50.596199 12052 sgd_solver.cpp:112] Iteration 5800, lr = 0.001
I0820 09:47:54.494738 12052 solver.cpp:239] Iteration 5900 (25.6505 iter/s, 3.89856s/100 iters), loss = 0.123203
I0820 09:47:54.494778 12052 solver.cpp:258]     Train net output #0: landmark_loss = 0.123203 (* 1 = 0.123203 loss)
I0820 09:47:54.494783 12052 sgd_solver.cpp:112] Iteration 5900, lr = 0.001
I0820 09:47:58.336956 12052 solver.cpp:347] Iteration 6000, Testing net (#0)
I0820 09:48:13.162104 12052 solver.cpp:414]     Test net output #0: landmark_loss = 0.0768766 (* 1 = 0.0768766 loss)
I0820 09:48:13.200780 12052 solver.cpp:239] Iteration 6000 (5.34585 iter/s, 18.7061s/100 iters), loss = 0.0916234
I0820 09:48:13.200809 12052 solver.cpp:258]     Train net output #0: landmark_loss = 0.0916234 (* 1 = 0.0916234 loss)
I0820 09:48:13.200814 12052 sgd_solver.cpp:112] Iteration 6000, lr = 0.001
I0820 09:48:17.099153 12052 solver.cpp:239] Iteration 6100 (25.6518 iter/s, 3.89836s/100 iters), loss = 0.0964422
I0820 09:48:17.099195 12052 solver.cpp:258]     Train net output #0: landmark_loss = 0.0964422 (* 1 = 0.0964422 loss)
I0820 09:48:17.099200 12052 sgd_solver.cpp:112] Iteration 6100, lr = 0.001
I0820 09:48:20.997406 12052 solver.cpp:239] Iteration 6200 (25.6527 iter/s, 3.89822s/100 iters), loss = 0.103315
I0820 09:48:20.997445 12052 solver.cpp:258]     Train net output #0: landmark_loss = 0.103315 (* 1 = 0.103315 loss)
I0820 09:48:20.997452 12052 sgd_solver.cpp:112] Iteration 6200, lr = 0.001
I0820 09:48:24.895913 12052 solver.cpp:239] Iteration 6300 (25.651 iter/s, 3.89848s/100 iters), loss = 0.0938319
I0820 09:48:24.895953 12052 solver.cpp:258]     Train net output #0: landmark_loss = 0.0938319 (* 1 = 0.0938319 loss)
I0820 09:48:24.895959 12052 sgd_solver.cpp:112] Iteration 6300, lr = 0.001
I0820 09:48:28.794538 12052 solver.cpp:239] Iteration 6400 (25.6503 iter/s, 3.8986s/100 iters), loss = 0.0854735
I0820 09:48:28.794577 12052 solver.cpp:258]     Train net output #0: landmark_loss = 0.0854735 (* 1 = 0.0854735 loss)
I0820 09:48:28.794584 12052 sgd_solver.cpp:112] Iteration 6400, lr = 0.001
I0820 09:48:32.694406 12052 solver.cpp:239] Iteration 6500 (25.6421 iter/s, 3.89984s/100 iters), loss = 0.0952747
I0820 09:48:32.694445 12052 solver.cpp:258]     Train net output #0: landmark_loss = 0.0952747 (* 1 = 0.0952747 loss)
I0820 09:48:32.694450 12052 sgd_solver.cpp:112] Iteration 6500, lr = 0.001
I0820 09:48:36.592911 12052 solver.cpp:239] Iteration 6600 (25.651 iter/s, 3.89848s/100 iters), loss = 0.100433
I0820 09:48:36.592952 12052 solver.cpp:258]     Train net output #0: landmark_loss = 0.100433 (* 1 = 0.100433 loss)
I0820 09:48:36.592957 12052 sgd_solver.cpp:112] Iteration 6600, lr = 0.001
I0820 09:48:40.491494 12052 solver.cpp:239] Iteration 6700 (25.6505 iter/s, 3.89856s/100 iters), loss = 0.0946333
I0820 09:48:40.491534 12052 solver.cpp:258]     Train net output #0: landmark_loss = 0.0946333 (* 1 = 0.0946333 loss)
I0820 09:48:40.491540 12052 sgd_solver.cpp:112] Iteration 6700, lr = 0.001
I0820 09:48:44.390235 12052 solver.cpp:239] Iteration 6800 (25.6495 iter/s, 3.89871s/100 iters), loss = 0.0783116
I0820 09:48:44.390276 12052 solver.cpp:258]     Train net output #0: landmark_loss = 0.0783116 (* 1 = 0.0783116 loss)
I0820 09:48:44.390281 12052 sgd_solver.cpp:112] Iteration 6800, lr = 0.001
I0820 09:48:48.292271 12052 solver.cpp:239] Iteration 6900 (25.6278 iter/s, 3.90201s/100 iters), loss = 0.0987029
I0820 09:48:48.292323 12052 solver.cpp:258]     Train net output #0: landmark_loss = 0.0987029 (* 1 = 0.0987029 loss)
I0820 09:48:48.292330 12052 sgd_solver.cpp:112] Iteration 6900, lr = 0.001
I0820 09:48:52.191155 12052 solver.cpp:239] Iteration 7000 (25.6486 iter/s, 3.89885s/100 iters), loss = 0.118018
I0820 09:48:52.191195 12052 solver.cpp:258]     Train net output #0: landmark_loss = 0.118018 (* 1 = 0.118018 loss)
I0820 09:48:52.191200 12052 sgd_solver.cpp:112] Iteration 7000, lr = 0.001
I0820 09:48:56.090520 12052 solver.cpp:239] Iteration 7100 (25.6454 iter/s, 3.89934s/100 iters), loss = 0.0785942
I0820 09:48:56.090560 12052 solver.cpp:258]     Train net output #0: landmark_loss = 0.0785942 (* 1 = 0.0785942 loss)
I0820 09:48:56.090565 12052 sgd_solver.cpp:112] Iteration 7100, lr = 0.001
I0820 09:48:59.989323 12052 solver.cpp:239] Iteration 7200 (25.6491 iter/s, 3.89878s/100 iters), loss = 0.0756716
I0820 09:48:59.989364 12052 solver.cpp:258]     Train net output #0: landmark_loss = 0.0756716 (* 1 = 0.0756716 loss)
I0820 09:48:59.989369 12052 sgd_solver.cpp:112] Iteration 7200, lr = 0.001
I0820 09:49:03.938113 12052 solver.cpp:239] Iteration 7300 (25.3244 iter/s, 3.94876s/100 iters), loss = 0.0804557
I0820 09:49:03.938153 12052 solver.cpp:258]     Train net output #0: landmark_loss = 0.0804557 (* 1 = 0.0804557 loss)
I0820 09:49:03.938159 12052 sgd_solver.cpp:112] Iteration 7300, lr = 0.001
I0820 09:49:07.840147 12052 solver.cpp:239] Iteration 7400 (25.6278 iter/s, 3.90201s/100 iters), loss = 0.121004
I0820 09:49:07.840188 12052 solver.cpp:258]     Train net output #0: landmark_loss = 0.121004 (* 1 = 0.121004 loss)
I0820 09:49:07.840193 12052 sgd_solver.cpp:112] Iteration 7400, lr = 0.001
I0820 09:49:11.739903 12052 solver.cpp:239] Iteration 7500 (25.6428 iter/s, 3.89973s/100 iters), loss = 0.152235
I0820 09:49:11.739943 12052 solver.cpp:258]     Train net output #0: landmark_loss = 0.152235 (* 1 = 0.152235 loss)
I0820 09:49:11.739948 12052 sgd_solver.cpp:112] Iteration 7500, lr = 0.001
I0820 09:49:15.641671 12052 solver.cpp:239] Iteration 7600 (25.6296 iter/s, 3.90174s/100 iters), loss = 0.104349
I0820 09:49:15.641710 12052 solver.cpp:258]     Train net output #0: landmark_loss = 0.104349 (* 1 = 0.104349 loss)
I0820 09:49:15.641716 12052 sgd_solver.cpp:112] Iteration 7600, lr = 0.001
I0820 09:49:19.540277 12052 solver.cpp:239] Iteration 7700 (25.6504 iter/s, 3.89858s/100 iters), loss = 0.0746859
I0820 09:49:19.540329 12052 solver.cpp:258]     Train net output #0: landmark_loss = 0.0746859 (* 1 = 0.0746859 loss)
I0820 09:49:19.540335 12052 sgd_solver.cpp:112] Iteration 7700, lr = 0.001
I0820 09:49:23.439167 12052 solver.cpp:239] Iteration 7800 (25.6486 iter/s, 3.89885s/100 iters), loss = 0.0725897
I0820 09:49:23.439206 12052 solver.cpp:258]     Train net output #0: landmark_loss = 0.0725897 (* 1 = 0.0725897 loss)
I0820 09:49:23.439211 12052 sgd_solver.cpp:112] Iteration 7800, lr = 0.001
I0820 09:49:27.342968 12052 solver.cpp:239] Iteration 7900 (25.6162 iter/s, 3.90377s/100 iters), loss = 0.0969046
I0820 09:49:27.343020 12052 solver.cpp:258]     Train net output #0: landmark_loss = 0.0969046 (* 1 = 0.0969046 loss)
I0820 09:49:27.343026 12052 sgd_solver.cpp:112] Iteration 7900, lr = 0.001
I0820 09:49:31.246984 12052 solver.cpp:239] Iteration 8000 (25.6149 iter/s, 3.90398s/100 iters), loss = 0.0821639
I0820 09:49:31.247037 12052 solver.cpp:258]     Train net output #0: landmark_loss = 0.0821639 (* 1 = 0.0821639 loss)
I0820 09:49:31.247043 12052 sgd_solver.cpp:112] Iteration 8000, lr = 0.001
I0820 09:49:35.146263 12052 solver.cpp:239] Iteration 8100 (25.646 iter/s, 3.89924s/100 iters), loss = 0.0806349
I0820 09:49:35.146304 12052 solver.cpp:258]     Train net output #0: landmark_loss = 0.0806349 (* 1 = 0.0806349 loss)
I0820 09:49:35.146309 12052 sgd_solver.cpp:112] Iteration 8100, lr = 0.001
I0820 09:49:39.045390 12052 solver.cpp:239] Iteration 8200 (25.647 iter/s, 3.8991s/100 iters), loss = 0.0827055
I0820 09:49:39.045430 12052 solver.cpp:258]     Train net output #0: landmark_loss = 0.0827055 (* 1 = 0.0827055 loss)
I0820 09:49:39.045436 12052 sgd_solver.cpp:112] Iteration 8200, lr = 0.001
I0820 09:49:42.945271 12052 solver.cpp:239] Iteration 8300 (25.642 iter/s, 3.89985s/100 iters), loss = 0.0893165
I0820 09:49:42.945323 12052 solver.cpp:258]     Train net output #0: landmark_loss = 0.0893165 (* 1 = 0.0893165 loss)
I0820 09:49:42.945329 12052 sgd_solver.cpp:112] Iteration 8300, lr = 0.001
I0820 09:49:46.845512 12052 solver.cpp:239] Iteration 8400 (25.6397 iter/s, 3.9002s/100 iters), loss = 0.0799502
I0820 09:49:46.845552 12052 solver.cpp:258]     Train net output #0: landmark_loss = 0.0799502 (* 1 = 0.0799502 loss)
I0820 09:49:46.845558 12052 sgd_solver.cpp:112] Iteration 8400, lr = 0.001
I0820 09:49:50.744952 12052 solver.cpp:239] Iteration 8500 (25.6449 iter/s, 3.89941s/100 iters), loss = 0.080022
I0820 09:49:50.744993 12052 solver.cpp:258]     Train net output #0: landmark_loss = 0.080022 (* 1 = 0.080022 loss)
I0820 09:49:50.744998 12052 sgd_solver.cpp:112] Iteration 8500, lr = 0.001
I0820 09:49:54.644410 12052 solver.cpp:239] Iteration 8600 (25.6448 iter/s, 3.89943s/100 iters), loss = 0.0892961
I0820 09:49:54.644450 12052 solver.cpp:258]     Train net output #0: landmark_loss = 0.0892961 (* 1 = 0.0892961 loss)
I0820 09:49:54.644456 12052 sgd_solver.cpp:112] Iteration 8600, lr = 0.001
I0820 09:49:58.543598 12052 solver.cpp:239] Iteration 8700 (25.6465 iter/s, 3.89916s/100 iters), loss = 0.0867505
I0820 09:49:58.543637 12052 solver.cpp:258]     Train net output #0: landmark_loss = 0.0867505 (* 1 = 0.0867505 loss)
I0820 09:49:58.543643 12052 sgd_solver.cpp:112] Iteration 8700, lr = 0.001
I0820 09:50:02.481745 12052 solver.cpp:239] Iteration 8800 (25.3928 iter/s, 3.93812s/100 iters), loss = 0.0746342
I0820 09:50:02.481788 12052 solver.cpp:258]     Train net output #0: landmark_loss = 0.0746342 (* 1 = 0.0746342 loss)
I0820 09:50:02.481794 12052 sgd_solver.cpp:112] Iteration 8800, lr = 0.001
I0820 09:50:06.392349 12052 solver.cpp:239] Iteration 8900 (25.5717 iter/s, 3.91057s/100 iters), loss = 0.0812454
I0820 09:50:06.392401 12052 solver.cpp:258]     Train net output #0: landmark_loss = 0.0812454 (* 1 = 0.0812454 loss)
I0820 09:50:06.392407 12052 sgd_solver.cpp:112] Iteration 8900, lr = 0.001
I0820 09:50:10.293639 12052 solver.cpp:239] Iteration 9000 (25.6328 iter/s, 3.90125s/100 iters), loss = 0.073439
I0820 09:50:10.293679 12052 solver.cpp:258]     Train net output #0: landmark_loss = 0.073439 (* 1 = 0.073439 loss)
I0820 09:50:10.293684 12052 sgd_solver.cpp:112] Iteration 9000, lr = 0.001
I0820 09:50:14.193714 12052 solver.cpp:239] Iteration 9100 (25.6407 iter/s, 3.90005s/100 iters), loss = 0.0673955
I0820 09:50:14.193765 12052 solver.cpp:258]     Train net output #0: landmark_loss = 0.0673955 (* 1 = 0.0673955 loss)
I0820 09:50:14.193771 12052 sgd_solver.cpp:112] Iteration 9100, lr = 0.001
I0820 09:50:18.096173 12052 solver.cpp:239] Iteration 9200 (25.625 iter/s, 3.90243s/100 iters), loss = 0.0998616
I0820 09:50:18.096225 12052 solver.cpp:258]     Train net output #0: landmark_loss = 0.0998616 (* 1 = 0.0998616 loss)
I0820 09:50:18.096230 12052 sgd_solver.cpp:112] Iteration 9200, lr = 0.001
I0820 09:50:21.996117 12052 solver.cpp:239] Iteration 9300 (25.6417 iter/s, 3.8999s/100 iters), loss = 0.0765017
I0820 09:50:21.996160 12052 solver.cpp:258]     Train net output #0: landmark_loss = 0.0765017 (* 1 = 0.0765017 loss)
I0820 09:50:21.996165 12052 sgd_solver.cpp:112] Iteration 9300, lr = 0.001
I0820 09:50:25.895735 12052 solver.cpp:239] Iteration 9400 (25.6437 iter/s, 3.89959s/100 iters), loss = 0.0828008
I0820 09:50:25.895776 12052 solver.cpp:258]     Train net output #0: landmark_loss = 0.0828008 (* 1 = 0.0828008 loss)
I0820 09:50:25.895781 12052 sgd_solver.cpp:112] Iteration 9400, lr = 0.001
I0820 09:50:29.795184 12052 solver.cpp:239] Iteration 9500 (25.6448 iter/s, 3.89942s/100 iters), loss = 0.0706616
I0820 09:50:29.795223 12052 solver.cpp:258]     Train net output #0: landmark_loss = 0.0706616 (* 1 = 0.0706616 loss)
I0820 09:50:29.795229 12052 sgd_solver.cpp:112] Iteration 9500, lr = 0.001
I0820 09:50:33.694545 12052 solver.cpp:239] Iteration 9600 (25.6454 iter/s, 3.89933s/100 iters), loss = 0.0869743
I0820 09:50:33.694595 12052 solver.cpp:258]     Train net output #0: landmark_loss = 0.0869743 (* 1 = 0.0869743 loss)
I0820 09:50:33.694602 12052 sgd_solver.cpp:112] Iteration 9600, lr = 0.001
I0820 09:50:37.594195 12052 solver.cpp:239] Iteration 9700 (25.6436 iter/s, 3.89961s/100 iters), loss = 0.0689321
I0820 09:50:37.594236 12052 solver.cpp:258]     Train net output #0: landmark_loss = 0.0689321 (* 1 = 0.0689321 loss)
I0820 09:50:37.594241 12052 sgd_solver.cpp:112] Iteration 9700, lr = 0.001
I0820 09:50:41.493337 12052 solver.cpp:239] Iteration 9800 (25.6469 iter/s, 3.89911s/100 iters), loss = 0.0732965
I0820 09:50:41.493377 12052 solver.cpp:258]     Train net output #0: landmark_loss = 0.0732965 (* 1 = 0.0732965 loss)
I0820 09:50:41.493383 12052 sgd_solver.cpp:112] Iteration 9800, lr = 0.001
I0820 09:50:45.392992 12052 solver.cpp:239] Iteration 9900 (25.6435 iter/s, 3.89963s/100 iters), loss = 0.079686
I0820 09:50:45.393031 12052 solver.cpp:258]     Train net output #0: landmark_loss = 0.079686 (* 1 = 0.079686 loss)
I0820 09:50:45.393038 12052 sgd_solver.cpp:112] Iteration 9900, lr = 0.001
I0820 09:50:49.236074 12052 solver.cpp:464] Snapshotting to binary proto file ./model/M3_iter_10000.caffemodel
I0820 09:50:49.344686 12052 sgd_solver.cpp:284] Snapshotting solver state to binary proto file ./model/M3_iter_10000.solverstate
I0820 09:50:49.570164 12052 solver.cpp:239] Iteration 10000 (23.9398 iter/s, 4.17714s/100 iters), loss = 0.0929144
I0820 09:50:49.570230 12052 solver.cpp:258]     Train net output #0: landmark_loss = 0.0929144 (* 1 = 0.0929144 loss)
I0820 09:50:49.570241 12052 sgd_solver.cpp:112] Iteration 10000, lr = 0.001
I0820 09:50:53.509598 12052 solver.cpp:239] Iteration 10100 (25.3847 iter/s, 3.93939s/100 iters), loss = 0.0703756
I0820 09:50:53.509639 12052 solver.cpp:258]     Train net output #0: landmark_loss = 0.0703756 (* 1 = 0.0703756 loss)
I0820 09:50:53.509645 12052 sgd_solver.cpp:112] Iteration 10100, lr = 0.001
I0820 09:50:57.417292 12052 solver.cpp:239] Iteration 10200 (25.5907 iter/s, 3.90766s/100 iters), loss = 0.0691648
I0820 09:50:57.417333 12052 solver.cpp:258]     Train net output #0: landmark_loss = 0.0691648 (* 1 = 0.0691648 loss)
I0820 09:50:57.417338 12052 sgd_solver.cpp:112] Iteration 10200, lr = 0.001
I0820 09:51:01.350339 12052 solver.cpp:239] Iteration 10300 (25.4258 iter/s, 3.93302s/100 iters), loss = 0.0833745
I0820 09:51:01.350381 12052 solver.cpp:258]     Train net output #0: landmark_loss = 0.0833745 (* 1 = 0.0833745 loss)
I0820 09:51:01.350389 12052 sgd_solver.cpp:112] Iteration 10300, lr = 0.001
I0820 09:51:05.279006 12052 solver.cpp:239] Iteration 10400 (25.4541 iter/s, 3.92864s/100 iters), loss = 0.0733353
I0820 09:51:05.279047 12052 solver.cpp:258]     Train net output #0: landmark_loss = 0.0733353 (* 1 = 0.0733353 loss)
I0820 09:51:05.279052 12052 sgd_solver.cpp:112] Iteration 10400, lr = 0.001
I0820 09:51:09.184870 12052 solver.cpp:239] Iteration 10500 (25.6027 iter/s, 3.90584s/100 iters), loss = 0.0925574
I0820 09:51:09.184911 12052 solver.cpp:258]     Train net output #0: landmark_loss = 0.0925574 (* 1 = 0.0925574 loss)
I0820 09:51:09.184917 12052 sgd_solver.cpp:112] Iteration 10500, lr = 0.001
I0820 09:51:13.091131 12052 solver.cpp:239] Iteration 10600 (25.6001 iter/s, 3.90623s/100 iters), loss = 0.0650411
I0820 09:51:13.091173 12052 solver.cpp:258]     Train net output #0: landmark_loss = 0.0650411 (* 1 = 0.0650411 loss)
I0820 09:51:13.091179 12052 sgd_solver.cpp:112] Iteration 10600, lr = 0.001
I0820 09:51:16.998504 12052 solver.cpp:239] Iteration 10700 (25.5929 iter/s, 3.90734s/100 iters), loss = 0.111703
I0820 09:51:16.998544 12052 solver.cpp:258]     Train net output #0: landmark_loss = 0.111703 (* 1 = 0.111703 loss)
I0820 09:51:16.998550 12052 sgd_solver.cpp:112] Iteration 10700, lr = 0.001
I0820 09:51:20.904314 12052 solver.cpp:239] Iteration 10800 (25.6031 iter/s, 3.90578s/100 iters), loss = 0.0828514
I0820 09:51:20.904353 12052 solver.cpp:258]     Train net output #0: landmark_loss = 0.0828514 (* 1 = 0.0828514 loss)
I0820 09:51:20.904359 12052 sgd_solver.cpp:112] Iteration 10800, lr = 0.001
I0820 09:51:24.810240 12052 solver.cpp:239] Iteration 10900 (25.6023 iter/s, 3.9059s/100 iters), loss = 0.0982598
I0820 09:51:24.810281 12052 solver.cpp:258]     Train net output #0: landmark_loss = 0.0982597 (* 1 = 0.0982597 loss)
I0820 09:51:24.810287 12052 sgd_solver.cpp:112] Iteration 10900, lr = 0.001
I0820 09:51:28.719219 12052 solver.cpp:239] Iteration 11000 (25.5823 iter/s, 3.90895s/100 iters), loss = 0.0725216
I0820 09:51:28.719260 12052 solver.cpp:258]     Train net output #0: landmark_loss = 0.0725216 (* 1 = 0.0725216 loss)
I0820 09:51:28.719265 12052 sgd_solver.cpp:112] Iteration 11000, lr = 0.001
I0820 09:51:32.628259 12052 solver.cpp:239] Iteration 11100 (25.5819 iter/s, 3.90901s/100 iters), loss = 0.0751258
I0820 09:51:32.628300 12052 solver.cpp:258]     Train net output #0: landmark_loss = 0.0751258 (* 1 = 0.0751258 loss)
I0820 09:51:32.628306 12052 sgd_solver.cpp:112] Iteration 11100, lr = 0.001
I0820 09:51:36.535521 12052 solver.cpp:239] Iteration 11200 (25.5936 iter/s, 3.90723s/100 iters), loss = 0.0848031
I0820 09:51:36.535563 12052 solver.cpp:258]     Train net output #0: landmark_loss = 0.084803 (* 1 = 0.084803 loss)
I0820 09:51:36.535568 12052 sgd_solver.cpp:112] Iteration 11200, lr = 0.001
I0820 09:51:40.442196 12052 solver.cpp:239] Iteration 11300 (25.5974 iter/s, 3.90664s/100 iters), loss = 0.070733
I0820 09:51:40.442236 12052 solver.cpp:258]     Train net output #0: landmark_loss = 0.070733 (* 1 = 0.070733 loss)
I0820 09:51:40.442242 12052 sgd_solver.cpp:112] Iteration 11300, lr = 0.001
I0820 09:51:44.348659 12052 solver.cpp:239] Iteration 11400 (25.5988 iter/s, 3.90644s/100 iters), loss = 0.0642376
I0820 09:51:44.348698 12052 solver.cpp:258]     Train net output #0: landmark_loss = 0.0642376 (* 1 = 0.0642376 loss)
I0820 09:51:44.348704 12052 sgd_solver.cpp:112] Iteration 11400, lr = 0.001
I0820 09:51:48.254259 12052 solver.cpp:239] Iteration 11500 (25.6044 iter/s, 3.90557s/100 iters), loss = 0.077048
I0820 09:51:48.254299 12052 solver.cpp:258]     Train net output #0: landmark_loss = 0.077048 (* 1 = 0.077048 loss)
I0820 09:51:48.254305 12052 sgd_solver.cpp:112] Iteration 11500, lr = 0.001
I0820 09:51:52.160028 12052 solver.cpp:239] Iteration 11600 (25.6033 iter/s, 3.90574s/100 iters), loss = 0.0794982
I0820 09:51:52.160069 12052 solver.cpp:258]     Train net output #0: landmark_loss = 0.0794981 (* 1 = 0.0794981 loss)
I0820 09:51:52.160075 12052 sgd_solver.cpp:112] Iteration 11600, lr = 0.001
I0820 09:51:56.067813 12052 solver.cpp:239] Iteration 11700 (25.5901 iter/s, 3.90776s/100 iters), loss = 0.0723871
I0820 09:51:56.067853 12052 solver.cpp:258]     Train net output #0: landmark_loss = 0.0723871 (* 1 = 0.0723871 loss)
I0820 09:51:56.067859 12052 sgd_solver.cpp:112] Iteration 11700, lr = 0.001
I0820 09:51:59.973418 12052 solver.cpp:239] Iteration 11800 (25.6044 iter/s, 3.90558s/100 iters), loss = 0.0756413
I0820 09:51:59.973459 12052 solver.cpp:258]     Train net output #0: landmark_loss = 0.0756413 (* 1 = 0.0756413 loss)
I0820 09:51:59.973465 12052 sgd_solver.cpp:112] Iteration 11800, lr = 0.001
I0820 09:52:03.920707 12052 solver.cpp:239] Iteration 11900 (25.334 iter/s, 3.94726s/100 iters), loss = 0.0650834
I0820 09:52:03.920747 12052 solver.cpp:258]     Train net output #0: landmark_loss = 0.0650833 (* 1 = 0.0650833 loss)
I0820 09:52:03.920753 12052 sgd_solver.cpp:112] Iteration 11900, lr = 0.001
I0820 09:52:07.770273 12052 solver.cpp:347] Iteration 12000, Testing net (#0)
I0820 09:52:22.551486 12052 solver.cpp:414]     Test net output #0: landmark_loss = 0.0483443 (* 1 = 0.0483443 loss)
I0820 09:52:22.590214 12052 solver.cpp:239] Iteration 12000 (5.35631 iter/s, 18.6696s/100 iters), loss = 0.0730088
I0820 09:52:22.590240 12052 solver.cpp:258]     Train net output #0: landmark_loss = 0.0730088 (* 1 = 0.0730088 loss)
I0820 09:52:22.590245 12052 sgd_solver.cpp:112] Iteration 12000, lr = 0.001
I0820 09:52:26.496305 12052 solver.cpp:239] Iteration 12100 (25.6011 iter/s, 3.90608s/100 iters), loss = 0.0837094
I0820 09:52:26.496346 12052 solver.cpp:258]     Train net output #0: landmark_loss = 0.0837093 (* 1 = 0.0837093 loss)
I0820 09:52:26.496352 12052 sgd_solver.cpp:112] Iteration 12100, lr = 0.001
I0820 09:52:30.402055 12052 solver.cpp:239] Iteration 12200 (25.6035 iter/s, 3.90572s/100 iters), loss = 0.0734874
I0820 09:52:30.402096 12052 solver.cpp:258]     Train net output #0: landmark_loss = 0.0734874 (* 1 = 0.0734874 loss)
I0820 09:52:30.402101 12052 sgd_solver.cpp:112] Iteration 12200, lr = 0.001
I0820 09:52:34.309201 12052 solver.cpp:239] Iteration 12300 (25.5943 iter/s, 3.90712s/100 iters), loss = 0.0723704
I0820 09:52:34.309255 12052 solver.cpp:258]     Train net output #0: landmark_loss = 0.0723704 (* 1 = 0.0723704 loss)
I0820 09:52:34.309262 12052 sgd_solver.cpp:112] Iteration 12300, lr = 0.001
I0820 09:52:38.220371 12052 solver.cpp:239] Iteration 12400 (25.5681 iter/s, 3.91113s/100 iters), loss = 0.0680715
I0820 09:52:38.220414 12052 solver.cpp:258]     Train net output #0: landmark_loss = 0.0680714 (* 1 = 0.0680714 loss)
I0820 09:52:38.220420 12052 sgd_solver.cpp:112] Iteration 12400, lr = 0.001
I0820 09:52:42.131006 12052 solver.cpp:239] Iteration 12500 (25.5715 iter/s, 3.9106s/100 iters), loss = 0.070061
I0820 09:52:42.131049 12052 solver.cpp:258]     Train net output #0: landmark_loss = 0.070061 (* 1 = 0.070061 loss)
I0820 09:52:42.131055 12052 sgd_solver.cpp:112] Iteration 12500, lr = 0.001
I0820 09:52:46.038250 12052 solver.cpp:239] Iteration 12600 (25.5937 iter/s, 3.90721s/100 iters), loss = 0.0773237
I0820 09:52:46.038292 12052 solver.cpp:258]     Train net output #0: landmark_loss = 0.0773236 (* 1 = 0.0773236 loss)
I0820 09:52:46.038298 12052 sgd_solver.cpp:112] Iteration 12600, lr = 0.001
I0820 09:52:49.945595 12052 solver.cpp:239] Iteration 12700 (25.593 iter/s, 3.90731s/100 iters), loss = 0.0599423
I0820 09:52:49.945636 12052 solver.cpp:258]     Train net output #0: landmark_loss = 0.0599423 (* 1 = 0.0599423 loss)
I0820 09:52:49.945641 12052 sgd_solver.cpp:112] Iteration 12700, lr = 0.001
I0820 09:52:53.852536 12052 solver.cpp:239] Iteration 12800 (25.5957 iter/s, 3.90691s/100 iters), loss = 0.0663686
I0820 09:52:53.852591 12052 solver.cpp:258]     Train net output #0: landmark_loss = 0.0663686 (* 1 = 0.0663686 loss)
I0820 09:52:53.852609 12052 sgd_solver.cpp:112] Iteration 12800, lr = 0.001
I0820 09:52:57.760365 12052 solver.cpp:239] Iteration 12900 (25.5899 iter/s, 3.90779s/100 iters), loss = 0.0646504
I0820 09:52:57.760418 12052 solver.cpp:258]     Train net output #0: landmark_loss = 0.0646504 (* 1 = 0.0646504 loss)
I0820 09:52:57.760426 12052 sgd_solver.cpp:112] Iteration 12900, lr = 0.001
I0820 09:53:01.699280 12052 solver.cpp:239] Iteration 13000 (25.388 iter/s, 3.93888s/100 iters), loss = 0.0658268
I0820 09:53:01.699324 12052 solver.cpp:258]     Train net output #0: landmark_loss = 0.0658268 (* 1 = 0.0658268 loss)
I0820 09:53:01.699331 12052 sgd_solver.cpp:112] Iteration 13000, lr = 0.001
I0820 09:53:05.623250 12052 solver.cpp:239] Iteration 13100 (25.4846 iter/s, 3.92394s/100 iters), loss = 0.0633778
I0820 09:53:05.623303 12052 solver.cpp:258]     Train net output #0: landmark_loss = 0.0633778 (* 1 = 0.0633778 loss)
I0820 09:53:05.623309 12052 sgd_solver.cpp:112] Iteration 13100, lr = 0.001
I0820 09:53:09.530802 12052 solver.cpp:239] Iteration 13200 (25.5918 iter/s, 3.90751s/100 iters), loss = 0.0744358
I0820 09:53:09.530841 12052 solver.cpp:258]     Train net output #0: landmark_loss = 0.0744358 (* 1 = 0.0744358 loss)
I0820 09:53:09.530848 12052 sgd_solver.cpp:112] Iteration 13200, lr = 0.001
I0820 09:53:13.437150 12052 solver.cpp:239] Iteration 13300 (25.5995 iter/s, 3.90632s/100 iters), loss = 0.0709046
I0820 09:53:13.437192 12052 solver.cpp:258]     Train net output #0: landmark_loss = 0.0709045 (* 1 = 0.0709045 loss)
I0820 09:53:13.437198 12052 sgd_solver.cpp:112] Iteration 13300, lr = 0.001
I0820 09:53:17.344296 12052 solver.cpp:239] Iteration 13400 (25.5943 iter/s, 3.90711s/100 iters), loss = 0.0586901
I0820 09:53:17.344338 12052 solver.cpp:258]     Train net output #0: landmark_loss = 0.0586901 (* 1 = 0.0586901 loss)
I0820 09:53:17.344344 12052 sgd_solver.cpp:112] Iteration 13400, lr = 0.001
I0820 09:53:21.253389 12052 solver.cpp:239] Iteration 13500 (25.5816 iter/s, 3.90906s/100 iters), loss = 0.0694049
I0820 09:53:21.253430 12052 solver.cpp:258]     Train net output #0: landmark_loss = 0.0694049 (* 1 = 0.0694049 loss)
I0820 09:53:21.253435 12052 sgd_solver.cpp:112] Iteration 13500, lr = 0.001
I0820 09:53:25.163226 12052 solver.cpp:239] Iteration 13600 (25.5767 iter/s, 3.90981s/100 iters), loss = 0.0684135
I0820 09:53:25.163266 12052 solver.cpp:258]     Train net output #0: landmark_loss = 0.0684135 (* 1 = 0.0684135 loss)
I0820 09:53:25.163272 12052 sgd_solver.cpp:112] Iteration 13600, lr = 0.001
I0820 09:53:29.068919 12052 solver.cpp:239] Iteration 13700 (25.6038 iter/s, 3.90566s/100 iters), loss = 0.0585949
I0820 09:53:29.068960 12052 solver.cpp:258]     Train net output #0: landmark_loss = 0.0585948 (* 1 = 0.0585948 loss)
I0820 09:53:29.068966 12052 sgd_solver.cpp:112] Iteration 13700, lr = 0.001
I0820 09:53:32.975313 12052 solver.cpp:239] Iteration 13800 (25.5993 iter/s, 3.90636s/100 iters), loss = 0.0620872
I0820 09:53:32.975353 12052 solver.cpp:258]     Train net output #0: landmark_loss = 0.0620872 (* 1 = 0.0620872 loss)
I0820 09:53:32.975359 12052 sgd_solver.cpp:112] Iteration 13800, lr = 0.001
I0820 09:53:36.881151 12052 solver.cpp:239] Iteration 13900 (25.6029 iter/s, 3.90581s/100 iters), loss = 0.0710206
I0820 09:53:36.881192 12052 solver.cpp:258]     Train net output #0: landmark_loss = 0.0710206 (* 1 = 0.0710206 loss)
I0820 09:53:36.881198 12052 sgd_solver.cpp:112] Iteration 13900, lr = 0.001
I0820 09:53:40.787261 12052 solver.cpp:239] Iteration 14000 (25.6011 iter/s, 3.90608s/100 iters), loss = 0.0687744
I0820 09:53:40.787312 12052 solver.cpp:258]     Train net output #0: landmark_loss = 0.0687743 (* 1 = 0.0687743 loss)
I0820 09:53:40.787318 12052 sgd_solver.cpp:112] Iteration 14000, lr = 0.001
I0820 09:53:44.697695 12052 solver.cpp:239] Iteration 14100 (25.5729 iter/s, 3.91039s/100 iters), loss = 0.0628261
I0820 09:53:44.697736 12052 solver.cpp:258]     Train net output #0: landmark_loss = 0.0628261 (* 1 = 0.0628261 loss)
I0820 09:53:44.697742 12052 sgd_solver.cpp:112] Iteration 14100, lr = 0.001
I0820 09:53:48.603879 12052 solver.cpp:239] Iteration 14200 (25.6006 iter/s, 3.90615s/100 iters), loss = 0.0648089
I0820 09:53:48.603920 12052 solver.cpp:258]     Train net output #0: landmark_loss = 0.0648089 (* 1 = 0.0648089 loss)
I0820 09:53:48.603925 12052 sgd_solver.cpp:112] Iteration 14200, lr = 0.001
I0820 09:53:52.511792 12052 solver.cpp:239] Iteration 14300 (25.5893 iter/s, 3.90788s/100 iters), loss = 0.0536942
I0820 09:53:52.511834 12052 solver.cpp:258]     Train net output #0: landmark_loss = 0.0536942 (* 1 = 0.0536942 loss)
I0820 09:53:52.511840 12052 sgd_solver.cpp:112] Iteration 14300, lr = 0.001
I0820 09:53:56.419430 12052 solver.cpp:239] Iteration 14400 (25.5911 iter/s, 3.90761s/100 iters), loss = 0.0719807
I0820 09:53:56.419472 12052 solver.cpp:258]     Train net output #0: landmark_loss = 0.0719807 (* 1 = 0.0719807 loss)
I0820 09:53:56.419477 12052 sgd_solver.cpp:112] Iteration 14400, lr = 0.001
I0820 09:54:00.342432 12052 solver.cpp:239] Iteration 14500 (25.4909 iter/s, 3.92297s/100 iters), loss = 0.0646025
I0820 09:54:00.342474 12052 solver.cpp:258]     Train net output #0: landmark_loss = 0.0646024 (* 1 = 0.0646024 loss)
I0820 09:54:00.342480 12052 sgd_solver.cpp:112] Iteration 14500, lr = 0.001
I0820 09:54:04.278468 12052 solver.cpp:239] Iteration 14600 (25.4065 iter/s, 3.936s/100 iters), loss = 0.0696012
I0820 09:54:04.278509 12052 solver.cpp:258]     Train net output #0: landmark_loss = 0.0696012 (* 1 = 0.0696012 loss)
I0820 09:54:04.278515 12052 sgd_solver.cpp:112] Iteration 14600, lr = 0.001
I0820 09:54:08.184320 12052 solver.cpp:239] Iteration 14700 (25.6028 iter/s, 3.90582s/100 iters), loss = 0.0810122
I0820 09:54:08.184361 12052 solver.cpp:258]     Train net output #0: landmark_loss = 0.0810121 (* 1 = 0.0810121 loss)
I0820 09:54:08.184367 12052 sgd_solver.cpp:112] Iteration 14700, lr = 0.001
I0820 09:54:12.093518 12052 solver.cpp:239] Iteration 14800 (25.5809 iter/s, 3.90917s/100 iters), loss = 0.0618052
I0820 09:54:12.093559 12052 solver.cpp:258]     Train net output #0: landmark_loss = 0.0618052 (* 1 = 0.0618052 loss)
I0820 09:54:12.093564 12052 sgd_solver.cpp:112] Iteration 14800, lr = 0.001
I0820 09:54:16.001943 12052 solver.cpp:239] Iteration 14900 (25.5859 iter/s, 3.9084s/100 iters), loss = 0.0558247
I0820 09:54:16.001983 12052 solver.cpp:258]     Train net output #0: landmark_loss = 0.0558247 (* 1 = 0.0558247 loss)
I0820 09:54:16.001989 12052 sgd_solver.cpp:112] Iteration 14900, lr = 0.001
I0820 09:54:19.908102 12052 solver.cpp:239] Iteration 15000 (25.6008 iter/s, 3.90613s/100 iters), loss = 0.0655394
I0820 09:54:19.908145 12052 solver.cpp:258]     Train net output #0: landmark_loss = 0.0655394 (* 1 = 0.0655394 loss)
I0820 09:54:19.908151 12052 sgd_solver.cpp:112] Iteration 15000, lr = 0.001
I0820 09:54:23.814116 12052 solver.cpp:239] Iteration 15100 (25.6018 iter/s, 3.90598s/100 iters), loss = 0.0649801
I0820 09:54:23.814158 12052 solver.cpp:258]     Train net output #0: landmark_loss = 0.0649801 (* 1 = 0.0649801 loss)
I0820 09:54:23.814163 12052 sgd_solver.cpp:112] Iteration 15100, lr = 0.001
I0820 09:54:27.719899 12052 solver.cpp:239] Iteration 15200 (25.6032 iter/s, 3.90576s/100 iters), loss = 0.0586422
I0820 09:54:27.719941 12052 solver.cpp:258]     Train net output #0: landmark_loss = 0.0586422 (* 1 = 0.0586422 loss)
I0820 09:54:27.719947 12052 sgd_solver.cpp:112] Iteration 15200, lr = 0.001
I0820 09:54:31.626482 12052 solver.cpp:239] Iteration 15300 (25.598 iter/s, 3.90655s/100 iters), loss = 0.0734808
I0820 09:54:31.626523 12052 solver.cpp:258]     Train net output #0: landmark_loss = 0.0734808 (* 1 = 0.0734808 loss)
I0820 09:54:31.626529 12052 sgd_solver.cpp:112] Iteration 15300, lr = 0.001
I0820 09:54:35.533814 12052 solver.cpp:239] Iteration 15400 (25.5931 iter/s, 3.9073s/100 iters), loss = 0.0637842
I0820 09:54:35.533856 12052 solver.cpp:258]     Train net output #0: landmark_loss = 0.0637842 (* 1 = 0.0637842 loss)
I0820 09:54:35.533861 12052 sgd_solver.cpp:112] Iteration 15400, lr = 0.001
I0820 09:54:39.439684 12052 solver.cpp:239] Iteration 15500 (25.6027 iter/s, 3.90584s/100 iters), loss = 0.0724587
I0820 09:54:39.439726 12052 solver.cpp:258]     Train net output #0: landmark_loss = 0.0724587 (* 1 = 0.0724587 loss)
I0820 09:54:39.439731 12052 sgd_solver.cpp:112] Iteration 15500, lr = 0.001
I0820 09:54:43.345465 12052 solver.cpp:239] Iteration 15600 (25.6033 iter/s, 3.90575s/100 iters), loss = 0.0588021
I0820 09:54:43.345506 12052 solver.cpp:258]     Train net output #0: landmark_loss = 0.058802 (* 1 = 0.058802 loss)
I0820 09:54:43.345512 12052 sgd_solver.cpp:112] Iteration 15600, lr = 0.001
I0820 09:54:47.251915 12052 solver.cpp:239] Iteration 15700 (25.5989 iter/s, 3.90642s/100 iters), loss = 0.0568809
I0820 09:54:47.251967 12052 solver.cpp:258]     Train net output #0: landmark_loss = 0.0568809 (* 1 = 0.0568809 loss)
I0820 09:54:47.251973 12052 sgd_solver.cpp:112] Iteration 15700, lr = 0.001
I0820 09:54:51.162854 12052 solver.cpp:239] Iteration 15800 (25.5696 iter/s, 3.9109s/100 iters), loss = 0.0562653
I0820 09:54:51.162907 12052 solver.cpp:258]     Train net output #0: landmark_loss = 0.0562653 (* 1 = 0.0562653 loss)
I0820 09:54:51.162914 12052 sgd_solver.cpp:112] Iteration 15800, lr = 0.001
I0820 09:54:55.071414 12052 solver.cpp:239] Iteration 15900 (25.5851 iter/s, 3.90852s/100 iters), loss = 0.0577826
I0820 09:54:55.071467 12052 solver.cpp:258]     Train net output #0: landmark_loss = 0.0577825 (* 1 = 0.0577825 loss)
I0820 09:54:55.071473 12052 sgd_solver.cpp:112] Iteration 15900, lr = 0.001
I0820 09:54:58.977586 12052 solver.cpp:239] Iteration 16000 (25.6008 iter/s, 3.90613s/100 iters), loss = 0.0579299
I0820 09:54:58.977627 12052 solver.cpp:258]     Train net output #0: landmark_loss = 0.0579299 (* 1 = 0.0579299 loss)
I0820 09:54:58.977633 12052 sgd_solver.cpp:112] Iteration 16000, lr = 0.001
I0820 09:55:02.926602 12052 solver.cpp:239] Iteration 16100 (25.323 iter/s, 3.94899s/100 iters), loss = 0.0658271
I0820 09:55:02.926646 12052 solver.cpp:258]     Train net output #0: landmark_loss = 0.0658271 (* 1 = 0.0658271 loss)
I0820 09:55:02.926652 12052 sgd_solver.cpp:112] Iteration 16100, lr = 0.001
I0820 09:55:06.840978 12052 solver.cpp:239] Iteration 16200 (25.5471 iter/s, 3.91434s/100 iters), loss = 0.0552204
I0820 09:55:06.841030 12052 solver.cpp:258]     Train net output #0: landmark_loss = 0.0552204 (* 1 = 0.0552204 loss)
I0820 09:55:06.841037 12052 sgd_solver.cpp:112] Iteration 16200, lr = 0.001
I0820 09:55:10.747756 12052 solver.cpp:239] Iteration 16300 (25.5968 iter/s, 3.90674s/100 iters), loss = 0.0634394
I0820 09:55:10.747797 12052 solver.cpp:258]     Train net output #0: landmark_loss = 0.0634394 (* 1 = 0.0634394 loss)
I0820 09:55:10.747803 12052 sgd_solver.cpp:112] Iteration 16300, lr = 0.001
I0820 09:55:14.653797 12052 solver.cpp:239] Iteration 16400 (25.6015 iter/s, 3.90601s/100 iters), loss = 0.0681323
I0820 09:55:14.653851 12052 solver.cpp:258]     Train net output #0: landmark_loss = 0.0681322 (* 1 = 0.0681322 loss)
I0820 09:55:14.653857 12052 sgd_solver.cpp:112] Iteration 16400, lr = 0.001
I0820 09:55:18.559895 12052 solver.cpp:239] Iteration 16500 (25.6013 iter/s, 3.90605s/100 iters), loss = 0.0601582
I0820 09:55:18.559936 12052 solver.cpp:258]     Train net output #0: landmark_loss = 0.0601582 (* 1 = 0.0601582 loss)
I0820 09:55:18.559942 12052 sgd_solver.cpp:112] Iteration 16500, lr = 0.001
I0820 09:55:22.466660 12052 solver.cpp:239] Iteration 16600 (25.5968 iter/s, 3.90674s/100 iters), loss = 0.0636325
I0820 09:55:22.466701 12052 solver.cpp:258]     Train net output #0: landmark_loss = 0.0636324 (* 1 = 0.0636324 loss)
I0820 09:55:22.466706 12052 sgd_solver.cpp:112] Iteration 16600, lr = 0.001
I0820 09:55:26.372170 12052 solver.cpp:239] Iteration 16700 (25.605 iter/s, 3.90548s/100 iters), loss = 0.0729784
I0820 09:55:26.372210 12052 solver.cpp:258]     Train net output #0: landmark_loss = 0.0729784 (* 1 = 0.0729784 loss)
I0820 09:55:26.372216 12052 sgd_solver.cpp:112] Iteration 16700, lr = 0.001
I0820 09:55:30.278520 12052 solver.cpp:239] Iteration 16800 (25.5995 iter/s, 3.90632s/100 iters), loss = 0.0722948
I0820 09:55:30.278561 12052 solver.cpp:258]     Train net output #0: landmark_loss = 0.0722948 (* 1 = 0.0722948 loss)
I0820 09:55:30.278568 12052 sgd_solver.cpp:112] Iteration 16800, lr = 0.001
I0820 09:55:34.184456 12052 solver.cpp:239] Iteration 16900 (25.6023 iter/s, 3.90591s/100 iters), loss = 0.070957
I0820 09:55:34.184496 12052 solver.cpp:258]     Train net output #0: landmark_loss = 0.070957 (* 1 = 0.070957 loss)
I0820 09:55:34.184502 12052 sgd_solver.cpp:112] Iteration 16900, lr = 0.001
I0820 09:55:38.091434 12052 solver.cpp:239] Iteration 17000 (25.5954 iter/s, 3.90695s/100 iters), loss = 0.0551757
I0820 09:55:38.091475 12052 solver.cpp:258]     Train net output #0: landmark_loss = 0.0551757 (* 1 = 0.0551757 loss)
I0820 09:55:38.091480 12052 sgd_solver.cpp:112] Iteration 17000, lr = 0.001
I0820 09:55:41.996860 12052 solver.cpp:239] Iteration 17100 (25.6056 iter/s, 3.90539s/100 iters), loss = 0.0735675
I0820 09:55:41.996901 12052 solver.cpp:258]     Train net output #0: landmark_loss = 0.0735675 (* 1 = 0.0735675 loss)
I0820 09:55:41.996906 12052 sgd_solver.cpp:112] Iteration 17100, lr = 0.001
I0820 09:55:45.903946 12052 solver.cpp:239] Iteration 17200 (25.5947 iter/s, 3.90706s/100 iters), loss = 0.0638025
I0820 09:55:45.903990 12052 solver.cpp:258]     Train net output #0: landmark_loss = 0.0638024 (* 1 = 0.0638024 loss)
I0820 09:55:45.903995 12052 sgd_solver.cpp:112] Iteration 17200, lr = 0.001
I0820 09:55:49.809484 12052 solver.cpp:239] Iteration 17300 (25.6049 iter/s, 3.90551s/100 iters), loss = 0.0617678
I0820 09:55:49.809526 12052 solver.cpp:258]     Train net output #0: landmark_loss = 0.0617678 (* 1 = 0.0617678 loss)
I0820 09:55:49.809531 12052 sgd_solver.cpp:112] Iteration 17300, lr = 0.001
I0820 09:55:53.715157 12052 solver.cpp:239] Iteration 17400 (25.604 iter/s, 3.90564s/100 iters), loss = 0.0526739
I0820 09:55:53.715198 12052 solver.cpp:258]     Train net output #0: landmark_loss = 0.0526739 (* 1 = 0.0526739 loss)
I0820 09:55:53.715204 12052 sgd_solver.cpp:112] Iteration 17400, lr = 0.001
I0820 09:55:57.620926 12052 solver.cpp:239] Iteration 17500 (25.6034 iter/s, 3.90574s/100 iters), loss = 0.0543062
I0820 09:55:57.620980 12052 solver.cpp:258]     Train net output #0: landmark_loss = 0.0543061 (* 1 = 0.0543061 loss)
I0820 09:55:57.620986 12052 sgd_solver.cpp:112] Iteration 17500, lr = 0.001
I0820 09:56:01.560215 12052 solver.cpp:239] Iteration 17600 (25.3855 iter/s, 3.93925s/100 iters), loss = 0.0519351
I0820 09:56:01.560256 12052 solver.cpp:258]     Train net output #0: landmark_loss = 0.051935 (* 1 = 0.051935 loss)
I0820 09:56:01.560262 12052 sgd_solver.cpp:112] Iteration 17600, lr = 0.001
I0820 09:56:05.487911 12052 solver.cpp:239] Iteration 17700 (25.4604 iter/s, 3.92767s/100 iters), loss = 0.0770386
I0820 09:56:05.487963 12052 solver.cpp:258]     Train net output #0: landmark_loss = 0.0770386 (* 1 = 0.0770386 loss)
I0820 09:56:05.487970 12052 sgd_solver.cpp:112] Iteration 17700, lr = 0.001
I0820 09:56:09.396524 12052 solver.cpp:239] Iteration 17800 (25.5848 iter/s, 3.90857s/100 iters), loss = 0.0622753
I0820 09:56:09.396565 12052 solver.cpp:258]     Train net output #0: landmark_loss = 0.0622752 (* 1 = 0.0622752 loss)
I0820 09:56:09.396571 12052 sgd_solver.cpp:112] Iteration 17800, lr = 0.001
I0820 09:56:13.305133 12052 solver.cpp:239] Iteration 17900 (25.5847 iter/s, 3.90858s/100 iters), loss = 0.0559803
I0820 09:56:13.305186 12052 solver.cpp:258]     Train net output #0: landmark_loss = 0.0559803 (* 1 = 0.0559803 loss)
I0820 09:56:13.305193 12052 sgd_solver.cpp:112] Iteration 17900, lr = 0.001
I0820 09:56:17.157790 12052 solver.cpp:347] Iteration 18000, Testing net (#0)
I0820 09:56:31.936604 12052 solver.cpp:414]     Test net output #0: landmark_loss = 0.0432775 (* 1 = 0.0432775 loss)
I0820 09:56:31.975354 12052 solver.cpp:239] Iteration 18000 (5.35611 iter/s, 18.6703s/100 iters), loss = 0.0615526
I0820 09:56:31.975383 12052 solver.cpp:258]     Train net output #0: landmark_loss = 0.0615526 (* 1 = 0.0615526 loss)
I0820 09:56:31.975389 12052 sgd_solver.cpp:112] Iteration 18000, lr = 0.001
I0820 09:56:35.880877 12052 solver.cpp:239] Iteration 18100 (25.6049 iter/s, 3.90551s/100 iters), loss = 0.060095
I0820 09:56:35.880919 12052 solver.cpp:258]     Train net output #0: landmark_loss = 0.0600949 (* 1 = 0.0600949 loss)
I0820 09:56:35.880925 12052 sgd_solver.cpp:112] Iteration 18100, lr = 0.001
I0820 09:56:39.787533 12052 solver.cpp:239] Iteration 18200 (25.5975 iter/s, 3.90663s/100 iters), loss = 0.0551917
I0820 09:56:39.787573 12052 solver.cpp:258]     Train net output #0: landmark_loss = 0.0551917 (* 1 = 0.0551917 loss)
I0820 09:56:39.787580 12052 sgd_solver.cpp:112] Iteration 18200, lr = 0.001
I0820 09:56:43.693207 12052 solver.cpp:239] Iteration 18300 (25.604 iter/s, 3.90565s/100 iters), loss = 0.0530882
I0820 09:56:43.693248 12052 solver.cpp:258]     Train net output #0: landmark_loss = 0.0530882 (* 1 = 0.0530882 loss)
I0820 09:56:43.693254 12052 sgd_solver.cpp:112] Iteration 18300, lr = 0.001
I0820 09:56:47.598407 12052 solver.cpp:239] Iteration 18400 (25.6071 iter/s, 3.90517s/100 iters), loss = 0.0661744
I0820 09:56:47.598446 12052 solver.cpp:258]     Train net output #0: landmark_loss = 0.0661744 (* 1 = 0.0661744 loss)
I0820 09:56:47.598453 12052 sgd_solver.cpp:112] Iteration 18400, lr = 0.001
I0820 09:56:51.507513 12052 solver.cpp:239] Iteration 18500 (25.5815 iter/s, 3.90908s/100 iters), loss = 0.0542364
I0820 09:56:51.507565 12052 solver.cpp:258]     Train net output #0: landmark_loss = 0.0542363 (* 1 = 0.0542363 loss)
I0820 09:56:51.507571 12052 sgd_solver.cpp:112] Iteration 18500, lr = 0.001
I0820 09:56:55.413676 12052 solver.cpp:239] Iteration 18600 (25.6008 iter/s, 3.90612s/100 iters), loss = 0.0561855
I0820 09:56:55.413718 12052 solver.cpp:258]     Train net output #0: landmark_loss = 0.0561855 (* 1 = 0.0561855 loss)
I0820 09:56:55.413724 12052 sgd_solver.cpp:112] Iteration 18600, lr = 0.001
I0820 09:56:59.319435 12052 solver.cpp:239] Iteration 18700 (25.6034 iter/s, 3.90573s/100 iters), loss = 0.0570722
I0820 09:56:59.319475 12052 solver.cpp:258]     Train net output #0: landmark_loss = 0.0570721 (* 1 = 0.0570721 loss)
I0820 09:56:59.319481 12052 sgd_solver.cpp:112] Iteration 18700, lr = 0.001
I0820 09:57:03.272323 12052 solver.cpp:239] Iteration 18800 (25.2982 iter/s, 3.95286s/100 iters), loss = 0.070702
I0820 09:57:03.272368 12052 solver.cpp:258]     Train net output #0: landmark_loss = 0.0707019 (* 1 = 0.0707019 loss)
I0820 09:57:03.272375 12052 sgd_solver.cpp:112] Iteration 18800, lr = 0.001
I0820 09:57:07.181978 12052 solver.cpp:239] Iteration 18900 (25.5779 iter/s, 3.90962s/100 iters), loss = 0.05844
I0820 09:57:07.182030 12052 solver.cpp:258]     Train net output #0: landmark_loss = 0.0584399 (* 1 = 0.0584399 loss)
I0820 09:57:07.182036 12052 sgd_solver.cpp:112] Iteration 18900, lr = 0.001
I0820 09:57:11.088300 12052 solver.cpp:239] Iteration 19000 (25.5998 iter/s, 3.90628s/100 iters), loss = 0.052431
I0820 09:57:11.088341 12052 solver.cpp:258]     Train net output #0: landmark_loss = 0.052431 (* 1 = 0.052431 loss)
I0820 09:57:11.088347 12052 sgd_solver.cpp:112] Iteration 19000, lr = 0.001
I0820 09:57:14.999635 12052 solver.cpp:239] Iteration 19100 (25.5669 iter/s, 3.9113s/100 iters), loss = 0.0735099
I0820 09:57:14.999678 12052 solver.cpp:258]     Train net output #0: landmark_loss = 0.0735099 (* 1 = 0.0735099 loss)
I0820 09:57:14.999686 12052 sgd_solver.cpp:112] Iteration 19100, lr = 0.001
I0820 09:57:18.949573 12052 solver.cpp:239] Iteration 19200 (25.3176 iter/s, 3.94982s/100 iters), loss = 0.0604028
I0820 09:57:18.949616 12052 solver.cpp:258]     Train net output #0: landmark_loss = 0.0604028 (* 1 = 0.0604028 loss)
I0820 09:57:18.949623 12052 sgd_solver.cpp:112] Iteration 19200, lr = 0.001
I0820 09:57:22.885251 12052 solver.cpp:239] Iteration 19300 (25.4093 iter/s, 3.93557s/100 iters), loss = 0.0612945
I0820 09:57:22.885293 12052 solver.cpp:258]     Train net output #0: landmark_loss = 0.0612944 (* 1 = 0.0612944 loss)
I0820 09:57:22.885299 12052 sgd_solver.cpp:112] Iteration 19300, lr = 0.001
I0820 09:57:26.862112 12052 solver.cpp:239] Iteration 19400 (25.1462 iter/s, 3.97675s/100 iters), loss = 0.0511796
I0820 09:57:26.862162 12052 solver.cpp:258]     Train net output #0: landmark_loss = 0.0511795 (* 1 = 0.0511795 loss)
I0820 09:57:26.862169 12052 sgd_solver.cpp:112] Iteration 19400, lr = 0.001
I0820 09:57:30.835182 12052 solver.cpp:239] Iteration 19500 (25.1702 iter/s, 3.97295s/100 iters), loss = 0.0722468
I0820 09:57:30.835233 12052 solver.cpp:258]     Train net output #0: landmark_loss = 0.0722468 (* 1 = 0.0722468 loss)
I0820 09:57:30.835240 12052 sgd_solver.cpp:112] Iteration 19500, lr = 0.001
I0820 09:57:34.811841 12052 solver.cpp:239] Iteration 19600 (25.1475 iter/s, 3.97654s/100 iters), loss = 0.0635947
I0820 09:57:34.811887 12052 solver.cpp:258]     Train net output #0: landmark_loss = 0.0635946 (* 1 = 0.0635946 loss)
I0820 09:57:34.811894 12052 sgd_solver.cpp:112] Iteration 19600, lr = 0.001
I0820 09:57:38.786161 12052 solver.cpp:239] Iteration 19700 (25.1623 iter/s, 3.9742s/100 iters), loss = 0.056981
I0820 09:57:38.786209 12052 solver.cpp:258]     Train net output #0: landmark_loss = 0.0569809 (* 1 = 0.0569809 loss)
I0820 09:57:38.786216 12052 sgd_solver.cpp:112] Iteration 19700, lr = 0.001
I0820 09:57:42.760475 12052 solver.cpp:239] Iteration 19800 (25.1623 iter/s, 3.9742s/100 iters), loss = 0.059141
I0820 09:57:42.760519 12052 solver.cpp:258]     Train net output #0: landmark_loss = 0.059141 (* 1 = 0.059141 loss)
I0820 09:57:42.760525 12052 sgd_solver.cpp:112] Iteration 19800, lr = 0.001
I0820 09:57:46.733857 12052 solver.cpp:239] Iteration 19900 (25.1682 iter/s, 3.97327s/100 iters), loss = 0.0590734
I0820 09:57:46.733902 12052 solver.cpp:258]     Train net output #0: landmark_loss = 0.0590733 (* 1 = 0.0590733 loss)
I0820 09:57:46.733911 12052 sgd_solver.cpp:112] Iteration 19900, lr = 0.001
I0820 09:57:50.650966 12052 solver.cpp:464] Snapshotting to binary proto file ./model/M3_iter_20000.caffemodel
I0820 09:57:50.759934 12052 sgd_solver.cpp:284] Snapshotting solver state to binary proto file ./model/M3_iter_20000.solverstate
I0820 09:57:50.856652 12052 solver.cpp:239] Iteration 20000 (24.2561 iter/s, 4.12268s/100 iters), loss = 0.065556
I0820 09:57:50.856693 12052 solver.cpp:258]     Train net output #0: landmark_loss = 0.0655559 (* 1 = 0.0655559 loss)
I0820 09:57:50.856700 12052 sgd_solver.cpp:112] Iteration 20000, lr = 0.001
I0820 09:57:54.830811 12052 solver.cpp:239] Iteration 20100 (25.1632 iter/s, 3.97405s/100 iters), loss = 0.0580496
I0820 09:57:54.830852 12052 solver.cpp:258]     Train net output #0: landmark_loss = 0.0580496 (* 1 = 0.0580496 loss)
I0820 09:57:54.830858 12052 sgd_solver.cpp:112] Iteration 20100, lr = 0.001
I0820 09:57:58.804503 12052 solver.cpp:239] Iteration 20200 (25.1662 iter/s, 3.97359s/100 iters), loss = 0.0575757
I0820 09:57:58.804550 12052 solver.cpp:258]     Train net output #0: landmark_loss = 0.0575757 (* 1 = 0.0575757 loss)
I0820 09:57:58.804558 12052 sgd_solver.cpp:112] Iteration 20200, lr = 0.001
I0820 09:58:02.791432 12052 solver.cpp:239] Iteration 20300 (25.0826 iter/s, 3.98682s/100 iters), loss = 0.0631865
I0820 09:58:02.791477 12052 solver.cpp:258]     Train net output #0: landmark_loss = 0.0631865 (* 1 = 0.0631865 loss)
I0820 09:58:02.791483 12052 sgd_solver.cpp:112] Iteration 20300, lr = 0.001
I0820 09:58:06.764163 12052 solver.cpp:239] Iteration 20400 (25.1723 iter/s, 3.97262s/100 iters), loss = 0.053749
I0820 09:58:06.764204 12052 solver.cpp:258]     Train net output #0: landmark_loss = 0.053749 (* 1 = 0.053749 loss)
I0820 09:58:06.764211 12052 sgd_solver.cpp:112] Iteration 20400, lr = 0.001
I0820 09:58:10.747556 12052 solver.cpp:239] Iteration 20500 (25.1049 iter/s, 3.98329s/100 iters), loss = 0.0518864
I0820 09:58:10.747602 12052 solver.cpp:258]     Train net output #0: landmark_loss = 0.0518864 (* 1 = 0.0518864 loss)
I0820 09:58:10.747609 12052 sgd_solver.cpp:112] Iteration 20500, lr = 0.001
I0820 09:58:14.719835 12052 solver.cpp:239] Iteration 20600 (25.1752 iter/s, 3.97217s/100 iters), loss = 0.0611041
I0820 09:58:14.719882 12052 solver.cpp:258]     Train net output #0: landmark_loss = 0.061104 (* 1 = 0.061104 loss)
I0820 09:58:14.719888 12052 sgd_solver.cpp:112] Iteration 20600, lr = 0.001
I0820 09:58:18.694703 12052 solver.cpp:239] Iteration 20700 (25.1588 iter/s, 3.97476s/100 iters), loss = 0.0618916
I0820 09:58:18.694752 12052 solver.cpp:258]     Train net output #0: landmark_loss = 0.0618916 (* 1 = 0.0618916 loss)
I0820 09:58:18.694759 12052 sgd_solver.cpp:112] Iteration 20700, lr = 0.001
I0820 09:58:22.671213 12052 solver.cpp:239] Iteration 20800 (25.1484 iter/s, 3.9764s/100 iters), loss = 0.0532712
I0820 09:58:22.671259 12052 solver.cpp:258]     Train net output #0: landmark_loss = 0.0532712 (* 1 = 0.0532712 loss)
I0820 09:58:22.671267 12052 sgd_solver.cpp:112] Iteration 20800, lr = 0.001
I0820 09:58:26.645870 12052 solver.cpp:239] Iteration 20900 (25.1601 iter/s, 3.97455s/100 iters), loss = 0.070986
I0820 09:58:26.645920 12052 solver.cpp:258]     Train net output #0: landmark_loss = 0.070986 (* 1 = 0.070986 loss)
I0820 09:58:26.645925 12052 sgd_solver.cpp:112] Iteration 20900, lr = 0.001
I0820 09:58:30.621954 12052 solver.cpp:239] Iteration 21000 (25.1511 iter/s, 3.97598s/100 iters), loss = 0.0571432
I0820 09:58:30.621999 12052 solver.cpp:258]     Train net output #0: landmark_loss = 0.0571432 (* 1 = 0.0571432 loss)
I0820 09:58:30.622005 12052 sgd_solver.cpp:112] Iteration 21000, lr = 0.001
I0820 09:58:34.596909 12052 solver.cpp:239] Iteration 21100 (25.1582 iter/s, 3.97485s/100 iters), loss = 0.0524691
I0820 09:58:34.596951 12052 solver.cpp:258]     Train net output #0: landmark_loss = 0.052469 (* 1 = 0.052469 loss)
I0820 09:58:34.596958 12052 sgd_solver.cpp:112] Iteration 21100, lr = 0.001
I0820 09:58:38.571961 12052 solver.cpp:239] Iteration 21200 (25.1576 iter/s, 3.97495s/100 iters), loss = 0.0536503
I0820 09:58:38.572008 12052 solver.cpp:258]     Train net output #0: landmark_loss = 0.0536502 (* 1 = 0.0536502 loss)
I0820 09:58:38.572016 12052 sgd_solver.cpp:112] Iteration 21200, lr = 0.001
I0820 09:58:42.546113 12052 solver.cpp:239] Iteration 21300 (25.1633 iter/s, 3.97405s/100 iters), loss = 0.0608788
I0820 09:58:42.546156 12052 solver.cpp:258]     Train net output #0: landmark_loss = 0.0608788 (* 1 = 0.0608788 loss)
I0820 09:58:42.546164 12052 sgd_solver.cpp:112] Iteration 21300, lr = 0.001
I0820 09:58:46.521374 12052 solver.cpp:239] Iteration 21400 (25.1562 iter/s, 3.97516s/100 iters), loss = 0.0593434
I0820 09:58:46.521420 12052 solver.cpp:258]     Train net output #0: landmark_loss = 0.0593433 (* 1 = 0.0593433 loss)
I0820 09:58:46.521426 12052 sgd_solver.cpp:112] Iteration 21400, lr = 0.001
I0820 09:58:50.495342 12052 solver.cpp:239] Iteration 21500 (25.1644 iter/s, 3.97387s/100 iters), loss = 0.0558237
I0820 09:58:50.495385 12052 solver.cpp:258]     Train net output #0: landmark_loss = 0.0558237 (* 1 = 0.0558237 loss)
I0820 09:58:50.495393 12052 sgd_solver.cpp:112] Iteration 21500, lr = 0.001
I0820 09:58:54.468752 12052 solver.cpp:239] Iteration 21600 (25.1679 iter/s, 3.97331s/100 iters), loss = 0.0611148
I0820 09:58:54.468798 12052 solver.cpp:258]     Train net output #0: landmark_loss = 0.0611148 (* 1 = 0.0611148 loss)
I0820 09:58:54.468806 12052 sgd_solver.cpp:112] Iteration 21600, lr = 0.001
I0820 09:58:58.442912 12052 solver.cpp:239] Iteration 21700 (25.1632 iter/s, 3.97406s/100 iters), loss = 0.0598678
I0820 09:58:58.442955 12052 solver.cpp:258]     Train net output #0: landmark_loss = 0.0598678 (* 1 = 0.0598678 loss)
I0820 09:58:58.442961 12052 sgd_solver.cpp:112] Iteration 21700, lr = 0.001
I0820 09:59:02.430156 12052 solver.cpp:239] Iteration 21800 (25.0806 iter/s, 3.98715s/100 iters), loss = 0.0784636
I0820 09:59:02.430197 12052 solver.cpp:258]     Train net output #0: landmark_loss = 0.0784636 (* 1 = 0.0784636 loss)
I0820 09:59:02.430204 12052 sgd_solver.cpp:112] Iteration 21800, lr = 0.001
I0820 09:59:06.404505 12052 solver.cpp:239] Iteration 21900 (25.162 iter/s, 3.97425s/100 iters), loss = 0.067008
I0820 09:59:06.404551 12052 solver.cpp:258]     Train net output #0: landmark_loss = 0.067008 (* 1 = 0.067008 loss)
I0820 09:59:06.404558 12052 sgd_solver.cpp:112] Iteration 21900, lr = 0.001
I0820 09:59:10.379544 12052 solver.cpp:239] Iteration 22000 (25.1576 iter/s, 3.97494s/100 iters), loss = 0.0543339
I0820 09:59:10.379588 12052 solver.cpp:258]     Train net output #0: landmark_loss = 0.0543339 (* 1 = 0.0543339 loss)
I0820 09:59:10.379595 12052 sgd_solver.cpp:112] Iteration 22000, lr = 0.001
I0820 09:59:14.351737 12052 solver.cpp:239] Iteration 22100 (25.1756 iter/s, 3.97209s/100 iters), loss = 0.0673566
I0820 09:59:14.351784 12052 solver.cpp:258]     Train net output #0: landmark_loss = 0.0673566 (* 1 = 0.0673566 loss)
I0820 09:59:14.351791 12052 sgd_solver.cpp:112] Iteration 22100, lr = 0.001
I0820 09:59:18.325282 12052 solver.cpp:239] Iteration 22200 (25.1671 iter/s, 3.97344s/100 iters), loss = 0.0533276
I0820 09:59:18.325328 12052 solver.cpp:258]     Train net output #0: landmark_loss = 0.0533276 (* 1 = 0.0533276 loss)
I0820 09:59:18.325335 12052 sgd_solver.cpp:112] Iteration 22200, lr = 0.001
I0820 09:59:22.298910 12052 solver.cpp:239] Iteration 22300 (25.1665 iter/s, 3.97353s/100 iters), loss = 0.058553
I0820 09:59:22.298956 12052 solver.cpp:258]     Train net output #0: landmark_loss = 0.058553 (* 1 = 0.058553 loss)
I0820 09:59:22.298962 12052 sgd_solver.cpp:112] Iteration 22300, lr = 0.001
I0820 09:59:26.272810 12052 solver.cpp:239] Iteration 22400 (25.1648 iter/s, 3.9738s/100 iters), loss = 0.0548625
I0820 09:59:26.272859 12052 solver.cpp:258]     Train net output #0: landmark_loss = 0.0548624 (* 1 = 0.0548624 loss)
I0820 09:59:26.272866 12052 sgd_solver.cpp:112] Iteration 22400, lr = 0.001
I0820 09:59:30.242110 12052 solver.cpp:239] Iteration 22500 (25.194 iter/s, 3.9692s/100 iters), loss = 0.0518478
I0820 09:59:30.242153 12052 solver.cpp:258]     Train net output #0: landmark_loss = 0.0518478 (* 1 = 0.0518478 loss)
I0820 09:59:30.242161 12052 sgd_solver.cpp:112] Iteration 22500, lr = 0.001
I0820 09:59:34.211239 12052 solver.cpp:239] Iteration 22600 (25.195 iter/s, 3.96903s/100 iters), loss = 0.0589044
I0820 09:59:34.211283 12052 solver.cpp:258]     Train net output #0: landmark_loss = 0.0589044 (* 1 = 0.0589044 loss)
I0820 09:59:34.211290 12052 sgd_solver.cpp:112] Iteration 22600, lr = 0.001
I0820 09:59:38.183768 12052 solver.cpp:239] Iteration 22700 (25.1735 iter/s, 3.97243s/100 iters), loss = 0.0664233
I0820 09:59:38.183812 12052 solver.cpp:258]     Train net output #0: landmark_loss = 0.0664232 (* 1 = 0.0664232 loss)
I0820 09:59:38.183820 12052 sgd_solver.cpp:112] Iteration 22700, lr = 0.001
I0820 09:59:42.160429 12052 solver.cpp:239] Iteration 22800 (25.1473 iter/s, 3.97656s/100 iters), loss = 0.0777813
I0820 09:59:42.160476 12052 solver.cpp:258]     Train net output #0: landmark_loss = 0.0777813 (* 1 = 0.0777813 loss)
I0820 09:59:42.160483 12052 sgd_solver.cpp:112] Iteration 22800, lr = 0.001
I0820 09:59:46.129093 12052 solver.cpp:239] Iteration 22900 (25.198 iter/s, 3.96857s/100 iters), loss = 0.0625083
I0820 09:59:46.129142 12052 solver.cpp:258]     Train net output #0: landmark_loss = 0.0625083 (* 1 = 0.0625083 loss)
I0820 09:59:46.129149 12052 sgd_solver.cpp:112] Iteration 22900, lr = 0.001
I0820 09:59:50.099059 12052 solver.cpp:239] Iteration 23000 (25.1898 iter/s, 3.96987s/100 iters), loss = 0.0510044
I0820 09:59:50.099103 12052 solver.cpp:258]     Train net output #0: landmark_loss = 0.0510044 (* 1 = 0.0510044 loss)
I0820 09:59:50.099110 12052 sgd_solver.cpp:112] Iteration 23000, lr = 0.001
I0820 09:59:54.068209 12052 solver.cpp:239] Iteration 23100 (25.1949 iter/s, 3.96906s/100 iters), loss = 0.0601255
I0820 09:59:54.068254 12052 solver.cpp:258]     Train net output #0: landmark_loss = 0.0601254 (* 1 = 0.0601254 loss)
I0820 09:59:54.068261 12052 sgd_solver.cpp:112] Iteration 23100, lr = 0.001
I0820 09:59:58.037318 12052 solver.cpp:239] Iteration 23200 (25.1952 iter/s, 3.96901s/100 iters), loss = 0.0431195
I0820 09:59:58.037364 12052 solver.cpp:258]     Train net output #0: landmark_loss = 0.0431194 (* 1 = 0.0431194 loss)
I0820 09:59:58.037371 12052 sgd_solver.cpp:112] Iteration 23200, lr = 0.001
I0820 10:00:02.019843 12052 solver.cpp:239] Iteration 23300 (25.1103 iter/s, 3.98243s/100 iters), loss = 0.054868
I0820 10:00:02.019888 12052 solver.cpp:258]     Train net output #0: landmark_loss = 0.0548679 (* 1 = 0.0548679 loss)
I0820 10:00:02.019896 12052 sgd_solver.cpp:112] Iteration 23300, lr = 0.001
I0820 10:00:05.991446 12052 solver.cpp:239] Iteration 23400 (25.1793 iter/s, 3.97151s/100 iters), loss = 0.0594896
I0820 10:00:05.991490 12052 solver.cpp:258]     Train net output #0: landmark_loss = 0.0594895 (* 1 = 0.0594895 loss)
I0820 10:00:05.991497 12052 sgd_solver.cpp:112] Iteration 23400, lr = 0.001
I0820 10:00:09.961112 12052 solver.cpp:239] Iteration 23500 (25.1916 iter/s, 3.96957s/100 iters), loss = 0.0506354
I0820 10:00:09.961160 12052 solver.cpp:258]     Train net output #0: landmark_loss = 0.0506354 (* 1 = 0.0506354 loss)
I0820 10:00:09.961167 12052 sgd_solver.cpp:112] Iteration 23500, lr = 0.001
I0820 10:00:13.932108 12052 solver.cpp:239] Iteration 23600 (25.1832 iter/s, 3.9709s/100 iters), loss = 0.0572575
I0820 10:00:13.932159 12052 solver.cpp:258]     Train net output #0: landmark_loss = 0.0572574 (* 1 = 0.0572574 loss)
I0820 10:00:13.932166 12052 sgd_solver.cpp:112] Iteration 23600, lr = 0.001
I0820 10:00:17.877077 12052 solver.cpp:239] Iteration 23700 (25.3494 iter/s, 3.94487s/100 iters), loss = 0.0537431
I0820 10:00:17.877128 12052 solver.cpp:258]     Train net output #0: landmark_loss = 0.0537431 (* 1 = 0.0537431 loss)
I0820 10:00:17.877135 12052 sgd_solver.cpp:112] Iteration 23700, lr = 0.001
I0820 10:00:21.833153 12052 solver.cpp:239] Iteration 23800 (25.2782 iter/s, 3.95598s/100 iters), loss = 0.0627182
I0820 10:00:21.833196 12052 solver.cpp:258]     Train net output #0: landmark_loss = 0.0627181 (* 1 = 0.0627181 loss)
I0820 10:00:21.833202 12052 sgd_solver.cpp:112] Iteration 23800, lr = 0.001
I0820 10:00:25.798467 12052 solver.cpp:239] Iteration 23900 (25.2193 iter/s, 3.96522s/100 iters), loss = 0.0533286
I0820 10:00:25.798513 12052 solver.cpp:258]     Train net output #0: landmark_loss = 0.0533286 (* 1 = 0.0533286 loss)
I0820 10:00:25.798521 12052 sgd_solver.cpp:112] Iteration 23900, lr = 0.001
I0820 10:00:29.712055 12052 solver.cpp:347] Iteration 24000, Testing net (#0)
I0820 10:00:44.956637 12052 solver.cpp:414]     Test net output #0: landmark_loss = 0.0362821 (* 1 = 0.0362821 loss)
I0820 10:00:44.995810 12052 solver.cpp:239] Iteration 24000 (5.20912 iter/s, 19.1971s/100 iters), loss = 0.0497147
I0820 10:00:44.995856 12052 solver.cpp:258]     Train net output #0: landmark_loss = 0.0497147 (* 1 = 0.0497147 loss)
I0820 10:00:44.995862 12052 sgd_solver.cpp:112] Iteration 24000, lr = 0.001
I0820 10:00:48.967411 12052 solver.cpp:239] Iteration 24100 (25.1793 iter/s, 3.97151s/100 iters), loss = 0.0571387
I0820 10:00:48.967456 12052 solver.cpp:258]     Train net output #0: landmark_loss = 0.0571387 (* 1 = 0.0571387 loss)
I0820 10:00:48.967464 12052 sgd_solver.cpp:112] Iteration 24100, lr = 0.001
I0820 10:00:52.936650 12052 solver.cpp:239] Iteration 24200 (25.1943 iter/s, 3.96915s/100 iters), loss = 0.0511741
I0820 10:00:52.936697 12052 solver.cpp:258]     Train net output #0: landmark_loss = 0.0511741 (* 1 = 0.0511741 loss)
I0820 10:00:52.936704 12052 sgd_solver.cpp:112] Iteration 24200, lr = 0.001
I0820 10:00:56.907690 12052 solver.cpp:239] Iteration 24300 (25.1829 iter/s, 3.97095s/100 iters), loss = 0.0515288
I0820 10:00:56.907735 12052 solver.cpp:258]     Train net output #0: landmark_loss = 0.0515288 (* 1 = 0.0515288 loss)
I0820 10:00:56.907742 12052 sgd_solver.cpp:112] Iteration 24300, lr = 0.001
I0820 10:01:00.889387 12052 solver.cpp:239] Iteration 24400 (25.1155 iter/s, 3.98161s/100 iters), loss = 0.0551071
I0820 10:01:00.889430 12052 solver.cpp:258]     Train net output #0: landmark_loss = 0.0551071 (* 1 = 0.0551071 loss)
I0820 10:01:00.889437 12052 sgd_solver.cpp:112] Iteration 24400, lr = 0.001
I0820 10:01:04.858657 12052 solver.cpp:239] Iteration 24500 (25.1941 iter/s, 3.96918s/100 iters), loss = 0.0570603
I0820 10:01:04.858700 12052 solver.cpp:258]     Train net output #0: landmark_loss = 0.0570603 (* 1 = 0.0570603 loss)
I0820 10:01:04.858707 12052 sgd_solver.cpp:112] Iteration 24500, lr = 0.001
I0820 10:01:08.827733 12052 solver.cpp:239] Iteration 24600 (25.1953 iter/s, 3.96899s/100 iters), loss = 0.0580432
I0820 10:01:08.827775 12052 solver.cpp:258]     Train net output #0: landmark_loss = 0.0580432 (* 1 = 0.0580432 loss)
I0820 10:01:08.827782 12052 sgd_solver.cpp:112] Iteration 24600, lr = 0.001
I0820 10:01:12.794219 12052 solver.cpp:239] Iteration 24700 (25.2118 iter/s, 3.9664s/100 iters), loss = 0.0530949
I0820 10:01:12.794266 12052 solver.cpp:258]     Train net output #0: landmark_loss = 0.0530949 (* 1 = 0.0530949 loss)
I0820 10:01:12.794273 12052 sgd_solver.cpp:112] Iteration 24700, lr = 0.001
I0820 10:01:16.760241 12052 solver.cpp:239] Iteration 24800 (25.2147 iter/s, 3.96593s/100 iters), loss = 0.0538567
I0820 10:01:16.760283 12052 solver.cpp:258]     Train net output #0: landmark_loss = 0.0538566 (* 1 = 0.0538566 loss)
I0820 10:01:16.760289 12052 sgd_solver.cpp:112] Iteration 24800, lr = 0.001
I0820 10:01:20.726012 12052 solver.cpp:239] Iteration 24900 (25.2163 iter/s, 3.96569s/100 iters), loss = 0.0608162
I0820 10:01:20.726053 12052 solver.cpp:258]     Train net output #0: landmark_loss = 0.0608162 (* 1 = 0.0608162 loss)
I0820 10:01:20.726059 12052 sgd_solver.cpp:112] Iteration 24900, lr = 0.001
I0820 10:01:24.676091 12052 solver.cpp:239] Iteration 25000 (25.3165 iter/s, 3.95s/100 iters), loss = 0.0498049
I0820 10:01:24.676137 12052 solver.cpp:258]     Train net output #0: landmark_loss = 0.0498049 (* 1 = 0.0498049 loss)
I0820 10:01:24.676144 12052 sgd_solver.cpp:112] Iteration 25000, lr = 0.001
I0820 10:01:28.649610 12052 solver.cpp:239] Iteration 25100 (25.1672 iter/s, 3.97343s/100 iters), loss = 0.0555845
I0820 10:01:28.649662 12052 solver.cpp:258]     Train net output #0: landmark_loss = 0.0555845 (* 1 = 0.0555845 loss)
I0820 10:01:28.649670 12052 sgd_solver.cpp:112] Iteration 25100, lr = 0.001
I0820 10:01:32.623731 12052 solver.cpp:239] Iteration 25200 (25.1634 iter/s, 3.97403s/100 iters), loss = 0.0557706
I0820 10:01:32.623777 12052 solver.cpp:258]     Train net output #0: landmark_loss = 0.0557706 (* 1 = 0.0557706 loss)
I0820 10:01:32.623785 12052 sgd_solver.cpp:112] Iteration 25200, lr = 0.001
I0820 10:01:36.598871 12052 solver.cpp:239] Iteration 25300 (25.1569 iter/s, 3.97505s/100 iters), loss = 0.061189
I0820 10:01:36.598919 12052 solver.cpp:258]     Train net output #0: landmark_loss = 0.061189 (* 1 = 0.061189 loss)
I0820 10:01:36.598927 12052 sgd_solver.cpp:112] Iteration 25300, lr = 0.001
I0820 10:01:40.574606 12052 solver.cpp:239] Iteration 25400 (25.1532 iter/s, 3.97564s/100 iters), loss = 0.0452272
I0820 10:01:40.574657 12052 solver.cpp:258]     Train net output #0: landmark_loss = 0.0452272 (* 1 = 0.0452272 loss)
I0820 10:01:40.574666 12052 sgd_solver.cpp:112] Iteration 25400, lr = 0.001
I0820 10:01:44.549933 12052 solver.cpp:239] Iteration 25500 (25.1558 iter/s, 3.97523s/100 iters), loss = 0.0572285
I0820 10:01:44.549983 12052 solver.cpp:258]     Train net output #0: landmark_loss = 0.0572285 (* 1 = 0.0572285 loss)
I0820 10:01:44.549990 12052 sgd_solver.cpp:112] Iteration 25500, lr = 0.001
I0820 10:01:48.525478 12052 solver.cpp:239] Iteration 25600 (25.1544 iter/s, 3.97546s/100 iters), loss = 0.0570004
I0820 10:01:48.525529 12052 solver.cpp:258]     Train net output #0: landmark_loss = 0.0570004 (* 1 = 0.0570004 loss)
I0820 10:01:48.525537 12052 sgd_solver.cpp:112] Iteration 25600, lr = 0.001
I0820 10:01:52.501019 12052 solver.cpp:239] Iteration 25700 (25.1544 iter/s, 3.97545s/100 iters), loss = 0.0582072
I0820 10:01:52.501065 12052 solver.cpp:258]     Train net output #0: landmark_loss = 0.0582071 (* 1 = 0.0582071 loss)
I0820 10:01:52.501071 12052 sgd_solver.cpp:112] Iteration 25700, lr = 0.001
I0820 10:01:56.477304 12052 solver.cpp:239] Iteration 25800 (25.1497 iter/s, 3.9762s/100 iters), loss = 0.0544399
I0820 10:01:56.477352 12052 solver.cpp:258]     Train net output #0: landmark_loss = 0.0544399 (* 1 = 0.0544399 loss)
I0820 10:01:56.477360 12052 sgd_solver.cpp:112] Iteration 25800, lr = 0.001
I0820 10:02:00.466190 12052 solver.cpp:239] Iteration 25900 (25.0702 iter/s, 3.9888s/100 iters), loss = 0.0424216
I0820 10:02:00.466240 12052 solver.cpp:258]     Train net output #0: landmark_loss = 0.0424215 (* 1 = 0.0424215 loss)
I0820 10:02:00.466248 12052 sgd_solver.cpp:112] Iteration 25900, lr = 0.001
I0820 10:02:04.438927 12052 solver.cpp:239] Iteration 26000 (25.1721 iter/s, 3.97265s/100 iters), loss = 0.0508734
I0820 10:02:04.438978 12052 solver.cpp:258]     Train net output #0: landmark_loss = 0.0508734 (* 1 = 0.0508734 loss)
I0820 10:02:04.438985 12052 sgd_solver.cpp:112] Iteration 26000, lr = 0.001
I0820 10:02:08.362326 12052 solver.cpp:239] Iteration 26100 (25.4887 iter/s, 3.92331s/100 iters), loss = 0.0512781
I0820 10:02:08.362370 12052 solver.cpp:258]     Train net output #0: landmark_loss = 0.051278 (* 1 = 0.051278 loss)
I0820 10:02:08.362375 12052 sgd_solver.cpp:112] Iteration 26100, lr = 0.001
I0820 10:02:12.276437 12052 solver.cpp:239] Iteration 26200 (25.5491 iter/s, 3.91403s/100 iters), loss = 0.0517813
I0820 10:02:12.276476 12052 solver.cpp:258]     Train net output #0: landmark_loss = 0.0517813 (* 1 = 0.0517813 loss)
I0820 10:02:12.276482 12052 sgd_solver.cpp:112] Iteration 26200, lr = 0.001
I0820 10:02:16.182813 12052 solver.cpp:239] Iteration 26300 (25.5997 iter/s, 3.9063s/100 iters), loss = 0.0506086
I0820 10:02:16.182866 12052 solver.cpp:258]     Train net output #0: landmark_loss = 0.0506085 (* 1 = 0.0506085 loss)
I0820 10:02:16.182873 12052 sgd_solver.cpp:112] Iteration 26300, lr = 0.001
I0820 10:02:20.090528 12052 solver.cpp:239] Iteration 26400 (25.591 iter/s, 3.90762s/100 iters), loss = 0.0599246
I0820 10:02:20.090569 12052 solver.cpp:258]     Train net output #0: landmark_loss = 0.0599246 (* 1 = 0.0599246 loss)
I0820 10:02:20.090574 12052 sgd_solver.cpp:112] Iteration 26400, lr = 0.001
I0820 10:02:23.996584 12052 solver.cpp:239] Iteration 26500 (25.6018 iter/s, 3.90598s/100 iters), loss = 0.048497
I0820 10:02:23.996626 12052 solver.cpp:258]     Train net output #0: landmark_loss = 0.0484969 (* 1 = 0.0484969 loss)
I0820 10:02:23.996632 12052 sgd_solver.cpp:112] Iteration 26500, lr = 0.001
I0820 10:02:27.903005 12052 solver.cpp:239] Iteration 26600 (25.5994 iter/s, 3.90634s/100 iters), loss = 0.0440206
I0820 10:02:27.903045 12052 solver.cpp:258]     Train net output #0: landmark_loss = 0.0440206 (* 1 = 0.0440206 loss)
I0820 10:02:27.903051 12052 sgd_solver.cpp:112] Iteration 26600, lr = 0.001
I0820 10:02:31.813062 12052 solver.cpp:239] Iteration 26700 (25.5756 iter/s, 3.90998s/100 iters), loss = 0.050544
I0820 10:02:31.813103 12052 solver.cpp:258]     Train net output #0: landmark_loss = 0.050544 (* 1 = 0.050544 loss)
I0820 10:02:31.813108 12052 sgd_solver.cpp:112] Iteration 26700, lr = 0.001
I0820 10:02:35.719074 12052 solver.cpp:239] Iteration 26800 (25.6021 iter/s, 3.90593s/100 iters), loss = 0.0563802
I0820 10:02:35.719115 12052 solver.cpp:258]     Train net output #0: landmark_loss = 0.0563802 (* 1 = 0.0563802 loss)
I0820 10:02:35.719120 12052 sgd_solver.cpp:112] Iteration 26800, lr = 0.001
I0820 10:02:39.626523 12052 solver.cpp:239] Iteration 26900 (25.5926 iter/s, 3.90737s/100 iters), loss = 0.0498325
I0820 10:02:39.626564 12052 solver.cpp:258]     Train net output #0: landmark_loss = 0.0498325 (* 1 = 0.0498325 loss)
I0820 10:02:39.626570 12052 sgd_solver.cpp:112] Iteration 26900, lr = 0.001
I0820 10:02:43.532552 12052 solver.cpp:239] Iteration 27000 (25.6019 iter/s, 3.90595s/100 iters), loss = 0.0565607
I0820 10:02:43.532593 12052 solver.cpp:258]     Train net output #0: landmark_loss = 0.0565606 (* 1 = 0.0565606 loss)
I0820 10:02:43.532599 12052 sgd_solver.cpp:112] Iteration 27000, lr = 0.001
I0820 10:02:47.438846 12052 solver.cpp:239] Iteration 27100 (25.6002 iter/s, 3.90622s/100 iters), loss = 0.0596484
I0820 10:02:47.438886 12052 solver.cpp:258]     Train net output #0: landmark_loss = 0.0596484 (* 1 = 0.0596484 loss)
I0820 10:02:47.438892 12052 sgd_solver.cpp:112] Iteration 27100, lr = 0.001
I0820 10:02:51.345057 12052 solver.cpp:239] Iteration 27200 (25.6007 iter/s, 3.90614s/100 iters), loss = 0.0508059
I0820 10:02:51.345098 12052 solver.cpp:258]     Train net output #0: landmark_loss = 0.0508059 (* 1 = 0.0508059 loss)
I0820 10:02:51.345103 12052 sgd_solver.cpp:112] Iteration 27200, lr = 0.001
I0820 10:02:55.251514 12052 solver.cpp:239] Iteration 27300 (25.5991 iter/s, 3.90638s/100 iters), loss = 0.0542957
I0820 10:02:55.251555 12052 solver.cpp:258]     Train net output #0: landmark_loss = 0.0542957 (* 1 = 0.0542957 loss)
I0820 10:02:55.251561 12052 sgd_solver.cpp:112] Iteration 27300, lr = 0.001
I0820 10:02:59.157972 12052 solver.cpp:239] Iteration 27400 (25.5991 iter/s, 3.90638s/100 iters), loss = 0.0472439
I0820 10:02:59.158012 12052 solver.cpp:258]     Train net output #0: landmark_loss = 0.0472439 (* 1 = 0.0472439 loss)
I0820 10:02:59.158018 12052 sgd_solver.cpp:112] Iteration 27400, lr = 0.001
I0820 10:03:03.109011 12052 solver.cpp:239] Iteration 27500 (25.3103 iter/s, 3.95097s/100 iters), loss = 0.0452425
I0820 10:03:03.109055 12052 solver.cpp:258]     Train net output #0: landmark_loss = 0.0452425 (* 1 = 0.0452425 loss)
I0820 10:03:03.109061 12052 sgd_solver.cpp:112] Iteration 27500, lr = 0.001
I0820 10:03:07.019718 12052 solver.cpp:239] Iteration 27600 (25.5713 iter/s, 3.91063s/100 iters), loss = 0.0577256
I0820 10:03:07.019759 12052 solver.cpp:258]     Train net output #0: landmark_loss = 0.0577256 (* 1 = 0.0577256 loss)
I0820 10:03:07.019765 12052 sgd_solver.cpp:112] Iteration 27600, lr = 0.001
I0820 10:03:10.926105 12052 solver.cpp:239] Iteration 27700 (25.5996 iter/s, 3.90631s/100 iters), loss = 0.0448704
I0820 10:03:10.926146 12052 solver.cpp:258]     Train net output #0: landmark_loss = 0.0448704 (* 1 = 0.0448704 loss)
I0820 10:03:10.926151 12052 sgd_solver.cpp:112] Iteration 27700, lr = 0.001
I0820 10:03:14.832552 12052 solver.cpp:239] Iteration 27800 (25.5992 iter/s, 3.90637s/100 iters), loss = 0.0493757
I0820 10:03:14.832593 12052 solver.cpp:258]     Train net output #0: landmark_loss = 0.0493757 (* 1 = 0.0493757 loss)
I0820 10:03:14.832598 12052 sgd_solver.cpp:112] Iteration 27800, lr = 0.001
I0820 10:03:18.738669 12052 solver.cpp:239] Iteration 27900 (25.6014 iter/s, 3.90604s/100 iters), loss = 0.0515286
I0820 10:03:18.738710 12052 solver.cpp:258]     Train net output #0: landmark_loss = 0.0515286 (* 1 = 0.0515286 loss)
I0820 10:03:18.738716 12052 sgd_solver.cpp:112] Iteration 27900, lr = 0.001
I0820 10:03:22.645114 12052 solver.cpp:239] Iteration 28000 (25.5992 iter/s, 3.90637s/100 iters), loss = 0.0482394
I0820 10:03:22.645156 12052 solver.cpp:258]     Train net output #0: landmark_loss = 0.0482394 (* 1 = 0.0482394 loss)
I0820 10:03:22.645162 12052 sgd_solver.cpp:112] Iteration 28000, lr = 0.001
I0820 10:03:26.551178 12052 solver.cpp:239] Iteration 28100 (25.6017 iter/s, 3.90599s/100 iters), loss = 0.0625213
I0820 10:03:26.551220 12052 solver.cpp:258]     Train net output #0: landmark_loss = 0.0625213 (* 1 = 0.0625213 loss)
I0820 10:03:26.551226 12052 sgd_solver.cpp:112] Iteration 28100, lr = 0.001
I0820 10:03:30.457296 12052 solver.cpp:239] Iteration 28200 (25.6014 iter/s, 3.90604s/100 iters), loss = 0.0499875
I0820 10:03:30.457337 12052 solver.cpp:258]     Train net output #0: landmark_loss = 0.0499875 (* 1 = 0.0499875 loss)
I0820 10:03:30.457343 12052 sgd_solver.cpp:112] Iteration 28200, lr = 0.001
I0820 10:03:34.363174 12052 solver.cpp:239] Iteration 28300 (25.6029 iter/s, 3.9058s/100 iters), loss = 0.0411274
I0820 10:03:34.363214 12052 solver.cpp:258]     Train net output #0: landmark_loss = 0.0411274 (* 1 = 0.0411274 loss)
I0820 10:03:34.363220 12052 sgd_solver.cpp:112] Iteration 28300, lr = 0.001
I0820 10:03:38.271605 12052 solver.cpp:239] Iteration 28400 (25.5862 iter/s, 3.90836s/100 iters), loss = 0.0464281
I0820 10:03:38.271647 12052 solver.cpp:258]     Train net output #0: landmark_loss = 0.0464281 (* 1 = 0.0464281 loss)
I0820 10:03:38.271653 12052 sgd_solver.cpp:112] Iteration 28400, lr = 0.001
I0820 10:03:42.177595 12052 solver.cpp:239] Iteration 28500 (25.6022 iter/s, 3.90592s/100 iters), loss = 0.0542244
I0820 10:03:42.177635 12052 solver.cpp:258]     Train net output #0: landmark_loss = 0.0542243 (* 1 = 0.0542243 loss)
I0820 10:03:42.177641 12052 sgd_solver.cpp:112] Iteration 28500, lr = 0.001
I0820 10:03:46.083660 12052 solver.cpp:239] Iteration 28600 (25.6017 iter/s, 3.90599s/100 iters), loss = 0.0564207
I0820 10:03:46.083701 12052 solver.cpp:258]     Train net output #0: landmark_loss = 0.0564206 (* 1 = 0.0564206 loss)
I0820 10:03:46.083708 12052 sgd_solver.cpp:112] Iteration 28600, lr = 0.001
I0820 10:03:49.989675 12052 solver.cpp:239] Iteration 28700 (25.602 iter/s, 3.90594s/100 iters), loss = 0.0531609
I0820 10:03:49.989715 12052 solver.cpp:258]     Train net output #0: landmark_loss = 0.0531608 (* 1 = 0.0531608 loss)
I0820 10:03:49.989722 12052 sgd_solver.cpp:112] Iteration 28700, lr = 0.001
I0820 10:03:53.895861 12052 solver.cpp:239] Iteration 28800 (25.6009 iter/s, 3.90611s/100 iters), loss = 0.0509895
I0820 10:03:53.895902 12052 solver.cpp:258]     Train net output #0: landmark_loss = 0.0509895 (* 1 = 0.0509895 loss)
I0820 10:03:53.895908 12052 sgd_solver.cpp:112] Iteration 28800, lr = 0.001
I0820 10:03:57.802040 12052 solver.cpp:239] Iteration 28900 (25.6009 iter/s, 3.90611s/100 iters), loss = 0.0510023
I0820 10:03:57.802081 12052 solver.cpp:258]     Train net output #0: landmark_loss = 0.0510023 (* 1 = 0.0510023 loss)
I0820 10:03:57.802088 12052 sgd_solver.cpp:112] Iteration 28900, lr = 0.001
I0820 10:04:01.738641 12052 solver.cpp:239] Iteration 29000 (25.4031 iter/s, 3.93653s/100 iters), loss = 0.0457919
I0820 10:04:01.738685 12052 solver.cpp:258]     Train net output #0: landmark_loss = 0.0457919 (* 1 = 0.0457919 loss)
I0820 10:04:01.738692 12052 sgd_solver.cpp:112] Iteration 29000, lr = 0.001
I0820 10:04:05.671510 12052 solver.cpp:239] Iteration 29100 (25.4272 iter/s, 3.93279s/100 iters), loss = 0.0535035
I0820 10:04:05.671563 12052 solver.cpp:258]     Train net output #0: landmark_loss = 0.0535035 (* 1 = 0.0535035 loss)
I0820 10:04:05.671569 12052 sgd_solver.cpp:112] Iteration 29100, lr = 0.001
I0820 10:04:09.584666 12052 solver.cpp:239] Iteration 29200 (25.5554 iter/s, 3.91307s/100 iters), loss = 0.0542052
I0820 10:04:09.584717 12052 solver.cpp:258]     Train net output #0: landmark_loss = 0.0542052 (* 1 = 0.0542052 loss)
I0820 10:04:09.584724 12052 sgd_solver.cpp:112] Iteration 29200, lr = 0.001
I0820 10:04:13.493290 12052 solver.cpp:239] Iteration 29300 (25.585 iter/s, 3.90854s/100 iters), loss = 0.0465288
I0820 10:04:13.493330 12052 solver.cpp:258]     Train net output #0: landmark_loss = 0.0465288 (* 1 = 0.0465288 loss)
I0820 10:04:13.493336 12052 sgd_solver.cpp:112] Iteration 29300, lr = 0.001
I0820 10:04:17.399595 12052 solver.cpp:239] Iteration 29400 (25.6001 iter/s, 3.90623s/100 iters), loss = 0.0540095
I0820 10:04:17.399636 12052 solver.cpp:258]     Train net output #0: landmark_loss = 0.0540095 (* 1 = 0.0540095 loss)
I0820 10:04:17.399641 12052 sgd_solver.cpp:112] Iteration 29400, lr = 0.001
I0820 10:04:21.305388 12052 solver.cpp:239] Iteration 29500 (25.6035 iter/s, 3.90572s/100 iters), loss = 0.0455458
I0820 10:04:21.305429 12052 solver.cpp:258]     Train net output #0: landmark_loss = 0.0455457 (* 1 = 0.0455457 loss)
I0820 10:04:21.305435 12052 sgd_solver.cpp:112] Iteration 29500, lr = 0.001
I0820 10:04:25.211834 12052 solver.cpp:239] Iteration 29600 (25.5992 iter/s, 3.90638s/100 iters), loss = 0.0500756
I0820 10:04:25.211875 12052 solver.cpp:258]     Train net output #0: landmark_loss = 0.0500756 (* 1 = 0.0500756 loss)
I0820 10:04:25.211880 12052 sgd_solver.cpp:112] Iteration 29600, lr = 0.001
I0820 10:04:29.118007 12052 solver.cpp:239] Iteration 29700 (25.601 iter/s, 3.9061s/100 iters), loss = 0.0402687
I0820 10:04:29.118049 12052 solver.cpp:258]     Train net output #0: landmark_loss = 0.0402687 (* 1 = 0.0402687 loss)
I0820 10:04:29.118054 12052 sgd_solver.cpp:112] Iteration 29700, lr = 0.001
I0820 10:04:33.024274 12052 solver.cpp:239] Iteration 29800 (25.6004 iter/s, 3.9062s/100 iters), loss = 0.0571396
I0820 10:04:33.024314 12052 solver.cpp:258]     Train net output #0: landmark_loss = 0.0571396 (* 1 = 0.0571396 loss)
I0820 10:04:33.024320 12052 sgd_solver.cpp:112] Iteration 29800, lr = 0.001
I0820 10:04:36.930682 12052 solver.cpp:239] Iteration 29900 (25.5994 iter/s, 3.90634s/100 iters), loss = 0.0498235
I0820 10:04:36.930723 12052 solver.cpp:258]     Train net output #0: landmark_loss = 0.0498235 (* 1 = 0.0498235 loss)
I0820 10:04:36.930729 12052 sgd_solver.cpp:112] Iteration 29900, lr = 0.001
I0820 10:04:40.780730 12052 solver.cpp:464] Snapshotting to binary proto file ./model/M3_iter_30000.caffemodel
I0820 10:04:40.883085 12052 sgd_solver.cpp:284] Snapshotting solver state to binary proto file ./model/M3_iter_30000.solverstate
I0820 10:04:40.935405 12052 solver.cpp:347] Iteration 30000, Testing net (#0)
I0820 10:04:55.700253 12052 solver.cpp:414]     Test net output #0: landmark_loss = 0.035596 (* 1 = 0.035596 loss)
I0820 10:04:55.738937 12052 solver.cpp:239] Iteration 30000 (5.31685 iter/s, 18.8081s/100 iters), loss = 0.0502082
I0820 10:04:55.738965 12052 solver.cpp:258]     Train net output #0: landmark_loss = 0.0502082 (* 1 = 0.0502082 loss)
I0820 10:04:55.738970 12052 sgd_solver.cpp:112] Iteration 30000, lr = 0.001
I0820 10:04:59.645124 12052 solver.cpp:239] Iteration 30100 (25.6008 iter/s, 3.90613s/100 iters), loss = 0.051509
I0820 10:04:59.645164 12052 solver.cpp:258]     Train net output #0: landmark_loss = 0.051509 (* 1 = 0.051509 loss)
I0820 10:04:59.645170 12052 sgd_solver.cpp:112] Iteration 30100, lr = 0.001
I0820 10:05:03.603431 12052 solver.cpp:239] Iteration 30200 (25.2638 iter/s, 3.95824s/100 iters), loss = 0.0600051
I0820 10:05:03.603485 12052 solver.cpp:258]     Train net output #0: landmark_loss = 0.0600051 (* 1 = 0.0600051 loss)
I0820 10:05:03.603492 12052 sgd_solver.cpp:112] Iteration 30200, lr = 0.001
I0820 10:05:07.541579 12052 solver.cpp:239] Iteration 30300 (25.3932 iter/s, 3.93807s/100 iters), loss = 0.0625316
I0820 10:05:07.541633 12052 solver.cpp:258]     Train net output #0: landmark_loss = 0.0625315 (* 1 = 0.0625315 loss)
I0820 10:05:07.541640 12052 sgd_solver.cpp:112] Iteration 30300, lr = 0.001
I0820 10:05:11.455308 12052 solver.cpp:239] Iteration 30400 (25.5516 iter/s, 3.91365s/100 iters), loss = 0.047356
I0820 10:05:11.455350 12052 solver.cpp:258]     Train net output #0: landmark_loss = 0.0473559 (* 1 = 0.0473559 loss)
I0820 10:05:11.455356 12052 sgd_solver.cpp:112] Iteration 30400, lr = 0.001
I0820 10:05:15.362522 12052 solver.cpp:239] Iteration 30500 (25.5941 iter/s, 3.90715s/100 iters), loss = 0.051212
I0820 10:05:15.362563 12052 solver.cpp:258]     Train net output #0: landmark_loss = 0.051212 (* 1 = 0.051212 loss)
I0820 10:05:15.362570 12052 sgd_solver.cpp:112] Iteration 30500, lr = 0.001
I0820 10:05:19.268724 12052 solver.cpp:239] Iteration 30600 (25.6007 iter/s, 3.90614s/100 iters), loss = 0.0544698
I0820 10:05:19.268764 12052 solver.cpp:258]     Train net output #0: landmark_loss = 0.0544698 (* 1 = 0.0544698 loss)
I0820 10:05:19.268770 12052 sgd_solver.cpp:112] Iteration 30600, lr = 0.001
I0820 10:05:23.175150 12052 solver.cpp:239] Iteration 30700 (25.5993 iter/s, 3.90636s/100 iters), loss = 0.0519173
I0820 10:05:23.175191 12052 solver.cpp:258]     Train net output #0: landmark_loss = 0.0519173 (* 1 = 0.0519173 loss)
I0820 10:05:23.175197 12052 sgd_solver.cpp:112] Iteration 30700, lr = 0.001
I0820 10:05:27.081307 12052 solver.cpp:239] Iteration 30800 (25.601 iter/s, 3.90609s/100 iters), loss = 0.0439591
I0820 10:05:27.081348 12052 solver.cpp:258]     Train net output #0: landmark_loss = 0.043959 (* 1 = 0.043959 loss)
I0820 10:05:27.081354 12052 sgd_solver.cpp:112] Iteration 30800, lr = 0.001
I0820 10:05:30.987907 12052 solver.cpp:239] Iteration 30900 (25.5982 iter/s, 3.90653s/100 iters), loss = 0.0539873
I0820 10:05:30.987949 12052 solver.cpp:258]     Train net output #0: landmark_loss = 0.0539873 (* 1 = 0.0539873 loss)
I0820 10:05:30.987956 12052 sgd_solver.cpp:112] Iteration 30900, lr = 0.001
I0820 10:05:34.894425 12052 solver.cpp:239] Iteration 31000 (25.5987 iter/s, 3.90645s/100 iters), loss = 0.0566725
I0820 10:05:34.894477 12052 solver.cpp:258]     Train net output #0: landmark_loss = 0.0566725 (* 1 = 0.0566725 loss)
I0820 10:05:34.894484 12052 sgd_solver.cpp:112] Iteration 31000, lr = 0.001
I0820 10:05:38.800582 12052 solver.cpp:239] Iteration 31100 (25.6011 iter/s, 3.90608s/100 iters), loss = 0.0613505
I0820 10:05:38.800624 12052 solver.cpp:258]     Train net output #0: landmark_loss = 0.0613505 (* 1 = 0.0613505 loss)
I0820 10:05:38.800631 12052 sgd_solver.cpp:112] Iteration 31100, lr = 0.001
I0820 10:05:42.707167 12052 solver.cpp:239] Iteration 31200 (25.5982 iter/s, 3.90652s/100 iters), loss = 0.0570051
I0820 10:05:42.707208 12052 solver.cpp:258]     Train net output #0: landmark_loss = 0.0570051 (* 1 = 0.0570051 loss)
I0820 10:05:42.707214 12052 sgd_solver.cpp:112] Iteration 31200, lr = 0.001
I0820 10:05:46.613934 12052 solver.cpp:239] Iteration 31300 (25.597 iter/s, 3.9067s/100 iters), loss = 0.0520824
I0820 10:05:46.613976 12052 solver.cpp:258]     Train net output #0: landmark_loss = 0.0520824 (* 1 = 0.0520824 loss)
I0820 10:05:46.613982 12052 sgd_solver.cpp:112] Iteration 31300, lr = 0.001
I0820 10:05:50.519997 12052 solver.cpp:239] Iteration 31400 (25.6017 iter/s, 3.906s/100 iters), loss = 0.0611846
I0820 10:05:50.520038 12052 solver.cpp:258]     Train net output #0: landmark_loss = 0.0611846 (* 1 = 0.0611846 loss)
I0820 10:05:50.520043 12052 sgd_solver.cpp:112] Iteration 31400, lr = 0.001
I0820 10:05:54.426265 12052 solver.cpp:239] Iteration 31500 (25.6003 iter/s, 3.9062s/100 iters), loss = 0.0408918
I0820 10:05:54.426306 12052 solver.cpp:258]     Train net output #0: landmark_loss = 0.0408918 (* 1 = 0.0408918 loss)
I0820 10:05:54.426311 12052 sgd_solver.cpp:112] Iteration 31500, lr = 0.001
I0820 10:05:58.332845 12052 solver.cpp:239] Iteration 31600 (25.5983 iter/s, 3.90652s/100 iters), loss = 0.0444815
I0820 10:05:58.332886 12052 solver.cpp:258]     Train net output #0: landmark_loss = 0.0444815 (* 1 = 0.0444815 loss)
I0820 10:05:58.332892 12052 sgd_solver.cpp:112] Iteration 31600, lr = 0.001
I0820 10:06:02.276702 12052 solver.cpp:239] Iteration 31700 (25.3563 iter/s, 3.94379s/100 iters), loss = 0.044644
I0820 10:06:02.276746 12052 solver.cpp:258]     Train net output #0: landmark_loss = 0.0446439 (* 1 = 0.0446439 loss)
I0820 10:06:02.276751 12052 sgd_solver.cpp:112] Iteration 31700, lr = 0.001
I0820 10:06:06.196159 12052 solver.cpp:239] Iteration 31800 (25.5141 iter/s, 3.91939s/100 iters), loss = 0.0549828
I0820 10:06:06.196199 12052 solver.cpp:258]     Train net output #0: landmark_loss = 0.0549828 (* 1 = 0.0549828 loss)
I0820 10:06:06.196205 12052 sgd_solver.cpp:112] Iteration 31800, lr = 0.001
I0820 10:06:10.102540 12052 solver.cpp:239] Iteration 31900 (25.5996 iter/s, 3.90632s/100 iters), loss = 0.0531849
I0820 10:06:10.102581 12052 solver.cpp:258]     Train net output #0: landmark_loss = 0.0531849 (* 1 = 0.0531849 loss)
I0820 10:06:10.102586 12052 sgd_solver.cpp:112] Iteration 31900, lr = 0.001
I0820 10:06:14.008931 12052 solver.cpp:239] Iteration 32000 (25.5995 iter/s, 3.90633s/100 iters), loss = 0.0458032
I0820 10:06:14.008971 12052 solver.cpp:258]     Train net output #0: landmark_loss = 0.0458032 (* 1 = 0.0458032 loss)
I0820 10:06:14.008977 12052 sgd_solver.cpp:112] Iteration 32000, lr = 0.001
I0820 10:06:17.915141 12052 solver.cpp:239] Iteration 32100 (25.6007 iter/s, 3.90615s/100 iters), loss = 0.0462729
I0820 10:06:17.915182 12052 solver.cpp:258]     Train net output #0: landmark_loss = 0.0462728 (* 1 = 0.0462728 loss)
I0820 10:06:17.915187 12052 sgd_solver.cpp:112] Iteration 32100, lr = 0.001
I0820 10:06:21.821198 12052 solver.cpp:239] Iteration 32200 (25.6017 iter/s, 3.906s/100 iters), loss = 0.0480351
I0820 10:06:21.821239 12052 solver.cpp:258]     Train net output #0: landmark_loss = 0.0480351 (* 1 = 0.0480351 loss)
I0820 10:06:21.821245 12052 sgd_solver.cpp:112] Iteration 32200, lr = 0.001
I0820 10:06:25.727636 12052 solver.cpp:239] Iteration 32300 (25.5992 iter/s, 3.90637s/100 iters), loss = 0.0508645
I0820 10:06:25.727677 12052 solver.cpp:258]     Train net output #0: landmark_loss = 0.0508645 (* 1 = 0.0508645 loss)
I0820 10:06:25.727684 12052 sgd_solver.cpp:112] Iteration 32300, lr = 0.001
I0820 10:06:29.633868 12052 solver.cpp:239] Iteration 32400 (25.6005 iter/s, 3.90617s/100 iters), loss = 0.0548203
I0820 10:06:29.633909 12052 solver.cpp:258]     Train net output #0: landmark_loss = 0.0548202 (* 1 = 0.0548202 loss)
I0820 10:06:29.633915 12052 sgd_solver.cpp:112] Iteration 32400, lr = 0.001
I0820 10:06:33.540220 12052 solver.cpp:239] Iteration 32500 (25.5998 iter/s, 3.90629s/100 iters), loss = 0.0476088
I0820 10:06:33.540259 12052 solver.cpp:258]     Train net output #0: landmark_loss = 0.0476088 (* 1 = 0.0476088 loss)
I0820 10:06:33.540266 12052 sgd_solver.cpp:112] Iteration 32500, lr = 0.001
I0820 10:06:37.446496 12052 solver.cpp:239] Iteration 32600 (25.6002 iter/s, 3.90622s/100 iters), loss = 0.0460616
I0820 10:06:37.446535 12052 solver.cpp:258]     Train net output #0: landmark_loss = 0.0460616 (* 1 = 0.0460616 loss)
I0820 10:06:37.446542 12052 sgd_solver.cpp:112] Iteration 32600, lr = 0.001
I0820 10:06:41.352648 12052 solver.cpp:239] Iteration 32700 (25.6011 iter/s, 3.90609s/100 iters), loss = 0.0493375
I0820 10:06:41.352689 12052 solver.cpp:258]     Train net output #0: landmark_loss = 0.0493375 (* 1 = 0.0493375 loss)
I0820 10:06:41.352694 12052 sgd_solver.cpp:112] Iteration 32700, lr = 0.001
I0820 10:06:45.259011 12052 solver.cpp:239] Iteration 32800 (25.5997 iter/s, 3.9063s/100 iters), loss = 0.0467251
I0820 10:06:45.259052 12052 solver.cpp:258]     Train net output #0: landmark_loss = 0.046725 (* 1 = 0.046725 loss)
I0820 10:06:45.259057 12052 sgd_solver.cpp:112] Iteration 32800, lr = 0.001
I0820 10:06:49.165483 12052 solver.cpp:239] Iteration 32900 (25.599 iter/s, 3.90641s/100 iters), loss = 0.0482191
I0820 10:06:49.165524 12052 solver.cpp:258]     Train net output #0: landmark_loss = 0.048219 (* 1 = 0.048219 loss)
I0820 10:06:49.165530 12052 sgd_solver.cpp:112] Iteration 32900, lr = 0.001
I0820 10:06:53.071624 12052 solver.cpp:239] Iteration 33000 (25.6011 iter/s, 3.90608s/100 iters), loss = 0.0470053
I0820 10:06:53.071664 12052 solver.cpp:258]     Train net output #0: landmark_loss = 0.0470053 (* 1 = 0.0470053 loss)
I0820 10:06:53.071671 12052 sgd_solver.cpp:112] Iteration 33000, lr = 0.001
I0820 10:06:56.978205 12052 solver.cpp:239] Iteration 33100 (25.5982 iter/s, 3.90652s/100 iters), loss = 0.0494818
I0820 10:06:56.978246 12052 solver.cpp:258]     Train net output #0: landmark_loss = 0.0494818 (* 1 = 0.0494818 loss)
I0820 10:06:56.978251 12052 sgd_solver.cpp:112] Iteration 33100, lr = 0.001
I0820 10:07:00.906046 12052 solver.cpp:239] Iteration 33200 (25.4597 iter/s, 3.92778s/100 iters), loss = 0.056826
I0820 10:07:00.906090 12052 solver.cpp:258]     Train net output #0: landmark_loss = 0.056826 (* 1 = 0.056826 loss)
I0820 10:07:00.906096 12052 sgd_solver.cpp:112] Iteration 33200, lr = 0.001
I0820 10:07:04.842428 12052 solver.cpp:239] Iteration 33300 (25.4044 iter/s, 3.93632s/100 iters), loss = 0.0600018
I0820 10:07:04.842480 12052 solver.cpp:258]     Train net output #0: landmark_loss = 0.0600017 (* 1 = 0.0600017 loss)
I0820 10:07:04.842486 12052 sgd_solver.cpp:112] Iteration 33300, lr = 0.001
I0820 10:07:08.749282 12052 solver.cpp:239] Iteration 33400 (25.5965 iter/s, 3.90678s/100 iters), loss = 0.0470269
I0820 10:07:08.749322 12052 solver.cpp:258]     Train net output #0: landmark_loss = 0.0470269 (* 1 = 0.0470269 loss)
I0820 10:07:08.749328 12052 sgd_solver.cpp:112] Iteration 33400, lr = 0.001
I0820 10:07:12.655488 12052 solver.cpp:239] Iteration 33500 (25.6007 iter/s, 3.90614s/100 iters), loss = 0.0416202
I0820 10:07:12.655527 12052 solver.cpp:258]     Train net output #0: landmark_loss = 0.0416202 (* 1 = 0.0416202 loss)
I0820 10:07:12.655534 12052 sgd_solver.cpp:112] Iteration 33500, lr = 0.001
I0820 10:07:16.561633 12052 solver.cpp:239] Iteration 33600 (25.6011 iter/s, 3.90608s/100 iters), loss = 0.0493144
I0820 10:07:16.561674 12052 solver.cpp:258]     Train net output #0: landmark_loss = 0.0493144 (* 1 = 0.0493144 loss)
I0820 10:07:16.561681 12052 sgd_solver.cpp:112] Iteration 33600, lr = 0.001
I0820 10:07:20.474401 12052 solver.cpp:239] Iteration 33700 (25.5577 iter/s, 3.91271s/100 iters), loss = 0.0449744
I0820 10:07:20.474453 12052 solver.cpp:258]     Train net output #0: landmark_loss = 0.0449743 (* 1 = 0.0449743 loss)
I0820 10:07:20.474459 12052 sgd_solver.cpp:112] Iteration 33700, lr = 0.001
I0820 10:07:24.381036 12052 solver.cpp:239] Iteration 33800 (25.5979 iter/s, 3.90656s/100 iters), loss = 0.0598155
I0820 10:07:24.381076 12052 solver.cpp:258]     Train net output #0: landmark_loss = 0.0598155 (* 1 = 0.0598155 loss)
I0820 10:07:24.381083 12052 sgd_solver.cpp:112] Iteration 33800, lr = 0.001
I0820 10:07:28.287104 12052 solver.cpp:239] Iteration 33900 (25.6016 iter/s, 3.90601s/100 iters), loss = 0.0456689
I0820 10:07:28.287145 12052 solver.cpp:258]     Train net output #0: landmark_loss = 0.0456689 (* 1 = 0.0456689 loss)
I0820 10:07:28.287150 12052 sgd_solver.cpp:112] Iteration 33900, lr = 0.001
I0820 10:07:32.193471 12052 solver.cpp:239] Iteration 34000 (25.5996 iter/s, 3.90631s/100 iters), loss = 0.0579987
I0820 10:07:32.193511 12052 solver.cpp:258]     Train net output #0: landmark_loss = 0.0579986 (* 1 = 0.0579986 loss)
I0820 10:07:32.193516 12052 sgd_solver.cpp:112] Iteration 34000, lr = 0.001
I0820 10:07:36.099690 12052 solver.cpp:239] Iteration 34100 (25.6006 iter/s, 3.90616s/100 iters), loss = 0.0483798
I0820 10:07:36.099731 12052 solver.cpp:258]     Train net output #0: landmark_loss = 0.0483798 (* 1 = 0.0483798 loss)
I0820 10:07:36.099737 12052 sgd_solver.cpp:112] Iteration 34100, lr = 0.001
I0820 10:07:40.005744 12052 solver.cpp:239] Iteration 34200 (25.6017 iter/s, 3.90599s/100 iters), loss = 0.0541839
I0820 10:07:40.005785 12052 solver.cpp:258]     Train net output #0: landmark_loss = 0.0541839 (* 1 = 0.0541839 loss)
I0820 10:07:40.005791 12052 sgd_solver.cpp:112] Iteration 34200, lr = 0.001
I0820 10:07:43.911633 12052 solver.cpp:239] Iteration 34300 (25.6028 iter/s, 3.90583s/100 iters), loss = 0.0579322
I0820 10:07:43.911674 12052 solver.cpp:258]     Train net output #0: landmark_loss = 0.0579321 (* 1 = 0.0579321 loss)
I0820 10:07:43.911679 12052 sgd_solver.cpp:112] Iteration 34300, lr = 0.001
I0820 10:07:47.817684 12052 solver.cpp:239] Iteration 34400 (25.6017 iter/s, 3.90599s/100 iters), loss = 0.0497126
I0820 10:07:47.817725 12052 solver.cpp:258]     Train net output #0: landmark_loss = 0.0497126 (* 1 = 0.0497126 loss)
I0820 10:07:47.817731 12052 sgd_solver.cpp:112] Iteration 34400, lr = 0.001
I0820 10:07:51.723894 12052 solver.cpp:239] Iteration 34500 (25.6007 iter/s, 3.90615s/100 iters), loss = 0.0543062
I0820 10:07:51.723935 12052 solver.cpp:258]     Train net output #0: landmark_loss = 0.0543062 (* 1 = 0.0543062 loss)
I0820 10:07:51.723942 12052 sgd_solver.cpp:112] Iteration 34500, lr = 0.001
I0820 10:07:55.630235 12052 solver.cpp:239] Iteration 34600 (25.5998 iter/s, 3.90628s/100 iters), loss = 0.0489613
I0820 10:07:55.630276 12052 solver.cpp:258]     Train net output #0: landmark_loss = 0.0489613 (* 1 = 0.0489613 loss)
I0820 10:07:55.630281 12052 sgd_solver.cpp:112] Iteration 34600, lr = 0.001
I0820 10:07:59.536289 12052 solver.cpp:239] Iteration 34700 (25.6017 iter/s, 3.906s/100 iters), loss = 0.0520829
I0820 10:07:59.536341 12052 solver.cpp:258]     Train net output #0: landmark_loss = 0.0520829 (* 1 = 0.0520829 loss)
I0820 10:07:59.536347 12052 sgd_solver.cpp:112] Iteration 34700, lr = 0.001
I0820 10:08:03.492679 12052 solver.cpp:239] Iteration 34800 (25.276 iter/s, 3.95632s/100 iters), loss = 0.0529243
I0820 10:08:03.492722 12052 solver.cpp:258]     Train net output #0: landmark_loss = 0.0529243 (* 1 = 0.0529243 loss)
I0820 10:08:03.492729 12052 sgd_solver.cpp:112] Iteration 34800, lr = 0.001
I0820 10:08:07.407681 12052 solver.cpp:239] Iteration 34900 (25.5432 iter/s, 3.91494s/100 iters), loss = 0.0411208
I0820 10:08:07.407733 12052 solver.cpp:258]     Train net output #0: landmark_loss = 0.0411208 (* 1 = 0.0411208 loss)
I0820 10:08:07.407739 12052 sgd_solver.cpp:112] Iteration 34900, lr = 0.001
I0820 10:08:11.314404 12052 solver.cpp:239] Iteration 35000 (25.5974 iter/s, 3.90665s/100 iters), loss = 0.0540369
I0820 10:08:11.314445 12052 solver.cpp:258]     Train net output #0: landmark_loss = 0.0540369 (* 1 = 0.0540369 loss)
I0820 10:08:11.314450 12052 sgd_solver.cpp:112] Iteration 35000, lr = 0.001
I0820 10:08:15.220562 12052 solver.cpp:239] Iteration 35100 (25.601 iter/s, 3.9061s/100 iters), loss = 0.0564793
I0820 10:08:15.220602 12052 solver.cpp:258]     Train net output #0: landmark_loss = 0.0564792 (* 1 = 0.0564792 loss)
I0820 10:08:15.220608 12052 sgd_solver.cpp:112] Iteration 35100, lr = 0.001
I0820 10:08:19.127032 12052 solver.cpp:239] Iteration 35200 (25.5989 iter/s, 3.90641s/100 iters), loss = 0.0460882
I0820 10:08:19.127071 12052 solver.cpp:258]     Train net output #0: landmark_loss = 0.0460882 (* 1 = 0.0460882 loss)
I0820 10:08:19.127077 12052 sgd_solver.cpp:112] Iteration 35200, lr = 0.001
I0820 10:08:23.035076 12052 solver.cpp:239] Iteration 35300 (25.5886 iter/s, 3.90799s/100 iters), loss = 0.0493212
I0820 10:08:23.035117 12052 solver.cpp:258]     Train net output #0: landmark_loss = 0.0493212 (* 1 = 0.0493212 loss)
I0820 10:08:23.035123 12052 sgd_solver.cpp:112] Iteration 35300, lr = 0.001
I0820 10:08:26.942072 12052 solver.cpp:239] Iteration 35400 (25.5955 iter/s, 3.90694s/100 iters), loss = 0.0456926
I0820 10:08:26.942112 12052 solver.cpp:258]     Train net output #0: landmark_loss = 0.0456926 (* 1 = 0.0456926 loss)
I0820 10:08:26.942118 12052 sgd_solver.cpp:112] Iteration 35400, lr = 0.001
I0820 10:08:30.848592 12052 solver.cpp:239] Iteration 35500 (25.5986 iter/s, 3.90646s/100 iters), loss = 0.0515569
I0820 10:08:30.848632 12052 solver.cpp:258]     Train net output #0: landmark_loss = 0.0515569 (* 1 = 0.0515569 loss)
I0820 10:08:30.848639 12052 sgd_solver.cpp:112] Iteration 35500, lr = 0.001
I0820 10:08:34.754995 12052 solver.cpp:239] Iteration 35600 (25.5994 iter/s, 3.90634s/100 iters), loss = 0.0463917
I0820 10:08:34.755038 12052 solver.cpp:258]     Train net output #0: landmark_loss = 0.0463917 (* 1 = 0.0463917 loss)
I0820 10:08:34.755043 12052 sgd_solver.cpp:112] Iteration 35600, lr = 0.001
I0820 10:08:38.661406 12052 solver.cpp:239] Iteration 35700 (25.5993 iter/s, 3.90635s/100 iters), loss = 0.0544887
I0820 10:08:38.661445 12052 solver.cpp:258]     Train net output #0: landmark_loss = 0.0544887 (* 1 = 0.0544887 loss)
I0820 10:08:38.661451 12052 sgd_solver.cpp:112] Iteration 35700, lr = 0.001
I0820 10:08:42.567673 12052 solver.cpp:239] Iteration 35800 (25.6003 iter/s, 3.90621s/100 iters), loss = 0.045015
I0820 10:08:42.567713 12052 solver.cpp:258]     Train net output #0: landmark_loss = 0.045015 (* 1 = 0.045015 loss)
I0820 10:08:42.567719 12052 sgd_solver.cpp:112] Iteration 35800, lr = 0.001
I0820 10:08:46.473778 12052 solver.cpp:239] Iteration 35900 (25.6013 iter/s, 3.90605s/100 iters), loss = 0.0491122
I0820 10:08:46.473819 12052 solver.cpp:258]     Train net output #0: landmark_loss = 0.0491121 (* 1 = 0.0491121 loss)
I0820 10:08:46.473824 12052 sgd_solver.cpp:112] Iteration 35900, lr = 0.001
I0820 10:08:50.324332 12052 solver.cpp:347] Iteration 36000, Testing net (#0)
I0820 10:09:05.200748 12052 solver.cpp:414]     Test net output #0: landmark_loss = 0.0364604 (* 1 = 0.0364604 loss)
I0820 10:09:05.239456 12052 solver.cpp:239] Iteration 36000 (5.3289 iter/s, 18.7656s/100 iters), loss = 0.0493269
I0820 10:09:05.239485 12052 solver.cpp:258]     Train net output #0: landmark_loss = 0.0493269 (* 1 = 0.0493269 loss)
I0820 10:09:05.239491 12052 sgd_solver.cpp:112] Iteration 36000, lr = 0.001
I0820 10:09:09.145678 12052 solver.cpp:239] Iteration 36100 (25.6005 iter/s, 3.90618s/100 iters), loss = 0.0467296
I0820 10:09:09.145720 12052 solver.cpp:258]     Train net output #0: landmark_loss = 0.0467295 (* 1 = 0.0467295 loss)
I0820 10:09:09.145725 12052 sgd_solver.cpp:112] Iteration 36100, lr = 0.001
I0820 10:09:13.052368 12052 solver.cpp:239] Iteration 36200 (25.5975 iter/s, 3.90663s/100 iters), loss = 0.0516408
I0820 10:09:13.052408 12052 solver.cpp:258]     Train net output #0: landmark_loss = 0.0516407 (* 1 = 0.0516407 loss)
I0820 10:09:13.052414 12052 sgd_solver.cpp:112] Iteration 36200, lr = 0.001
I0820 10:09:16.959633 12052 solver.cpp:239] Iteration 36300 (25.5937 iter/s, 3.90721s/100 iters), loss = 0.048013
I0820 10:09:16.959676 12052 solver.cpp:258]     Train net output #0: landmark_loss = 0.048013 (* 1 = 0.048013 loss)
I0820 10:09:16.959681 12052 sgd_solver.cpp:112] Iteration 36300, lr = 0.001
I0820 10:09:20.866226 12052 solver.cpp:239] Iteration 36400 (25.5981 iter/s, 3.90653s/100 iters), loss = 0.045846
I0820 10:09:20.866268 12052 solver.cpp:258]     Train net output #0: landmark_loss = 0.045846 (* 1 = 0.045846 loss)
I0820 10:09:20.866273 12052 sgd_solver.cpp:112] Iteration 36400, lr = 0.001
I0820 10:09:24.772352 12052 solver.cpp:239] Iteration 36500 (25.6012 iter/s, 3.90607s/100 iters), loss = 0.044373
I0820 10:09:24.772393 12052 solver.cpp:258]     Train net output #0: landmark_loss = 0.0443729 (* 1 = 0.0443729 loss)
I0820 10:09:24.772399 12052 sgd_solver.cpp:112] Iteration 36500, lr = 0.001
I0820 10:09:28.678838 12052 solver.cpp:239] Iteration 36600 (25.5988 iter/s, 3.90643s/100 iters), loss = 0.04455
I0820 10:09:28.678879 12052 solver.cpp:258]     Train net output #0: landmark_loss = 0.04455 (* 1 = 0.04455 loss)
I0820 10:09:28.678885 12052 sgd_solver.cpp:112] Iteration 36600, lr = 0.001
I0820 10:09:32.585253 12052 solver.cpp:239] Iteration 36700 (25.5993 iter/s, 3.90636s/100 iters), loss = 0.0494608
I0820 10:09:32.585295 12052 solver.cpp:258]     Train net output #0: landmark_loss = 0.0494607 (* 1 = 0.0494607 loss)
I0820 10:09:32.585301 12052 sgd_solver.cpp:112] Iteration 36700, lr = 0.001
I0820 10:09:36.491631 12052 solver.cpp:239] Iteration 36800 (25.5995 iter/s, 3.90632s/100 iters), loss = 0.0458381
I0820 10:09:36.491672 12052 solver.cpp:258]     Train net output #0: landmark_loss = 0.0458381 (* 1 = 0.0458381 loss)
I0820 10:09:36.491677 12052 sgd_solver.cpp:112] Iteration 36800, lr = 0.001
I0820 10:09:40.398085 12052 solver.cpp:239] Iteration 36900 (25.599 iter/s, 3.9064s/100 iters), loss = 0.0532568
I0820 10:09:40.398128 12052 solver.cpp:258]     Train net output #0: landmark_loss = 0.0532567 (* 1 = 0.0532567 loss)
I0820 10:09:40.398133 12052 sgd_solver.cpp:112] Iteration 36900, lr = 0.001
I0820 10:09:44.304225 12052 solver.cpp:239] Iteration 37000 (25.6011 iter/s, 3.90608s/100 iters), loss = 0.0471957
I0820 10:09:44.304265 12052 solver.cpp:258]     Train net output #0: landmark_loss = 0.0471957 (* 1 = 0.0471957 loss)
I0820 10:09:44.304271 12052 sgd_solver.cpp:112] Iteration 37000, lr = 0.001
I0820 10:09:48.210296 12052 solver.cpp:239] Iteration 37100 (25.6015 iter/s, 3.90601s/100 iters), loss = 0.0489565
I0820 10:09:48.210337 12052 solver.cpp:258]     Train net output #0: landmark_loss = 0.0489565 (* 1 = 0.0489565 loss)
I0820 10:09:48.210342 12052 sgd_solver.cpp:112] Iteration 37100, lr = 0.001
I0820 10:09:52.116921 12052 solver.cpp:239] Iteration 37200 (25.5979 iter/s, 3.90657s/100 iters), loss = 0.0490063
I0820 10:09:52.116962 12052 solver.cpp:258]     Train net output #0: landmark_loss = 0.0490062 (* 1 = 0.0490062 loss)
I0820 10:09:52.116967 12052 sgd_solver.cpp:112] Iteration 37200, lr = 0.001
I0820 10:09:56.026067 12052 solver.cpp:239] Iteration 37300 (25.5814 iter/s, 3.90909s/100 iters), loss = 0.0499458
I0820 10:09:56.026108 12052 solver.cpp:258]     Train net output #0: landmark_loss = 0.0499458 (* 1 = 0.0499458 loss)
I0820 10:09:56.026114 12052 sgd_solver.cpp:112] Iteration 37300, lr = 0.001
I0820 10:09:59.932691 12052 solver.cpp:239] Iteration 37400 (25.5979 iter/s, 3.90657s/100 iters), loss = 0.045602
I0820 10:09:59.932732 12052 solver.cpp:258]     Train net output #0: landmark_loss = 0.0456019 (* 1 = 0.0456019 loss)
I0820 10:09:59.932737 12052 sgd_solver.cpp:112] Iteration 37400, lr = 0.001
I0820 10:10:03.892323 12052 solver.cpp:239] Iteration 37500 (25.2552 iter/s, 3.95958s/100 iters), loss = 0.0423186
I0820 10:10:03.892377 12052 solver.cpp:258]     Train net output #0: landmark_loss = 0.0423186 (* 1 = 0.0423186 loss)
I0820 10:10:03.892383 12052 sgd_solver.cpp:112] Iteration 37500, lr = 0.001
I0820 10:10:07.807649 12052 solver.cpp:239] Iteration 37600 (25.5411 iter/s, 3.91526s/100 iters), loss = 0.0488011
I0820 10:10:07.807690 12052 solver.cpp:258]     Train net output #0: landmark_loss = 0.0488011 (* 1 = 0.0488011 loss)
I0820 10:10:07.807696 12052 sgd_solver.cpp:112] Iteration 37600, lr = 0.001
I0820 10:10:11.714131 12052 solver.cpp:239] Iteration 37700 (25.5988 iter/s, 3.90643s/100 iters), loss = 0.0443535
I0820 10:10:11.714172 12052 solver.cpp:258]     Train net output #0: landmark_loss = 0.0443535 (* 1 = 0.0443535 loss)
I0820 10:10:11.714179 12052 sgd_solver.cpp:112] Iteration 37700, lr = 0.001
I0820 10:10:15.620580 12052 solver.cpp:239] Iteration 37800 (25.5991 iter/s, 3.90639s/100 iters), loss = 0.0477075
I0820 10:10:15.620621 12052 solver.cpp:258]     Train net output #0: landmark_loss = 0.0477075 (* 1 = 0.0477075 loss)
I0820 10:10:15.620627 12052 sgd_solver.cpp:112] Iteration 37800, lr = 0.001
I0820 10:10:19.526619 12052 solver.cpp:239] Iteration 37900 (25.6017 iter/s, 3.90598s/100 iters), loss = 0.0555149
I0820 10:10:19.526661 12052 solver.cpp:258]     Train net output #0: landmark_loss = 0.0555149 (* 1 = 0.0555149 loss)
I0820 10:10:19.526666 12052 sgd_solver.cpp:112] Iteration 37900, lr = 0.001
I0820 10:10:23.432997 12052 solver.cpp:239] Iteration 38000 (25.5995 iter/s, 3.90632s/100 iters), loss = 0.0468488
I0820 10:10:23.433039 12052 solver.cpp:258]     Train net output #0: landmark_loss = 0.0468488 (* 1 = 0.0468488 loss)
I0820 10:10:23.433045 12052 sgd_solver.cpp:112] Iteration 38000, lr = 0.001
I0820 10:10:27.338984 12052 solver.cpp:239] Iteration 38100 (25.6021 iter/s, 3.90593s/100 iters), loss = 0.064566
I0820 10:10:27.339023 12052 solver.cpp:258]     Train net output #0: landmark_loss = 0.064566 (* 1 = 0.064566 loss)
I0820 10:10:27.339030 12052 sgd_solver.cpp:112] Iteration 38100, lr = 0.001
I0820 10:10:31.245415 12052 solver.cpp:239] Iteration 38200 (25.5992 iter/s, 3.90638s/100 iters), loss = 0.0443891
I0820 10:10:31.245456 12052 solver.cpp:258]     Train net output #0: landmark_loss = 0.0443891 (* 1 = 0.0443891 loss)
I0820 10:10:31.245462 12052 sgd_solver.cpp:112] Iteration 38200, lr = 0.001
I0820 10:10:35.151301 12052 solver.cpp:239] Iteration 38300 (25.6027 iter/s, 3.90583s/100 iters), loss = 0.0445054
I0820 10:10:35.151340 12052 solver.cpp:258]     Train net output #0: landmark_loss = 0.0445053 (* 1 = 0.0445053 loss)
I0820 10:10:35.151346 12052 sgd_solver.cpp:112] Iteration 38300, lr = 0.001
I0820 10:10:39.057287 12052 solver.cpp:239] Iteration 38400 (25.6021 iter/s, 3.90593s/100 iters), loss = 0.0445292
I0820 10:10:39.057329 12052 solver.cpp:258]     Train net output #0: landmark_loss = 0.0445292 (* 1 = 0.0445292 loss)
I0820 10:10:39.057334 12052 sgd_solver.cpp:112] Iteration 38400, lr = 0.001
I0820 10:10:42.963436 12052 solver.cpp:239] Iteration 38500 (25.601 iter/s, 3.90609s/100 iters), loss = 0.0454881
I0820 10:10:42.963477 12052 solver.cpp:258]     Train net output #0: landmark_loss = 0.0454881 (* 1 = 0.0454881 loss)
I0820 10:10:42.963485 12052 sgd_solver.cpp:112] Iteration 38500, lr = 0.001
I0820 10:10:46.869623 12052 solver.cpp:239] Iteration 38600 (25.6008 iter/s, 3.90613s/100 iters), loss = 0.0495773
I0820 10:10:46.869664 12052 solver.cpp:258]     Train net output #0: landmark_loss = 0.0495772 (* 1 = 0.0495772 loss)
I0820 10:10:46.869670 12052 sgd_solver.cpp:112] Iteration 38600, lr = 0.001
I0820 10:10:50.776024 12052 solver.cpp:239] Iteration 38700 (25.5994 iter/s, 3.90635s/100 iters), loss = 0.0497352
I0820 10:10:50.776065 12052 solver.cpp:258]     Train net output #0: landmark_loss = 0.0497352 (* 1 = 0.0497352 loss)
I0820 10:10:50.776072 12052 sgd_solver.cpp:112] Iteration 38700, lr = 0.001
I0820 10:10:54.682204 12052 solver.cpp:239] Iteration 38800 (25.6008 iter/s, 3.90612s/100 iters), loss = 0.0461824
I0820 10:10:54.682245 12052 solver.cpp:258]     Train net output #0: landmark_loss = 0.0461824 (* 1 = 0.0461824 loss)
I0820 10:10:54.682250 12052 sgd_solver.cpp:112] Iteration 38800, lr = 0.001
I0820 10:10:58.588685 12052 solver.cpp:239] Iteration 38900 (25.5988 iter/s, 3.90643s/100 iters), loss = 0.0458722
I0820 10:10:58.588726 12052 solver.cpp:258]     Train net output #0: landmark_loss = 0.0458722 (* 1 = 0.0458722 loss)
I0820 10:10:58.588730 12052 sgd_solver.cpp:112] Iteration 38900, lr = 0.001
I0820 10:11:02.533114 12052 solver.cpp:239] Iteration 39000 (25.3526 iter/s, 3.94438s/100 iters), loss = 0.0487556
I0820 10:11:02.533169 12052 solver.cpp:258]     Train net output #0: landmark_loss = 0.0487556 (* 1 = 0.0487556 loss)
I0820 10:11:02.533175 12052 sgd_solver.cpp:112] Iteration 39000, lr = 0.001
I0820 10:11:06.447299 12052 solver.cpp:239] Iteration 39100 (25.5485 iter/s, 3.91412s/100 iters), loss = 0.04703
I0820 10:11:06.447340 12052 solver.cpp:258]     Train net output #0: landmark_loss = 0.04703 (* 1 = 0.04703 loss)
I0820 10:11:06.447346 12052 sgd_solver.cpp:112] Iteration 39100, lr = 0.001
I0820 10:11:10.353582 12052 solver.cpp:239] Iteration 39200 (25.6001 iter/s, 3.90623s/100 iters), loss = 0.0606054
I0820 10:11:10.353624 12052 solver.cpp:258]     Train net output #0: landmark_loss = 0.0606054 (* 1 = 0.0606054 loss)
I0820 10:11:10.353631 12052 sgd_solver.cpp:112] Iteration 39200, lr = 0.001
I0820 10:11:14.260087 12052 solver.cpp:239] Iteration 39300 (25.5987 iter/s, 3.90645s/100 iters), loss = 0.0608696
I0820 10:11:14.260128 12052 solver.cpp:258]     Train net output #0: landmark_loss = 0.0608696 (* 1 = 0.0608696 loss)
I0820 10:11:14.260138 12052 sgd_solver.cpp:112] Iteration 39300, lr = 0.001
I0820 10:11:18.166368 12052 solver.cpp:239] Iteration 39400 (25.6002 iter/s, 3.90623s/100 iters), loss = 0.0427933
I0820 10:11:18.166409 12052 solver.cpp:258]     Train net output #0: landmark_loss = 0.0427932 (* 1 = 0.0427932 loss)
I0820 10:11:18.166414 12052 sgd_solver.cpp:112] Iteration 39400, lr = 0.001
I0820 10:11:22.072824 12052 solver.cpp:239] Iteration 39500 (25.599 iter/s, 3.90641s/100 iters), loss = 0.0467005
I0820 10:11:22.072865 12052 solver.cpp:258]     Train net output #0: landmark_loss = 0.0467004 (* 1 = 0.0467004 loss)
I0820 10:11:22.072870 12052 sgd_solver.cpp:112] Iteration 39500, lr = 0.001
I0820 10:11:25.978991 12052 solver.cpp:239] Iteration 39600 (25.6009 iter/s, 3.90611s/100 iters), loss = 0.0430215
I0820 10:11:25.979032 12052 solver.cpp:258]     Train net output #0: landmark_loss = 0.0430215 (* 1 = 0.0430215 loss)
I0820 10:11:25.979038 12052 sgd_solver.cpp:112] Iteration 39600, lr = 0.001
I0820 10:11:29.885051 12052 solver.cpp:239] Iteration 39700 (25.6016 iter/s, 3.90601s/100 iters), loss = 0.0490103
I0820 10:11:29.885092 12052 solver.cpp:258]     Train net output #0: landmark_loss = 0.0490103 (* 1 = 0.0490103 loss)
I0820 10:11:29.885097 12052 sgd_solver.cpp:112] Iteration 39700, lr = 0.001
I0820 10:11:33.791445 12052 solver.cpp:239] Iteration 39800 (25.5994 iter/s, 3.90634s/100 iters), loss = 0.0487334
I0820 10:11:33.791486 12052 solver.cpp:258]     Train net output #0: landmark_loss = 0.0487334 (* 1 = 0.0487334 loss)
I0820 10:11:33.791492 12052 sgd_solver.cpp:112] Iteration 39800, lr = 0.001
I0820 10:11:37.698392 12052 solver.cpp:239] Iteration 39900 (25.5958 iter/s, 3.90689s/100 iters), loss = 0.0627219
I0820 10:11:37.698433 12052 solver.cpp:258]     Train net output #0: landmark_loss = 0.0627219 (* 1 = 0.0627219 loss)
I0820 10:11:37.698439 12052 sgd_solver.cpp:112] Iteration 39900, lr = 0.001
I0820 10:11:41.548369 12052 solver.cpp:464] Snapshotting to binary proto file ./model/M3_iter_40000.caffemodel
I0820 10:11:41.650485 12052 sgd_solver.cpp:284] Snapshotting solver state to binary proto file ./model/M3_iter_40000.solverstate
I0820 10:11:41.741784 12052 solver.cpp:239] Iteration 40000 (24.732 iter/s, 4.04334s/100 iters), loss = 0.0470896
I0820 10:11:41.741825 12052 solver.cpp:258]     Train net output #0: landmark_loss = 0.0470896 (* 1 = 0.0470896 loss)
I0820 10:11:41.741832 12052 sgd_solver.cpp:112] Iteration 40000, lr = 0.001
I0820 10:11:45.647872 12052 solver.cpp:239] Iteration 40100 (25.6014 iter/s, 3.90604s/100 iters), loss = 0.0442487
I0820 10:11:45.647913 12052 solver.cpp:258]     Train net output #0: landmark_loss = 0.0442487 (* 1 = 0.0442487 loss)
I0820 10:11:45.647919 12052 sgd_solver.cpp:112] Iteration 40100, lr = 0.001
I0820 10:11:49.553967 12052 solver.cpp:239] Iteration 40200 (25.6014 iter/s, 3.90604s/100 iters), loss = 0.0453551
I0820 10:11:49.554008 12052 solver.cpp:258]     Train net output #0: landmark_loss = 0.0453551 (* 1 = 0.0453551 loss)
I0820 10:11:49.554013 12052 sgd_solver.cpp:112] Iteration 40200, lr = 0.001
I0820 10:11:53.459828 12052 solver.cpp:239] Iteration 40300 (25.6029 iter/s, 3.90581s/100 iters), loss = 0.0702222
I0820 10:11:53.459870 12052 solver.cpp:258]     Train net output #0: landmark_loss = 0.0702222 (* 1 = 0.0702222 loss)
I0820 10:11:53.459875 12052 sgd_solver.cpp:112] Iteration 40300, lr = 0.001
I0820 10:11:57.367458 12052 solver.cpp:239] Iteration 40400 (25.5913 iter/s, 3.90758s/100 iters), loss = 0.052718
I0820 10:11:57.367499 12052 solver.cpp:258]     Train net output #0: landmark_loss = 0.0527179 (* 1 = 0.0527179 loss)
I0820 10:11:57.367506 12052 sgd_solver.cpp:112] Iteration 40400, lr = 0.001
I0820 10:12:01.300115 12052 solver.cpp:239] Iteration 40500 (25.4284 iter/s, 3.9326s/100 iters), loss = 0.0607411
I0820 10:12:01.300161 12052 solver.cpp:258]     Train net output #0: landmark_loss = 0.060741 (* 1 = 0.060741 loss)
I0820 10:12:01.300168 12052 sgd_solver.cpp:112] Iteration 40500, lr = 0.001
I0820 10:12:05.229647 12052 solver.cpp:239] Iteration 40600 (25.4487 iter/s, 3.92947s/100 iters), loss = 0.0476866
I0820 10:12:05.229701 12052 solver.cpp:258]     Train net output #0: landmark_loss = 0.0476866 (* 1 = 0.0476866 loss)
I0820 10:12:05.229707 12052 sgd_solver.cpp:112] Iteration 40600, lr = 0.001
I0820 10:12:09.141278 12052 solver.cpp:239] Iteration 40700 (25.5652 iter/s, 3.91157s/100 iters), loss = 0.0497346
I0820 10:12:09.141319 12052 solver.cpp:258]     Train net output #0: landmark_loss = 0.0497346 (* 1 = 0.0497346 loss)
I0820 10:12:09.141324 12052 sgd_solver.cpp:112] Iteration 40700, lr = 0.001
I0820 10:12:13.047953 12052 solver.cpp:239] Iteration 40800 (25.5975 iter/s, 3.90662s/100 iters), loss = 0.0455189
I0820 10:12:13.047994 12052 solver.cpp:258]     Train net output #0: landmark_loss = 0.0455189 (* 1 = 0.0455189 loss)
I0820 10:12:13.048000 12052 sgd_solver.cpp:112] Iteration 40800, lr = 0.001
I0820 10:12:16.954290 12052 solver.cpp:239] Iteration 40900 (25.5998 iter/s, 3.90628s/100 iters), loss = 0.0434946
I0820 10:12:16.954330 12052 solver.cpp:258]     Train net output #0: landmark_loss = 0.0434946 (* 1 = 0.0434946 loss)
I0820 10:12:16.954336 12052 sgd_solver.cpp:112] Iteration 40900, lr = 0.001
I0820 10:12:20.860726 12052 solver.cpp:239] Iteration 41000 (25.5991 iter/s, 3.90638s/100 iters), loss = 0.0546054
I0820 10:12:20.860767 12052 solver.cpp:258]     Train net output #0: landmark_loss = 0.0546053 (* 1 = 0.0546053 loss)
I0820 10:12:20.860772 12052 sgd_solver.cpp:112] Iteration 41000, lr = 0.001
I0820 10:12:24.767052 12052 solver.cpp:239] Iteration 41100 (25.5998 iter/s, 3.90627s/100 iters), loss = 0.0515884
I0820 10:12:24.767093 12052 solver.cpp:258]     Train net output #0: landmark_loss = 0.0515884 (* 1 = 0.0515884 loss)
I0820 10:12:24.767099 12052 sgd_solver.cpp:112] Iteration 41100, lr = 0.001
I0820 10:12:28.673466 12052 solver.cpp:239] Iteration 41200 (25.5993 iter/s, 3.90636s/100 iters), loss = 0.0436085
I0820 10:12:28.673508 12052 solver.cpp:258]     Train net output #0: landmark_loss = 0.0436085 (* 1 = 0.0436085 loss)
I0820 10:12:28.673514 12052 sgd_solver.cpp:112] Iteration 41200, lr = 0.001
I0820 10:12:32.579874 12052 solver.cpp:239] Iteration 41300 (25.5993 iter/s, 3.90635s/100 iters), loss = 0.0537664
I0820 10:12:32.579915 12052 solver.cpp:258]     Train net output #0: landmark_loss = 0.0537663 (* 1 = 0.0537663 loss)
I0820 10:12:32.579921 12052 sgd_solver.cpp:112] Iteration 41300, lr = 0.001
I0820 10:12:36.486439 12052 solver.cpp:239] Iteration 41400 (25.5983 iter/s, 3.90651s/100 iters), loss = 0.039393
I0820 10:12:36.486481 12052 solver.cpp:258]     Train net output #0: landmark_loss = 0.039393 (* 1 = 0.039393 loss)
I0820 10:12:36.486487 12052 sgd_solver.cpp:112] Iteration 41400, lr = 0.001
I0820 10:12:40.392766 12052 solver.cpp:239] Iteration 41500 (25.5998 iter/s, 3.90627s/100 iters), loss = 0.0450475
I0820 10:12:40.392807 12052 solver.cpp:258]     Train net output #0: landmark_loss = 0.0450475 (* 1 = 0.0450475 loss)
I0820 10:12:40.392813 12052 sgd_solver.cpp:112] Iteration 41500, lr = 0.001
I0820 10:12:44.299015 12052 solver.cpp:239] Iteration 41600 (25.6003 iter/s, 3.9062s/100 iters), loss = 0.0407808
I0820 10:12:44.299057 12052 solver.cpp:258]     Train net output #0: landmark_loss = 0.0407808 (* 1 = 0.0407808 loss)
I0820 10:12:44.299062 12052 sgd_solver.cpp:112] Iteration 41600, lr = 0.001
I0820 10:12:48.205299 12052 solver.cpp:239] Iteration 41700 (25.6001 iter/s, 3.90623s/100 iters), loss = 0.0439071
I0820 10:12:48.205339 12052 solver.cpp:258]     Train net output #0: landmark_loss = 0.0439071 (* 1 = 0.0439071 loss)
I0820 10:12:48.205345 12052 sgd_solver.cpp:112] Iteration 41700, lr = 0.001
I0820 10:12:52.111475 12052 solver.cpp:239] Iteration 41800 (25.6008 iter/s, 3.90613s/100 iters), loss = 0.0505514
I0820 10:12:52.111515 12052 solver.cpp:258]     Train net output #0: landmark_loss = 0.0505513 (* 1 = 0.0505513 loss)
I0820 10:12:52.111521 12052 sgd_solver.cpp:112] Iteration 41800, lr = 0.001
I0820 10:12:56.017670 12052 solver.cpp:239] Iteration 41900 (25.6007 iter/s, 3.90614s/100 iters), loss = 0.0499576
I0820 10:12:56.017714 12052 solver.cpp:258]     Train net output #0: landmark_loss = 0.0499576 (* 1 = 0.0499576 loss)
I0820 10:12:56.017719 12052 sgd_solver.cpp:112] Iteration 41900, lr = 0.001
I0820 10:12:59.867483 12052 solver.cpp:347] Iteration 42000, Testing net (#0)
I0820 10:13:14.785591 12052 solver.cpp:414]     Test net output #0: landmark_loss = 0.0306495 (* 1 = 0.0306495 loss)
I0820 10:13:14.824252 12052 solver.cpp:239] Iteration 42000 (5.3173 iter/s, 18.8065s/100 iters), loss = 0.0477197
I0820 10:13:14.824280 12052 solver.cpp:258]     Train net output #0: landmark_loss = 0.0477196 (* 1 = 0.0477196 loss)
I0820 10:13:14.824286 12052 sgd_solver.cpp:112] Iteration 42000, lr = 0.001
I0820 10:13:18.730418 12052 solver.cpp:239] Iteration 42100 (25.6008 iter/s, 3.90613s/100 iters), loss = 0.0454849
I0820 10:13:18.730459 12052 solver.cpp:258]     Train net output #0: landmark_loss = 0.0454849 (* 1 = 0.0454849 loss)
I0820 10:13:18.730466 12052 sgd_solver.cpp:112] Iteration 42100, lr = 0.001
I0820 10:13:22.636592 12052 solver.cpp:239] Iteration 42200 (25.6008 iter/s, 3.90612s/100 iters), loss = 0.0640199
I0820 10:13:22.636636 12052 solver.cpp:258]     Train net output #0: landmark_loss = 0.0640198 (* 1 = 0.0640198 loss)
I0820 10:13:22.636641 12052 sgd_solver.cpp:112] Iteration 42200, lr = 0.001
I0820 10:13:26.548810 12052 solver.cpp:239] Iteration 42300 (25.5613 iter/s, 3.91217s/100 iters), loss = 0.0402082
I0820 10:13:26.548866 12052 solver.cpp:258]     Train net output #0: landmark_loss = 0.0402082 (* 1 = 0.0402082 loss)
I0820 10:13:26.548871 12052 sgd_solver.cpp:112] Iteration 42300, lr = 0.001
I0820 10:13:30.456825 12052 solver.cpp:239] Iteration 42400 (25.5889 iter/s, 3.90795s/100 iters), loss = 0.0516811
I0820 10:13:30.456866 12052 solver.cpp:258]     Train net output #0: landmark_loss = 0.0516811 (* 1 = 0.0516811 loss)
I0820 10:13:30.456871 12052 sgd_solver.cpp:112] Iteration 42400, lr = 0.001
I0820 10:13:34.364536 12052 solver.cpp:239] Iteration 42500 (25.5908 iter/s, 3.90766s/100 iters), loss = 0.0424606
I0820 10:13:34.364578 12052 solver.cpp:258]     Train net output #0: landmark_loss = 0.0424606 (* 1 = 0.0424606 loss)
I0820 10:13:34.364583 12052 sgd_solver.cpp:112] Iteration 42500, lr = 0.001
I0820 10:13:38.270661 12052 solver.cpp:239] Iteration 42600 (25.6012 iter/s, 3.90607s/100 iters), loss = 0.0454978
I0820 10:13:38.270702 12052 solver.cpp:258]     Train net output #0: landmark_loss = 0.0454978 (* 1 = 0.0454978 loss)
I0820 10:13:38.270709 12052 sgd_solver.cpp:112] Iteration 42600, lr = 0.001
I0820 10:13:42.176767 12052 solver.cpp:239] Iteration 42700 (25.6013 iter/s, 3.90606s/100 iters), loss = 0.0489251
I0820 10:13:42.176807 12052 solver.cpp:258]     Train net output #0: landmark_loss = 0.048925 (* 1 = 0.048925 loss)
I0820 10:13:42.176813 12052 sgd_solver.cpp:112] Iteration 42700, lr = 0.001
I0820 10:13:46.082667 12052 solver.cpp:239] Iteration 42800 (25.6026 iter/s, 3.90585s/100 iters), loss = 0.0477893
I0820 10:13:46.082708 12052 solver.cpp:258]     Train net output #0: landmark_loss = 0.0477893 (* 1 = 0.0477893 loss)
I0820 10:13:46.082715 12052 sgd_solver.cpp:112] Iteration 42800, lr = 0.001
I0820 10:13:49.989027 12052 solver.cpp:239] Iteration 42900 (25.5996 iter/s, 3.90631s/100 iters), loss = 0.0490525
I0820 10:13:49.989069 12052 solver.cpp:258]     Train net output #0: landmark_loss = 0.0490525 (* 1 = 0.0490525 loss)
I0820 10:13:49.989075 12052 sgd_solver.cpp:112] Iteration 42900, lr = 0.001
I0820 10:13:53.895447 12052 solver.cpp:239] Iteration 43000 (25.5992 iter/s, 3.90637s/100 iters), loss = 0.0451329
I0820 10:13:53.895489 12052 solver.cpp:258]     Train net output #0: landmark_loss = 0.0451328 (* 1 = 0.0451328 loss)
I0820 10:13:53.895494 12052 sgd_solver.cpp:112] Iteration 43000, lr = 0.001
I0820 10:13:57.801635 12052 solver.cpp:239] Iteration 43100 (25.6007 iter/s, 3.90614s/100 iters), loss = 0.0427259
I0820 10:13:57.801676 12052 solver.cpp:258]     Train net output #0: landmark_loss = 0.0427259 (* 1 = 0.0427259 loss)
I0820 10:13:57.801681 12052 sgd_solver.cpp:112] Iteration 43100, lr = 0.001
I0820 10:14:01.738420 12052 solver.cpp:239] Iteration 43200 (25.4018 iter/s, 3.93673s/100 iters), loss = 0.0435698
I0820 10:14:01.738462 12052 solver.cpp:258]     Train net output #0: landmark_loss = 0.0435698 (* 1 = 0.0435698 loss)
I0820 10:14:01.738469 12052 sgd_solver.cpp:112] Iteration 43200, lr = 0.001
I0820 10:14:05.663524 12052 solver.cpp:239] Iteration 43300 (25.4774 iter/s, 3.92505s/100 iters), loss = 0.0407855
I0820 10:14:05.663565 12052 solver.cpp:258]     Train net output #0: landmark_loss = 0.0407855 (* 1 = 0.0407855 loss)
I0820 10:14:05.663571 12052 sgd_solver.cpp:112] Iteration 43300, lr = 0.001
I0820 10:14:09.569571 12052 solver.cpp:239] Iteration 43400 (25.6017 iter/s, 3.906s/100 iters), loss = 0.0473178
I0820 10:14:09.569612 12052 solver.cpp:258]     Train net output #0: landmark_loss = 0.0473177 (* 1 = 0.0473177 loss)
I0820 10:14:09.569617 12052 sgd_solver.cpp:112] Iteration 43400, lr = 0.001
I0820 10:14:13.475883 12052 solver.cpp:239] Iteration 43500 (25.5999 iter/s, 3.90626s/100 iters), loss = 0.0578306
I0820 10:14:13.475924 12052 solver.cpp:258]     Train net output #0: landmark_loss = 0.0578306 (* 1 = 0.0578306 loss)
I0820 10:14:13.475929 12052 sgd_solver.cpp:112] Iteration 43500, lr = 0.001
I0820 10:14:17.382107 12052 solver.cpp:239] Iteration 43600 (25.6005 iter/s, 3.90617s/100 iters), loss = 0.0398417
I0820 10:14:17.382148 12052 solver.cpp:258]     Train net output #0: landmark_loss = 0.0398416 (* 1 = 0.0398416 loss)
I0820 10:14:17.382154 12052 sgd_solver.cpp:112] Iteration 43600, lr = 0.001
I0820 10:14:21.288247 12052 solver.cpp:239] Iteration 43700 (25.601 iter/s, 3.90609s/100 iters), loss = 0.0418526
I0820 10:14:21.288290 12052 solver.cpp:258]     Train net output #0: landmark_loss = 0.0418526 (* 1 = 0.0418526 loss)
I0820 10:14:21.288295 12052 sgd_solver.cpp:112] Iteration 43700, lr = 0.001
I0820 10:14:25.194312 12052 solver.cpp:239] Iteration 43800 (25.6015 iter/s, 3.90601s/100 iters), loss = 0.0486891
I0820 10:14:25.194352 12052 solver.cpp:258]     Train net output #0: landmark_loss = 0.0486891 (* 1 = 0.0486891 loss)
I0820 10:14:25.194358 12052 sgd_solver.cpp:112] Iteration 43800, lr = 0.001
I0820 10:14:29.100450 12052 solver.cpp:239] Iteration 43900 (25.6011 iter/s, 3.90609s/100 iters), loss = 0.0434315
I0820 10:14:29.100489 12052 solver.cpp:258]     Train net output #0: landmark_loss = 0.0434314 (* 1 = 0.0434314 loss)
I0820 10:14:29.100495 12052 sgd_solver.cpp:112] Iteration 43900, lr = 0.001
I0820 10:14:33.006284 12052 solver.cpp:239] Iteration 44000 (25.603 iter/s, 3.90579s/100 iters), loss = 0.0521069
I0820 10:14:33.006325 12052 solver.cpp:258]     Train net output #0: landmark_loss = 0.0521069 (* 1 = 0.0521069 loss)
I0820 10:14:33.006330 12052 sgd_solver.cpp:112] Iteration 44000, lr = 0.001
I0820 10:14:36.912015 12052 solver.cpp:239] Iteration 44100 (25.6037 iter/s, 3.90568s/100 iters), loss = 0.0418094
I0820 10:14:36.912056 12052 solver.cpp:258]     Train net output #0: landmark_loss = 0.0418094 (* 1 = 0.0418094 loss)
I0820 10:14:36.912062 12052 sgd_solver.cpp:112] Iteration 44100, lr = 0.001
I0820 10:14:40.818114 12052 solver.cpp:239] Iteration 44200 (25.6013 iter/s, 3.90605s/100 iters), loss = 0.0468529
I0820 10:14:40.818156 12052 solver.cpp:258]     Train net output #0: landmark_loss = 0.0468529 (* 1 = 0.0468529 loss)
I0820 10:14:40.818161 12052 sgd_solver.cpp:112] Iteration 44200, lr = 0.001
I0820 10:14:44.724561 12052 solver.cpp:239] Iteration 44300 (25.599 iter/s, 3.9064s/100 iters), loss = 0.0477536
I0820 10:14:44.724602 12052 solver.cpp:258]     Train net output #0: landmark_loss = 0.0477536 (* 1 = 0.0477536 loss)
I0820 10:14:44.724608 12052 sgd_solver.cpp:112] Iteration 44300, lr = 0.001
I0820 10:14:48.630760 12052 solver.cpp:239] Iteration 44400 (25.6007 iter/s, 3.90615s/100 iters), loss = 0.0438499
I0820 10:14:48.630800 12052 solver.cpp:258]     Train net output #0: landmark_loss = 0.0438499 (* 1 = 0.0438499 loss)
I0820 10:14:48.630806 12052 sgd_solver.cpp:112] Iteration 44400, lr = 0.001
I0820 10:14:52.537380 12052 solver.cpp:239] Iteration 44500 (25.5979 iter/s, 3.90657s/100 iters), loss = 0.0450487
I0820 10:14:52.537421 12052 solver.cpp:258]     Train net output #0: landmark_loss = 0.0450487 (* 1 = 0.0450487 loss)
I0820 10:14:52.537427 12052 sgd_solver.cpp:112] Iteration 44500, lr = 0.001
I0820 10:14:56.443684 12052 solver.cpp:239] Iteration 44600 (25.6 iter/s, 3.90625s/100 iters), loss = 0.0493127
I0820 10:14:56.443725 12052 solver.cpp:258]     Train net output #0: landmark_loss = 0.0493127 (* 1 = 0.0493127 loss)
I0820 10:14:56.443732 12052 sgd_solver.cpp:112] Iteration 44600, lr = 0.001
I0820 10:15:00.366663 12052 solver.cpp:239] Iteration 44700 (25.4912 iter/s, 3.92293s/100 iters), loss = 0.0438073
I0820 10:15:00.366706 12052 solver.cpp:258]     Train net output #0: landmark_loss = 0.0438072 (* 1 = 0.0438072 loss)
I0820 10:15:00.366714 12052 sgd_solver.cpp:112] Iteration 44700, lr = 0.001
I0820 10:15:04.306171 12052 solver.cpp:239] Iteration 44800 (25.3842 iter/s, 3.93946s/100 iters), loss = 0.0574245
I0820 10:15:04.306212 12052 solver.cpp:258]     Train net output #0: landmark_loss = 0.0574244 (* 1 = 0.0574244 loss)
I0820 10:15:04.306218 12052 sgd_solver.cpp:112] Iteration 44800, lr = 0.001
I0820 10:15:08.212199 12052 solver.cpp:239] Iteration 44900 (25.6018 iter/s, 3.90598s/100 iters), loss = 0.0475189
I0820 10:15:08.212239 12052 solver.cpp:258]     Train net output #0: landmark_loss = 0.0475188 (* 1 = 0.0475188 loss)
I0820 10:15:08.212245 12052 sgd_solver.cpp:112] Iteration 44900, lr = 0.001
I0820 10:15:12.118592 12052 solver.cpp:239] Iteration 45000 (25.5994 iter/s, 3.90634s/100 iters), loss = 0.0504108
I0820 10:15:12.118631 12052 solver.cpp:258]     Train net output #0: landmark_loss = 0.0504107 (* 1 = 0.0504107 loss)
I0820 10:15:12.118636 12052 sgd_solver.cpp:112] Iteration 45000, lr = 0.001
I0820 10:15:16.025513 12052 solver.cpp:239] Iteration 45100 (25.5959 iter/s, 3.90687s/100 iters), loss = 0.0432971
I0820 10:15:16.025554 12052 solver.cpp:258]     Train net output #0: landmark_loss = 0.0432971 (* 1 = 0.0432971 loss)
I0820 10:15:16.025560 12052 sgd_solver.cpp:112] Iteration 45100, lr = 0.001
I0820 10:15:19.932020 12052 solver.cpp:239] Iteration 45200 (25.5986 iter/s, 3.90646s/100 iters), loss = 0.0506046
I0820 10:15:19.932061 12052 solver.cpp:258]     Train net output #0: landmark_loss = 0.0506045 (* 1 = 0.0506045 loss)
I0820 10:15:19.932067 12052 sgd_solver.cpp:112] Iteration 45200, lr = 0.001
I0820 10:15:23.838151 12052 solver.cpp:239] Iteration 45300 (25.6011 iter/s, 3.90608s/100 iters), loss = 0.0411063
I0820 10:15:23.838192 12052 solver.cpp:258]     Train net output #0: landmark_loss = 0.0411063 (* 1 = 0.0411063 loss)
I0820 10:15:23.838198 12052 sgd_solver.cpp:112] Iteration 45300, lr = 0.001
I0820 10:15:27.744895 12052 solver.cpp:239] Iteration 45400 (25.5971 iter/s, 3.90669s/100 iters), loss = 0.0511891
I0820 10:15:27.744936 12052 solver.cpp:258]     Train net output #0: landmark_loss = 0.0511891 (* 1 = 0.0511891 loss)
I0820 10:15:27.744942 12052 sgd_solver.cpp:112] Iteration 45400, lr = 0.001
I0820 10:15:31.651145 12052 solver.cpp:239] Iteration 45500 (25.6003 iter/s, 3.9062s/100 iters), loss = 0.0449656
I0820 10:15:31.651186 12052 solver.cpp:258]     Train net output #0: landmark_loss = 0.0449656 (* 1 = 0.0449656 loss)
I0820 10:15:31.651192 12052 sgd_solver.cpp:112] Iteration 45500, lr = 0.001
I0820 10:15:35.557534 12052 solver.cpp:239] Iteration 45600 (25.5994 iter/s, 3.90634s/100 iters), loss = 0.0497235
I0820 10:15:35.557575 12052 solver.cpp:258]     Train net output #0: landmark_loss = 0.0497235 (* 1 = 0.0497235 loss)
I0820 10:15:35.557580 12052 sgd_solver.cpp:112] Iteration 45600, lr = 0.001
I0820 10:15:39.464663 12052 solver.cpp:239] Iteration 45700 (25.5945 iter/s, 3.90708s/100 iters), loss = 0.0414099
I0820 10:15:39.464716 12052 solver.cpp:258]     Train net output #0: landmark_loss = 0.0414099 (* 1 = 0.0414099 loss)
I0820 10:15:39.464722 12052 sgd_solver.cpp:112] Iteration 45700, lr = 0.001
I0820 10:15:43.371371 12052 solver.cpp:239] Iteration 45800 (25.5974 iter/s, 3.90665s/100 iters), loss = 0.0436303
I0820 10:15:43.371412 12052 solver.cpp:258]     Train net output #0: landmark_loss = 0.0436303 (* 1 = 0.0436303 loss)
I0820 10:15:43.371418 12052 sgd_solver.cpp:112] Iteration 45800, lr = 0.001
I0820 10:15:47.277488 12052 solver.cpp:239] Iteration 45900 (25.6012 iter/s, 3.90607s/100 iters), loss = 0.0473343
I0820 10:15:47.277530 12052 solver.cpp:258]     Train net output #0: landmark_loss = 0.0473343 (* 1 = 0.0473343 loss)
I0820 10:15:47.277536 12052 sgd_solver.cpp:112] Iteration 45900, lr = 0.001
I0820 10:15:51.183562 12052 solver.cpp:239] Iteration 46000 (25.6015 iter/s, 3.90602s/100 iters), loss = 0.0526293
I0820 10:15:51.183604 12052 solver.cpp:258]     Train net output #0: landmark_loss = 0.0526293 (* 1 = 0.0526293 loss)
I0820 10:15:51.183609 12052 sgd_solver.cpp:112] Iteration 46000, lr = 0.001
I0820 10:15:55.089601 12052 solver.cpp:239] Iteration 46100 (25.6017 iter/s, 3.90599s/100 iters), loss = 0.0468993
I0820 10:15:55.089643 12052 solver.cpp:258]     Train net output #0: landmark_loss = 0.0468992 (* 1 = 0.0468992 loss)
I0820 10:15:55.089648 12052 sgd_solver.cpp:112] Iteration 46100, lr = 0.001
I0820 10:15:58.995923 12052 solver.cpp:239] Iteration 46200 (25.5998 iter/s, 3.90627s/100 iters), loss = 0.0423016
I0820 10:15:58.995965 12052 solver.cpp:258]     Train net output #0: landmark_loss = 0.0423016 (* 1 = 0.0423016 loss)
I0820 10:15:58.995970 12052 sgd_solver.cpp:112] Iteration 46200, lr = 0.001
I0820 10:16:02.943981 12052 solver.cpp:239] Iteration 46300 (25.3292 iter/s, 3.94801s/100 iters), loss = 0.0389275
I0820 10:16:02.944023 12052 solver.cpp:258]     Train net output #0: landmark_loss = 0.0389275 (* 1 = 0.0389275 loss)
I0820 10:16:02.944030 12052 sgd_solver.cpp:112] Iteration 46300, lr = 0.001
I0820 10:16:06.856413 12052 solver.cpp:239] Iteration 46400 (25.5598 iter/s, 3.91239s/100 iters), loss = 0.0579892
I0820 10:16:06.856467 12052 solver.cpp:258]     Train net output #0: landmark_loss = 0.0579892 (* 1 = 0.0579892 loss)
I0820 10:16:06.856483 12052 sgd_solver.cpp:112] Iteration 46400, lr = 0.001
I0820 10:16:10.762986 12052 solver.cpp:239] Iteration 46500 (25.5983 iter/s, 3.90651s/100 iters), loss = 0.0444216
I0820 10:16:10.763027 12052 solver.cpp:258]     Train net output #0: landmark_loss = 0.0444216 (* 1 = 0.0444216 loss)
I0820 10:16:10.763032 12052 sgd_solver.cpp:112] Iteration 46500, lr = 0.001
I0820 10:16:14.669353 12052 solver.cpp:239] Iteration 46600 (25.5996 iter/s, 3.90632s/100 iters), loss = 0.0427475
I0820 10:16:14.669394 12052 solver.cpp:258]     Train net output #0: landmark_loss = 0.0427475 (* 1 = 0.0427475 loss)
I0820 10:16:14.669399 12052 sgd_solver.cpp:112] Iteration 46600, lr = 0.001
I0820 10:16:18.575431 12052 solver.cpp:239] Iteration 46700 (25.6014 iter/s, 3.90603s/100 iters), loss = 0.0433762
I0820 10:16:18.575474 12052 solver.cpp:258]     Train net output #0: landmark_loss = 0.0433762 (* 1 = 0.0433762 loss)
I0820 10:16:18.575479 12052 sgd_solver.cpp:112] Iteration 46700, lr = 0.001
I0820 10:16:22.481353 12052 solver.cpp:239] Iteration 46800 (25.6025 iter/s, 3.90587s/100 iters), loss = 0.0547712
I0820 10:16:22.481393 12052 solver.cpp:258]     Train net output #0: landmark_loss = 0.0547712 (* 1 = 0.0547712 loss)
I0820 10:16:22.481400 12052 sgd_solver.cpp:112] Iteration 46800, lr = 0.001
I0820 10:16:26.387723 12052 solver.cpp:239] Iteration 46900 (25.5995 iter/s, 3.90632s/100 iters), loss = 0.0448974
I0820 10:16:26.387764 12052 solver.cpp:258]     Train net output #0: landmark_loss = 0.0448974 (* 1 = 0.0448974 loss)
I0820 10:16:26.387770 12052 sgd_solver.cpp:112] Iteration 46900, lr = 0.001
I0820 10:16:30.294222 12052 solver.cpp:239] Iteration 47000 (25.5987 iter/s, 3.90645s/100 iters), loss = 0.039322
I0820 10:16:30.294263 12052 solver.cpp:258]     Train net output #0: landmark_loss = 0.039322 (* 1 = 0.039322 loss)
I0820 10:16:30.294268 12052 sgd_solver.cpp:112] Iteration 47000, lr = 0.001
I0820 10:16:34.200302 12052 solver.cpp:239] Iteration 47100 (25.6014 iter/s, 3.90603s/100 iters), loss = 0.0437842
I0820 10:16:34.200343 12052 solver.cpp:258]     Train net output #0: landmark_loss = 0.0437841 (* 1 = 0.0437841 loss)
I0820 10:16:34.200350 12052 sgd_solver.cpp:112] Iteration 47100, lr = 0.001
I0820 10:16:38.106395 12052 solver.cpp:239] Iteration 47200 (25.6013 iter/s, 3.90604s/100 iters), loss = 0.047468
I0820 10:16:38.106436 12052 solver.cpp:258]     Train net output #0: landmark_loss = 0.047468 (* 1 = 0.047468 loss)
I0820 10:16:38.106441 12052 sgd_solver.cpp:112] Iteration 47200, lr = 0.001
I0820 10:16:42.012527 12052 solver.cpp:239] Iteration 47300 (25.6011 iter/s, 3.90609s/100 iters), loss = 0.044965
I0820 10:16:42.012567 12052 solver.cpp:258]     Train net output #0: landmark_loss = 0.044965 (* 1 = 0.044965 loss)
I0820 10:16:42.012573 12052 sgd_solver.cpp:112] Iteration 47300, lr = 0.001
I0820 10:16:45.918794 12052 solver.cpp:239] Iteration 47400 (25.6002 iter/s, 3.90622s/100 iters), loss = 0.0536477
I0820 10:16:45.918835 12052 solver.cpp:258]     Train net output #0: landmark_loss = 0.0536477 (* 1 = 0.0536477 loss)
I0820 10:16:45.918840 12052 sgd_solver.cpp:112] Iteration 47400, lr = 0.001
I0820 10:16:49.825045 12052 solver.cpp:239] Iteration 47500 (25.6003 iter/s, 3.9062s/100 iters), loss = 0.047236
I0820 10:16:49.825086 12052 solver.cpp:258]     Train net output #0: landmark_loss = 0.047236 (* 1 = 0.047236 loss)
I0820 10:16:49.825093 12052 sgd_solver.cpp:112] Iteration 47500, lr = 0.001
I0820 10:16:53.731207 12052 solver.cpp:239] Iteration 47600 (25.6009 iter/s, 3.90611s/100 iters), loss = 0.0526121
I0820 10:16:53.731247 12052 solver.cpp:258]     Train net output #0: landmark_loss = 0.0526121 (* 1 = 0.0526121 loss)
I0820 10:16:53.731253 12052 sgd_solver.cpp:112] Iteration 47600, lr = 0.001
I0820 10:16:57.637634 12052 solver.cpp:239] Iteration 47700 (25.5991 iter/s, 3.90638s/100 iters), loss = 0.0429111
I0820 10:16:57.637675 12052 solver.cpp:258]     Train net output #0: landmark_loss = 0.042911 (* 1 = 0.042911 loss)
I0820 10:16:57.637681 12052 sgd_solver.cpp:112] Iteration 47700, lr = 0.001
I0820 10:17:01.572541 12052 solver.cpp:239] Iteration 47800 (25.4139 iter/s, 3.93486s/100 iters), loss = 0.0423361
I0820 10:17:01.572582 12052 solver.cpp:258]     Train net output #0: landmark_loss = 0.0423361 (* 1 = 0.0423361 loss)
I0820 10:17:01.572589 12052 sgd_solver.cpp:112] Iteration 47800, lr = 0.001
I0820 10:17:05.499994 12052 solver.cpp:239] Iteration 47900 (25.4621 iter/s, 3.9274s/100 iters), loss = 0.0412509
I0820 10:17:05.500033 12052 solver.cpp:258]     Train net output #0: landmark_loss = 0.0412509 (* 1 = 0.0412509 loss)
I0820 10:17:05.500039 12052 sgd_solver.cpp:112] Iteration 47900, lr = 0.001
I0820 10:17:09.350332 12052 solver.cpp:347] Iteration 48000, Testing net (#0)
I0820 10:17:24.162454 12052 solver.cpp:414]     Test net output #0: landmark_loss = 0.0307497 (* 1 = 0.0307497 loss)
I0820 10:17:24.201220 12052 solver.cpp:239] Iteration 48000 (5.34725 iter/s, 18.7012s/100 iters), loss = 0.0464056
I0820 10:17:24.201249 12052 solver.cpp:258]     Train net output #0: landmark_loss = 0.0464056 (* 1 = 0.0464056 loss)
I0820 10:17:24.201256 12052 sgd_solver.cpp:112] Iteration 48000, lr = 0.001
I0820 10:17:28.107280 12052 solver.cpp:239] Iteration 48100 (25.6015 iter/s, 3.90602s/100 iters), loss = 0.0470476
I0820 10:17:28.107319 12052 solver.cpp:258]     Train net output #0: landmark_loss = 0.0470476 (* 1 = 0.0470476 loss)
I0820 10:17:28.107326 12052 sgd_solver.cpp:112] Iteration 48100, lr = 0.001
I0820 10:17:32.013826 12052 solver.cpp:239] Iteration 48200 (25.5984 iter/s, 3.9065s/100 iters), loss = 0.0488612
I0820 10:17:32.013865 12052 solver.cpp:258]     Train net output #0: landmark_loss = 0.0488612 (* 1 = 0.0488612 loss)
I0820 10:17:32.013871 12052 sgd_solver.cpp:112] Iteration 48200, lr = 0.001
I0820 10:17:35.919838 12052 solver.cpp:239] Iteration 48300 (25.6019 iter/s, 3.90597s/100 iters), loss = 0.0474517
I0820 10:17:35.919878 12052 solver.cpp:258]     Train net output #0: landmark_loss = 0.0474517 (* 1 = 0.0474517 loss)
I0820 10:17:35.919883 12052 sgd_solver.cpp:112] Iteration 48300, lr = 0.001
I0820 10:17:39.826051 12052 solver.cpp:239] Iteration 48400 (25.6005 iter/s, 3.90617s/100 iters), loss = 0.0456203
I0820 10:17:39.826093 12052 solver.cpp:258]     Train net output #0: landmark_loss = 0.0456203 (* 1 = 0.0456203 loss)
I0820 10:17:39.826098 12052 sgd_solver.cpp:112] Iteration 48400, lr = 0.001
I0820 10:17:43.734952 12052 solver.cpp:239] Iteration 48500 (25.5829 iter/s, 3.90885s/100 iters), loss = 0.0423239
I0820 10:17:43.734993 12052 solver.cpp:258]     Train net output #0: landmark_loss = 0.0423239 (* 1 = 0.0423239 loss)
I0820 10:17:43.734999 12052 sgd_solver.cpp:112] Iteration 48500, lr = 0.001
I0820 10:17:47.641780 12052 solver.cpp:239] Iteration 48600 (25.5965 iter/s, 3.90678s/100 iters), loss = 0.0469351
I0820 10:17:47.641821 12052 solver.cpp:258]     Train net output #0: landmark_loss = 0.0469351 (* 1 = 0.0469351 loss)
I0820 10:17:47.641827 12052 sgd_solver.cpp:112] Iteration 48600, lr = 0.001
I0820 10:17:51.548817 12052 solver.cpp:239] Iteration 48700 (25.5951 iter/s, 3.90699s/100 iters), loss = 0.052311
I0820 10:17:51.548856 12052 solver.cpp:258]     Train net output #0: landmark_loss = 0.0523109 (* 1 = 0.0523109 loss)
I0820 10:17:51.548862 12052 sgd_solver.cpp:112] Iteration 48700, lr = 0.001
I0820 10:17:55.457543 12052 solver.cpp:239] Iteration 48800 (25.5841 iter/s, 3.90868s/100 iters), loss = 0.0448024
I0820 10:17:55.457584 12052 solver.cpp:258]     Train net output #0: landmark_loss = 0.0448024 (* 1 = 0.0448024 loss)
I0820 10:17:55.457590 12052 sgd_solver.cpp:112] Iteration 48800, lr = 0.001
I0820 10:17:59.363217 12052 solver.cpp:239] Iteration 48900 (25.6041 iter/s, 3.90563s/100 iters), loss = 0.0422758
I0820 10:17:59.363257 12052 solver.cpp:258]     Train net output #0: landmark_loss = 0.0422758 (* 1 = 0.0422758 loss)
I0820 10:17:59.363263 12052 sgd_solver.cpp:112] Iteration 48900, lr = 0.001
I0820 10:18:03.313051 12052 solver.cpp:239] Iteration 49000 (25.3178 iter/s, 3.94979s/100 iters), loss = 0.0434014
I0820 10:18:03.313107 12052 solver.cpp:258]     Train net output #0: landmark_loss = 0.0434013 (* 1 = 0.0434013 loss)
I0820 10:18:03.313112 12052 sgd_solver.cpp:112] Iteration 49000, lr = 0.001
I0820 10:18:07.220886 12052 solver.cpp:239] Iteration 49100 (25.59 iter/s, 3.90777s/100 iters), loss = 0.0488214
I0820 10:18:07.220927 12052 solver.cpp:258]     Train net output #0: landmark_loss = 0.0488214 (* 1 = 0.0488214 loss)
I0820 10:18:07.220932 12052 sgd_solver.cpp:112] Iteration 49100, lr = 0.001
I0820 10:18:11.127691 12052 solver.cpp:239] Iteration 49200 (25.5967 iter/s, 3.90676s/100 iters), loss = 0.0486353
I0820 10:18:11.127743 12052 solver.cpp:258]     Train net output #0: landmark_loss = 0.0486353 (* 1 = 0.0486353 loss)
I0820 10:18:11.127748 12052 sgd_solver.cpp:112] Iteration 49200, lr = 0.001
I0820 10:18:15.034705 12052 solver.cpp:239] Iteration 49300 (25.5954 iter/s, 3.90696s/100 iters), loss = 0.0455948
I0820 10:18:15.034745 12052 solver.cpp:258]     Train net output #0: landmark_loss = 0.0455947 (* 1 = 0.0455947 loss)
I0820 10:18:15.034751 12052 sgd_solver.cpp:112] Iteration 49300, lr = 0.001
I0820 10:18:18.940807 12052 solver.cpp:239] Iteration 49400 (25.6013 iter/s, 3.90606s/100 iters), loss = 0.043384
I0820 10:18:18.940848 12052 solver.cpp:258]     Train net output #0: landmark_loss = 0.0433839 (* 1 = 0.0433839 loss)
I0820 10:18:18.940853 12052 sgd_solver.cpp:112] Iteration 49400, lr = 0.001
I0820 10:18:22.847970 12052 solver.cpp:239] Iteration 49500 (25.5943 iter/s, 3.90712s/100 iters), loss = 0.0445647
I0820 10:18:22.848022 12052 solver.cpp:258]     Train net output #0: landmark_loss = 0.0445646 (* 1 = 0.0445646 loss)
I0820 10:18:22.848028 12052 sgd_solver.cpp:112] Iteration 49500, lr = 0.001
I0820 10:18:26.755481 12052 solver.cpp:239] Iteration 49600 (25.5921 iter/s, 3.90745s/100 iters), loss = 0.0434339
I0820 10:18:26.755522 12052 solver.cpp:258]     Train net output #0: landmark_loss = 0.0434339 (* 1 = 0.0434339 loss)
I0820 10:18:26.755527 12052 sgd_solver.cpp:112] Iteration 49600, lr = 0.001
I0820 10:18:30.662187 12052 solver.cpp:239] Iteration 49700 (25.5973 iter/s, 3.90666s/100 iters), loss = 0.0544458
I0820 10:18:30.662227 12052 solver.cpp:258]     Train net output #0: landmark_loss = 0.0544457 (* 1 = 0.0544457 loss)
I0820 10:18:30.662233 12052 sgd_solver.cpp:112] Iteration 49700, lr = 0.001
I0820 10:18:34.568075 12052 solver.cpp:239] Iteration 49800 (25.6027 iter/s, 3.90584s/100 iters), loss = 0.0437446
I0820 10:18:34.568115 12052 solver.cpp:258]     Train net output #0: landmark_loss = 0.0437445 (* 1 = 0.0437445 loss)
I0820 10:18:34.568121 12052 sgd_solver.cpp:112] Iteration 49800, lr = 0.001
I0820 10:18:38.477157 12052 solver.cpp:239] Iteration 49900 (25.5818 iter/s, 3.90904s/100 iters), loss = 0.0366073
I0820 10:18:38.477210 12052 solver.cpp:258]     Train net output #0: landmark_loss = 0.0366072 (* 1 = 0.0366072 loss)
I0820 10:18:38.477216 12052 sgd_solver.cpp:112] Iteration 49900, lr = 0.001
I0820 10:18:42.328804 12052 solver.cpp:464] Snapshotting to binary proto file ./model/M3_iter_50000.caffemodel
I0820 10:18:42.430752 12052 sgd_solver.cpp:284] Snapshotting solver state to binary proto file ./model/M3_iter_50000.solverstate
I0820 10:18:42.522018 12052 solver.cpp:239] Iteration 50000 (24.7231 iter/s, 4.0448s/100 iters), loss = 0.0420487
I0820 10:18:42.522058 12052 solver.cpp:258]     Train net output #0: landmark_loss = 0.0420487 (* 1 = 0.0420487 loss)
I0820 10:18:42.522065 12052 sgd_solver.cpp:112] Iteration 50000, lr = 0.001
I0820 10:18:46.429323 12052 solver.cpp:239] Iteration 50100 (25.5934 iter/s, 3.90726s/100 iters), loss = 0.0422538
I0820 10:18:46.429364 12052 solver.cpp:258]     Train net output #0: landmark_loss = 0.0422537 (* 1 = 0.0422537 loss)
I0820 10:18:46.429370 12052 sgd_solver.cpp:112] Iteration 50100, lr = 0.001
I0820 10:18:50.335254 12052 solver.cpp:239] Iteration 50200 (25.6024 iter/s, 3.90588s/100 iters), loss = 0.0403932
I0820 10:18:50.335296 12052 solver.cpp:258]     Train net output #0: landmark_loss = 0.0403932 (* 1 = 0.0403932 loss)
I0820 10:18:50.335302 12052 sgd_solver.cpp:112] Iteration 50200, lr = 0.001
I0820 10:18:54.241586 12052 solver.cpp:239] Iteration 50300 (25.5998 iter/s, 3.90629s/100 iters), loss = 0.0420961
I0820 10:18:54.241626 12052 solver.cpp:258]     Train net output #0: landmark_loss = 0.0420961 (* 1 = 0.0420961 loss)
I0820 10:18:54.241632 12052 sgd_solver.cpp:112] Iteration 50300, lr = 0.001
I0820 10:18:58.147960 12052 solver.cpp:239] Iteration 50400 (25.5995 iter/s, 3.90633s/100 iters), loss = 0.0449727
I0820 10:18:58.148000 12052 solver.cpp:258]     Train net output #0: landmark_loss = 0.0449727 (* 1 = 0.0449727 loss)
I0820 10:18:58.148006 12052 sgd_solver.cpp:112] Iteration 50400, lr = 0.001
I0820 10:19:02.096899 12052 solver.cpp:239] Iteration 50500 (25.3235 iter/s, 3.9489s/100 iters), loss = 0.0478803
I0820 10:19:02.096940 12052 solver.cpp:258]     Train net output #0: landmark_loss = 0.0478803 (* 1 = 0.0478803 loss)
I0820 10:19:02.096946 12052 sgd_solver.cpp:112] Iteration 50500, lr = 0.001
I0820 10:19:06.020365 12052 solver.cpp:239] Iteration 50600 (25.4879 iter/s, 3.92342s/100 iters), loss = 0.0473059
I0820 10:19:06.020406 12052 solver.cpp:258]     Train net output #0: landmark_loss = 0.0473059 (* 1 = 0.0473059 loss)
I0820 10:19:06.020412 12052 sgd_solver.cpp:112] Iteration 50600, lr = 0.001
I0820 10:19:09.927055 12052 solver.cpp:239] Iteration 50700 (25.5974 iter/s, 3.90664s/100 iters), loss = 0.0430795
I0820 10:19:09.927096 12052 solver.cpp:258]     Train net output #0: landmark_loss = 0.0430795 (* 1 = 0.0430795 loss)
I0820 10:19:09.927103 12052 sgd_solver.cpp:112] Iteration 50700, lr = 0.001
I0820 10:19:13.833166 12052 solver.cpp:239] Iteration 50800 (25.6012 iter/s, 3.90607s/100 iters), loss = 0.0517911
I0820 10:19:13.833206 12052 solver.cpp:258]     Train net output #0: landmark_loss = 0.0517911 (* 1 = 0.0517911 loss)
I0820 10:19:13.833212 12052 sgd_solver.cpp:112] Iteration 50800, lr = 0.001
I0820 10:19:17.739758 12052 solver.cpp:239] Iteration 50900 (25.5981 iter/s, 3.90655s/100 iters), loss = 0.043341
I0820 10:19:17.739799 12052 solver.cpp:258]     Train net output #0: landmark_loss = 0.043341 (* 1 = 0.043341 loss)
I0820 10:19:17.739804 12052 sgd_solver.cpp:112] Iteration 50900, lr = 0.001
I0820 10:19:21.650431 12052 solver.cpp:239] Iteration 51000 (25.5713 iter/s, 3.91063s/100 iters), loss = 0.0496921
I0820 10:19:21.650473 12052 solver.cpp:258]     Train net output #0: landmark_loss = 0.0496921 (* 1 = 0.0496921 loss)
I0820 10:19:21.650478 12052 sgd_solver.cpp:112] Iteration 51000, lr = 0.001
I0820 10:19:25.557533 12052 solver.cpp:239] Iteration 51100 (25.5947 iter/s, 3.90705s/100 iters), loss = 0.0557073
I0820 10:19:25.557586 12052 solver.cpp:258]     Train net output #0: landmark_loss = 0.0557072 (* 1 = 0.0557072 loss)
I0820 10:19:25.557592 12052 sgd_solver.cpp:112] Iteration 51100, lr = 0.001
I0820 10:19:29.464063 12052 solver.cpp:239] Iteration 51200 (25.5985 iter/s, 3.90647s/100 iters), loss = 0.0429616
I0820 10:19:29.464103 12052 solver.cpp:258]     Train net output #0: landmark_loss = 0.0429616 (* 1 = 0.0429616 loss)
I0820 10:19:29.464109 12052 sgd_solver.cpp:112] Iteration 51200, lr = 0.001
I0820 10:19:33.370925 12052 solver.cpp:239] Iteration 51300 (25.5963 iter/s, 3.90682s/100 iters), loss = 0.049394
I0820 10:19:33.370965 12052 solver.cpp:258]     Train net output #0: landmark_loss = 0.0493939 (* 1 = 0.0493939 loss)
I0820 10:19:33.370971 12052 sgd_solver.cpp:112] Iteration 51300, lr = 0.001
I0820 10:19:37.277370 12052 solver.cpp:239] Iteration 51400 (25.599 iter/s, 3.9064s/100 iters), loss = 0.0477307
I0820 10:19:37.277422 12052 solver.cpp:258]     Train net output #0: landmark_loss = 0.0477307 (* 1 = 0.0477307 loss)
I0820 10:19:37.277428 12052 sgd_solver.cpp:112] Iteration 51400, lr = 0.001
I0820 10:19:41.183790 12052 solver.cpp:239] Iteration 51500 (25.5992 iter/s, 3.90637s/100 iters), loss = 0.0493178
I0820 10:19:41.183832 12052 solver.cpp:258]     Train net output #0: landmark_loss = 0.0493178 (* 1 = 0.0493178 loss)
I0820 10:19:41.183838 12052 sgd_solver.cpp:112] Iteration 51500, lr = 0.001
I0820 10:19:45.090713 12052 solver.cpp:239] Iteration 51600 (25.5959 iter/s, 3.90688s/100 iters), loss = 0.041362
I0820 10:19:45.090754 12052 solver.cpp:258]     Train net output #0: landmark_loss = 0.041362 (* 1 = 0.041362 loss)
I0820 10:19:45.090759 12052 sgd_solver.cpp:112] Iteration 51600, lr = 0.001
I0820 10:19:48.997048 12052 solver.cpp:239] Iteration 51700 (25.5997 iter/s, 3.90629s/100 iters), loss = 0.0476748
I0820 10:19:48.997088 12052 solver.cpp:258]     Train net output #0: landmark_loss = 0.0476748 (* 1 = 0.0476748 loss)
I0820 10:19:48.997094 12052 sgd_solver.cpp:112] Iteration 51700, lr = 0.001
I0820 10:19:52.905932 12052 solver.cpp:239] Iteration 51800 (25.583 iter/s, 3.90884s/100 iters), loss = 0.039919
I0820 10:19:52.905973 12052 solver.cpp:258]     Train net output #0: landmark_loss = 0.039919 (* 1 = 0.039919 loss)
I0820 10:19:52.905978 12052 sgd_solver.cpp:112] Iteration 51800, lr = 0.001
I0820 10:19:56.812211 12052 solver.cpp:239] Iteration 51900 (25.6001 iter/s, 3.90623s/100 iters), loss = 0.0421914
I0820 10:19:56.812252 12052 solver.cpp:258]     Train net output #0: landmark_loss = 0.0421914 (* 1 = 0.0421914 loss)
I0820 10:19:56.812258 12052 sgd_solver.cpp:112] Iteration 51900, lr = 0.001
I0820 10:20:00.737582 12052 solver.cpp:239] Iteration 52000 (25.4756 iter/s, 3.92533s/100 iters), loss = 0.0487776
I0820 10:20:00.737625 12052 solver.cpp:258]     Train net output #0: landmark_loss = 0.0487775 (* 1 = 0.0487775 loss)
I0820 10:20:00.737632 12052 sgd_solver.cpp:112] Iteration 52000, lr = 0.001
I0820 10:20:04.673272 12052 solver.cpp:239] Iteration 52100 (25.4088 iter/s, 3.93564s/100 iters), loss = 0.0396659
I0820 10:20:04.673324 12052 solver.cpp:258]     Train net output #0: landmark_loss = 0.0396659 (* 1 = 0.0396659 loss)
I0820 10:20:04.673331 12052 sgd_solver.cpp:112] Iteration 52100, lr = 0.001
I0820 10:20:08.580375 12052 solver.cpp:239] Iteration 52200 (25.5948 iter/s, 3.90705s/100 iters), loss = 0.050611
I0820 10:20:08.580416 12052 solver.cpp:258]     Train net output #0: landmark_loss = 0.0506109 (* 1 = 0.0506109 loss)
I0820 10:20:08.580422 12052 sgd_solver.cpp:112] Iteration 52200, lr = 0.001
I0820 10:20:12.487735 12052 solver.cpp:239] Iteration 52300 (25.593 iter/s, 3.90731s/100 iters), loss = 0.0449769
I0820 10:20:12.487776 12052 solver.cpp:258]     Train net output #0: landmark_loss = 0.0449769 (* 1 = 0.0449769 loss)
I0820 10:20:12.487782 12052 sgd_solver.cpp:112] Iteration 52300, lr = 0.001
I0820 10:20:16.397341 12052 solver.cpp:239] Iteration 52400 (25.5783 iter/s, 3.90956s/100 iters), loss = 0.0485945
I0820 10:20:16.397382 12052 solver.cpp:258]     Train net output #0: landmark_loss = 0.0485945 (* 1 = 0.0485945 loss)
I0820 10:20:16.397387 12052 sgd_solver.cpp:112] Iteration 52400, lr = 0.001
I0820 10:20:20.306488 12052 solver.cpp:239] Iteration 52500 (25.5813 iter/s, 3.9091s/100 iters), loss = 0.0469314
I0820 10:20:20.306530 12052 solver.cpp:258]     Train net output #0: landmark_loss = 0.0469313 (* 1 = 0.0469313 loss)
I0820 10:20:20.306535 12052 sgd_solver.cpp:112] Iteration 52500, lr = 0.001
I0820 10:20:24.213080 12052 solver.cpp:239] Iteration 52600 (25.5981 iter/s, 3.90655s/100 iters), loss = 0.046338
I0820 10:20:24.213122 12052 solver.cpp:258]     Train net output #0: landmark_loss = 0.0463379 (* 1 = 0.0463379 loss)
I0820 10:20:24.213127 12052 sgd_solver.cpp:112] Iteration 52600, lr = 0.001
I0820 10:20:28.120030 12052 solver.cpp:239] Iteration 52700 (25.5957 iter/s, 3.9069s/100 iters), loss = 0.0565801
I0820 10:20:28.120070 12052 solver.cpp:258]     Train net output #0: landmark_loss = 0.0565801 (* 1 = 0.0565801 loss)
I0820 10:20:28.120076 12052 sgd_solver.cpp:112] Iteration 52700, lr = 0.001
I0820 10:20:32.026273 12052 solver.cpp:239] Iteration 52800 (25.6003 iter/s, 3.9062s/100 iters), loss = 0.0433054
I0820 10:20:32.026312 12052 solver.cpp:258]     Train net output #0: landmark_loss = 0.0433054 (* 1 = 0.0433054 loss)
I0820 10:20:32.026319 12052 sgd_solver.cpp:112] Iteration 52800, lr = 0.001
I0820 10:20:35.975615 12052 solver.cpp:239] Iteration 52900 (25.3209 iter/s, 3.9493s/100 iters), loss = 0.045239
I0820 10:20:35.975656 12052 solver.cpp:258]     Train net output #0: landmark_loss = 0.045239 (* 1 = 0.045239 loss)
I0820 10:20:35.975661 12052 sgd_solver.cpp:112] Iteration 52900, lr = 0.001
I0820 10:20:40.432895 12052 solver.cpp:239] Iteration 53000 (22.4357 iter/s, 4.45718s/100 iters), loss = 0.0475002
I0820 10:20:40.432948 12052 solver.cpp:258]     Train net output #0: landmark_loss = 0.0475001 (* 1 = 0.0475001 loss)
I0820 10:20:40.432955 12052 sgd_solver.cpp:112] Iteration 53000, lr = 0.001
I0820 10:20:45.120203 12052 solver.cpp:239] Iteration 53100 (21.3347 iter/s, 4.6872s/100 iters), loss = 0.0419921
I0820 10:20:45.120255 12052 solver.cpp:258]     Train net output #0: landmark_loss = 0.0419921 (* 1 = 0.0419921 loss)
I0820 10:20:45.120261 12052 sgd_solver.cpp:112] Iteration 53100, lr = 0.001
I0820 10:20:49.808305 12052 solver.cpp:239] Iteration 53200 (21.3311 iter/s, 4.688s/100 iters), loss = 0.0444234
I0820 10:20:49.808357 12052 solver.cpp:258]     Train net output #0: landmark_loss = 0.0444233 (* 1 = 0.0444233 loss)
I0820 10:20:49.808362 12052 sgd_solver.cpp:112] Iteration 53200, lr = 0.001
I0820 10:20:54.496160 12052 solver.cpp:239] Iteration 53300 (21.3322 iter/s, 4.68775s/100 iters), loss = 0.0476578
I0820 10:20:54.496213 12052 solver.cpp:258]     Train net output #0: landmark_loss = 0.0476577 (* 1 = 0.0476577 loss)
I0820 10:20:54.496219 12052 sgd_solver.cpp:112] Iteration 53300, lr = 0.001
I0820 10:20:59.185796 12052 solver.cpp:239] Iteration 53400 (21.3241 iter/s, 4.68953s/100 iters), loss = 0.0462474
I0820 10:20:59.185849 12052 solver.cpp:258]     Train net output #0: landmark_loss = 0.0462473 (* 1 = 0.0462473 loss)
I0820 10:20:59.185855 12052 sgd_solver.cpp:112] Iteration 53400, lr = 0.001
I0820 10:21:03.677995 12052 solver.cpp:239] Iteration 53500 (22.2613 iter/s, 4.49209s/100 iters), loss = 0.0486308
I0820 10:21:03.678048 12052 solver.cpp:258]     Train net output #0: landmark_loss = 0.0486308 (* 1 = 0.0486308 loss)
I0820 10:21:03.678055 12052 sgd_solver.cpp:112] Iteration 53500, lr = 0.001
I0820 10:21:08.032670 12052 solver.cpp:239] Iteration 53600 (22.9641 iter/s, 4.35462s/100 iters), loss = 0.0450099
I0820 10:21:08.032719 12052 solver.cpp:258]     Train net output #0: landmark_loss = 0.0450098 (* 1 = 0.0450098 loss)
I0820 10:21:08.032725 12052 sgd_solver.cpp:112] Iteration 53600, lr = 0.001
I0820 10:21:12.711030 12052 solver.cpp:239] Iteration 53700 (21.3755 iter/s, 4.67826s/100 iters), loss = 0.0387523
I0820 10:21:12.711081 12052 solver.cpp:258]     Train net output #0: landmark_loss = 0.0387523 (* 1 = 0.0387523 loss)
I0820 10:21:12.711087 12052 sgd_solver.cpp:112] Iteration 53700, lr = 0.001
I0820 10:21:17.388948 12052 solver.cpp:239] Iteration 53800 (21.3775 iter/s, 4.67782s/100 iters), loss = 0.0419506
I0820 10:21:17.389000 12052 solver.cpp:258]     Train net output #0: landmark_loss = 0.0419506 (* 1 = 0.0419506 loss)
I0820 10:21:17.389006 12052 sgd_solver.cpp:112] Iteration 53800, lr = 0.001
I0820 10:21:22.066781 12052 solver.cpp:239] Iteration 53900 (21.3779 iter/s, 4.67773s/100 iters), loss = 0.0427844
I0820 10:21:22.066830 12052 solver.cpp:258]     Train net output #0: landmark_loss = 0.0427844 (* 1 = 0.0427844 loss)
I0820 10:21:22.066836 12052 sgd_solver.cpp:112] Iteration 53900, lr = 0.001
I0820 10:21:26.678705 12052 solver.cpp:347] Iteration 54000, Testing net (#0)
I0820 10:21:46.605602 12052 solver.cpp:414]     Test net output #0: landmark_loss = 0.0272535 (* 1 = 0.0272535 loss)
I0820 10:21:46.652362 12052 solver.cpp:239] Iteration 54000 (4.06744 iter/s, 24.5855s/100 iters), loss = 0.0478725
I0820 10:21:46.652395 12052 solver.cpp:258]     Train net output #0: landmark_loss = 0.0478725 (* 1 = 0.0478725 loss)
I0820 10:21:46.652401 12052 sgd_solver.cpp:112] Iteration 54000, lr = 0.001
I0820 10:21:51.367861 12052 solver.cpp:239] Iteration 54100 (21.2071 iter/s, 4.71539s/100 iters), loss = 0.0527403
I0820 10:21:51.367913 12052 solver.cpp:258]     Train net output #0: landmark_loss = 0.0527403 (* 1 = 0.0527403 loss)
I0820 10:21:51.367920 12052 sgd_solver.cpp:112] Iteration 54100, lr = 0.001
I0820 10:21:56.083669 12052 solver.cpp:239] Iteration 54200 (21.2057 iter/s, 4.7157s/100 iters), loss = 0.0356756
I0820 10:21:56.083721 12052 solver.cpp:258]     Train net output #0: landmark_loss = 0.0356756 (* 1 = 0.0356756 loss)
I0820 10:21:56.083727 12052 sgd_solver.cpp:112] Iteration 54200, lr = 0.001
I0820 10:22:00.821033 12052 solver.cpp:239] Iteration 54300 (21.1093 iter/s, 4.73726s/100 iters), loss = 0.0478993
I0820 10:22:00.821075 12052 solver.cpp:258]     Train net output #0: landmark_loss = 0.0478993 (* 1 = 0.0478993 loss)
I0820 10:22:00.821081 12052 sgd_solver.cpp:112] Iteration 54300, lr = 0.001
I0820 10:22:05.565536 12052 solver.cpp:239] Iteration 54400 (21.0775 iter/s, 4.7444s/100 iters), loss = 0.0502206
I0820 10:22:05.565587 12052 solver.cpp:258]     Train net output #0: landmark_loss = 0.0502205 (* 1 = 0.0502205 loss)
I0820 10:22:05.565593 12052 sgd_solver.cpp:112] Iteration 54400, lr = 0.001
I0820 10:22:10.309360 12052 solver.cpp:239] Iteration 54500 (21.0805 iter/s, 4.74372s/100 iters), loss = 0.0466828
I0820 10:22:10.309412 12052 solver.cpp:258]     Train net output #0: landmark_loss = 0.0466828 (* 1 = 0.0466828 loss)
I0820 10:22:10.309418 12052 sgd_solver.cpp:112] Iteration 54500, lr = 0.001
I0820 10:22:15.028336 12052 solver.cpp:239] Iteration 54600 (21.1915 iter/s, 4.71887s/100 iters), loss = 0.0381894
I0820 10:22:15.028388 12052 solver.cpp:258]     Train net output #0: landmark_loss = 0.0381893 (* 1 = 0.0381893 loss)
I0820 10:22:15.028394 12052 sgd_solver.cpp:112] Iteration 54600, lr = 0.001
I0820 10:22:19.747272 12052 solver.cpp:239] Iteration 54700 (21.1917 iter/s, 4.71883s/100 iters), loss = 0.0383457
I0820 10:22:19.747326 12052 solver.cpp:258]     Train net output #0: landmark_loss = 0.0383456 (* 1 = 0.0383456 loss)
I0820 10:22:19.747332 12052 sgd_solver.cpp:112] Iteration 54700, lr = 0.001
I0820 10:22:24.465963 12052 solver.cpp:239] Iteration 54800 (21.1928 iter/s, 4.71858s/100 iters), loss = 0.0424265
I0820 10:22:24.466014 12052 solver.cpp:258]     Train net output #0: landmark_loss = 0.0424265 (* 1 = 0.0424265 loss)
I0820 10:22:24.466020 12052 sgd_solver.cpp:112] Iteration 54800, lr = 0.001
I0820 10:22:29.185384 12052 solver.cpp:239] Iteration 54900 (21.1895 iter/s, 4.71932s/100 iters), loss = 0.0401589
I0820 10:22:29.185436 12052 solver.cpp:258]     Train net output #0: landmark_loss = 0.0401589 (* 1 = 0.0401589 loss)
I0820 10:22:29.185441 12052 sgd_solver.cpp:112] Iteration 54900, lr = 0.001
I0820 10:22:33.904093 12052 solver.cpp:239] Iteration 55000 (21.1927 iter/s, 4.71861s/100 iters), loss = 0.0568855
I0820 10:22:33.904150 12052 solver.cpp:258]     Train net output #0: landmark_loss = 0.0568855 (* 1 = 0.0568855 loss)
I0820 10:22:33.904157 12052 sgd_solver.cpp:112] Iteration 55000, lr = 0.001
I0820 10:22:38.622628 12052 solver.cpp:239] Iteration 55100 (21.1935 iter/s, 4.71843s/100 iters), loss = 0.0428138
I0820 10:22:38.622679 12052 solver.cpp:258]     Train net output #0: landmark_loss = 0.0428137 (* 1 = 0.0428137 loss)
I0820 10:22:38.622686 12052 sgd_solver.cpp:112] Iteration 55100, lr = 0.001
I0820 10:22:43.342319 12052 solver.cpp:239] Iteration 55200 (21.1883 iter/s, 4.71959s/100 iters), loss = 0.048581
I0820 10:22:43.342370 12052 solver.cpp:258]     Train net output #0: landmark_loss = 0.048581 (* 1 = 0.048581 loss)
I0820 10:22:43.342376 12052 sgd_solver.cpp:112] Iteration 55200, lr = 0.001
I0820 10:22:48.064311 12052 solver.cpp:239] Iteration 55300 (21.178 iter/s, 4.72189s/100 iters), loss = 0.0392232
I0820 10:22:48.064363 12052 solver.cpp:258]     Train net output #0: landmark_loss = 0.0392232 (* 1 = 0.0392232 loss)
I0820 10:22:48.064368 12052 sgd_solver.cpp:112] Iteration 55300, lr = 0.001
I0820 10:22:52.782470 12052 solver.cpp:239] Iteration 55400 (21.1952 iter/s, 4.71806s/100 iters), loss = 0.0411512
I0820 10:22:52.782521 12052 solver.cpp:258]     Train net output #0: landmark_loss = 0.0411511 (* 1 = 0.0411511 loss)
I0820 10:22:52.782527 12052 sgd_solver.cpp:112] Iteration 55400, lr = 0.001
I0820 10:22:57.501435 12052 solver.cpp:239] Iteration 55500 (21.1916 iter/s, 4.71886s/100 iters), loss = 0.0450277
I0820 10:22:57.501485 12052 solver.cpp:258]     Train net output #0: landmark_loss = 0.0450277 (* 1 = 0.0450277 loss)
I0820 10:22:57.501492 12052 sgd_solver.cpp:112] Iteration 55500, lr = 0.001
I0820 10:23:02.241012 12052 solver.cpp:239] Iteration 55600 (21.0994 iter/s, 4.73948s/100 iters), loss = 0.0433
I0820 10:23:02.241055 12052 solver.cpp:258]     Train net output #0: landmark_loss = 0.0433 (* 1 = 0.0433 loss)
I0820 10:23:02.241061 12052 sgd_solver.cpp:112] Iteration 55600, lr = 0.001
I0820 10:23:06.945782 12052 solver.cpp:239] Iteration 55700 (21.2555 iter/s, 4.70466s/100 iters), loss = 0.0425185
I0820 10:23:06.945833 12052 solver.cpp:258]     Train net output #0: landmark_loss = 0.0425185 (* 1 = 0.0425185 loss)
I0820 10:23:06.945839 12052 sgd_solver.cpp:112] Iteration 55700, lr = 0.001
I0820 10:23:11.636528 12052 solver.cpp:239] Iteration 55800 (21.319 iter/s, 4.69064s/100 iters), loss = 0.0436296
I0820 10:23:11.636580 12052 solver.cpp:258]     Train net output #0: landmark_loss = 0.0436296 (* 1 = 0.0436296 loss)
I0820 10:23:11.636586 12052 sgd_solver.cpp:112] Iteration 55800, lr = 0.001
I0820 10:23:16.327893 12052 solver.cpp:239] Iteration 55900 (21.3162 iter/s, 4.69126s/100 iters), loss = 0.0507133
I0820 10:23:16.327944 12052 solver.cpp:258]     Train net output #0: landmark_loss = 0.0507132 (* 1 = 0.0507132 loss)
I0820 10:23:16.327950 12052 sgd_solver.cpp:112] Iteration 55900, lr = 0.001
I0820 10:23:21.019413 12052 solver.cpp:239] Iteration 56000 (21.3155 iter/s, 4.69142s/100 iters), loss = 0.0442146
I0820 10:23:21.019464 12052 solver.cpp:258]     Train net output #0: landmark_loss = 0.0442146 (* 1 = 0.0442146 loss)
I0820 10:23:21.019470 12052 sgd_solver.cpp:112] Iteration 56000, lr = 0.001
I0820 10:23:25.710906 12052 solver.cpp:239] Iteration 56100 (21.3157 iter/s, 4.69139s/100 iters), loss = 0.0598175
I0820 10:23:25.710956 12052 solver.cpp:258]     Train net output #0: landmark_loss = 0.0598175 (* 1 = 0.0598175 loss)
I0820 10:23:25.710963 12052 sgd_solver.cpp:112] Iteration 56100, lr = 0.001
I0820 10:23:29.844017 12052 solver.cpp:239] Iteration 56200 (24.1954 iter/s, 4.13301s/100 iters), loss = 0.0484426
I0820 10:23:29.844065 12052 solver.cpp:258]     Train net output #0: landmark_loss = 0.0484426 (* 1 = 0.0484426 loss)
I0820 10:23:29.844072 12052 sgd_solver.cpp:112] Iteration 56200, lr = 0.001
I0820 10:23:34.411278 12052 solver.cpp:239] Iteration 56300 (21.8955 iter/s, 4.56715s/100 iters), loss = 0.0467334
I0820 10:23:34.411330 12052 solver.cpp:258]     Train net output #0: landmark_loss = 0.0467333 (* 1 = 0.0467333 loss)
I0820 10:23:34.411336 12052 sgd_solver.cpp:112] Iteration 56300, lr = 0.001
I0820 10:23:39.134235 12052 solver.cpp:239] Iteration 56400 (21.1737 iter/s, 4.72284s/100 iters), loss = 0.0493406
I0820 10:23:39.134289 12052 solver.cpp:258]     Train net output #0: landmark_loss = 0.0493406 (* 1 = 0.0493406 loss)
I0820 10:23:39.134294 12052 sgd_solver.cpp:112] Iteration 56400, lr = 0.001
I0820 10:23:43.857923 12052 solver.cpp:239] Iteration 56500 (21.1704 iter/s, 4.72357s/100 iters), loss = 0.0438665
I0820 10:23:43.857975 12052 solver.cpp:258]     Train net output #0: landmark_loss = 0.0438665 (* 1 = 0.0438665 loss)
I0820 10:23:43.857981 12052 sgd_solver.cpp:112] Iteration 56500, lr = 0.001
I0820 10:23:48.581501 12052 solver.cpp:239] Iteration 56600 (21.1709 iter/s, 4.72346s/100 iters), loss = 0.0443807
I0820 10:23:48.581553 12052 solver.cpp:258]     Train net output #0: landmark_loss = 0.0443807 (* 1 = 0.0443807 loss)
I0820 10:23:48.581559 12052 sgd_solver.cpp:112] Iteration 56600, lr = 0.001
I0820 10:23:53.304790 12052 solver.cpp:239] Iteration 56700 (21.1722 iter/s, 4.72318s/100 iters), loss = 0.0392085
I0820 10:23:53.304841 12052 solver.cpp:258]     Train net output #0: landmark_loss = 0.0392085 (* 1 = 0.0392085 loss)
I0820 10:23:53.304847 12052 sgd_solver.cpp:112] Iteration 56700, lr = 0.001
I0820 10:23:58.027261 12052 solver.cpp:239] Iteration 56800 (21.1759 iter/s, 4.72236s/100 iters), loss = 0.0420402
I0820 10:23:58.027313 12052 solver.cpp:258]     Train net output #0: landmark_loss = 0.0420402 (* 1 = 0.0420402 loss)
I0820 10:23:58.027319 12052 sgd_solver.cpp:112] Iteration 56800, lr = 0.001
I0820 10:24:02.780998 12052 solver.cpp:239] Iteration 56900 (21.0366 iter/s, 4.75362s/100 iters), loss = 0.0506441
I0820 10:24:02.781040 12052 solver.cpp:258]     Train net output #0: landmark_loss = 0.0506441 (* 1 = 0.0506441 loss)
I0820 10:24:02.781046 12052 sgd_solver.cpp:112] Iteration 56900, lr = 0.001
I0820 10:24:07.519881 12052 solver.cpp:239] Iteration 57000 (21.1025 iter/s, 4.73877s/100 iters), loss = 0.0406993
I0820 10:24:07.519933 12052 solver.cpp:258]     Train net output #0: landmark_loss = 0.0406993 (* 1 = 0.0406993 loss)
I0820 10:24:07.519939 12052 sgd_solver.cpp:112] Iteration 57000, lr = 0.001
I0820 10:24:11.884013 12052 solver.cpp:239] Iteration 57100 (22.9146 iter/s, 4.36403s/100 iters), loss = 0.0483293
I0820 10:24:11.884057 12052 solver.cpp:258]     Train net output #0: landmark_loss = 0.0483293 (* 1 = 0.0483293 loss)
I0820 10:24:11.884063 12052 sgd_solver.cpp:112] Iteration 57100, lr = 0.001
I0820 10:24:16.096474 12052 solver.cpp:239] Iteration 57200 (23.7397 iter/s, 4.21234s/100 iters), loss = 0.0429161
I0820 10:24:16.096527 12052 solver.cpp:258]     Train net output #0: landmark_loss = 0.0429161 (* 1 = 0.0429161 loss)
I0820 10:24:16.096534 12052 sgd_solver.cpp:112] Iteration 57200, lr = 0.001
I0820 10:24:20.780616 12052 solver.cpp:239] Iteration 57300 (21.349 iter/s, 4.68405s/100 iters), loss = 0.0358948
I0820 10:24:20.780668 12052 solver.cpp:258]     Train net output #0: landmark_loss = 0.0358948 (* 1 = 0.0358948 loss)
I0820 10:24:20.780674 12052 sgd_solver.cpp:112] Iteration 57300, lr = 0.001
I0820 10:24:25.467236 12052 solver.cpp:239] Iteration 57400 (21.3378 iter/s, 4.68652s/100 iters), loss = 0.0414707
I0820 10:24:25.467286 12052 solver.cpp:258]     Train net output #0: landmark_loss = 0.0414706 (* 1 = 0.0414706 loss)
I0820 10:24:25.467293 12052 sgd_solver.cpp:112] Iteration 57400, lr = 0.001
I0820 10:24:30.154783 12052 solver.cpp:239] Iteration 57500 (21.3336 iter/s, 4.68744s/100 iters), loss = 0.0485514
I0820 10:24:30.154835 12052 solver.cpp:258]     Train net output #0: landmark_loss = 0.0485514 (* 1 = 0.0485514 loss)
I0820 10:24:30.154841 12052 sgd_solver.cpp:112] Iteration 57500, lr = 0.001
I0820 10:24:34.841959 12052 solver.cpp:239] Iteration 57600 (21.3353 iter/s, 4.68707s/100 iters), loss = 0.0503626
I0820 10:24:34.842011 12052 solver.cpp:258]     Train net output #0: landmark_loss = 0.0503625 (* 1 = 0.0503625 loss)
I0820 10:24:34.842017 12052 sgd_solver.cpp:112] Iteration 57600, lr = 0.001
I0820 10:24:39.536782 12052 solver.cpp:239] Iteration 57700 (21.3005 iter/s, 4.69472s/100 iters), loss = 0.0494235
I0820 10:24:39.536834 12052 solver.cpp:258]     Train net output #0: landmark_loss = 0.0494234 (* 1 = 0.0494234 loss)
I0820 10:24:39.536840 12052 sgd_solver.cpp:112] Iteration 57700, lr = 0.001
I0820 10:24:44.223178 12052 solver.cpp:239] Iteration 57800 (21.3388 iter/s, 4.68629s/100 iters), loss = 0.0477519
I0820 10:24:44.223229 12052 solver.cpp:258]     Train net output #0: landmark_loss = 0.0477519 (* 1 = 0.0477519 loss)
I0820 10:24:44.223235 12052 sgd_solver.cpp:112] Iteration 57800, lr = 0.001
I0820 10:24:48.908543 12052 solver.cpp:239] Iteration 57900 (21.3435 iter/s, 4.68526s/100 iters), loss = 0.0469682
I0820 10:24:48.908594 12052 solver.cpp:258]     Train net output #0: landmark_loss = 0.0469681 (* 1 = 0.0469681 loss)
I0820 10:24:48.908599 12052 sgd_solver.cpp:112] Iteration 57900, lr = 0.001
I0820 10:24:53.595163 12052 solver.cpp:239] Iteration 58000 (21.3378 iter/s, 4.68652s/100 iters), loss = 0.0407813
I0820 10:24:53.595214 12052 solver.cpp:258]     Train net output #0: landmark_loss = 0.0407812 (* 1 = 0.0407812 loss)
I0820 10:24:53.595221 12052 sgd_solver.cpp:112] Iteration 58000, lr = 0.001
I0820 10:24:58.280478 12052 solver.cpp:239] Iteration 58100 (21.3437 iter/s, 4.68521s/100 iters), loss = 0.0467299
I0820 10:24:58.280529 12052 solver.cpp:258]     Train net output #0: landmark_loss = 0.0467299 (* 1 = 0.0467299 loss)
I0820 10:24:58.280535 12052 sgd_solver.cpp:112] Iteration 58100, lr = 0.001
I0820 10:25:02.999728 12052 solver.cpp:239] Iteration 58200 (21.1903 iter/s, 4.71915s/100 iters), loss = 0.0561304
I0820 10:25:02.999769 12052 solver.cpp:258]     Train net output #0: landmark_loss = 0.0561304 (* 1 = 0.0561304 loss)
I0820 10:25:02.999775 12052 sgd_solver.cpp:112] Iteration 58200, lr = 0.001
I0820 10:25:07.691679 12052 solver.cpp:239] Iteration 58300 (21.3136 iter/s, 4.69185s/100 iters), loss = 0.0443895
I0820 10:25:07.691728 12052 solver.cpp:258]     Train net output #0: landmark_loss = 0.0443894 (* 1 = 0.0443894 loss)
I0820 10:25:07.691735 12052 sgd_solver.cpp:112] Iteration 58300, lr = 0.001
I0820 10:25:12.377022 12052 solver.cpp:239] Iteration 58400 (21.3436 iter/s, 4.68524s/100 iters), loss = 0.0415148
I0820 10:25:12.377074 12052 solver.cpp:258]     Train net output #0: landmark_loss = 0.0415148 (* 1 = 0.0415148 loss)
I0820 10:25:12.377080 12052 sgd_solver.cpp:112] Iteration 58400, lr = 0.001
I0820 10:25:17.060998 12052 solver.cpp:239] Iteration 58500 (21.3498 iter/s, 4.68387s/100 iters), loss = 0.036894
I0820 10:25:17.061050 12052 solver.cpp:258]     Train net output #0: landmark_loss = 0.036894 (* 1 = 0.036894 loss)
I0820 10:25:17.061056 12052 sgd_solver.cpp:112] Iteration 58500, lr = 0.001
I0820 10:25:21.745894 12052 solver.cpp:239] Iteration 58600 (21.3457 iter/s, 4.68479s/100 iters), loss = 0.0472713
I0820 10:25:21.745946 12052 solver.cpp:258]     Train net output #0: landmark_loss = 0.0472713 (* 1 = 0.0472713 loss)
I0820 10:25:21.745952 12052 sgd_solver.cpp:112] Iteration 58600, lr = 0.001
I0820 10:25:26.431805 12052 solver.cpp:239] Iteration 58700 (21.341 iter/s, 4.68581s/100 iters), loss = 0.0401935
I0820 10:25:26.431856 12052 solver.cpp:258]     Train net output #0: landmark_loss = 0.0401934 (* 1 = 0.0401934 loss)
I0820 10:25:26.431862 12052 sgd_solver.cpp:112] Iteration 58700, lr = 0.001
I0820 10:25:31.026026 12052 solver.cpp:239] Iteration 58800 (21.767 iter/s, 4.59412s/100 iters), loss = 0.0399107
I0820 10:25:31.026067 12052 solver.cpp:258]     Train net output #0: landmark_loss = 0.0399107 (* 1 = 0.0399107 loss)
I0820 10:25:31.026073 12052 sgd_solver.cpp:112] Iteration 58800, lr = 0.001
I0820 10:25:35.696043 12052 solver.cpp:239] Iteration 58900 (21.4137 iter/s, 4.66991s/100 iters), loss = 0.0404062
I0820 10:25:35.696095 12052 solver.cpp:258]     Train net output #0: landmark_loss = 0.0404062 (* 1 = 0.0404062 loss)
I0820 10:25:35.696101 12052 sgd_solver.cpp:112] Iteration 58900, lr = 0.001
I0820 10:25:40.377398 12052 solver.cpp:239] Iteration 59000 (21.3618 iter/s, 4.68125s/100 iters), loss = 0.0436138
I0820 10:25:40.377451 12052 solver.cpp:258]     Train net output #0: landmark_loss = 0.0436138 (* 1 = 0.0436138 loss)
I0820 10:25:40.377457 12052 sgd_solver.cpp:112] Iteration 59000, lr = 0.001
I0820 10:25:45.060446 12052 solver.cpp:239] Iteration 59100 (21.3541 iter/s, 4.68294s/100 iters), loss = 0.0494052
I0820 10:25:45.060499 12052 solver.cpp:258]     Train net output #0: landmark_loss = 0.0494051 (* 1 = 0.0494051 loss)
I0820 10:25:45.060505 12052 sgd_solver.cpp:112] Iteration 59100, lr = 0.001
I0820 10:25:49.744096 12052 solver.cpp:239] Iteration 59200 (21.3513 iter/s, 4.68355s/100 iters), loss = 0.0410931
I0820 10:25:49.744164 12052 solver.cpp:258]     Train net output #0: landmark_loss = 0.041093 (* 1 = 0.041093 loss)
I0820 10:25:49.744174 12052 sgd_solver.cpp:112] Iteration 59200, lr = 0.001
I0820 10:25:54.155601 12052 solver.cpp:239] Iteration 59300 (22.6685 iter/s, 4.4114s/100 iters), loss = 0.040266
I0820 10:25:54.155642 12052 solver.cpp:258]     Train net output #0: landmark_loss = 0.040266 (* 1 = 0.040266 loss)
I0820 10:25:54.155648 12052 sgd_solver.cpp:112] Iteration 59300, lr = 0.001
I0820 10:25:58.842934 12052 solver.cpp:239] Iteration 59400 (21.3346 iter/s, 4.68723s/100 iters), loss = 0.039103
I0820 10:25:58.842985 12052 solver.cpp:258]     Train net output #0: landmark_loss = 0.039103 (* 1 = 0.039103 loss)
I0820 10:25:58.842993 12052 sgd_solver.cpp:112] Iteration 59400, lr = 0.001
I0820 10:26:03.604142 12052 solver.cpp:239] Iteration 59500 (21.0035 iter/s, 4.7611s/100 iters), loss = 0.0530941
I0820 10:26:03.604194 12052 solver.cpp:258]     Train net output #0: landmark_loss = 0.0530941 (* 1 = 0.0530941 loss)
I0820 10:26:03.604202 12052 sgd_solver.cpp:112] Iteration 59500, lr = 0.001
I0820 10:26:08.328747 12052 solver.cpp:239] Iteration 59600 (21.1662 iter/s, 4.7245s/100 iters), loss = 0.0515594
I0820 10:26:08.328797 12052 solver.cpp:258]     Train net output #0: landmark_loss = 0.0515594 (* 1 = 0.0515594 loss)
I0820 10:26:08.328804 12052 sgd_solver.cpp:112] Iteration 59600, lr = 0.001
I0820 10:26:13.054064 12052 solver.cpp:239] Iteration 59700 (21.163 iter/s, 4.72522s/100 iters), loss = 0.0371454
I0820 10:26:13.054113 12052 solver.cpp:258]     Train net output #0: landmark_loss = 0.0371453 (* 1 = 0.0371453 loss)
I0820 10:26:13.054121 12052 sgd_solver.cpp:112] Iteration 59700, lr = 0.001
I0820 10:26:17.780546 12052 solver.cpp:239] Iteration 59800 (21.1578 iter/s, 4.72638s/100 iters), loss = 0.0418868
I0820 10:26:17.780599 12052 solver.cpp:258]     Train net output #0: landmark_loss = 0.0418867 (* 1 = 0.0418867 loss)
I0820 10:26:17.780606 12052 sgd_solver.cpp:112] Iteration 59800, lr = 0.001
I0820 10:26:22.494983 12052 solver.cpp:239] Iteration 59900 (21.2119 iter/s, 4.71433s/100 iters), loss = 0.0472155
I0820 10:26:22.495034 12052 solver.cpp:258]     Train net output #0: landmark_loss = 0.0472155 (* 1 = 0.0472155 loss)
I0820 10:26:22.495040 12052 sgd_solver.cpp:112] Iteration 59900, lr = 0.001
I0820 10:26:27.117754 12052 solver.cpp:464] Snapshotting to binary proto file ./model/M3_iter_60000.caffemodel
I0820 10:26:27.220525 12052 sgd_solver.cpp:284] Snapshotting solver state to binary proto file ./model/M3_iter_60000.solverstate
I0820 10:26:27.272430 12052 solver.cpp:347] Iteration 60000, Testing net (#0)
I0820 10:26:46.944945 12052 solver.cpp:414]     Test net output #0: landmark_loss = 0.0304395 (* 1 = 0.0304395 loss)
I0820 10:26:46.983945 12052 solver.cpp:239] Iteration 60000 (4.08348 iter/s, 24.4889s/100 iters), loss = 0.0424108
I0820 10:26:46.983985 12052 solver.cpp:258]     Train net output #0: landmark_loss = 0.0424108 (* 1 = 0.0424108 loss)
I0820 10:26:46.983991 12052 sgd_solver.cpp:112] Iteration 60000, lr = 0.001
I0820 10:26:51.405328 12052 solver.cpp:239] Iteration 60100 (22.6175 iter/s, 4.42136s/100 iters), loss = 0.0480831
I0820 10:26:51.405380 12052 solver.cpp:258]     Train net output #0: landmark_loss = 0.0480831 (* 1 = 0.0480831 loss)
I0820 10:26:51.405386 12052 sgd_solver.cpp:112] Iteration 60100, lr = 0.001
I0820 10:26:56.157768 12052 solver.cpp:239] Iteration 60200 (21.0423 iter/s, 4.75232s/100 iters), loss = 0.0433447
I0820 10:26:56.157820 12052 solver.cpp:258]     Train net output #0: landmark_loss = 0.0433447 (* 1 = 0.0433447 loss)
I0820 10:26:56.157826 12052 sgd_solver.cpp:112] Iteration 60200, lr = 0.001
I0820 10:27:00.927850 12052 solver.cpp:239] Iteration 60300 (20.9645 iter/s, 4.76998s/100 iters), loss = 0.0539707
I0820 10:27:00.927892 12052 solver.cpp:258]     Train net output #0: landmark_loss = 0.0539706 (* 1 = 0.0539706 loss)
I0820 10:27:00.927899 12052 sgd_solver.cpp:112] Iteration 60300, lr = 0.001
I0820 10:27:05.676070 12052 solver.cpp:239] Iteration 60400 (21.061 iter/s, 4.74811s/100 iters), loss = 0.0515989
I0820 10:27:05.676123 12052 solver.cpp:258]     Train net output #0: landmark_loss = 0.0515988 (* 1 = 0.0515988 loss)
I0820 10:27:05.676134 12052 sgd_solver.cpp:112] Iteration 60400, lr = 0.001
I0820 10:27:10.408747 12052 solver.cpp:239] Iteration 60500 (21.1301 iter/s, 4.73257s/100 iters), loss = 0.0497276
I0820 10:27:10.408798 12052 solver.cpp:258]     Train net output #0: landmark_loss = 0.0497276 (* 1 = 0.0497276 loss)
I0820 10:27:10.408804 12052 sgd_solver.cpp:112] Iteration 60500, lr = 0.001
I0820 10:27:15.159968 12052 solver.cpp:239] Iteration 60600 (21.0477 iter/s, 4.75112s/100 iters), loss = 0.0392461
I0820 10:27:15.160019 12052 solver.cpp:258]     Train net output #0: landmark_loss = 0.0392461 (* 1 = 0.0392461 loss)
I0820 10:27:15.160025 12052 sgd_solver.cpp:112] Iteration 60600, lr = 0.001
I0820 10:27:19.928411 12052 solver.cpp:239] Iteration 60700 (20.9717 iter/s, 4.76834s/100 iters), loss = 0.0432142
I0820 10:27:19.928463 12052 solver.cpp:258]     Train net output #0: landmark_loss = 0.0432141 (* 1 = 0.0432141 loss)
I0820 10:27:19.928470 12052 sgd_solver.cpp:112] Iteration 60700, lr = 0.001
I0820 10:27:24.694610 12052 solver.cpp:239] Iteration 60800 (20.9816 iter/s, 4.76609s/100 iters), loss = 0.0472666
I0820 10:27:24.694664 12052 solver.cpp:258]     Train net output #0: landmark_loss = 0.0472665 (* 1 = 0.0472665 loss)
I0820 10:27:24.694669 12052 sgd_solver.cpp:112] Iteration 60800, lr = 0.001
I0820 10:27:29.462335 12052 solver.cpp:239] Iteration 60900 (20.9749 iter/s, 4.7676s/100 iters), loss = 0.0469464
I0820 10:27:29.462388 12052 solver.cpp:258]     Train net output #0: landmark_loss = 0.0469464 (* 1 = 0.0469464 loss)
I0820 10:27:29.462393 12052 sgd_solver.cpp:112] Iteration 60900, lr = 0.001
I0820 10:27:34.232933 12052 solver.cpp:239] Iteration 61000 (20.9622 iter/s, 4.77049s/100 iters), loss = 0.0426747
I0820 10:27:34.232985 12052 solver.cpp:258]     Train net output #0: landmark_loss = 0.0426747 (* 1 = 0.0426747 loss)
I0820 10:27:34.232990 12052 sgd_solver.cpp:112] Iteration 61000, lr = 0.001
I0820 10:27:38.997918 12052 solver.cpp:239] Iteration 61100 (20.9869 iter/s, 4.76487s/100 iters), loss = 0.0444944
I0820 10:27:38.997972 12052 solver.cpp:258]     Train net output #0: landmark_loss = 0.0444944 (* 1 = 0.0444944 loss)
I0820 10:27:38.997977 12052 sgd_solver.cpp:112] Iteration 61100, lr = 0.001
I0820 10:27:43.764253 12052 solver.cpp:239] Iteration 61200 (20.981 iter/s, 4.76622s/100 iters), loss = 0.0509336
I0820 10:27:43.764305 12052 solver.cpp:258]     Train net output #0: landmark_loss = 0.0509336 (* 1 = 0.0509336 loss)
I0820 10:27:43.764312 12052 sgd_solver.cpp:112] Iteration 61200, lr = 0.001
I0820 10:27:48.529413 12052 solver.cpp:239] Iteration 61300 (20.9862 iter/s, 4.76504s/100 iters), loss = 0.0418236
I0820 10:27:48.529466 12052 solver.cpp:258]     Train net output #0: landmark_loss = 0.0418236 (* 1 = 0.0418236 loss)
I0820 10:27:48.529472 12052 sgd_solver.cpp:112] Iteration 61300, lr = 0.001
I0820 10:27:53.295153 12052 solver.cpp:239] Iteration 61400 (20.9836 iter/s, 4.76563s/100 iters), loss = 0.0454929
I0820 10:27:53.295207 12052 solver.cpp:258]     Train net output #0: landmark_loss = 0.0454929 (* 1 = 0.0454929 loss)
I0820 10:27:53.295213 12052 sgd_solver.cpp:112] Iteration 61400, lr = 0.001
I0820 10:27:58.059630 12052 solver.cpp:239] Iteration 61500 (20.9891 iter/s, 4.76437s/100 iters), loss = 0.0534246
I0820 10:27:58.059682 12052 solver.cpp:258]     Train net output #0: landmark_loss = 0.0534245 (* 1 = 0.0534245 loss)
I0820 10:27:58.059689 12052 sgd_solver.cpp:112] Iteration 61500, lr = 0.001
I0820 10:28:02.514667 12052 solver.cpp:239] Iteration 61600 (22.4471 iter/s, 4.45491s/100 iters), loss = 0.0426387
I0820 10:28:02.514710 12052 solver.cpp:258]     Train net output #0: landmark_loss = 0.0426387 (* 1 = 0.0426387 loss)
I0820 10:28:02.514716 12052 sgd_solver.cpp:112] Iteration 61600, lr = 0.001
I0820 10:28:07.228771 12052 solver.cpp:239] Iteration 61700 (21.2134 iter/s, 4.71401s/100 iters), loss = 0.0387629
I0820 10:28:07.228824 12052 solver.cpp:258]     Train net output #0: landmark_loss = 0.0387628 (* 1 = 0.0387628 loss)
I0820 10:28:07.228830 12052 sgd_solver.cpp:112] Iteration 61700, lr = 0.001
I0820 10:28:11.938714 12052 solver.cpp:239] Iteration 61800 (21.2321 iter/s, 4.70984s/100 iters), loss = 0.0497653
I0820 10:28:11.938767 12052 solver.cpp:258]     Train net output #0: landmark_loss = 0.0497653 (* 1 = 0.0497653 loss)
I0820 10:28:11.938773 12052 sgd_solver.cpp:112] Iteration 61800, lr = 0.001
I0820 10:28:16.648931 12052 solver.cpp:239] Iteration 61900 (21.2309 iter/s, 4.71012s/100 iters), loss = 0.0415166
I0820 10:28:16.648982 12052 solver.cpp:258]     Train net output #0: landmark_loss = 0.0415166 (* 1 = 0.0415166 loss)
I0820 10:28:16.648988 12052 sgd_solver.cpp:112] Iteration 61900, lr = 0.001
I0820 10:28:21.355770 12052 solver.cpp:239] Iteration 62000 (21.2461 iter/s, 4.70674s/100 iters), loss = 0.0537093
I0820 10:28:21.355823 12052 solver.cpp:258]     Train net output #0: landmark_loss = 0.0537093 (* 1 = 0.0537093 loss)
I0820 10:28:21.355829 12052 sgd_solver.cpp:112] Iteration 62000, lr = 0.001
I0820 10:28:26.064024 12052 solver.cpp:239] Iteration 62100 (21.2398 iter/s, 4.70815s/100 iters), loss = 0.0504849
I0820 10:28:26.064074 12052 solver.cpp:258]     Train net output #0: landmark_loss = 0.0504849 (* 1 = 0.0504849 loss)
I0820 10:28:26.064080 12052 sgd_solver.cpp:112] Iteration 62100, lr = 0.001
I0820 10:28:30.771298 12052 solver.cpp:239] Iteration 62200 (21.2442 iter/s, 4.70718s/100 iters), loss = 0.0535211
I0820 10:28:30.771350 12052 solver.cpp:258]     Train net output #0: landmark_loss = 0.0535211 (* 1 = 0.0535211 loss)
I0820 10:28:30.771356 12052 sgd_solver.cpp:112] Iteration 62200, lr = 0.001
I0820 10:28:35.479670 12052 solver.cpp:239] Iteration 62300 (21.2392 iter/s, 4.70827s/100 iters), loss = 0.0418569
I0820 10:28:35.479720 12052 solver.cpp:258]     Train net output #0: landmark_loss = 0.0418569 (* 1 = 0.0418569 loss)
I0820 10:28:35.479727 12052 sgd_solver.cpp:112] Iteration 62300, lr = 0.001
I0820 10:28:40.187996 12052 solver.cpp:239] Iteration 62400 (21.2394 iter/s, 4.70823s/100 iters), loss = 0.0486088
I0820 10:28:40.188050 12052 solver.cpp:258]     Train net output #0: landmark_loss = 0.0486087 (* 1 = 0.0486087 loss)
I0820 10:28:40.188056 12052 sgd_solver.cpp:112] Iteration 62400, lr = 0.001
I0820 10:28:44.895269 12052 solver.cpp:239] Iteration 62500 (21.2442 iter/s, 4.70717s/100 iters), loss = 0.0456808
I0820 10:28:44.895323 12052 solver.cpp:258]     Train net output #0: landmark_loss = 0.0456808 (* 1 = 0.0456808 loss)
I0820 10:28:44.895328 12052 sgd_solver.cpp:112] Iteration 62500, lr = 0.001
I0820 10:28:49.602831 12052 solver.cpp:239] Iteration 62600 (21.2429 iter/s, 4.70746s/100 iters), loss = 0.0443924
I0820 10:28:49.602883 12052 solver.cpp:258]     Train net output #0: landmark_loss = 0.0443924 (* 1 = 0.0443924 loss)
I0820 10:28:49.602890 12052 sgd_solver.cpp:112] Iteration 62600, lr = 0.001
I0820 10:28:54.312991 12052 solver.cpp:239] Iteration 62700 (21.2312 iter/s, 4.71006s/100 iters), loss = 0.0433351
I0820 10:28:54.313045 12052 solver.cpp:258]     Train net output #0: landmark_loss = 0.0433351 (* 1 = 0.0433351 loss)
I0820 10:28:54.313050 12052 sgd_solver.cpp:112] Iteration 62700, lr = 0.001
I0820 10:28:59.022339 12052 solver.cpp:239] Iteration 62800 (21.2348 iter/s, 4.70925s/100 iters), loss = 0.0413794
I0820 10:28:59.022392 12052 solver.cpp:258]     Train net output #0: landmark_loss = 0.0413793 (* 1 = 0.0413793 loss)
I0820 10:28:59.022398 12052 sgd_solver.cpp:112] Iteration 62800, lr = 0.001
I0820 10:29:03.767027 12052 solver.cpp:239] Iteration 62900 (21.0767 iter/s, 4.74458s/100 iters), loss = 0.0432554
I0820 10:29:03.767081 12052 solver.cpp:258]     Train net output #0: landmark_loss = 0.0432553 (* 1 = 0.0432553 loss)
I0820 10:29:03.767087 12052 sgd_solver.cpp:112] Iteration 62900, lr = 0.001
I0820 10:29:08.491294 12052 solver.cpp:239] Iteration 63000 (21.1678 iter/s, 4.72417s/100 iters), loss = 0.0456567
I0820 10:29:08.491346 12052 solver.cpp:258]     Train net output #0: landmark_loss = 0.0456567 (* 1 = 0.0456567 loss)
I0820 10:29:08.491351 12052 sgd_solver.cpp:112] Iteration 63000, lr = 0.001
I0820 10:29:13.200932 12052 solver.cpp:239] Iteration 63100 (21.2335 iter/s, 4.70954s/100 iters), loss = 0.0408367
I0820 10:29:13.200984 12052 solver.cpp:258]     Train net output #0: landmark_loss = 0.0408367 (* 1 = 0.0408367 loss)
I0820 10:29:13.200989 12052 sgd_solver.cpp:112] Iteration 63100, lr = 0.001
I0820 10:29:17.908123 12052 solver.cpp:239] Iteration 63200 (21.2445 iter/s, 4.70709s/100 iters), loss = 0.0469173
I0820 10:29:17.908191 12052 solver.cpp:258]     Train net output #0: landmark_loss = 0.0469173 (* 1 = 0.0469173 loss)
I0820 10:29:17.908198 12052 sgd_solver.cpp:112] Iteration 63200, lr = 0.001
I0820 10:29:22.638180 12052 solver.cpp:239] Iteration 63300 (21.1419 iter/s, 4.72994s/100 iters), loss = 0.0454976
I0820 10:29:22.638232 12052 solver.cpp:258]     Train net output #0: landmark_loss = 0.0454976 (* 1 = 0.0454976 loss)
I0820 10:29:22.638238 12052 sgd_solver.cpp:112] Iteration 63300, lr = 0.001
I0820 10:29:27.366500 12052 solver.cpp:239] Iteration 63400 (21.1497 iter/s, 4.72821s/100 iters), loss = 0.0528449
I0820 10:29:27.366544 12052 solver.cpp:258]     Train net output #0: landmark_loss = 0.0528448 (* 1 = 0.0528448 loss)
I0820 10:29:27.366549 12052 sgd_solver.cpp:112] Iteration 63400, lr = 0.001
I0820 10:29:32.120750 12052 solver.cpp:239] Iteration 63500 (21.0342 iter/s, 4.75415s/100 iters), loss = 0.0525448
I0820 10:29:32.120801 12052 solver.cpp:258]     Train net output #0: landmark_loss = 0.0525448 (* 1 = 0.0525448 loss)
I0820 10:29:32.120807 12052 sgd_solver.cpp:112] Iteration 63500, lr = 0.001
I0820 10:29:36.907222 12052 solver.cpp:239] Iteration 63600 (20.8928 iter/s, 4.78634s/100 iters), loss = 0.0530114
I0820 10:29:36.907271 12052 solver.cpp:258]     Train net output #0: landmark_loss = 0.0530114 (* 1 = 0.0530114 loss)
I0820 10:29:36.907277 12052 sgd_solver.cpp:112] Iteration 63600, lr = 0.001
I0820 10:29:41.692992 12052 solver.cpp:239] Iteration 63700 (20.8958 iter/s, 4.78564s/100 iters), loss = 0.0519675
I0820 10:29:41.693043 12052 solver.cpp:258]     Train net output #0: landmark_loss = 0.0519674 (* 1 = 0.0519674 loss)
I0820 10:29:41.693049 12052 sgd_solver.cpp:112] Iteration 63700, lr = 0.001
I0820 10:29:46.383026 12052 solver.cpp:239] Iteration 63800 (21.3224 iter/s, 4.6899s/100 iters), loss = 0.0381145
I0820 10:29:46.383077 12052 solver.cpp:258]     Train net output #0: landmark_loss = 0.0381145 (* 1 = 0.0381145 loss)
I0820 10:29:46.383083 12052 sgd_solver.cpp:112] Iteration 63800, lr = 0.001
I0820 10:29:51.057936 12052 solver.cpp:239] Iteration 63900 (21.3912 iter/s, 4.67481s/100 iters), loss = 0.0423527
I0820 10:29:51.057988 12052 solver.cpp:258]     Train net output #0: landmark_loss = 0.0423527 (* 1 = 0.0423527 loss)
I0820 10:29:51.057994 12052 sgd_solver.cpp:112] Iteration 63900, lr = 0.001
I0820 10:29:55.733572 12052 solver.cpp:239] Iteration 64000 (21.3879 iter/s, 4.67554s/100 iters), loss = 0.0412808
I0820 10:29:55.733623 12052 solver.cpp:258]     Train net output #0: landmark_loss = 0.0412808 (* 1 = 0.0412808 loss)
I0820 10:29:55.733629 12052 sgd_solver.cpp:112] Iteration 64000, lr = 0.001
I0820 10:30:00.431094 12052 solver.cpp:239] Iteration 64100 (21.2883 iter/s, 4.69742s/100 iters), loss = 0.045691
I0820 10:30:00.431138 12052 solver.cpp:258]     Train net output #0: landmark_loss = 0.0456909 (* 1 = 0.0456909 loss)
I0820 10:30:00.431144 12052 sgd_solver.cpp:112] Iteration 64100, lr = 0.001
I0820 10:30:05.125901 12052 solver.cpp:239] Iteration 64200 (21.3006 iter/s, 4.69471s/100 iters), loss = 0.0468784
I0820 10:30:05.125953 12052 solver.cpp:258]     Train net output #0: landmark_loss = 0.0468784 (* 1 = 0.0468784 loss)
I0820 10:30:05.125959 12052 sgd_solver.cpp:112] Iteration 64200, lr = 0.001
I0820 10:30:09.799867 12052 solver.cpp:239] Iteration 64300 (21.3956 iter/s, 4.67387s/100 iters), loss = 0.0413856
I0820 10:30:09.799919 12052 solver.cpp:258]     Train net output #0: landmark_loss = 0.0413856 (* 1 = 0.0413856 loss)
I0820 10:30:09.799926 12052 sgd_solver.cpp:112] Iteration 64300, lr = 0.001
I0820 10:30:14.473647 12052 solver.cpp:239] Iteration 64400 (21.3964 iter/s, 4.67368s/100 iters), loss = 0.0393597
I0820 10:30:14.473700 12052 solver.cpp:258]     Train net output #0: landmark_loss = 0.0393597 (* 1 = 0.0393597 loss)
I0820 10:30:14.473706 12052 sgd_solver.cpp:112] Iteration 64400, lr = 0.001
I0820 10:30:19.155911 12052 solver.cpp:239] Iteration 64500 (21.3577 iter/s, 4.68216s/100 iters), loss = 0.0504864
I0820 10:30:19.155963 12052 solver.cpp:258]     Train net output #0: landmark_loss = 0.0504863 (* 1 = 0.0504863 loss)
I0820 10:30:19.155969 12052 sgd_solver.cpp:112] Iteration 64500, lr = 0.001
I0820 10:30:23.865590 12052 solver.cpp:239] Iteration 64600 (21.2334 iter/s, 4.70957s/100 iters), loss = 0.0492211
I0820 10:30:23.865643 12052 solver.cpp:258]     Train net output #0: landmark_loss = 0.049221 (* 1 = 0.049221 loss)
I0820 10:30:23.865648 12052 sgd_solver.cpp:112] Iteration 64600, lr = 0.001
I0820 10:30:28.499718 12052 solver.cpp:239] Iteration 64700 (21.5795 iter/s, 4.63402s/100 iters), loss = 0.042492
I0820 10:30:28.499768 12052 solver.cpp:258]     Train net output #0: landmark_loss = 0.042492 (* 1 = 0.042492 loss)
I0820 10:30:28.499775 12052 sgd_solver.cpp:112] Iteration 64700, lr = 0.001
I0820 10:30:33.277943 12052 solver.cpp:239] Iteration 64800 (20.9287 iter/s, 4.77812s/100 iters), loss = 0.043702
I0820 10:30:33.277995 12052 solver.cpp:258]     Train net output #0: landmark_loss = 0.043702 (* 1 = 0.043702 loss)
I0820 10:30:33.278002 12052 sgd_solver.cpp:112] Iteration 64800, lr = 0.001
I0820 10:30:38.056378 12052 solver.cpp:239] Iteration 64900 (20.9279 iter/s, 4.77831s/100 iters), loss = 0.0438303
I0820 10:30:38.056432 12052 solver.cpp:258]     Train net output #0: landmark_loss = 0.0438303 (* 1 = 0.0438303 loss)
I0820 10:30:38.056437 12052 sgd_solver.cpp:112] Iteration 64900, lr = 0.001
I0820 10:30:42.835070 12052 solver.cpp:239] Iteration 65000 (20.9267 iter/s, 4.77859s/100 iters), loss = 0.0567234
I0820 10:30:42.835122 12052 solver.cpp:258]     Train net output #0: landmark_loss = 0.0567234 (* 1 = 0.0567234 loss)
I0820 10:30:42.835129 12052 sgd_solver.cpp:112] Iteration 65000, lr = 0.001
I0820 10:30:47.422464 12052 solver.cpp:239] Iteration 65100 (21.7993 iter/s, 4.5873s/100 iters), loss = 0.0425989
I0820 10:30:47.422507 12052 solver.cpp:258]     Train net output #0: landmark_loss = 0.0425989 (* 1 = 0.0425989 loss)
I0820 10:30:47.422513 12052 sgd_solver.cpp:112] Iteration 65100, lr = 0.001
I0820 10:30:52.167862 12052 solver.cpp:239] Iteration 65200 (21.0735 iter/s, 4.7453s/100 iters), loss = 0.044149
I0820 10:30:52.167915 12052 solver.cpp:258]     Train net output #0: landmark_loss = 0.044149 (* 1 = 0.044149 loss)
I0820 10:30:52.167922 12052 sgd_solver.cpp:112] Iteration 65200, lr = 0.001
I0820 10:30:56.938676 12052 solver.cpp:239] Iteration 65300 (20.9612 iter/s, 4.77071s/100 iters), loss = 0.0401315
I0820 10:30:56.938717 12052 solver.cpp:258]     Train net output #0: landmark_loss = 0.0401315 (* 1 = 0.0401315 loss)
I0820 10:30:56.938735 12052 sgd_solver.cpp:112] Iteration 65300, lr = 0.001
I0820 10:31:01.739310 12052 solver.cpp:239] Iteration 65400 (20.831 iter/s, 4.80053s/100 iters), loss = 0.041481
I0820 10:31:01.739353 12052 solver.cpp:258]     Train net output #0: landmark_loss = 0.041481 (* 1 = 0.041481 loss)
I0820 10:31:01.739359 12052 sgd_solver.cpp:112] Iteration 65400, lr = 0.001
I0820 10:31:06.518718 12052 solver.cpp:239] Iteration 65500 (20.9236 iter/s, 4.7793s/100 iters), loss = 0.0537157
I0820 10:31:06.518771 12052 solver.cpp:258]     Train net output #0: landmark_loss = 0.0537157 (* 1 = 0.0537157 loss)
I0820 10:31:06.518777 12052 sgd_solver.cpp:112] Iteration 65500, lr = 0.001
I0820 10:31:11.288143 12052 solver.cpp:239] Iteration 65600 (20.9674 iter/s, 4.76932s/100 iters), loss = 0.0416941
I0820 10:31:11.288197 12052 solver.cpp:258]     Train net output #0: landmark_loss = 0.0416941 (* 1 = 0.0416941 loss)
I0820 10:31:11.288203 12052 sgd_solver.cpp:112] Iteration 65600, lr = 0.001
I0820 10:31:16.059111 12052 solver.cpp:239] Iteration 65700 (20.9606 iter/s, 4.77086s/100 iters), loss = 0.0439495
I0820 10:31:16.059165 12052 solver.cpp:258]     Train net output #0: landmark_loss = 0.0439494 (* 1 = 0.0439494 loss)
I0820 10:31:16.059170 12052 sgd_solver.cpp:112] Iteration 65700, lr = 0.001
I0820 10:31:20.828900 12052 solver.cpp:239] Iteration 65800 (20.9657 iter/s, 4.76969s/100 iters), loss = 0.0465416
I0820 10:31:20.828953 12052 solver.cpp:258]     Train net output #0: landmark_loss = 0.0465416 (* 1 = 0.0465416 loss)
I0820 10:31:20.828959 12052 sgd_solver.cpp:112] Iteration 65800, lr = 0.001
I0820 10:31:25.612777 12052 solver.cpp:239] Iteration 65900 (20.9041 iter/s, 4.78376s/100 iters), loss = 0.0488339
I0820 10:31:25.612820 12052 solver.cpp:258]     Train net output #0: landmark_loss = 0.0488339 (* 1 = 0.0488339 loss)
I0820 10:31:25.612828 12052 sgd_solver.cpp:112] Iteration 65900, lr = 0.001
I0820 10:31:30.329303 12052 solver.cpp:347] Iteration 66000, Testing net (#0)
I0820 10:31:51.426318 12052 solver.cpp:414]     Test net output #0: landmark_loss = 0.0267967 (* 1 = 0.0267967 loss)
I0820 10:31:51.473618 12052 solver.cpp:239] Iteration 66000 (3.86689 iter/s, 25.8606s/100 iters), loss = 0.0435812
I0820 10:31:51.473659 12052 solver.cpp:258]     Train net output #0: landmark_loss = 0.0435812 (* 1 = 0.0435812 loss)
I0820 10:31:51.473665 12052 sgd_solver.cpp:112] Iteration 66000, lr = 0.001
I0820 10:31:56.243934 12052 solver.cpp:239] Iteration 66100 (20.9636 iter/s, 4.77018s/100 iters), loss = 0.0486799
I0820 10:31:56.243986 12052 solver.cpp:258]     Train net output #0: landmark_loss = 0.0486798 (* 1 = 0.0486798 loss)
I0820 10:31:56.243993 12052 sgd_solver.cpp:112] Iteration 66100, lr = 0.001
I0820 10:32:01.039259 12052 solver.cpp:239] Iteration 66200 (20.8542 iter/s, 4.79519s/100 iters), loss = 0.0411344
I0820 10:32:01.039304 12052 solver.cpp:258]     Train net output #0: landmark_loss = 0.0411344 (* 1 = 0.0411344 loss)
I0820 10:32:01.039309 12052 sgd_solver.cpp:112] Iteration 66200, lr = 0.001
I0820 10:32:05.822464 12052 solver.cpp:239] Iteration 66300 (20.9071 iter/s, 4.78306s/100 iters), loss = 0.0465978
I0820 10:32:05.822518 12052 solver.cpp:258]     Train net output #0: landmark_loss = 0.0465977 (* 1 = 0.0465977 loss)
I0820 10:32:05.822525 12052 sgd_solver.cpp:112] Iteration 66300, lr = 0.001
I0820 10:32:10.592622 12052 solver.cpp:239] Iteration 66400 (20.9643 iter/s, 4.77002s/100 iters), loss = 0.0408982
I0820 10:32:10.592677 12052 solver.cpp:258]     Train net output #0: landmark_loss = 0.0408981 (* 1 = 0.0408981 loss)
I0820 10:32:10.592684 12052 sgd_solver.cpp:112] Iteration 66400, lr = 0.001
I0820 10:32:15.324578 12052 solver.cpp:239] Iteration 66500 (21.1335 iter/s, 4.73182s/100 iters), loss = 0.039313
I0820 10:32:15.324622 12052 solver.cpp:258]     Train net output #0: landmark_loss = 0.039313 (* 1 = 0.039313 loss)
I0820 10:32:15.324628 12052 sgd_solver.cpp:112] Iteration 66500, lr = 0.001
I0820 10:32:20.037633 12052 solver.cpp:239] Iteration 66600 (21.2183 iter/s, 4.71292s/100 iters), loss = 0.0439807
I0820 10:32:20.037688 12052 solver.cpp:258]     Train net output #0: landmark_loss = 0.0439806 (* 1 = 0.0439806 loss)
I0820 10:32:20.037693 12052 sgd_solver.cpp:112] Iteration 66600, lr = 0.001
I0820 10:32:24.750674 12052 solver.cpp:239] Iteration 66700 (21.2183 iter/s, 4.7129s/100 iters), loss = 0.0414758
I0820 10:32:24.750726 12052 solver.cpp:258]     Train net output #0: landmark_loss = 0.0414758 (* 1 = 0.0414758 loss)
I0820 10:32:24.750732 12052 sgd_solver.cpp:112] Iteration 66700, lr = 0.001
I0820 10:32:29.496484 12052 solver.cpp:239] Iteration 66800 (21.0718 iter/s, 4.74567s/100 iters), loss = 0.0384186
I0820 10:32:29.496536 12052 solver.cpp:258]     Train net output #0: landmark_loss = 0.0384186 (* 1 = 0.0384186 loss)
I0820 10:32:29.496542 12052 sgd_solver.cpp:112] Iteration 66800, lr = 0.001
I0820 10:32:34.255039 12052 solver.cpp:239] Iteration 66900 (21.0154 iter/s, 4.75842s/100 iters), loss = 0.0609798
I0820 10:32:34.255095 12052 solver.cpp:258]     Train net output #0: landmark_loss = 0.0609798 (* 1 = 0.0609798 loss)
I0820 10:32:34.255100 12052 sgd_solver.cpp:112] Iteration 66900, lr = 0.001
I0820 10:32:39.014436 12052 solver.cpp:239] Iteration 67000 (21.0117 iter/s, 4.75926s/100 iters), loss = 0.0443957
I0820 10:32:39.014490 12052 solver.cpp:258]     Train net output #0: landmark_loss = 0.0443957 (* 1 = 0.0443957 loss)
I0820 10:32:39.014497 12052 sgd_solver.cpp:112] Iteration 67000, lr = 0.001
I0820 10:32:43.772497 12052 solver.cpp:239] Iteration 67100 (21.0176 iter/s, 4.75792s/100 iters), loss = 0.0511854
I0820 10:32:43.772549 12052 solver.cpp:258]     Train net output #0: landmark_loss = 0.0511854 (* 1 = 0.0511854 loss)
I0820 10:32:43.772557 12052 sgd_solver.cpp:112] Iteration 67100, lr = 0.001
I0820 10:32:48.483311 12052 solver.cpp:239] Iteration 67200 (21.2284 iter/s, 4.71068s/100 iters), loss = 0.0471037
I0820 10:32:48.483363 12052 solver.cpp:258]     Train net output #0: landmark_loss = 0.0471037 (* 1 = 0.0471037 loss)
I0820 10:32:48.483369 12052 sgd_solver.cpp:112] Iteration 67200, lr = 0.001
I0820 10:32:53.194516 12052 solver.cpp:239] Iteration 67300 (21.2266 iter/s, 4.71107s/100 iters), loss = 0.0398974
I0820 10:32:53.194569 12052 solver.cpp:258]     Train net output #0: landmark_loss = 0.0398974 (* 1 = 0.0398974 loss)
I0820 10:32:53.194576 12052 sgd_solver.cpp:112] Iteration 67300, lr = 0.001
I0820 10:32:57.845587 12052 solver.cpp:239] Iteration 67400 (21.501 iter/s, 4.65094s/100 iters), loss = 0.0401574
I0820 10:32:57.845635 12052 solver.cpp:258]     Train net output #0: landmark_loss = 0.0401574 (* 1 = 0.0401574 loss)
I0820 10:32:57.845641 12052 sgd_solver.cpp:112] Iteration 67400, lr = 0.001
I0820 10:33:02.551991 12052 solver.cpp:239] Iteration 67500 (21.248 iter/s, 4.70633s/100 iters), loss = 0.0434467
I0820 10:33:02.552037 12052 solver.cpp:258]     Train net output #0: landmark_loss = 0.0434467 (* 1 = 0.0434467 loss)
I0820 10:33:02.552042 12052 sgd_solver.cpp:112] Iteration 67500, lr = 0.001
I0820 10:33:07.294023 12052 solver.cpp:239] Iteration 67600 (21.0886 iter/s, 4.7419s/100 iters), loss = 0.0438161
I0820 10:33:07.294075 12052 solver.cpp:258]     Train net output #0: landmark_loss = 0.0438161 (* 1 = 0.0438161 loss)
I0820 10:33:07.294081 12052 sgd_solver.cpp:112] Iteration 67600, lr = 0.001
I0820 10:33:12.030836 12052 solver.cpp:239] Iteration 67700 (21.1118 iter/s, 4.73668s/100 iters), loss = 0.0489153
I0820 10:33:12.030886 12052 solver.cpp:258]     Train net output #0: landmark_loss = 0.0489153 (* 1 = 0.0489153 loss)
I0820 10:33:12.030894 12052 sgd_solver.cpp:112] Iteration 67700, lr = 0.001
I0820 10:33:16.767339 12052 solver.cpp:239] Iteration 67800 (21.1132 iter/s, 4.73637s/100 iters), loss = 0.0468168
I0820 10:33:16.767392 12052 solver.cpp:258]     Train net output #0: landmark_loss = 0.0468167 (* 1 = 0.0468167 loss)
I0820 10:33:16.767398 12052 sgd_solver.cpp:112] Iteration 67800, lr = 0.001
I0820 10:33:21.504158 12052 solver.cpp:239] Iteration 67900 (21.1118 iter/s, 4.73668s/100 iters), loss = 0.0389204
I0820 10:33:21.504209 12052 solver.cpp:258]     Train net output #0: landmark_loss = 0.0389204 (* 1 = 0.0389204 loss)
I0820 10:33:21.504215 12052 sgd_solver.cpp:112] Iteration 67900, lr = 0.001
I0820 10:33:26.256752 12052 solver.cpp:239] Iteration 68000 (21.0418 iter/s, 4.75245s/100 iters), loss = 0.041225
I0820 10:33:26.256805 12052 solver.cpp:258]     Train net output #0: landmark_loss = 0.0412249 (* 1 = 0.0412249 loss)
I0820 10:33:26.256811 12052 sgd_solver.cpp:112] Iteration 68000, lr = 0.001
I0820 10:33:30.999112 12052 solver.cpp:239] Iteration 68100 (21.0871 iter/s, 4.74223s/100 iters), loss = 0.0404855
I0820 10:33:30.999166 12052 solver.cpp:258]     Train net output #0: landmark_loss = 0.0404855 (* 1 = 0.0404855 loss)
I0820 10:33:30.999171 12052 sgd_solver.cpp:112] Iteration 68100, lr = 0.001
I0820 10:33:35.735857 12052 solver.cpp:239] Iteration 68200 (21.1122 iter/s, 4.7366s/100 iters), loss = 0.0461068
I0820 10:33:35.735908 12052 solver.cpp:258]     Train net output #0: landmark_loss = 0.0461067 (* 1 = 0.0461067 loss)
I0820 10:33:35.735914 12052 sgd_solver.cpp:112] Iteration 68200, lr = 0.001
I0820 10:33:39.837852 12052 solver.cpp:239] Iteration 68300 (24.3792 iter/s, 4.10185s/100 iters), loss = 0.0510367
I0820 10:33:39.837905 12052 solver.cpp:258]     Train net output #0: landmark_loss = 0.0510367 (* 1 = 0.0510367 loss)
I0820 10:33:39.837911 12052 sgd_solver.cpp:112] Iteration 68300, lr = 0.001
I0820 10:33:43.908712 12052 solver.cpp:239] Iteration 68400 (24.5652 iter/s, 4.0708s/100 iters), loss = 0.044967
I0820 10:33:43.908764 12052 solver.cpp:258]     Train net output #0: landmark_loss = 0.044967 (* 1 = 0.044967 loss)
I0820 10:33:43.908771 12052 sgd_solver.cpp:112] Iteration 68400, lr = 0.001
I0820 10:33:48.593228 12052 solver.cpp:239] Iteration 68500 (21.3475 iter/s, 4.68439s/100 iters), loss = 0.0381792
I0820 10:33:48.593281 12052 solver.cpp:258]     Train net output #0: landmark_loss = 0.0381792 (* 1 = 0.0381792 loss)
I0820 10:33:48.593286 12052 sgd_solver.cpp:112] Iteration 68500, lr = 0.001
I0820 10:33:53.268954 12052 solver.cpp:239] Iteration 68600 (21.3876 iter/s, 4.6756s/100 iters), loss = 0.0450062
I0820 10:33:53.269006 12052 solver.cpp:258]     Train net output #0: landmark_loss = 0.0450062 (* 1 = 0.0450062 loss)
I0820 10:33:53.269011 12052 sgd_solver.cpp:112] Iteration 68600, lr = 0.001
I0820 10:33:57.962595 12052 solver.cpp:239] Iteration 68700 (21.306 iter/s, 4.69351s/100 iters), loss = 0.0439261
I0820 10:33:57.962646 12052 solver.cpp:258]     Train net output #0: landmark_loss = 0.0439261 (* 1 = 0.0439261 loss)
I0820 10:33:57.962652 12052 sgd_solver.cpp:112] Iteration 68700, lr = 0.001
I0820 10:34:02.744750 12052 solver.cpp:239] Iteration 68800 (20.9116 iter/s, 4.78203s/100 iters), loss = 0.0417492
I0820 10:34:02.744794 12052 solver.cpp:258]     Train net output #0: landmark_loss = 0.0417492 (* 1 = 0.0417492 loss)
I0820 10:34:02.744801 12052 sgd_solver.cpp:112] Iteration 68800, lr = 0.001
I0820 10:34:07.502053 12052 solver.cpp:239] Iteration 68900 (21.0209 iter/s, 4.75717s/100 iters), loss = 0.0350736
I0820 10:34:07.502106 12052 solver.cpp:258]     Train net output #0: landmark_loss = 0.0350736 (* 1 = 0.0350736 loss)
I0820 10:34:07.502112 12052 sgd_solver.cpp:112] Iteration 68900, lr = 0.001
I0820 10:34:12.255107 12052 solver.cpp:239] Iteration 69000 (21.0397 iter/s, 4.75292s/100 iters), loss = 0.0441545
I0820 10:34:12.255161 12052 solver.cpp:258]     Train net output #0: landmark_loss = 0.0441544 (* 1 = 0.0441544 loss)
I0820 10:34:12.255167 12052 sgd_solver.cpp:112] Iteration 69000, lr = 0.001
I0820 10:34:17.008086 12052 solver.cpp:239] Iteration 69100 (21.04 iter/s, 4.75284s/100 iters), loss = 0.0447415
I0820 10:34:17.008155 12052 solver.cpp:258]     Train net output #0: landmark_loss = 0.0447415 (* 1 = 0.0447415 loss)
I0820 10:34:17.008164 12052 sgd_solver.cpp:112] Iteration 69100, lr = 0.001
I0820 10:34:21.760197 12052 solver.cpp:239] Iteration 69200 (21.0439 iter/s, 4.75197s/100 iters), loss = 0.0526213
I0820 10:34:21.760251 12052 solver.cpp:258]     Train net output #0: landmark_loss = 0.0526213 (* 1 = 0.0526213 loss)
I0820 10:34:21.760257 12052 sgd_solver.cpp:112] Iteration 69200, lr = 0.001
I0820 10:34:26.512260 12052 solver.cpp:239] Iteration 69300 (21.0441 iter/s, 4.75192s/100 iters), loss = 0.0468429
I0820 10:34:26.512312 12052 solver.cpp:258]     Train net output #0: landmark_loss = 0.0468429 (* 1 = 0.0468429 loss)
I0820 10:34:26.512318 12052 sgd_solver.cpp:112] Iteration 69300, lr = 0.001
I0820 10:34:31.264160 12052 solver.cpp:239] Iteration 69400 (21.0448 iter/s, 4.75177s/100 iters), loss = 0.0476289
I0820 10:34:31.264212 12052 solver.cpp:258]     Train net output #0: landmark_loss = 0.0476289 (* 1 = 0.0476289 loss)
I0820 10:34:31.264219 12052 sgd_solver.cpp:112] Iteration 69400, lr = 0.001
I0820 10:34:36.016655 12052 solver.cpp:239] Iteration 69500 (21.0421 iter/s, 4.75237s/100 iters), loss = 0.0398344
I0820 10:34:36.016708 12052 solver.cpp:258]     Train net output #0: landmark_loss = 0.0398344 (* 1 = 0.0398344 loss)
I0820 10:34:36.016714 12052 sgd_solver.cpp:112] Iteration 69500, lr = 0.001
I0820 10:34:40.768662 12052 solver.cpp:239] Iteration 69600 (21.0443 iter/s, 4.75188s/100 iters), loss = 0.0399644
I0820 10:34:40.768714 12052 solver.cpp:258]     Train net output #0: landmark_loss = 0.0399644 (* 1 = 0.0399644 loss)
I0820 10:34:40.768720 12052 sgd_solver.cpp:112] Iteration 69600, lr = 0.001
I0820 10:34:45.524123 12052 solver.cpp:239] Iteration 69700 (21.029 iter/s, 4.75534s/100 iters), loss = 0.0402466
I0820 10:34:45.524188 12052 solver.cpp:258]     Train net output #0: landmark_loss = 0.0402466 (* 1 = 0.0402466 loss)
I0820 10:34:45.524194 12052 sgd_solver.cpp:112] Iteration 69700, lr = 0.001
I0820 10:34:50.214565 12052 solver.cpp:239] Iteration 69800 (21.3206 iter/s, 4.6903s/100 iters), loss = 0.035448
I0820 10:34:50.214617 12052 solver.cpp:258]     Train net output #0: landmark_loss = 0.035448 (* 1 = 0.035448 loss)
I0820 10:34:50.214623 12052 sgd_solver.cpp:112] Iteration 69800, lr = 0.001
I0820 10:34:54.906356 12052 solver.cpp:239] Iteration 69900 (21.3144 iter/s, 4.69166s/100 iters), loss = 0.0473757
I0820 10:34:54.906407 12052 solver.cpp:258]     Train net output #0: landmark_loss = 0.0473757 (* 1 = 0.0473757 loss)
I0820 10:34:54.906414 12052 sgd_solver.cpp:112] Iteration 69900, lr = 0.001
I0820 10:34:59.531599 12052 solver.cpp:464] Snapshotting to binary proto file ./model/M3_iter_70000.caffemodel
I0820 10:34:59.634766 12052 sgd_solver.cpp:284] Snapshotting solver state to binary proto file ./model/M3_iter_70000.solverstate
I0820 10:34:59.733464 12052 solver.cpp:239] Iteration 70000 (20.7169 iter/s, 4.82698s/100 iters), loss = 0.0410957
I0820 10:34:59.733515 12052 solver.cpp:258]     Train net output #0: landmark_loss = 0.0410956 (* 1 = 0.0410956 loss)
I0820 10:34:59.733520 12052 sgd_solver.cpp:112] Iteration 70000, lr = 0.001
I0820 10:35:04.463107 12052 solver.cpp:239] Iteration 70100 (21.1438 iter/s, 4.72952s/100 iters), loss = 0.0493864
I0820 10:35:04.463158 12052 solver.cpp:258]     Train net output #0: landmark_loss = 0.0493864 (* 1 = 0.0493864 loss)
I0820 10:35:04.463165 12052 sgd_solver.cpp:112] Iteration 70100, lr = 0.001
I0820 10:35:09.154171 12052 solver.cpp:239] Iteration 70200 (21.3177 iter/s, 4.69094s/100 iters), loss = 0.0405449
I0820 10:35:09.154222 12052 solver.cpp:258]     Train net output #0: landmark_loss = 0.0405449 (* 1 = 0.0405449 loss)
I0820 10:35:09.154229 12052 sgd_solver.cpp:112] Iteration 70200, lr = 0.001
I0820 10:35:13.222826 12052 solver.cpp:239] Iteration 70300 (24.5789 iter/s, 4.06853s/100 iters), loss = 0.04503
I0820 10:35:13.222867 12052 solver.cpp:258]     Train net output #0: landmark_loss = 0.04503 (* 1 = 0.04503 loss)
I0820 10:35:13.222872 12052 sgd_solver.cpp:112] Iteration 70300, lr = 0.001
I0820 10:35:17.504802 12052 solver.cpp:239] Iteration 70400 (23.354 iter/s, 4.28192s/100 iters), loss = 0.0423415
I0820 10:35:17.504853 12052 solver.cpp:258]     Train net output #0: landmark_loss = 0.0423414 (* 1 = 0.0423414 loss)
I0820 10:35:17.504859 12052 sgd_solver.cpp:112] Iteration 70400, lr = 0.001
I0820 10:35:22.179792 12052 solver.cpp:239] Iteration 70500 (21.391 iter/s, 4.67486s/100 iters), loss = 0.0416833
I0820 10:35:22.179843 12052 solver.cpp:258]     Train net output #0: landmark_loss = 0.0416833 (* 1 = 0.0416833 loss)
I0820 10:35:22.179849 12052 sgd_solver.cpp:112] Iteration 70500, lr = 0.001
I0820 10:35:26.859190 12052 solver.cpp:239] Iteration 70600 (21.3709 iter/s, 4.67927s/100 iters), loss = 0.0383507
I0820 10:35:26.859242 12052 solver.cpp:258]     Train net output #0: landmark_loss = 0.0383507 (* 1 = 0.0383507 loss)
I0820 10:35:26.859248 12052 sgd_solver.cpp:112] Iteration 70600, lr = 0.001
I0820 10:35:31.538815 12052 solver.cpp:239] Iteration 70700 (21.3698 iter/s, 4.6795s/100 iters), loss = 0.0448928
I0820 10:35:31.538866 12052 solver.cpp:258]     Train net output #0: landmark_loss = 0.0448927 (* 1 = 0.0448927 loss)
I0820 10:35:31.538872 12052 sgd_solver.cpp:112] Iteration 70700, lr = 0.001
I0820 10:35:36.219035 12052 solver.cpp:239] Iteration 70800 (21.3671 iter/s, 4.6801s/100 iters), loss = 0.0427631
I0820 10:35:36.219087 12052 solver.cpp:258]     Train net output #0: landmark_loss = 0.0427631 (* 1 = 0.0427631 loss)
I0820 10:35:36.219094 12052 sgd_solver.cpp:112] Iteration 70800, lr = 0.001
I0820 10:35:40.897481 12052 solver.cpp:239] Iteration 70900 (21.3752 iter/s, 4.67832s/100 iters), loss = 0.0432464
I0820 10:35:40.897532 12052 solver.cpp:258]     Train net output #0: landmark_loss = 0.0432463 (* 1 = 0.0432463 loss)
I0820 10:35:40.897538 12052 sgd_solver.cpp:112] Iteration 70900, lr = 0.001
I0820 10:35:45.575731 12052 solver.cpp:239] Iteration 71000 (21.3761 iter/s, 4.67813s/100 iters), loss = 0.043201
I0820 10:35:45.575783 12052 solver.cpp:258]     Train net output #0: landmark_loss = 0.0432009 (* 1 = 0.0432009 loss)
I0820 10:35:45.575789 12052 sgd_solver.cpp:112] Iteration 71000, lr = 0.001
I0820 10:35:50.254462 12052 solver.cpp:239] Iteration 71100 (21.3739 iter/s, 4.6786s/100 iters), loss = 0.0523032
I0820 10:35:50.254514 12052 solver.cpp:258]     Train net output #0: landmark_loss = 0.0523032 (* 1 = 0.0523032 loss)
I0820 10:35:50.254520 12052 sgd_solver.cpp:112] Iteration 71100, lr = 0.001
I0820 10:35:54.942013 12052 solver.cpp:239] Iteration 71200 (21.3337 iter/s, 4.68743s/100 iters), loss = 0.0422005
I0820 10:35:54.942065 12052 solver.cpp:258]     Train net output #0: landmark_loss = 0.0422005 (* 1 = 0.0422005 loss)
I0820 10:35:54.942071 12052 sgd_solver.cpp:112] Iteration 71200, lr = 0.001
I0820 10:35:59.619654 12052 solver.cpp:239] Iteration 71300 (21.3789 iter/s, 4.67752s/100 iters), loss = 0.0385439
I0820 10:35:59.619706 12052 solver.cpp:258]     Train net output #0: landmark_loss = 0.0385438 (* 1 = 0.0385438 loss)
I0820 10:35:59.619712 12052 sgd_solver.cpp:112] Iteration 71300, lr = 0.001
I0820 10:36:04.335779 12052 solver.cpp:239] Iteration 71400 (21.2044 iter/s, 4.716s/100 iters), loss = 0.0504677
I0820 10:36:04.335831 12052 solver.cpp:258]     Train net output #0: landmark_loss = 0.0504677 (* 1 = 0.0504677 loss)
I0820 10:36:04.335837 12052 sgd_solver.cpp:112] Iteration 71400, lr = 0.001
I0820 10:36:09.017463 12052 solver.cpp:239] Iteration 71500 (21.3604 iter/s, 4.68156s/100 iters), loss = 0.0408859
I0820 10:36:09.017514 12052 solver.cpp:258]     Train net output #0: landmark_loss = 0.0408859 (* 1 = 0.0408859 loss)
I0820 10:36:09.017520 12052 sgd_solver.cpp:112] Iteration 71500, lr = 0.001
I0820 10:36:13.694869 12052 solver.cpp:239] Iteration 71600 (21.3799 iter/s, 4.67728s/100 iters), loss = 0.0459807
I0820 10:36:13.694921 12052 solver.cpp:258]     Train net output #0: landmark_loss = 0.0459807 (* 1 = 0.0459807 loss)
I0820 10:36:13.694927 12052 sgd_solver.cpp:112] Iteration 71600, lr = 0.001
I0820 10:36:18.374846 12052 solver.cpp:239] Iteration 71700 (21.3682 iter/s, 4.67985s/100 iters), loss = 0.044368
I0820 10:36:18.374898 12052 solver.cpp:258]     Train net output #0: landmark_loss = 0.044368 (* 1 = 0.044368 loss)
I0820 10:36:18.374904 12052 sgd_solver.cpp:112] Iteration 71700, lr = 0.001
I0820 10:36:23.157842 12052 solver.cpp:239] Iteration 71800 (20.9079 iter/s, 4.78287s/100 iters), loss = 0.0648878
I0820 10:36:23.157896 12052 solver.cpp:258]     Train net output #0: landmark_loss = 0.0648878 (* 1 = 0.0648878 loss)
I0820 10:36:23.157902 12052 sgd_solver.cpp:112] Iteration 71800, lr = 0.001
I0820 10:36:27.941551 12052 solver.cpp:239] Iteration 71900 (20.9049 iter/s, 4.78358s/100 iters), loss = 0.0481589
I0820 10:36:27.941603 12052 solver.cpp:258]     Train net output #0: landmark_loss = 0.0481589 (* 1 = 0.0481589 loss)
I0820 10:36:27.941609 12052 sgd_solver.cpp:112] Iteration 71900, lr = 0.001
I0820 10:36:32.657392 12052 solver.cpp:347] Iteration 72000, Testing net (#0)
I0820 10:36:53.845834 12052 solver.cpp:414]     Test net output #0: landmark_loss = 0.0341055 (* 1 = 0.0341055 loss)
I0820 10:36:53.893241 12052 solver.cpp:239] Iteration 72000 (3.85334 iter/s, 25.9515s/100 iters), loss = 0.0470739
I0820 10:36:53.893281 12052 solver.cpp:258]     Train net output #0: landmark_loss = 0.0470738 (* 1 = 0.0470738 loss)
I0820 10:36:53.893287 12052 sgd_solver.cpp:112] Iteration 72000, lr = 0.001
I0820 10:36:58.618873 12052 solver.cpp:239] Iteration 72100 (21.1618 iter/s, 4.7255s/100 iters), loss = 0.0418146
I0820 10:36:58.618924 12052 solver.cpp:258]     Train net output #0: landmark_loss = 0.0418146 (* 1 = 0.0418146 loss)
I0820 10:36:58.618932 12052 sgd_solver.cpp:112] Iteration 72100, lr = 0.001
I0820 10:37:03.358083 12052 solver.cpp:239] Iteration 72200 (21.1011 iter/s, 4.73909s/100 iters), loss = 0.050096
I0820 10:37:03.358126 12052 solver.cpp:258]     Train net output #0: landmark_loss = 0.050096 (* 1 = 0.050096 loss)
I0820 10:37:03.358132 12052 sgd_solver.cpp:112] Iteration 72200, lr = 0.001
I0820 10:37:08.061161 12052 solver.cpp:239] Iteration 72300 (21.2632 iter/s, 4.70295s/100 iters), loss = 0.0444699
I0820 10:37:08.061211 12052 solver.cpp:258]     Train net output #0: landmark_loss = 0.0444699 (* 1 = 0.0444699 loss)
I0820 10:37:08.061218 12052 sgd_solver.cpp:112] Iteration 72300, lr = 0.001
I0820 10:37:12.747296 12052 solver.cpp:239] Iteration 72400 (21.3401 iter/s, 4.68602s/100 iters), loss = 0.0461769
I0820 10:37:12.747349 12052 solver.cpp:258]     Train net output #0: landmark_loss = 0.0461768 (* 1 = 0.0461768 loss)
I0820 10:37:12.747354 12052 sgd_solver.cpp:112] Iteration 72400, lr = 0.001
I0820 10:37:17.440059 12052 solver.cpp:239] Iteration 72500 (21.31 iter/s, 4.69264s/100 iters), loss = 0.0612989
I0820 10:37:17.440110 12052 solver.cpp:258]     Train net output #0: landmark_loss = 0.0612989 (* 1 = 0.0612989 loss)
I0820 10:37:17.440116 12052 sgd_solver.cpp:112] Iteration 72500, lr = 0.001
I0820 10:37:22.150734 12052 solver.cpp:239] Iteration 72600 (21.229 iter/s, 4.71054s/100 iters), loss = 0.045586
I0820 10:37:22.150785 12052 solver.cpp:258]     Train net output #0: landmark_loss = 0.045586 (* 1 = 0.045586 loss)
I0820 10:37:22.150791 12052 sgd_solver.cpp:112] Iteration 72600, lr = 0.001
I0820 10:37:26.861840 12052 solver.cpp:239] Iteration 72700 (21.227 iter/s, 4.71099s/100 iters), loss = 0.0489265
I0820 10:37:26.861892 12052 solver.cpp:258]     Train net output #0: landmark_loss = 0.0489265 (* 1 = 0.0489265 loss)
I0820 10:37:26.861898 12052 sgd_solver.cpp:112] Iteration 72700, lr = 0.001
I0820 10:37:31.572237 12052 solver.cpp:239] Iteration 72800 (21.2302 iter/s, 4.71027s/100 iters), loss = 0.0406086
I0820 10:37:31.572288 12052 solver.cpp:258]     Train net output #0: landmark_loss = 0.0406086 (* 1 = 0.0406086 loss)
I0820 10:37:31.572294 12052 sgd_solver.cpp:112] Iteration 72800, lr = 0.001
I0820 10:37:36.280738 12052 solver.cpp:239] Iteration 72900 (21.2387 iter/s, 4.70838s/100 iters), loss = 0.0439212
I0820 10:37:36.280791 12052 solver.cpp:258]     Train net output #0: landmark_loss = 0.0439212 (* 1 = 0.0439212 loss)
I0820 10:37:36.280797 12052 sgd_solver.cpp:112] Iteration 72900, lr = 0.001
I0820 10:37:40.991955 12052 solver.cpp:239] Iteration 73000 (21.2265 iter/s, 4.71109s/100 iters), loss = 0.0394265
I0820 10:37:40.992007 12052 solver.cpp:258]     Train net output #0: landmark_loss = 0.0394264 (* 1 = 0.0394264 loss)
I0820 10:37:40.992012 12052 sgd_solver.cpp:112] Iteration 73000, lr = 0.001
I0820 10:37:46.199867 12052 solver.cpp:239] Iteration 73100 (19.202 iter/s, 5.20779s/100 iters), loss = 0.0428787
I0820 10:37:46.199918 12052 solver.cpp:258]     Train net output #0: landmark_loss = 0.0428787 (* 1 = 0.0428787 loss)
I0820 10:37:46.199924 12052 sgd_solver.cpp:112] Iteration 73100, lr = 0.001
I0820 10:37:50.879158 12052 solver.cpp:239] Iteration 73200 (21.3713 iter/s, 4.67917s/100 iters), loss = 0.0433762
I0820 10:37:50.879210 12052 solver.cpp:258]     Train net output #0: landmark_loss = 0.0433762 (* 1 = 0.0433762 loss)
I0820 10:37:50.879216 12052 sgd_solver.cpp:112] Iteration 73200, lr = 0.001
I0820 10:37:55.557515 12052 solver.cpp:239] Iteration 73300 (21.3756 iter/s, 4.67824s/100 iters), loss = 0.0366784
I0820 10:37:55.557567 12052 solver.cpp:258]     Train net output #0: landmark_loss = 0.0366784 (* 1 = 0.0366784 loss)
I0820 10:37:55.557574 12052 sgd_solver.cpp:112] Iteration 73300, lr = 0.001
I0820 10:38:00.252224 12052 solver.cpp:239] Iteration 73400 (21.3011 iter/s, 4.69459s/100 iters), loss = 0.0376927
I0820 10:38:00.252267 12052 solver.cpp:258]     Train net output #0: landmark_loss = 0.0376927 (* 1 = 0.0376927 loss)
I0820 10:38:00.252274 12052 sgd_solver.cpp:112] Iteration 73400, lr = 0.001
I0820 10:38:04.955952 12052 solver.cpp:239] Iteration 73500 (21.2605 iter/s, 4.70355s/100 iters), loss = 0.0417512
I0820 10:38:04.956004 12052 solver.cpp:258]     Train net output #0: landmark_loss = 0.0417511 (* 1 = 0.0417511 loss)
I0820 10:38:04.956012 12052 sgd_solver.cpp:112] Iteration 73500, lr = 0.001
I0820 10:38:09.640424 12052 solver.cpp:239] Iteration 73600 (21.3477 iter/s, 4.68435s/100 iters), loss = 0.0435082
I0820 10:38:09.640488 12052 solver.cpp:258]     Train net output #0: landmark_loss = 0.0435081 (* 1 = 0.0435081 loss)
I0820 10:38:09.640494 12052 sgd_solver.cpp:112] Iteration 73600, lr = 0.001
I0820 10:38:14.318761 12052 solver.cpp:239] Iteration 73700 (21.3757 iter/s, 4.67822s/100 iters), loss = 0.0386973
I0820 10:38:14.318814 12052 solver.cpp:258]     Train net output #0: landmark_loss = 0.0386973 (* 1 = 0.0386973 loss)
I0820 10:38:14.318819 12052 sgd_solver.cpp:112] Iteration 73700, lr = 0.001
I0820 10:38:18.998653 12052 solver.cpp:239] Iteration 73800 (21.3686 iter/s, 4.67977s/100 iters), loss = 0.0477906
I0820 10:38:18.998706 12052 solver.cpp:258]     Train net output #0: landmark_loss = 0.0477905 (* 1 = 0.0477905 loss)
I0820 10:38:18.998713 12052 sgd_solver.cpp:112] Iteration 73800, lr = 0.001
I0820 10:38:23.635777 12052 solver.cpp:239] Iteration 73900 (21.5656 iter/s, 4.63701s/100 iters), loss = 0.0478932
I0820 10:38:23.635829 12052 solver.cpp:258]     Train net output #0: landmark_loss = 0.0478932 (* 1 = 0.0478932 loss)
I0820 10:38:23.635835 12052 sgd_solver.cpp:112] Iteration 73900, lr = 0.001
I0820 10:38:28.301571 12052 solver.cpp:239] Iteration 74000 (21.4331 iter/s, 4.66567s/100 iters), loss = 0.0409179
I0820 10:38:28.301622 12052 solver.cpp:258]     Train net output #0: landmark_loss = 0.0409178 (* 1 = 0.0409178 loss)
I0820 10:38:28.301628 12052 sgd_solver.cpp:112] Iteration 74000, lr = 0.001
I0820 10:38:32.981845 12052 solver.cpp:239] Iteration 74100 (21.3668 iter/s, 4.68016s/100 iters), loss = 0.0365789
I0820 10:38:32.981896 12052 solver.cpp:258]     Train net output #0: landmark_loss = 0.0365789 (* 1 = 0.0365789 loss)
I0820 10:38:32.981902 12052 sgd_solver.cpp:112] Iteration 74100, lr = 0.001
I0820 10:38:37.662796 12052 solver.cpp:239] Iteration 74200 (21.3637 iter/s, 4.68083s/100 iters), loss = 0.0479329
I0820 10:38:37.662847 12052 solver.cpp:258]     Train net output #0: landmark_loss = 0.0479329 (* 1 = 0.0479329 loss)
I0820 10:38:37.662853 12052 sgd_solver.cpp:112] Iteration 74200, lr = 0.001
I0820 10:38:42.343842 12052 solver.cpp:239] Iteration 74300 (21.3633 iter/s, 4.68093s/100 iters), loss = 0.0370795
I0820 10:38:42.343892 12052 solver.cpp:258]     Train net output #0: landmark_loss = 0.0370795 (* 1 = 0.0370795 loss)
I0820 10:38:42.343899 12052 sgd_solver.cpp:112] Iteration 74300, lr = 0.001
I0820 10:38:47.024935 12052 solver.cpp:239] Iteration 74400 (21.3631 iter/s, 4.68097s/100 iters), loss = 0.0438146
I0820 10:38:47.024986 12052 solver.cpp:258]     Train net output #0: landmark_loss = 0.0438146 (* 1 = 0.0438146 loss)
I0820 10:38:47.024992 12052 sgd_solver.cpp:112] Iteration 74400, lr = 0.001
I0820 10:38:51.704407 12052 solver.cpp:239] Iteration 74500 (21.3705 iter/s, 4.67936s/100 iters), loss = 0.0403194
I0820 10:38:51.704460 12052 solver.cpp:258]     Train net output #0: landmark_loss = 0.0403193 (* 1 = 0.0403193 loss)
I0820 10:38:51.704478 12052 sgd_solver.cpp:112] Iteration 74500, lr = 0.001
I0820 10:38:56.386150 12052 solver.cpp:239] Iteration 74600 (21.3601 iter/s, 4.68162s/100 iters), loss = 0.0436533
I0820 10:38:56.386202 12052 solver.cpp:258]     Train net output #0: landmark_loss = 0.0436533 (* 1 = 0.0436533 loss)
I0820 10:38:56.386209 12052 sgd_solver.cpp:112] Iteration 74600, lr = 0.001
I0820 10:39:01.095489 12052 solver.cpp:239] Iteration 74700 (21.2349 iter/s, 4.70922s/100 iters), loss = 0.0367055
I0820 10:39:01.095530 12052 solver.cpp:258]     Train net output #0: landmark_loss = 0.0367055 (* 1 = 0.0367055 loss)
I0820 10:39:01.095536 12052 sgd_solver.cpp:112] Iteration 74700, lr = 0.001
I0820 10:39:05.798163 12052 solver.cpp:239] Iteration 74800 (21.265 iter/s, 4.70256s/100 iters), loss = 0.0392423
I0820 10:39:05.798216 12052 solver.cpp:258]     Train net output #0: landmark_loss = 0.0392423 (* 1 = 0.0392423 loss)
I0820 10:39:05.798223 12052 sgd_solver.cpp:112] Iteration 74800, lr = 0.001
I0820 10:39:10.482614 12052 solver.cpp:239] Iteration 74900 (21.3478 iter/s, 4.68433s/100 iters), loss = 0.0474319
I0820 10:39:10.482666 12052 solver.cpp:258]     Train net output #0: landmark_loss = 0.0474319 (* 1 = 0.0474319 loss)
I0820 10:39:10.482671 12052 sgd_solver.cpp:112] Iteration 74900, lr = 0.001
I0820 10:39:15.163543 12052 solver.cpp:239] Iteration 75000 (21.3638 iter/s, 4.68081s/100 iters), loss = 0.0332908
I0820 10:39:15.163595 12052 solver.cpp:258]     Train net output #0: landmark_loss = 0.0332908 (* 1 = 0.0332908 loss)
I0820 10:39:15.163601 12052 sgd_solver.cpp:112] Iteration 75000, lr = 0.001
I0820 10:39:19.844446 12052 solver.cpp:239] Iteration 75100 (21.3639 iter/s, 4.68079s/100 iters), loss = 0.175602
I0820 10:39:19.844498 12052 solver.cpp:258]     Train net output #0: landmark_loss = 0.175602 (* 1 = 0.175602 loss)
I0820 10:39:19.844504 12052 sgd_solver.cpp:112] Iteration 75100, lr = 0.001
I0820 10:39:24.525684 12052 solver.cpp:239] Iteration 75200 (21.3624 iter/s, 4.68112s/100 iters), loss = 0.0863897
I0820 10:39:24.525737 12052 solver.cpp:258]     Train net output #0: landmark_loss = 0.0863897 (* 1 = 0.0863897 loss)
I0820 10:39:24.525743 12052 sgd_solver.cpp:112] Iteration 75200, lr = 0.001
I0820 10:39:29.209609 12052 solver.cpp:239] Iteration 75300 (21.3501 iter/s, 4.68381s/100 iters), loss = 0.0611243
I0820 10:39:29.209661 12052 solver.cpp:258]     Train net output #0: landmark_loss = 0.0611243 (* 1 = 0.0611243 loss)
I0820 10:39:29.209666 12052 sgd_solver.cpp:112] Iteration 75300, lr = 0.001
I0820 10:39:33.891041 12052 solver.cpp:239] Iteration 75400 (21.3615 iter/s, 4.68131s/100 iters), loss = 0.0509505
I0820 10:39:33.891093 12052 solver.cpp:258]     Train net output #0: landmark_loss = 0.0509505 (* 1 = 0.0509505 loss)
I0820 10:39:33.891098 12052 sgd_solver.cpp:112] Iteration 75400, lr = 0.001
I0820 10:39:38.329924 12052 solver.cpp:239] Iteration 75500 (22.5288 iter/s, 4.43876s/100 iters), loss = 0.0515329
I0820 10:39:38.329977 12052 solver.cpp:258]     Train net output #0: landmark_loss = 0.0515328 (* 1 = 0.0515328 loss)
I0820 10:39:38.329983 12052 sgd_solver.cpp:112] Iteration 75500, lr = 0.001
I0820 10:39:42.333325 12052 solver.cpp:239] Iteration 75600 (24.9791 iter/s, 4.00335s/100 iters), loss = 0.0475183
I0820 10:39:42.333366 12052 solver.cpp:258]     Train net output #0: landmark_loss = 0.0475183 (* 1 = 0.0475183 loss)
I0820 10:39:42.333372 12052 sgd_solver.cpp:112] Iteration 75600, lr = 0.001
I0820 10:39:47.011981 12052 solver.cpp:239] Iteration 75700 (21.3742 iter/s, 4.67854s/100 iters), loss = 0.0401435
I0820 10:39:47.012032 12052 solver.cpp:258]     Train net output #0: landmark_loss = 0.0401435 (* 1 = 0.0401435 loss)
I0820 10:39:47.012038 12052 sgd_solver.cpp:112] Iteration 75700, lr = 0.001
I0820 10:39:51.689523 12052 solver.cpp:239] Iteration 75800 (21.3793 iter/s, 4.67743s/100 iters), loss = 0.0545024
I0820 10:39:51.689574 12052 solver.cpp:258]     Train net output #0: landmark_loss = 0.0545024 (* 1 = 0.0545024 loss)
I0820 10:39:51.689580 12052 sgd_solver.cpp:112] Iteration 75800, lr = 0.001
I0820 10:39:56.365895 12052 solver.cpp:239] Iteration 75900 (21.3846 iter/s, 4.67626s/100 iters), loss = 0.0399942
I0820 10:39:56.365944 12052 solver.cpp:258]     Train net output #0: landmark_loss = 0.0399942 (* 1 = 0.0399942 loss)
I0820 10:39:56.365950 12052 sgd_solver.cpp:112] Iteration 75900, lr = 0.001
I0820 10:40:01.068593 12052 solver.cpp:239] Iteration 76000 (21.2649 iter/s, 4.70258s/100 iters), loss = 0.042704
I0820 10:40:01.068634 12052 solver.cpp:258]     Train net output #0: landmark_loss = 0.042704 (* 1 = 0.042704 loss)
I0820 10:40:01.068640 12052 sgd_solver.cpp:112] Iteration 76000, lr = 0.001
I0820 10:40:05.767380 12052 solver.cpp:239] Iteration 76100 (21.2826 iter/s, 4.69867s/100 iters), loss = 0.0421095
I0820 10:40:05.767433 12052 solver.cpp:258]     Train net output #0: landmark_loss = 0.0421094 (* 1 = 0.0421094 loss)
I0820 10:40:05.767439 12052 sgd_solver.cpp:112] Iteration 76100, lr = 0.001
I0820 10:40:10.449445 12052 solver.cpp:239] Iteration 76200 (21.3586 iter/s, 4.68195s/100 iters), loss = 0.0462549
I0820 10:40:10.449497 12052 solver.cpp:258]     Train net output #0: landmark_loss = 0.0462548 (* 1 = 0.0462548 loss)
I0820 10:40:10.449503 12052 sgd_solver.cpp:112] Iteration 76200, lr = 0.001
I0820 10:40:15.138021 12052 solver.cpp:239] Iteration 76300 (21.329 iter/s, 4.68846s/100 iters), loss = 0.0411238
I0820 10:40:15.138075 12052 solver.cpp:258]     Train net output #0: landmark_loss = 0.0411238 (* 1 = 0.0411238 loss)
I0820 10:40:15.138082 12052 sgd_solver.cpp:112] Iteration 76300, lr = 0.001
I0820 10:40:19.818423 12052 solver.cpp:239] Iteration 76400 (21.3662 iter/s, 4.68028s/100 iters), loss = 0.0419607
I0820 10:40:19.818473 12052 solver.cpp:258]     Train net output #0: landmark_loss = 0.0419607 (* 1 = 0.0419607 loss)
I0820 10:40:19.818480 12052 sgd_solver.cpp:112] Iteration 76400, lr = 0.001
I0820 10:40:24.220409 12052 solver.cpp:239] Iteration 76500 (22.7176 iter/s, 4.40187s/100 iters), loss = 0.0383485
I0820 10:40:24.220463 12052 solver.cpp:258]     Train net output #0: landmark_loss = 0.0383485 (* 1 = 0.0383485 loss)
I0820 10:40:24.220468 12052 sgd_solver.cpp:112] Iteration 76500, lr = 0.001
I0820 10:40:28.899286 12052 solver.cpp:239] Iteration 76600 (21.3732 iter/s, 4.67876s/100 iters), loss = 0.037912
I0820 10:40:28.899338 12052 solver.cpp:258]     Train net output #0: landmark_loss = 0.037912 (* 1 = 0.037912 loss)
I0820 10:40:28.899343 12052 sgd_solver.cpp:112] Iteration 76600, lr = 0.001
I0820 10:40:33.578125 12052 solver.cpp:239] Iteration 76700 (21.3734 iter/s, 4.67872s/100 iters), loss = 0.0469663
I0820 10:40:33.578176 12052 solver.cpp:258]     Train net output #0: landmark_loss = 0.0469663 (* 1 = 0.0469663 loss)
I0820 10:40:33.578182 12052 sgd_solver.cpp:112] Iteration 76700, lr = 0.001
I0820 10:40:38.256083 12052 solver.cpp:239] Iteration 76800 (21.3774 iter/s, 4.67785s/100 iters), loss = 0.0345608
I0820 10:40:38.256139 12052 solver.cpp:258]     Train net output #0: landmark_loss = 0.0345608 (* 1 = 0.0345608 loss)
I0820 10:40:38.256145 12052 sgd_solver.cpp:112] Iteration 76800, lr = 0.001
I0820 10:40:42.936149 12052 solver.cpp:239] Iteration 76900 (21.3677 iter/s, 4.67995s/100 iters), loss = 0.0411162
I0820 10:40:42.936203 12052 solver.cpp:258]     Train net output #0: landmark_loss = 0.0411162 (* 1 = 0.0411162 loss)
I0820 10:40:42.936208 12052 sgd_solver.cpp:112] Iteration 76900, lr = 0.001
I0820 10:40:47.618001 12052 solver.cpp:239] Iteration 77000 (21.3596 iter/s, 4.68173s/100 iters), loss = 0.0460907
I0820 10:40:47.618052 12052 solver.cpp:258]     Train net output #0: landmark_loss = 0.0460907 (* 1 = 0.0460907 loss)
I0820 10:40:47.618057 12052 sgd_solver.cpp:112] Iteration 77000, lr = 0.001
I0820 10:40:52.298261 12052 solver.cpp:239] Iteration 77100 (21.3669 iter/s, 4.68014s/100 iters), loss = 0.0366047
I0820 10:40:52.298312 12052 solver.cpp:258]     Train net output #0: landmark_loss = 0.0366046 (* 1 = 0.0366046 loss)
I0820 10:40:52.298318 12052 sgd_solver.cpp:112] Iteration 77100, lr = 0.001
I0820 10:40:56.975397 12052 solver.cpp:239] Iteration 77200 (21.3811 iter/s, 4.67702s/100 iters), loss = 0.0410184
I0820 10:40:56.975447 12052 solver.cpp:258]     Train net output #0: landmark_loss = 0.0410184 (* 1 = 0.0410184 loss)
I0820 10:40:56.975453 12052 sgd_solver.cpp:112] Iteration 77200, lr = 0.001
I0820 10:41:01.680976 12052 solver.cpp:239] Iteration 77300 (21.2519 iter/s, 4.70546s/100 iters), loss = 0.0446015
I0820 10:41:01.681017 12052 solver.cpp:258]     Train net output #0: landmark_loss = 0.0446014 (* 1 = 0.0446014 loss)
I0820 10:41:01.681023 12052 sgd_solver.cpp:112] Iteration 77300, lr = 0.001
I0820 10:41:06.368587 12052 solver.cpp:239] Iteration 77400 (21.3333 iter/s, 4.6875s/100 iters), loss = 0.0432786
I0820 10:41:06.368638 12052 solver.cpp:258]     Train net output #0: landmark_loss = 0.0432785 (* 1 = 0.0432785 loss)
I0820 10:41:06.368644 12052 sgd_solver.cpp:112] Iteration 77400, lr = 0.001
I0820 10:41:10.883554 12052 solver.cpp:239] Iteration 77500 (22.1491 iter/s, 4.51485s/100 iters), loss = 0.0421931
I0820 10:41:10.883607 12052 solver.cpp:258]     Train net output #0: landmark_loss = 0.0421931 (* 1 = 0.0421931 loss)
I0820 10:41:10.883613 12052 sgd_solver.cpp:112] Iteration 77500, lr = 0.001
I0820 10:41:15.569432 12052 solver.cpp:239] Iteration 77600 (21.3412 iter/s, 4.68576s/100 iters), loss = 0.046135
I0820 10:41:15.569484 12052 solver.cpp:258]     Train net output #0: landmark_loss = 0.0461349 (* 1 = 0.0461349 loss)
I0820 10:41:15.569490 12052 sgd_solver.cpp:112] Iteration 77600, lr = 0.001
I0820 10:41:20.256454 12052 solver.cpp:239] Iteration 77700 (21.336 iter/s, 4.68691s/100 iters), loss = 0.0496098
I0820 10:41:20.256506 12052 solver.cpp:258]     Train net output #0: landmark_loss = 0.0496098 (* 1 = 0.0496098 loss)
I0820 10:41:20.256512 12052 sgd_solver.cpp:112] Iteration 77700, lr = 0.001
I0820 10:41:24.956238 12052 solver.cpp:239] Iteration 77800 (21.2781 iter/s, 4.69967s/100 iters), loss = 0.040735
I0820 10:41:24.956287 12052 solver.cpp:258]     Train net output #0: landmark_loss = 0.0407349 (* 1 = 0.0407349 loss)
I0820 10:41:24.956293 12052 sgd_solver.cpp:112] Iteration 77800, lr = 0.001
I0820 10:41:29.672276 12052 solver.cpp:239] Iteration 77900 (21.2047 iter/s, 4.71593s/100 iters), loss = 0.0377428
I0820 10:41:29.672318 12052 solver.cpp:258]     Train net output #0: landmark_loss = 0.0377428 (* 1 = 0.0377428 loss)
I0820 10:41:29.672324 12052 sgd_solver.cpp:112] Iteration 77900, lr = 0.001
I0820 10:41:34.326722 12052 solver.cpp:347] Iteration 78000, Testing net (#0)
I0820 10:41:54.405486 12052 solver.cpp:414]     Test net output #0: landmark_loss = 0.0251685 (* 1 = 0.0251685 loss)
I0820 10:41:54.452201 12052 solver.cpp:239] Iteration 78000 (4.03554 iter/s, 24.7798s/100 iters), loss = 0.0421604
I0820 10:41:54.452240 12052 solver.cpp:258]     Train net output #0: landmark_loss = 0.0421604 (* 1 = 0.0421604 loss)
I0820 10:41:54.452247 12052 sgd_solver.cpp:112] Iteration 78000, lr = 0.001
I0820 10:41:59.144263 12052 solver.cpp:239] Iteration 78100 (21.3131 iter/s, 4.69195s/100 iters), loss = 0.0408868
I0820 10:41:59.144316 12052 solver.cpp:258]     Train net output #0: landmark_loss = 0.0408868 (* 1 = 0.0408868 loss)
I0820 10:41:59.144322 12052 sgd_solver.cpp:112] Iteration 78100, lr = 0.001
I0820 10:42:03.874362 12052 solver.cpp:239] Iteration 78200 (21.1417 iter/s, 4.72998s/100 iters), loss = 0.04296
I0820 10:42:03.874415 12052 solver.cpp:258]     Train net output #0: landmark_loss = 0.04296 (* 1 = 0.04296 loss)
I0820 10:42:03.874421 12052 sgd_solver.cpp:112] Iteration 78200, lr = 0.001
I0820 10:42:08.567848 12052 solver.cpp:239] Iteration 78300 (21.3067 iter/s, 4.69337s/100 iters), loss = 0.0425075
I0820 10:42:08.567900 12052 solver.cpp:258]     Train net output #0: landmark_loss = 0.0425075 (* 1 = 0.0425075 loss)
I0820 10:42:08.567906 12052 sgd_solver.cpp:112] Iteration 78300, lr = 0.001
I0820 10:42:13.261108 12052 solver.cpp:239] Iteration 78400 (21.3077 iter/s, 4.69315s/100 iters), loss = 0.0401889
I0820 10:42:13.261162 12052 solver.cpp:258]     Train net output #0: landmark_loss = 0.0401889 (* 1 = 0.0401889 loss)
I0820 10:42:13.261168 12052 sgd_solver.cpp:112] Iteration 78400, lr = 0.001
I0820 10:42:17.952890 12052 solver.cpp:239] Iteration 78500 (21.3144 iter/s, 4.69166s/100 iters), loss = 0.0432823
I0820 10:42:17.952942 12052 solver.cpp:258]     Train net output #0: landmark_loss = 0.0432823 (* 1 = 0.0432823 loss)
I0820 10:42:17.952949 12052 sgd_solver.cpp:112] Iteration 78500, lr = 0.001
I0820 10:42:22.644454 12052 solver.cpp:239] Iteration 78600 (21.3154 iter/s, 4.69144s/100 iters), loss = 0.0413814
I0820 10:42:22.644506 12052 solver.cpp:258]     Train net output #0: landmark_loss = 0.0413814 (* 1 = 0.0413814 loss)
I0820 10:42:22.644512 12052 sgd_solver.cpp:112] Iteration 78600, lr = 0.001
I0820 10:42:27.336172 12052 solver.cpp:239] Iteration 78700 (21.3147 iter/s, 4.6916s/100 iters), loss = 0.0449662
I0820 10:42:27.336226 12052 solver.cpp:258]     Train net output #0: landmark_loss = 0.0449661 (* 1 = 0.0449661 loss)
I0820 10:42:27.336233 12052 sgd_solver.cpp:112] Iteration 78700, lr = 0.001
I0820 10:42:32.028431 12052 solver.cpp:239] Iteration 78800 (21.3122 iter/s, 4.69214s/100 iters), loss = 0.0393044
I0820 10:42:32.028496 12052 solver.cpp:258]     Train net output #0: landmark_loss = 0.0393043 (* 1 = 0.0393043 loss)
I0820 10:42:32.028501 12052 sgd_solver.cpp:112] Iteration 78800, lr = 0.001
I0820 10:42:36.720325 12052 solver.cpp:239] Iteration 78900 (21.3139 iter/s, 4.69177s/100 iters), loss = 0.0451537
I0820 10:42:36.720381 12052 solver.cpp:258]     Train net output #0: landmark_loss = 0.0451537 (* 1 = 0.0451537 loss)
I0820 10:42:36.720386 12052 sgd_solver.cpp:112] Iteration 78900, lr = 0.001
I0820 10:42:41.411043 12052 solver.cpp:239] Iteration 79000 (21.3192 iter/s, 4.6906s/100 iters), loss = 0.0497459
I0820 10:42:41.411096 12052 solver.cpp:258]     Train net output #0: landmark_loss = 0.0497459 (* 1 = 0.0497459 loss)
I0820 10:42:41.411103 12052 sgd_solver.cpp:112] Iteration 79000, lr = 0.001
I0820 10:42:46.103868 12052 solver.cpp:239] Iteration 79100 (21.3097 iter/s, 4.69271s/100 iters), loss = 0.0457874
I0820 10:42:46.103919 12052 solver.cpp:258]     Train net output #0: landmark_loss = 0.0457874 (* 1 = 0.0457874 loss)
I0820 10:42:46.103925 12052 sgd_solver.cpp:112] Iteration 79100, lr = 0.001
I0820 10:42:50.795222 12052 solver.cpp:239] Iteration 79200 (21.3163 iter/s, 4.69124s/100 iters), loss = 0.043135
I0820 10:42:50.795274 12052 solver.cpp:258]     Train net output #0: landmark_loss = 0.043135 (* 1 = 0.043135 loss)
I0820 10:42:50.795279 12052 sgd_solver.cpp:112] Iteration 79200, lr = 0.001
I0820 10:42:55.487020 12052 solver.cpp:239] Iteration 79300 (21.3143 iter/s, 4.69169s/100 iters), loss = 0.0418724
I0820 10:42:55.487073 12052 solver.cpp:258]     Train net output #0: landmark_loss = 0.0418723 (* 1 = 0.0418723 loss)
I0820 10:42:55.487080 12052 sgd_solver.cpp:112] Iteration 79300, lr = 0.001
I0820 10:43:00.189968 12052 solver.cpp:239] Iteration 79400 (21.2638 iter/s, 4.70283s/100 iters), loss = 0.0371693
I0820 10:43:00.190011 12052 solver.cpp:258]     Train net output #0: landmark_loss = 0.0371693 (* 1 = 0.0371693 loss)
I0820 10:43:00.190017 12052 sgd_solver.cpp:112] Iteration 79400, lr = 0.001
I0820 10:43:04.921578 12052 solver.cpp:239] Iteration 79500 (21.1352 iter/s, 4.73144s/100 iters), loss = 0.0495681
I0820 10:43:04.921622 12052 solver.cpp:258]     Train net output #0: landmark_loss = 0.0495681 (* 1 = 0.0495681 loss)
I0820 10:43:04.921627 12052 sgd_solver.cpp:112] Iteration 79500, lr = 0.001
I0820 10:43:09.631567 12052 solver.cpp:239] Iteration 79600 (21.232 iter/s, 4.70988s/100 iters), loss = 0.0357328
I0820 10:43:09.631618 12052 solver.cpp:258]     Train net output #0: landmark_loss = 0.0357328 (* 1 = 0.0357328 loss)
I0820 10:43:09.631624 12052 sgd_solver.cpp:112] Iteration 79600, lr = 0.001
I0820 10:43:14.328342 12052 solver.cpp:239] Iteration 79700 (21.2917 iter/s, 4.69666s/100 iters), loss = 0.0379925
I0820 10:43:14.328393 12052 solver.cpp:258]     Train net output #0: landmark_loss = 0.0379924 (* 1 = 0.0379924 loss)
I0820 10:43:14.328398 12052 sgd_solver.cpp:112] Iteration 79700, lr = 0.001
I0820 10:43:19.023836 12052 solver.cpp:239] Iteration 79800 (21.2975 iter/s, 4.69538s/100 iters), loss = 0.0454657
I0820 10:43:19.023888 12052 solver.cpp:258]     Train net output #0: landmark_loss = 0.0454656 (* 1 = 0.0454656 loss)
I0820 10:43:19.023895 12052 sgd_solver.cpp:112] Iteration 79800, lr = 0.001
I0820 10:43:23.719470 12052 solver.cpp:239] Iteration 79900 (21.2969 iter/s, 4.69552s/100 iters), loss = 0.0425324
I0820 10:43:23.719521 12052 solver.cpp:258]     Train net output #0: landmark_loss = 0.0425324 (* 1 = 0.0425324 loss)
I0820 10:43:23.719528 12052 sgd_solver.cpp:112] Iteration 79900, lr = 0.001
I0820 10:43:28.348184 12052 solver.cpp:464] Snapshotting to binary proto file ./model/M3_iter_80000.caffemodel
I0820 10:43:28.451066 12052 sgd_solver.cpp:284] Snapshotting solver state to binary proto file ./model/M3_iter_80000.solverstate
I0820 10:43:28.549724 12052 solver.cpp:239] Iteration 80000 (20.7033 iter/s, 4.83014s/100 iters), loss = 0.0533307
I0820 10:43:28.549774 12052 solver.cpp:258]     Train net output #0: landmark_loss = 0.0533307 (* 1 = 0.0533307 loss)
I0820 10:43:28.549780 12052 sgd_solver.cpp:112] Iteration 80000, lr = 0.001
I0820 10:43:33.246572 12052 solver.cpp:239] Iteration 80100 (21.2914 iter/s, 4.69673s/100 iters), loss = 0.045375
I0820 10:43:33.246623 12052 solver.cpp:258]     Train net output #0: landmark_loss = 0.045375 (* 1 = 0.045375 loss)
I0820 10:43:33.246630 12052 sgd_solver.cpp:112] Iteration 80100, lr = 0.001
I0820 10:43:37.943174 12052 solver.cpp:239] Iteration 80200 (21.2925 iter/s, 4.69649s/100 iters), loss = 0.0356287
I0820 10:43:37.943228 12052 solver.cpp:258]     Train net output #0: landmark_loss = 0.0356286 (* 1 = 0.0356286 loss)
I0820 10:43:37.943234 12052 sgd_solver.cpp:112] Iteration 80200, lr = 0.001
I0820 10:43:42.637570 12052 solver.cpp:239] Iteration 80300 (21.3025 iter/s, 4.69428s/100 iters), loss = 0.0435961
I0820 10:43:42.637624 12052 solver.cpp:258]     Train net output #0: landmark_loss = 0.043596 (* 1 = 0.043596 loss)
I0820 10:43:42.637629 12052 sgd_solver.cpp:112] Iteration 80300, lr = 0.001
I0820 10:43:47.333670 12052 solver.cpp:239] Iteration 80400 (21.2948 iter/s, 4.69598s/100 iters), loss = 0.0435327
I0820 10:43:47.333720 12052 solver.cpp:258]     Train net output #0: landmark_loss = 0.0435327 (* 1 = 0.0435327 loss)
I0820 10:43:47.333726 12052 sgd_solver.cpp:112] Iteration 80400, lr = 0.001
I0820 10:43:52.039824 12052 solver.cpp:239] Iteration 80500 (21.2493 iter/s, 4.70604s/100 iters), loss = 0.0424209
I0820 10:43:52.039875 12052 solver.cpp:258]     Train net output #0: landmark_loss = 0.0424209 (* 1 = 0.0424209 loss)
I0820 10:43:52.039881 12052 sgd_solver.cpp:112] Iteration 80500, lr = 0.001
I0820 10:43:56.749181 12052 solver.cpp:239] Iteration 80600 (21.2348 iter/s, 4.70925s/100 iters), loss = 0.0576409
I0820 10:43:56.749230 12052 solver.cpp:258]     Train net output #0: landmark_loss = 0.0576409 (* 1 = 0.0576409 loss)
I0820 10:43:56.749236 12052 sgd_solver.cpp:112] Iteration 80600, lr = 0.001
I0820 10:44:01.475494 12052 solver.cpp:239] Iteration 80700 (21.1587 iter/s, 4.7262s/100 iters), loss = 0.0480131
I0820 10:44:01.475533 12052 solver.cpp:258]     Train net output #0: landmark_loss = 0.0480131 (* 1 = 0.0480131 loss)
I0820 10:44:01.475538 12052 sgd_solver.cpp:112] Iteration 80700, lr = 0.001
I0820 10:44:06.185518 12052 solver.cpp:239] Iteration 80800 (21.2318 iter/s, 4.70992s/100 iters), loss = 0.047443
I0820 10:44:06.185570 12052 solver.cpp:258]     Train net output #0: landmark_loss = 0.0474429 (* 1 = 0.0474429 loss)
I0820 10:44:06.185576 12052 sgd_solver.cpp:112] Iteration 80800, lr = 0.001
I0820 10:44:10.878283 12052 solver.cpp:239] Iteration 80900 (21.3099 iter/s, 4.69265s/100 iters), loss = 0.0469976
I0820 10:44:10.878334 12052 solver.cpp:258]     Train net output #0: landmark_loss = 0.0469975 (* 1 = 0.0469975 loss)
I0820 10:44:10.878340 12052 sgd_solver.cpp:112] Iteration 80900, lr = 0.001
I0820 10:44:15.569576 12052 solver.cpp:239] Iteration 81000 (21.3166 iter/s, 4.69119s/100 iters), loss = 0.0437521
I0820 10:44:15.569628 12052 solver.cpp:258]     Train net output #0: landmark_loss = 0.0437521 (* 1 = 0.0437521 loss)
I0820 10:44:15.569633 12052 sgd_solver.cpp:112] Iteration 81000, lr = 0.001
I0820 10:44:20.261529 12052 solver.cpp:239] Iteration 81100 (21.3136 iter/s, 4.69184s/100 iters), loss = 0.0467863
I0820 10:44:20.261580 12052 solver.cpp:258]     Train net output #0: landmark_loss = 0.0467863 (* 1 = 0.0467863 loss)
I0820 10:44:20.261586 12052 sgd_solver.cpp:112] Iteration 81100, lr = 0.001
I0820 10:44:24.952085 12052 solver.cpp:239] Iteration 81200 (21.32 iter/s, 4.69044s/100 iters), loss = 0.0340843
I0820 10:44:24.952141 12052 solver.cpp:258]     Train net output #0: landmark_loss = 0.0340843 (* 1 = 0.0340843 loss)
I0820 10:44:24.952147 12052 sgd_solver.cpp:112] Iteration 81200, lr = 0.001
I0820 10:44:29.106127 12052 solver.cpp:239] Iteration 81300 (24.0736 iter/s, 4.15393s/100 iters), loss = 0.042537
I0820 10:44:29.106179 12052 solver.cpp:258]     Train net output #0: landmark_loss = 0.0425369 (* 1 = 0.0425369 loss)
I0820 10:44:29.106185 12052 sgd_solver.cpp:112] Iteration 81300, lr = 0.001
I0820 10:44:33.786501 12052 solver.cpp:239] Iteration 81400 (21.3663 iter/s, 4.68026s/100 iters), loss = 0.0476684
I0820 10:44:33.786552 12052 solver.cpp:258]     Train net output #0: landmark_loss = 0.0476684 (* 1 = 0.0476684 loss)
I0820 10:44:33.786558 12052 sgd_solver.cpp:112] Iteration 81400, lr = 0.001
I0820 10:44:38.460409 12052 solver.cpp:239] Iteration 81500 (21.3959 iter/s, 4.6738s/100 iters), loss = 0.0481693
I0820 10:44:38.460460 12052 solver.cpp:258]     Train net output #0: landmark_loss = 0.0481693 (* 1 = 0.0481693 loss)
I0820 10:44:38.460466 12052 sgd_solver.cpp:112] Iteration 81500, lr = 0.001
I0820 10:44:43.135915 12052 solver.cpp:239] Iteration 81600 (21.3886 iter/s, 4.6754s/100 iters), loss = 0.0534791
I0820 10:44:43.135967 12052 solver.cpp:258]     Train net output #0: landmark_loss = 0.053479 (* 1 = 0.053479 loss)
I0820 10:44:43.135972 12052 sgd_solver.cpp:112] Iteration 81600, lr = 0.001
I0820 10:44:47.811262 12052 solver.cpp:239] Iteration 81700 (21.3893 iter/s, 4.67524s/100 iters), loss = 0.0367607
I0820 10:44:47.811314 12052 solver.cpp:258]     Train net output #0: landmark_loss = 0.0367607 (* 1 = 0.0367607 loss)
I0820 10:44:47.811321 12052 sgd_solver.cpp:112] Iteration 81700, lr = 0.001
I0820 10:44:52.486918 12052 solver.cpp:239] Iteration 81800 (21.3879 iter/s, 4.67554s/100 iters), loss = 0.044226
I0820 10:44:52.486970 12052 solver.cpp:258]     Train net output #0: landmark_loss = 0.044226 (* 1 = 0.044226 loss)
I0820 10:44:52.486976 12052 sgd_solver.cpp:112] Iteration 81800, lr = 0.001
I0820 10:44:57.160953 12052 solver.cpp:239] Iteration 81900 (21.3953 iter/s, 4.67392s/100 iters), loss = 0.0470854
I0820 10:44:57.161005 12052 solver.cpp:258]     Train net output #0: landmark_loss = 0.0470854 (* 1 = 0.0470854 loss)
I0820 10:44:57.161011 12052 sgd_solver.cpp:112] Iteration 81900, lr = 0.001
I0820 10:45:01.876461 12052 solver.cpp:239] Iteration 82000 (21.2071 iter/s, 4.71539s/100 iters), loss = 0.0360841
I0820 10:45:01.876502 12052 solver.cpp:258]     Train net output #0: landmark_loss = 0.036084 (* 1 = 0.036084 loss)
I0820 10:45:01.876508 12052 sgd_solver.cpp:112] Iteration 82000, lr = 0.001
I0820 10:45:05.943183 12052 solver.cpp:239] Iteration 82100 (24.5905 iter/s, 4.06662s/100 iters), loss = 0.0501402
I0820 10:45:05.943226 12052 solver.cpp:258]     Train net output #0: landmark_loss = 0.0501401 (* 1 = 0.0501401 loss)
I0820 10:45:05.943233 12052 sgd_solver.cpp:112] Iteration 82100, lr = 0.001
I0820 10:45:10.592702 12052 solver.cpp:239] Iteration 82200 (21.5081 iter/s, 4.64941s/100 iters), loss = 0.0456994
I0820 10:45:10.592754 12052 solver.cpp:258]     Train net output #0: landmark_loss = 0.0456993 (* 1 = 0.0456993 loss)
I0820 10:45:10.592761 12052 sgd_solver.cpp:112] Iteration 82200, lr = 0.001
I0820 10:45:15.286828 12052 solver.cpp:239] Iteration 82300 (21.3037 iter/s, 4.69402s/100 iters), loss = 0.042827
I0820 10:45:15.286878 12052 solver.cpp:258]     Train net output #0: landmark_loss = 0.042827 (* 1 = 0.042827 loss)
I0820 10:45:15.286885 12052 sgd_solver.cpp:112] Iteration 82300, lr = 0.001
I0820 10:45:19.964591 12052 solver.cpp:239] Iteration 82400 (21.3782 iter/s, 4.67765s/100 iters), loss = 0.0450887
I0820 10:45:19.964642 12052 solver.cpp:258]     Train net output #0: landmark_loss = 0.0450887 (* 1 = 0.0450887 loss)
I0820 10:45:19.964648 12052 sgd_solver.cpp:112] Iteration 82400, lr = 0.001
I0820 10:45:24.947948 12052 solver.cpp:239] Iteration 82500 (20.0672 iter/s, 4.98325s/100 iters), loss = 0.0419839
I0820 10:45:24.947999 12052 solver.cpp:258]     Train net output #0: landmark_loss = 0.0419839 (* 1 = 0.0419839 loss)
I0820 10:45:24.948005 12052 sgd_solver.cpp:112] Iteration 82500, lr = 0.001
I0820 10:45:29.649997 12052 solver.cpp:239] Iteration 82600 (21.2679 iter/s, 4.70193s/100 iters), loss = 0.0334984
I0820 10:45:29.650049 12052 solver.cpp:258]     Train net output #0: landmark_loss = 0.0334983 (* 1 = 0.0334983 loss)
I0820 10:45:29.650056 12052 sgd_solver.cpp:112] Iteration 82600, lr = 0.001
I0820 10:45:34.357565 12052 solver.cpp:239] Iteration 82700 (21.2429 iter/s, 4.70746s/100 iters), loss = 0.0466807
I0820 10:45:34.357617 12052 solver.cpp:258]     Train net output #0: landmark_loss = 0.0466806 (* 1 = 0.0466806 loss)
I0820 10:45:34.357623 12052 sgd_solver.cpp:112] Iteration 82700, lr = 0.001
I0820 10:45:39.099211 12052 solver.cpp:239] Iteration 82800 (21.0902 iter/s, 4.74154s/100 iters), loss = 0.0490612
I0820 10:45:39.099262 12052 solver.cpp:258]     Train net output #0: landmark_loss = 0.0490612 (* 1 = 0.0490612 loss)
I0820 10:45:39.099268 12052 sgd_solver.cpp:112] Iteration 82800, lr = 0.001
I0820 10:45:43.841861 12052 solver.cpp:239] Iteration 82900 (21.0857 iter/s, 4.74254s/100 iters), loss = 0.0396557
I0820 10:45:43.841912 12052 solver.cpp:258]     Train net output #0: landmark_loss = 0.0396557 (* 1 = 0.0396557 loss)
I0820 10:45:43.841917 12052 sgd_solver.cpp:112] Iteration 82900, lr = 0.001
I0820 10:45:48.556350 12052 solver.cpp:239] Iteration 83000 (21.2117 iter/s, 4.71438s/100 iters), loss = 0.0445327
I0820 10:45:48.556402 12052 solver.cpp:258]     Train net output #0: landmark_loss = 0.0445326 (* 1 = 0.0445326 loss)
I0820 10:45:48.556408 12052 sgd_solver.cpp:112] Iteration 83000, lr = 0.001
I0820 10:45:53.260433 12052 solver.cpp:239] Iteration 83100 (21.2587 iter/s, 4.70397s/100 iters), loss = 0.0457668
I0820 10:45:53.260498 12052 solver.cpp:258]     Train net output #0: landmark_loss = 0.0457668 (* 1 = 0.0457668 loss)
I0820 10:45:53.260504 12052 sgd_solver.cpp:112] Iteration 83100, lr = 0.001
I0820 10:45:57.879916 12052 solver.cpp:239] Iteration 83200 (21.648 iter/s, 4.61936s/100 iters), loss = 0.0387319
I0820 10:45:57.879968 12052 solver.cpp:258]     Train net output #0: landmark_loss = 0.0387319 (* 1 = 0.0387319 loss)
I0820 10:45:57.879974 12052 sgd_solver.cpp:112] Iteration 83200, lr = 0.001
I0820 10:46:02.400118 12052 solver.cpp:239] Iteration 83300 (22.1235 iter/s, 4.52009s/100 iters), loss = 0.041013
I0820 10:46:02.400164 12052 solver.cpp:258]     Train net output #0: landmark_loss = 0.041013 (* 1 = 0.041013 loss)
I0820 10:46:02.400171 12052 sgd_solver.cpp:112] Iteration 83300, lr = 0.001
I0820 10:46:07.101958 12052 solver.cpp:239] Iteration 83400 (21.2688 iter/s, 4.70173s/100 iters), loss = 0.0427332
I0820 10:46:07.102010 12052 solver.cpp:258]     Train net output #0: landmark_loss = 0.0427331 (* 1 = 0.0427331 loss)
I0820 10:46:07.102016 12052 sgd_solver.cpp:112] Iteration 83400, lr = 0.001
I0820 10:46:11.796528 12052 solver.cpp:239] Iteration 83500 (21.3017 iter/s, 4.69446s/100 iters), loss = 0.0347111
I0820 10:46:11.796581 12052 solver.cpp:258]     Train net output #0: landmark_loss = 0.0347111 (* 1 = 0.0347111 loss)
I0820 10:46:11.796586 12052 sgd_solver.cpp:112] Iteration 83500, lr = 0.001
I0820 10:46:16.491637 12052 solver.cpp:239] Iteration 83600 (21.2993 iter/s, 4.695s/100 iters), loss = 0.050127
I0820 10:46:16.491688 12052 solver.cpp:258]     Train net output #0: landmark_loss = 0.050127 (* 1 = 0.050127 loss)
I0820 10:46:16.491694 12052 sgd_solver.cpp:112] Iteration 83600, lr = 0.001
I0820 10:46:21.189410 12052 solver.cpp:239] Iteration 83700 (21.2872 iter/s, 4.69766s/100 iters), loss = 0.0447794
I0820 10:46:21.189461 12052 solver.cpp:258]     Train net output #0: landmark_loss = 0.0447794 (* 1 = 0.0447794 loss)
I0820 10:46:21.189467 12052 sgd_solver.cpp:112] Iteration 83700, lr = 0.001
I0820 10:46:25.887328 12052 solver.cpp:239] Iteration 83800 (21.2865 iter/s, 4.69781s/100 iters), loss = 0.0376034
I0820 10:46:25.887379 12052 solver.cpp:258]     Train net output #0: landmark_loss = 0.0376033 (* 1 = 0.0376033 loss)
I0820 10:46:25.887385 12052 sgd_solver.cpp:112] Iteration 83800, lr = 0.001
I0820 10:46:30.584909 12052 solver.cpp:239] Iteration 83900 (21.2881 iter/s, 4.69747s/100 iters), loss = 0.0422027
I0820 10:46:30.584961 12052 solver.cpp:258]     Train net output #0: landmark_loss = 0.0422026 (* 1 = 0.0422026 loss)
I0820 10:46:30.584967 12052 sgd_solver.cpp:112] Iteration 83900, lr = 0.001
I0820 10:46:35.216789 12052 solver.cpp:347] Iteration 84000, Testing net (#0)
I0820 10:46:55.731714 12052 solver.cpp:414]     Test net output #0: landmark_loss = 0.0251541 (* 1 = 0.0251541 loss)
I0820 10:46:55.778203 12052 solver.cpp:239] Iteration 84000 (3.96933 iter/s, 25.1932s/100 iters), loss = 0.0441126
I0820 10:46:55.778244 12052 solver.cpp:258]     Train net output #0: landmark_loss = 0.0441125 (* 1 = 0.0441125 loss)
I0820 10:46:55.778250 12052 sgd_solver.cpp:112] Iteration 84000, lr = 0.001
I0820 10:47:00.494698 12052 solver.cpp:239] Iteration 84100 (21.2028 iter/s, 4.71637s/100 iters), loss = 0.0462902
I0820 10:47:00.494741 12052 solver.cpp:258]     Train net output #0: landmark_loss = 0.0462902 (* 1 = 0.0462902 loss)
I0820 10:47:00.494747 12052 sgd_solver.cpp:112] Iteration 84100, lr = 0.001
I0820 10:47:05.232362 12052 solver.cpp:239] Iteration 84200 (21.108 iter/s, 4.73755s/100 iters), loss = 0.0371496
I0820 10:47:05.232414 12052 solver.cpp:258]     Train net output #0: landmark_loss = 0.0371496 (* 1 = 0.0371496 loss)
I0820 10:47:05.232419 12052 sgd_solver.cpp:112] Iteration 84200, lr = 0.001
I0820 10:47:09.926059 12052 solver.cpp:239] Iteration 84300 (21.3057 iter/s, 4.69359s/100 iters), loss = 0.044575
I0820 10:47:09.926110 12052 solver.cpp:258]     Train net output #0: landmark_loss = 0.044575 (* 1 = 0.044575 loss)
I0820 10:47:09.926117 12052 sgd_solver.cpp:112] Iteration 84300, lr = 0.001
I0820 10:47:14.620733 12052 solver.cpp:239] Iteration 84400 (21.3012 iter/s, 4.69457s/100 iters), loss = 0.0542176
I0820 10:47:14.620785 12052 solver.cpp:258]     Train net output #0: landmark_loss = 0.0542175 (* 1 = 0.0542175 loss)
I0820 10:47:14.620791 12052 sgd_solver.cpp:112] Iteration 84400, lr = 0.001
I0820 10:47:19.314812 12052 solver.cpp:239] Iteration 84500 (21.3039 iter/s, 4.69397s/100 iters), loss = 0.0410259
I0820 10:47:19.314865 12052 solver.cpp:258]     Train net output #0: landmark_loss = 0.0410259 (* 1 = 0.0410259 loss)
I0820 10:47:19.314872 12052 sgd_solver.cpp:112] Iteration 84500, lr = 0.001
I0820 10:47:24.009837 12052 solver.cpp:239] Iteration 84600 (21.2997 iter/s, 4.69491s/100 iters), loss = 0.0416112
I0820 10:47:24.009889 12052 solver.cpp:258]     Train net output #0: landmark_loss = 0.0416111 (* 1 = 0.0416111 loss)
I0820 10:47:24.009896 12052 sgd_solver.cpp:112] Iteration 84600, lr = 0.001
I0820 10:47:28.704346 12052 solver.cpp:239] Iteration 84700 (21.302 iter/s, 4.6944s/100 iters), loss = 0.0426603
I0820 10:47:28.704397 12052 solver.cpp:258]     Train net output #0: landmark_loss = 0.0426603 (* 1 = 0.0426603 loss)
I0820 10:47:28.704403 12052 sgd_solver.cpp:112] Iteration 84700, lr = 0.001
I0820 10:47:33.399097 12052 solver.cpp:239] Iteration 84800 (21.3009 iter/s, 4.69464s/100 iters), loss = 0.0403494
I0820 10:47:33.399149 12052 solver.cpp:258]     Train net output #0: landmark_loss = 0.0403494 (* 1 = 0.0403494 loss)
I0820 10:47:33.399155 12052 sgd_solver.cpp:112] Iteration 84800, lr = 0.001
I0820 10:47:38.093202 12052 solver.cpp:239] Iteration 84900 (21.3038 iter/s, 4.69399s/100 iters), loss = 0.0416392
I0820 10:47:38.093253 12052 solver.cpp:258]     Train net output #0: landmark_loss = 0.0416392 (* 1 = 0.0416392 loss)
I0820 10:47:38.093259 12052 sgd_solver.cpp:112] Iteration 84900, lr = 0.001
I0820 10:47:42.787796 12052 solver.cpp:239] Iteration 85000 (21.3016 iter/s, 4.69448s/100 iters), loss = 0.0580462
I0820 10:47:42.787849 12052 solver.cpp:258]     Train net output #0: landmark_loss = 0.0580462 (* 1 = 0.0580462 loss)
I0820 10:47:42.787855 12052 sgd_solver.cpp:112] Iteration 85000, lr = 0.001
I0820 10:47:47.482867 12052 solver.cpp:239] Iteration 85100 (21.2995 iter/s, 4.69495s/100 iters), loss = 0.0397538
I0820 10:47:47.482918 12052 solver.cpp:258]     Train net output #0: landmark_loss = 0.0397538 (* 1 = 0.0397538 loss)
I0820 10:47:47.482924 12052 sgd_solver.cpp:112] Iteration 85100, lr = 0.001
I0820 10:47:52.178706 12052 solver.cpp:239] Iteration 85200 (21.2959 iter/s, 4.69573s/100 iters), loss = 0.0432454
I0820 10:47:52.178756 12052 solver.cpp:258]     Train net output #0: landmark_loss = 0.0432453 (* 1 = 0.0432453 loss)
I0820 10:47:52.178762 12052 sgd_solver.cpp:112] Iteration 85200, lr = 0.001
I0820 10:47:56.873020 12052 solver.cpp:239] Iteration 85300 (21.3029 iter/s, 4.69421s/100 iters), loss = 0.0458707
I0820 10:47:56.873071 12052 solver.cpp:258]     Train net output #0: landmark_loss = 0.0458707 (* 1 = 0.0458707 loss)
I0820 10:47:56.873077 12052 sgd_solver.cpp:112] Iteration 85300, lr = 0.001
I0820 10:48:01.594362 12052 solver.cpp:239] Iteration 85400 (21.1809 iter/s, 4.72123s/100 iters), loss = 0.0424462
I0820 10:48:01.594403 12052 solver.cpp:258]     Train net output #0: landmark_loss = 0.0424462 (* 1 = 0.0424462 loss)
I0820 10:48:01.594408 12052 sgd_solver.cpp:112] Iteration 85400, lr = 0.001
I0820 10:48:06.303020 12052 solver.cpp:239] Iteration 85500 (21.2379 iter/s, 4.70855s/100 iters), loss = 0.0343812
I0820 10:48:06.303071 12052 solver.cpp:258]     Train net output #0: landmark_loss = 0.0343812 (* 1 = 0.0343812 loss)
I0820 10:48:06.303077 12052 sgd_solver.cpp:112] Iteration 85500, lr = 0.001
I0820 10:48:11.002074 12052 solver.cpp:239] Iteration 85600 (21.2814 iter/s, 4.69894s/100 iters), loss = 0.0442743
I0820 10:48:11.002125 12052 solver.cpp:258]     Train net output #0: landmark_loss = 0.0442743 (* 1 = 0.0442743 loss)
I0820 10:48:11.002130 12052 sgd_solver.cpp:112] Iteration 85600, lr = 0.001
I0820 10:48:15.702523 12052 solver.cpp:239] Iteration 85700 (21.2751 iter/s, 4.70033s/100 iters), loss = 0.0481815
I0820 10:48:15.702574 12052 solver.cpp:258]     Train net output #0: landmark_loss = 0.0481815 (* 1 = 0.0481815 loss)
I0820 10:48:15.702580 12052 sgd_solver.cpp:112] Iteration 85700, lr = 0.001
I0820 10:48:20.403807 12052 solver.cpp:239] Iteration 85800 (21.2713 iter/s, 4.70118s/100 iters), loss = 0.0421311
I0820 10:48:20.403858 12052 solver.cpp:258]     Train net output #0: landmark_loss = 0.042131 (* 1 = 0.042131 loss)
I0820 10:48:20.403864 12052 sgd_solver.cpp:112] Iteration 85800, lr = 0.001
I0820 10:48:25.104583 12052 solver.cpp:239] Iteration 85900 (21.2736 iter/s, 4.70067s/100 iters), loss = 0.0379116
I0820 10:48:25.104635 12052 solver.cpp:258]     Train net output #0: landmark_loss = 0.0379116 (* 1 = 0.0379116 loss)
I0820 10:48:25.104641 12052 sgd_solver.cpp:112] Iteration 85900, lr = 0.001
I0820 10:48:29.796445 12052 solver.cpp:239] Iteration 86000 (21.314 iter/s, 4.69175s/100 iters), loss = 0.0454909
I0820 10:48:29.796496 12052 solver.cpp:258]     Train net output #0: landmark_loss = 0.0454909 (* 1 = 0.0454909 loss)
I0820 10:48:29.796502 12052 sgd_solver.cpp:112] Iteration 86000, lr = 0.001
I0820 10:48:34.486732 12052 solver.cpp:239] Iteration 86100 (21.3211 iter/s, 4.69018s/100 iters), loss = 0.043004
I0820 10:48:34.486784 12052 solver.cpp:258]     Train net output #0: landmark_loss = 0.043004 (* 1 = 0.043004 loss)
I0820 10:48:34.486790 12052 sgd_solver.cpp:112] Iteration 86100, lr = 0.001
I0820 10:48:39.175958 12052 solver.cpp:239] Iteration 86200 (21.326 iter/s, 4.68911s/100 iters), loss = 0.0472303
I0820 10:48:39.176009 12052 solver.cpp:258]     Train net output #0: landmark_loss = 0.0472303 (* 1 = 0.0472303 loss)
I0820 10:48:39.176015 12052 sgd_solver.cpp:112] Iteration 86200, lr = 0.001
I0820 10:48:43.865906 12052 solver.cpp:239] Iteration 86300 (21.3227 iter/s, 4.68983s/100 iters), loss = 0.0438869
I0820 10:48:43.865957 12052 solver.cpp:258]     Train net output #0: landmark_loss = 0.0438869 (* 1 = 0.0438869 loss)
I0820 10:48:43.865962 12052 sgd_solver.cpp:112] Iteration 86300, lr = 0.001
I0820 10:48:48.556104 12052 solver.cpp:239] Iteration 86400 (21.3216 iter/s, 4.69009s/100 iters), loss = 0.041383
I0820 10:48:48.556169 12052 solver.cpp:258]     Train net output #0: landmark_loss = 0.0413829 (* 1 = 0.0413829 loss)
I0820 10:48:48.556176 12052 sgd_solver.cpp:112] Iteration 86400, lr = 0.001
I0820 10:48:53.307979 12052 solver.cpp:239] Iteration 86500 (21.0448 iter/s, 4.75176s/100 iters), loss = 0.0683046
I0820 10:48:53.308029 12052 solver.cpp:258]     Train net output #0: landmark_loss = 0.0683045 (* 1 = 0.0683045 loss)
I0820 10:48:53.308035 12052 sgd_solver.cpp:112] Iteration 86500, lr = 0.001
I0820 10:48:58.094487 12052 solver.cpp:239] Iteration 86600 (20.8925 iter/s, 4.7864s/100 iters), loss = 0.0480166
I0820 10:48:58.094540 12052 solver.cpp:258]     Train net output #0: landmark_loss = 0.0480165 (* 1 = 0.0480165 loss)
I0820 10:48:58.094557 12052 sgd_solver.cpp:112] Iteration 86600, lr = 0.001
I0820 10:49:02.914484 12052 solver.cpp:239] Iteration 86700 (20.7474 iter/s, 4.81988s/100 iters), loss = 0.0515766
I0820 10:49:02.914526 12052 solver.cpp:258]     Train net output #0: landmark_loss = 0.0515765 (* 1 = 0.0515765 loss)
I0820 10:49:02.914532 12052 sgd_solver.cpp:112] Iteration 86700, lr = 0.001
I0820 10:49:07.704946 12052 solver.cpp:239] Iteration 86800 (20.8754 iter/s, 4.79032s/100 iters), loss = 0.0492158
I0820 10:49:07.704998 12052 solver.cpp:258]     Train net output #0: landmark_loss = 0.0492157 (* 1 = 0.0492157 loss)
I0820 10:49:07.705004 12052 sgd_solver.cpp:112] Iteration 86800, lr = 0.001
I0820 10:49:12.510136 12052 solver.cpp:239] Iteration 86900 (20.8113 iter/s, 4.80508s/100 iters), loss = 0.0483528
I0820 10:49:12.510179 12052 solver.cpp:258]     Train net output #0: landmark_loss = 0.0483527 (* 1 = 0.0483527 loss)
I0820 10:49:12.510185 12052 sgd_solver.cpp:112] Iteration 86900, lr = 0.001
I0820 10:49:17.309049 12052 solver.cpp:239] Iteration 87000 (20.8386 iter/s, 4.79879s/100 iters), loss = 0.0409175
I0820 10:49:17.309103 12052 solver.cpp:258]     Train net output #0: landmark_loss = 0.0409174 (* 1 = 0.0409174 loss)
I0820 10:49:17.309108 12052 sgd_solver.cpp:112] Iteration 87000, lr = 0.001
I0820 10:49:22.108357 12052 solver.cpp:239] Iteration 87100 (20.8368 iter/s, 4.7992s/100 iters), loss = 0.0419592
I0820 10:49:22.108398 12052 solver.cpp:258]     Train net output #0: landmark_loss = 0.0419591 (* 1 = 0.0419591 loss)
I0820 10:49:22.108405 12052 sgd_solver.cpp:112] Iteration 87100, lr = 0.001
I0820 10:49:26.906093 12052 solver.cpp:239] Iteration 87200 (20.8436 iter/s, 4.79763s/100 iters), loss = 0.0434602
I0820 10:49:26.906144 12052 solver.cpp:258]     Train net output #0: landmark_loss = 0.0434601 (* 1 = 0.0434601 loss)
I0820 10:49:26.906150 12052 sgd_solver.cpp:112] Iteration 87200, lr = 0.001
I0820 10:49:31.705752 12052 solver.cpp:239] Iteration 87300 (20.8353 iter/s, 4.79955s/100 iters), loss = 0.0511327
I0820 10:49:31.705806 12052 solver.cpp:258]     Train net output #0: landmark_loss = 0.0511326 (* 1 = 0.0511326 loss)
I0820 10:49:31.705811 12052 sgd_solver.cpp:112] Iteration 87300, lr = 0.001
I0820 10:49:36.504362 12052 solver.cpp:239] Iteration 87400 (20.8399 iter/s, 4.79849s/100 iters), loss = 0.0446617
I0820 10:49:36.504416 12052 solver.cpp:258]     Train net output #0: landmark_loss = 0.0446617 (* 1 = 0.0446617 loss)
I0820 10:49:36.504423 12052 sgd_solver.cpp:112] Iteration 87400, lr = 0.001
I0820 10:49:41.304060 12052 solver.cpp:239] Iteration 87500 (20.8352 iter/s, 4.79957s/100 iters), loss = 0.045001
I0820 10:49:41.304113 12052 solver.cpp:258]     Train net output #0: landmark_loss = 0.045001 (* 1 = 0.045001 loss)
I0820 10:49:41.304119 12052 sgd_solver.cpp:112] Iteration 87500, lr = 0.001
I0820 10:49:46.103667 12052 solver.cpp:239] Iteration 87600 (20.8355 iter/s, 4.7995s/100 iters), loss = 0.0437842
I0820 10:49:46.103719 12052 solver.cpp:258]     Train net output #0: landmark_loss = 0.0437841 (* 1 = 0.0437841 loss)
I0820 10:49:46.103725 12052 sgd_solver.cpp:112] Iteration 87600, lr = 0.001
I0820 10:49:50.902319 12052 solver.cpp:239] Iteration 87700 (20.8397 iter/s, 4.79854s/100 iters), loss = 0.0470903
I0820 10:49:50.902372 12052 solver.cpp:258]     Train net output #0: landmark_loss = 0.0470903 (* 1 = 0.0470903 loss)
I0820 10:49:50.902379 12052 sgd_solver.cpp:112] Iteration 87700, lr = 0.001
I0820 10:49:55.701097 12052 solver.cpp:239] Iteration 87800 (20.8392 iter/s, 4.79866s/100 iters), loss = 0.0373774
I0820 10:49:55.701148 12052 solver.cpp:258]     Train net output #0: landmark_loss = 0.0373774 (* 1 = 0.0373774 loss)
I0820 10:49:55.701154 12052 sgd_solver.cpp:112] Iteration 87800, lr = 0.001
I0820 10:50:00.524987 12052 solver.cpp:239] Iteration 87900 (20.7307 iter/s, 4.82377s/100 iters), loss = 0.0355571
I0820 10:50:00.525032 12052 solver.cpp:258]     Train net output #0: landmark_loss = 0.035557 (* 1 = 0.035557 loss)
I0820 10:50:00.525038 12052 sgd_solver.cpp:112] Iteration 87900, lr = 0.001
I0820 10:50:05.338194 12052 solver.cpp:239] Iteration 88000 (20.7767 iter/s, 4.81309s/100 iters), loss = 0.0451048
I0820 10:50:05.338248 12052 solver.cpp:258]     Train net output #0: landmark_loss = 0.0451047 (* 1 = 0.0451047 loss)
I0820 10:50:05.338253 12052 sgd_solver.cpp:112] Iteration 88000, lr = 0.001
I0820 10:50:10.137014 12052 solver.cpp:239] Iteration 88100 (20.8389 iter/s, 4.79871s/100 iters), loss = 0.0480655
I0820 10:50:10.137066 12052 solver.cpp:258]     Train net output #0: landmark_loss = 0.0480655 (* 1 = 0.0480655 loss)
I0820 10:50:10.137073 12052 sgd_solver.cpp:112] Iteration 88100, lr = 0.001
I0820 10:50:14.936092 12052 solver.cpp:239] Iteration 88200 (20.8378 iter/s, 4.79896s/100 iters), loss = 0.0450271
I0820 10:50:14.936147 12052 solver.cpp:258]     Train net output #0: landmark_loss = 0.0450271 (* 1 = 0.0450271 loss)
I0820 10:50:14.936154 12052 sgd_solver.cpp:112] Iteration 88200, lr = 0.001
I0820 10:50:19.736361 12052 solver.cpp:239] Iteration 88300 (20.8327 iter/s, 4.80016s/100 iters), loss = 0.0406995
I0820 10:50:19.736414 12052 solver.cpp:258]     Train net output #0: landmark_loss = 0.0406994 (* 1 = 0.0406994 loss)
I0820 10:50:19.736420 12052 sgd_solver.cpp:112] Iteration 88300, lr = 0.001
I0820 10:50:24.536140 12052 solver.cpp:239] Iteration 88400 (20.8348 iter/s, 4.79966s/100 iters), loss = 0.0443671
I0820 10:50:24.536192 12052 solver.cpp:258]     Train net output #0: landmark_loss = 0.0443671 (* 1 = 0.0443671 loss)
I0820 10:50:24.536200 12052 sgd_solver.cpp:112] Iteration 88400, lr = 0.001
I0820 10:50:29.337000 12052 solver.cpp:239] Iteration 88500 (20.8302 iter/s, 4.80071s/100 iters), loss = 0.0411231
I0820 10:50:29.337052 12052 solver.cpp:258]     Train net output #0: landmark_loss = 0.0411231 (* 1 = 0.0411231 loss)
I0820 10:50:29.337059 12052 sgd_solver.cpp:112] Iteration 88500, lr = 0.001
I0820 10:50:34.136405 12052 solver.cpp:239] Iteration 88600 (20.8364 iter/s, 4.79929s/100 iters), loss = 0.0389364
I0820 10:50:34.136456 12052 solver.cpp:258]     Train net output #0: landmark_loss = 0.0389363 (* 1 = 0.0389363 loss)
I0820 10:50:34.136462 12052 sgd_solver.cpp:112] Iteration 88600, lr = 0.001
I0820 10:50:38.936053 12052 solver.cpp:239] Iteration 88700 (20.8353 iter/s, 4.79954s/100 iters), loss = 0.0420634
I0820 10:50:38.936105 12052 solver.cpp:258]     Train net output #0: landmark_loss = 0.0420634 (* 1 = 0.0420634 loss)
I0820 10:50:38.936111 12052 sgd_solver.cpp:112] Iteration 88700, lr = 0.001
I0820 10:50:43.733855 12052 solver.cpp:239] Iteration 88800 (20.8434 iter/s, 4.79769s/100 iters), loss = 0.0404739
I0820 10:50:43.733908 12052 solver.cpp:258]     Train net output #0: landmark_loss = 0.0404739 (* 1 = 0.0404739 loss)
I0820 10:50:43.733914 12052 sgd_solver.cpp:112] Iteration 88800, lr = 0.001
I0820 10:50:48.533892 12052 solver.cpp:239] Iteration 88900 (20.8336 iter/s, 4.79993s/100 iters), loss = 0.0445949
I0820 10:50:48.533943 12052 solver.cpp:258]     Train net output #0: landmark_loss = 0.0445949 (* 1 = 0.0445949 loss)
I0820 10:50:48.533949 12052 sgd_solver.cpp:112] Iteration 88900, lr = 0.001
I0820 10:50:53.331892 12052 solver.cpp:239] Iteration 89000 (20.8425 iter/s, 4.79788s/100 iters), loss = 0.0376827
I0820 10:50:53.331946 12052 solver.cpp:258]     Train net output #0: landmark_loss = 0.0376826 (* 1 = 0.0376826 loss)
I0820 10:50:53.331952 12052 sgd_solver.cpp:112] Iteration 89000, lr = 0.001
I0820 10:50:58.095556 12052 solver.cpp:239] Iteration 89100 (20.9927 iter/s, 4.76355s/100 iters), loss = 0.0320026
I0820 10:50:58.095607 12052 solver.cpp:258]     Train net output #0: landmark_loss = 0.0320025 (* 1 = 0.0320025 loss)
I0820 10:50:58.095613 12052 sgd_solver.cpp:112] Iteration 89100, lr = 0.001
I0820 10:51:02.839918 12052 solver.cpp:239] Iteration 89200 (21.0781 iter/s, 4.74425s/100 iters), loss = 0.0375683
I0820 10:51:02.839962 12052 solver.cpp:258]     Train net output #0: landmark_loss = 0.0375683 (* 1 = 0.0375683 loss)
I0820 10:51:02.839967 12052 sgd_solver.cpp:112] Iteration 89200, lr = 0.001
I0820 10:51:07.579057 12052 solver.cpp:239] Iteration 89300 (21.1014 iter/s, 4.73903s/100 iters), loss = 0.0383864
I0820 10:51:07.579109 12052 solver.cpp:258]     Train net output #0: landmark_loss = 0.0383864 (* 1 = 0.0383864 loss)
I0820 10:51:07.579115 12052 sgd_solver.cpp:112] Iteration 89300, lr = 0.001
I0820 10:51:12.314678 12052 solver.cpp:239] Iteration 89400 (21.117 iter/s, 4.73551s/100 iters), loss = 0.0426776
I0820 10:51:12.314730 12052 solver.cpp:258]     Train net output #0: landmark_loss = 0.0426775 (* 1 = 0.0426775 loss)
I0820 10:51:12.314738 12052 sgd_solver.cpp:112] Iteration 89400, lr = 0.001
I0820 10:51:17.049633 12052 solver.cpp:239] Iteration 89500 (21.12 iter/s, 4.73485s/100 iters), loss = 0.0497022
I0820 10:51:17.049685 12052 solver.cpp:258]     Train net output #0: landmark_loss = 0.0497022 (* 1 = 0.0497022 loss)
I0820 10:51:17.049690 12052 sgd_solver.cpp:112] Iteration 89500, lr = 0.001
I0820 10:51:21.784765 12052 solver.cpp:239] Iteration 89600 (21.1192 iter/s, 4.73502s/100 iters), loss = 0.0427063
I0820 10:51:21.784818 12052 solver.cpp:258]     Train net output #0: landmark_loss = 0.0427063 (* 1 = 0.0427063 loss)
I0820 10:51:21.784824 12052 sgd_solver.cpp:112] Iteration 89600, lr = 0.001
I0820 10:51:26.464862 12052 solver.cpp:239] Iteration 89700 (21.3676 iter/s, 4.67999s/100 iters), loss = 0.0395151
I0820 10:51:26.464913 12052 solver.cpp:258]     Train net output #0: landmark_loss = 0.039515 (* 1 = 0.039515 loss)
I0820 10:51:26.464920 12052 sgd_solver.cpp:112] Iteration 89700, lr = 0.001
I0820 10:51:31.142333 12052 solver.cpp:239] Iteration 89800 (21.3796 iter/s, 4.67736s/100 iters), loss = 0.0395044
I0820 10:51:31.142383 12052 solver.cpp:258]     Train net output #0: landmark_loss = 0.0395043 (* 1 = 0.0395043 loss)
I0820 10:51:31.142390 12052 sgd_solver.cpp:112] Iteration 89800, lr = 0.001
I0820 10:51:35.819078 12052 solver.cpp:239] Iteration 89900 (21.3829 iter/s, 4.67664s/100 iters), loss = 0.0448462
I0820 10:51:35.819131 12052 solver.cpp:258]     Train net output #0: landmark_loss = 0.0448461 (* 1 = 0.0448461 loss)
I0820 10:51:35.819139 12052 sgd_solver.cpp:112] Iteration 89900, lr = 0.001
